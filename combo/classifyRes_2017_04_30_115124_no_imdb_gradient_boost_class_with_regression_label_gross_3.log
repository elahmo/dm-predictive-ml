#########################################
###Starting all estimators for cl: label_gross_3
#########################################

LogPol True
n_components
[193, 115, 57]
pw_lst
[{'pw': 1}]
####################################################################################
################# Runing the itteration 1  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [193, 115, 57], 'preprocessor__kw_args': [{'pw': 1}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__n_features_to_select': 193, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
Finished precomp pipline for {'reducer__n_features_to_select': 193, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
Starting precomp pipline for {'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
Finished precomp pipline for {'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
Starting precomp pipline for {'reducer__n_features_to_select': 57, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
Finished precomp pipline for {'reducer__n_features_to_select': 57, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}

LogPol True
n_components
[203, 121, 60]
pw_lst
[{'pw': 1}, {'pw': 2}]
####################################################################################
################# Runing the itteration 2  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [203, 121, 60], 'preprocessor__kw_args': [{'pw': 2}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__n_features_to_select': 203, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
Finished precomp pipline for {'reducer__n_features_to_select': 203, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
Starting precomp pipline for {'reducer__n_features_to_select': 121, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
Finished precomp pipline for {'reducer__n_features_to_select': 121, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
Starting precomp pipline for {'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
Finished precomp pipline for {'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}

LogPol True
n_components
[213, 127, 63]
pw_lst
[{'pw': 1}, {'pw': 2}, {'pw': 3}]
####################################################################################
################# Runing the itteration 3  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [213, 127, 63], 'preprocessor__kw_args': [{'pw': 3}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
Finished precomp pipline for {'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
Starting precomp pipline for {'reducer__n_features_to_select': 127, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
Finished precomp pipline for {'reducer__n_features_to_select': 127, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
Starting precomp pipline for {'reducer__n_features_to_select': 63, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
Finished precomp pipline for {'reducer__n_features_to_select': 63, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
####################################################################################
################# Runing the itteration 4  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'mean_fit_time': array([ 1.04511875]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-3.323228]), 'std_score_time': array([ 0.00362715]), 'params': ({},), 'split3_train_score': array([-3.28660159]), 'mean_test_score': array([-2.49792034]), 'std_train_score': array([ 0.96916873]), 'std_fit_time': array([ 0.304717]), 'split1_test_score': array([-1.72209892]), 'std_test_score': array([ 1.0072027]), 'split0_test_score': array([-1.29555822]), 'split3_test_score': array([-3.65079623]), 'split1_train_score': array([-1.47225765]), 'split0_train_score': array([-1.21460435]), 'mean_train_score': array([-2.30826188]), 'split2_train_score': array([-3.25958394]), 'mean_score_time': array([ 0.01076555])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.4979203448
####################################################################################
################# Runing the itteration 5  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'mean_fit_time': array([ 1.83312219]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.132419]), 'std_score_time': array([ 0.00157908]), 'params': ({},), 'split3_train_score': array([ 0.77737366]), 'mean_test_score': array([-0.21269252]), 'std_train_score': array([ 0.00264745]), 'std_fit_time': array([ 0.01939279]), 'split1_test_score': array([-0.15522809]), 'std_test_score': array([ 0.07196937]), 'split0_test_score': array([-0.30882403]), 'split3_test_score': array([-0.25429897]), 'split1_train_score': array([ 0.77536265]), 'split0_train_score': array([ 0.77628348]), 'mean_train_score': array([ 0.77781215]), 'split2_train_score': array([ 0.78222881]), 'mean_score_time': array([ 0.01349473])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.2126925193
####################################################################################
################# Runing the itteration 6  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'mean_fit_time': array([ 1.17397535]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.5511768]), 'std_score_time': array([ 0.00189438]), 'params': ({},), 'split3_train_score': array([ 0.9921036]), 'mean_test_score': array([-0.36483458]), 'std_train_score': array([ 0.00118496]), 'std_fit_time': array([ 0.08967526]), 'split1_test_score': array([-0.1883701]), 'std_test_score': array([ 0.12845152]), 'split0_test_score': array([-0.35329074]), 'split3_test_score': array([-0.36650069]), 'split1_train_score': array([ 0.99297703]), 'split0_train_score': array([ 0.990533]), 'mean_train_score': array([ 0.99141033]), 'split2_train_score': array([ 0.99002769]), 'mean_score_time': array([ 0.01159191])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.364834581798
####################################################################################
################# Runing the itteration 7  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'mean_fit_time': array([ 1.54446858]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.06778412]), 'std_score_time': array([ 0.00145008]), 'params': ({},), 'split3_train_score': array([ 0.21748623]), 'mean_test_score': array([-0.06009485]), 'std_train_score': array([ 0.01168406]), 'std_fit_time': array([ 0.04532983]), 'split1_test_score': array([-0.06290776]), 'std_test_score': array([ 0.00979324]), 'split0_test_score': array([-0.04341036]), 'split3_test_score': array([-0.06627714]), 'split1_train_score': array([ 0.19389304]), 'split0_train_score': array([ 0.1862305]), 'mean_train_score': array([ 0.19807369]), 'split2_train_score': array([ 0.19468496]), 'mean_score_time': array([ 0.0084002])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0600948453154
####################################################################################
################# Runing the itteration 8  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'mean_fit_time': array([ 1.90462404]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.17161168]), 'std_score_time': array([ 0.00304721]), 'params': ({},), 'split3_train_score': array([ 0.79077428]), 'mean_test_score': array([-0.19492227]), 'std_train_score': array([ 0.0119184]), 'std_fit_time': array([ 0.09251414]), 'split1_test_score': array([-0.20182198]), 'std_test_score': array([ 0.02962407]), 'split0_test_score': array([-0.16581353]), 'split3_test_score': array([-0.24044187]), 'split1_train_score': array([ 0.7965724]), 'split0_train_score': array([ 0.76564542]), 'mean_train_score': array([ 0.7828121]), 'split2_train_score': array([ 0.77825628]), 'mean_score_time': array([ 0.01096326])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.194922265062
####################################################################################
################# Runing the itteration 9  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'mean_fit_time': array([ 0.20210451]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.02967658]), 'std_score_time': array([ 0.01045436]), 'params': ({},), 'split3_train_score': array([ 0.03630867]), 'mean_test_score': array([-0.02226558]), 'std_train_score': array([ 0.00052309]), 'std_fit_time': array([ 0.00830009]), 'split1_test_score': array([-0.01800375]), 'std_test_score': array([ 0.00806973]), 'split0_test_score': array([-0.01114015]), 'split3_test_score': array([-0.03024183]), 'split1_train_score': array([ 0.0352473]), 'split0_train_score': array([ 0.03506941]), 'mean_train_score': array([ 0.03566976]), 'split2_train_score': array([ 0.03605368]), 'mean_score_time': array([ 0.03010583])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0222655798127
####################################################################################
################# Runing the itteration 10  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'mean_fit_time': array([ 0.31464607]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.09424451]), 'std_score_time': array([ 0.00097847]), 'params': ({},), 'split3_train_score': array([-0.08038353]), 'mean_test_score': array([-0.08872301]), 'std_train_score': array([ 0.00039088]), 'std_fit_time': array([ 0.09961422]), 'split1_test_score': array([-0.09058186]), 'std_test_score': array([ 0.00395792]), 'split0_test_score': array([-0.08417164]), 'split3_test_score': array([-0.085894]), 'split1_train_score': array([-0.07996743]), 'split0_train_score': array([-0.08033272]), 'mean_train_score': array([-0.08002212]), 'split2_train_score': array([-0.07940482]), 'mean_score_time': array([ 0.00409764])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0887230053634
####################################################################################
################# Runing the itteration 11  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [Lasso] estimatorrun are
{'mean_fit_time': array([ 1.90624756]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.86130035]), 'std_score_time': array([ 0.00911873]), 'params': ({},), 'split3_train_score': array([ 0.04684134]), 'mean_test_score': array([-2.69484391]), 'std_train_score': array([ 0.00246171]), 'std_fit_time': array([ 0.01679372]), 'split1_test_score': array([-0.07037127]), 'std_test_score': array([ 4.10116166]), 'split0_test_score': array([-0.07146006]), 'split3_test_score': array([-9.77624394]), 'split1_train_score': array([ 0.0454566]), 'split0_train_score': array([ 0.04754727]), 'mean_train_score': array([ 0.04526175]), 'split2_train_score': array([ 0.04120178]), 'mean_score_time': array([ 0.03361428])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.69484390518
####################################################################################
################# Runing the itteration 12  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'mean_fit_time': array([ 0.19086218]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.02351218]), 'std_score_time': array([ 0.00229128]), 'params': ({},), 'split3_train_score': array([ 0.03787669]), 'mean_test_score': array([-0.23976917]), 'std_train_score': array([ 0.0028893]), 'std_fit_time': array([ 0.04059671]), 'split1_test_score': array([-0.02571644]), 'std_test_score': array([ 0.35829051]), 'split0_test_score': array([-0.86009034]), 'split3_test_score': array([-0.04975773]), 'split1_train_score': array([ 0.0365155]), 'split0_train_score': array([ 0.04243891]), 'mean_train_score': array([ 0.03785815]), 'split2_train_score': array([ 0.03460151]), 'mean_score_time': array([ 0.00705397])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.239769171404
####################################################################################
################# Runing the itteration 13  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'mean_fit_time': array([ 0.18723637]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-105.58293673]), 'std_score_time': array([ 0.00198619]), 'params': ({},), 'split3_train_score': array([ 0.04372487]), 'mean_test_score': array([-49.01326897]), 'std_train_score': array([ 0.00186283]), 'std_fit_time': array([ 0.0408829]), 'split1_test_score': array([-0.06212794]), 'std_test_score': array([ 49.24818999]), 'split0_test_score': array([-0.0588266]), 'split3_test_score': array([-90.34918461]), 'split1_train_score': array([ 0.04338531]), 'split0_train_score': array([ 0.03905937]), 'mean_train_score': array([ 0.04188608]), 'split2_train_score': array([ 0.04137476]), 'mean_score_time': array([ 0.00436884])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-49.013268969
####################################################################################
################# Runing the itteration 14  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'mean_fit_time': array([ 0.04387569]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.27379456]), 'std_score_time': array([ 0.00509501]), 'params': ({},), 'split3_train_score': array([-0.28818436]), 'mean_test_score': array([-0.29280553]), 'std_train_score': array([ 0.00831075]), 'std_fit_time': array([ 0.01197425]), 'split1_test_score': array([-0.33302412]), 'std_test_score': array([ 0.02566529]), 'split0_test_score': array([-0.2675219]), 'split3_test_score': array([-0.29688153]), 'split1_train_score': array([-0.276624]), 'split0_train_score': array([-0.29799426]), 'mean_train_score': array([-0.28958874]), 'split2_train_score': array([-0.29555235]), 'mean_score_time': array([ 0.02182496])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292805525988
####################################################################################
################# Runing the itteration 15  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.1s
[CV]  ................................................................
[CV] ................................................. , total=   3.1s
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
GREP_ME***Results of [Ridge] estimatorrun are
{'mean_fit_time': array([ 3.15304416]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-1.05194836]), 'std_score_time': array([ 0.00581605]), 'params': ({},), 'split3_train_score': array([ 0.04092779]), 'mean_test_score': array([-0.37499171]), 'std_train_score': array([ 0.0028684]), 'std_fit_time': array([ 0.08104237]), 'split1_test_score': array([-0.06988077]), 'std_test_score': array([ 0.40497764]), 'split0_test_score': array([-0.32235414]), 'split3_test_score': array([-0.05578356]), 'split1_train_score': array([ 0.04483707]), 'split0_train_score': array([ 0.04873644]), 'mean_train_score': array([ 0.04438438]), 'split2_train_score': array([ 0.04303622]), 'mean_score_time': array([ 0.01052231])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.374991705352
####################################################################################
################# Runing the itteration 16  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'mean_fit_time': array([ 0.04102534]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-59411.04018634]), 'std_score_time': array([ 0.01000553]), 'params': ({},), 'split3_train_score': array([-1715913.26622582]), 'mean_test_score': array([-36967.24040406]), 'std_train_score': array([ 583591.58745603]), 'std_fit_time': array([ 0.00701781]), 'split1_test_score': array([-57255.82496714]), 'std_test_score': array([ 22058.53267864]), 'split0_test_score': array([-7921.97577511]), 'split3_test_score': array([-23280.12068764]), 'split1_train_score': array([-185497.03139171]), 'split0_train_score': array([-418496.48968859]), 'mean_train_score': array([-759163.269914]), 'split2_train_score': array([-716746.29234987]), 'mean_score_time': array([ 0.02978444])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-36967.2404041
####################################################################################
################# Runing the itteration 17  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'mean_fit_time': array([ 0.07520682]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.03258285]), 'std_score_time': array([ 0.00237381]), 'params': ({},), 'split3_train_score': array([ 0.01868991]), 'mean_test_score': array([-0.07862729]), 'std_train_score': array([ 0.00144913]), 'std_fit_time': array([ 0.01453608]), 'split1_test_score': array([-0.02936606]), 'std_test_score': array([ 0.08287793]), 'split0_test_score': array([-0.03039825]), 'split3_test_score': array([-0.22216199]), 'split1_train_score': array([ 0.01940997]), 'split0_train_score': array([ 0.01689082]), 'mean_train_score': array([ 0.01768262]), 'split2_train_score': array([ 0.01573978]), 'mean_score_time': array([ 0.00443965])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0786272880072
####################################################################################
################# Runing the itteration 18  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   6.0s
[CV]  ................................................................
[CV] ................................................. , total=   6.7s
[CV]  ................................................................
[CV] ................................................. , total=   7.0s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'mean_fit_time': array([ 6.62837631]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([ -1.08438699e+21]), 'std_score_time': array([ 0.00627434]), 'params': ({},), 'split3_train_score': array([ -4.57828474e+25]), 'mean_test_score': array([ -2.36909622e+25]), 'std_train_score': array([  2.58535650e+25]), 'std_fit_time': array([ 0.4103565]), 'split1_test_score': array([ -5.52370536e+25]), 'std_test_score': array([  2.43102484e+25]), 'split0_test_score': array([ -5.59218571e+22]), 'split3_test_score': array([ -3.94697891e+25]), 'split1_train_score': array([ -5.65620496e+25]), 'split0_train_score': array([ -5.97349969e+22]), 'mean_train_score': array([ -2.56013225e+25]), 'split2_train_score': array([ -6.57908223e+20]), 'mean_score_time': array([ 0.01901621])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.36909622326e+25
####################################################################################
################# Runing the itteration 19  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'mean_fit_time': array([ 0.04884112]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.27896633]), 'std_score_time': array([ 0.08924366]), 'params': ({},), 'split3_train_score': array([ 0.19285335]), 'mean_test_score': array([-0.23001845]), 'std_train_score': array([ 0.00886872]), 'std_fit_time': array([ 0.00137123]), 'split1_test_score': array([-0.19405048]), 'std_test_score': array([ 0.03631939]), 'split0_test_score': array([-0.25093802]), 'split3_test_score': array([-0.19611896]), 'split1_train_score': array([ 0.20811163]), 'split0_train_score': array([ 0.18341388]), 'mean_train_score': array([ 0.19536916]), 'split2_train_score': array([ 0.1970978]), 'mean_score_time': array([ 1.00046211])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.230018445274
####################################################################################
################# Runing the itteration 20  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=3649    1
1348    2
909     2
3958    1
2072    ...  1
2549    2
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.4979203448038829}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.21269251930012895}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.022265579812708214}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.36483458179826944}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.060094845315392609}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.088723005363352203}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.23001844527384901}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.694843905180115}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.23976917140447365}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -49.013268968994772}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.40175022, -0.39154775, -0.33991442, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 3649    1
1348    2
909     2
3958    1
2072    ...  1
2549    2
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.4979203448038829}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.21269251930012895}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.022265579812708214}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.36483458179826944}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.060094845315392609}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.088723005363352203}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.23001844527384901}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.694843905180115}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.23976917140447365}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -49.013268968994772}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=866     145443360
3160     11000000
1401     791...     12592907
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.4979203448038829}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.21269251930012895}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.022265579812708214}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.36483458179826944}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.060094845315392609}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.088723005363352203}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.23001844527384901}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.694843905180115}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.23976917140447365}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -49.013268968994772}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 866     145443360
3160     11000000
1401     791...     12592907
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=866     145443360
3160     11000000
1401     791...     12592907
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 866     145443360
3160     11000000
1401     791...     12592907
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=866     145443360
3160     11000000
1401     791...     12592907
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 11:55:46 2017
PID: 32670                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], 866     145443360
3160     11000000
1401     791...     12592907
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], 866     145443360
3160     11000000
1401     791...     12592907
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=866     145443360
3160     11000000
1401     791...     12592907
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], y_test=866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], 866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], 866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], 866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], 866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], y=866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y = 866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], y=866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64, y_pred=array([             nan,   1.39015628e+08,      ...        nan,              nan,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 866     145443360
3160     11000000
1401     791...     98963392
Name: worldwide_gross, dtype: int64
        y_pred = array([             nan,   1.39015628e+08,      ...        nan,              nan,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([145443360,  11000000,  79114085, ...,         0,   4420000,
        98963392]), y_pred=array([             nan,   1.39015628e+08,      ...        nan,              nan,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([             nan,   1.39015628e+08,      ...        nan,              nan,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([             nan,   1.39015628e+08,      ...        nan,              nan,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([             nan,   1.39015628e+08,      ...        nan,              nan,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([             nan,   1.39015628e+08,      ...        nan,              nan,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 21  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.0min
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
[CV]  ................................................................
[CV] ................................................. , total= 1.2min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'mean_fit_time': array([ 66.94697171]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.35782117]), 'std_score_time': array([ 0.01709773]), 'params': ({},), 'split3_train_score': array([-0.27718851]), 'mean_test_score': array([-0.29918333]), 'std_train_score': array([ 0.01606667]), 'std_fit_time': array([ 2.78235212]), 'split1_test_score': array([-0.26420059]), 'std_test_score': array([ 0.04856763]), 'split0_test_score': array([-0.23995699]), 'split3_test_score': array([-0.33475456]), 'split1_train_score': array([-0.2991917]), 'split0_train_score': array([-0.31247878]), 'mean_train_score': array([-0.29053315]), 'split2_train_score': array([-0.27327362]), 'mean_score_time': array([ 0.02992457])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.299183327624
####################################################################################
################# Runing the itteration 22  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'mean_fit_time': array([ 4.14246255]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.11950624]), 'std_score_time': array([ 0.03685371]), 'params': ({},), 'split3_train_score': array([-0.13031096]), 'mean_test_score': array([-0.13298819]), 'std_train_score': array([ 0.00471744]), 'std_fit_time': array([ 0.11560617]), 'split1_test_score': array([-0.13477545]), 'std_test_score': array([ 0.00893752]), 'split0_test_score': array([-0.13308328]), 'split3_test_score': array([-0.1445878]), 'split1_train_score': array([-0.12775173]), 'split0_train_score': array([-0.12982965]), 'mean_train_score': array([-0.13196386]), 'split2_train_score': array([-0.13996311]), 'mean_score_time': array([ 1.20041883])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132988192721
####################################################################################
################# Runing the itteration 23  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'mean_fit_time': array([ 0.03083652]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.3208376]), 'std_score_time': array([ 0.03244085]), 'params': ({},), 'split3_train_score': array([-0.29989081]), 'mean_test_score': array([-0.29467666]), 'std_train_score': array([ 0.00612911]), 'std_fit_time': array([ 0.00109392]), 'split1_test_score': array([-0.30399489]), 'std_test_score': array([ 0.02169175]), 'split0_test_score': array([-0.29245351]), 'split3_test_score': array([-0.26142065]), 'split1_train_score': array([-0.28478661]), 'split0_train_score': array([-0.29026015]), 'mean_train_score': array([-0.28997964]), 'split2_train_score': array([-0.28498098]), 'mean_score_time': array([ 0.039253])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.294676662514
####################################################################################
################# Runing the itteration 24  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.6s
GREP_ME***Results of [NuSVR] estimatorrun are
{'mean_fit_time': array([ 2.94636929]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.06979768]), 'std_score_time': array([ 0.00745388]), 'params': ({},), 'split3_train_score': array([-0.05266435]), 'mean_test_score': array([-0.05240967]), 'std_train_score': array([ 0.00153063]), 'std_fit_time': array([ 0.071454]), 'split1_test_score': array([-0.04097053]), 'std_test_score': array([ 0.01072981]), 'split0_test_score': array([-0.04724162]), 'split3_test_score': array([-0.05162884]), 'split1_train_score': array([-0.05428091]), 'split0_train_score': array([-0.04999629]), 'mean_train_score': array([-0.05233972]), 'split2_train_score': array([-0.05241731]), 'mean_score_time': array([ 0.56745166])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0524096666161
####################################################################################
################# Runing the itteration 25  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'mean_fit_time': array([ 0.32716256]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.92484785]), 'std_score_time': array([ 0.00091564]), 'params': ({},), 'split3_train_score': array([ 0.98766117]), 'mean_test_score': array([-1.18691128]), 'std_train_score': array([ 0.00229881]), 'std_fit_time': array([ 0.03043754]), 'split1_test_score': array([-0.81849514]), 'std_test_score': array([ 0.34336199]), 'split0_test_score': array([-1.68712388]), 'split3_test_score': array([-1.31717827]), 'split1_train_score': array([ 0.99291728]), 'split0_train_score': array([ 0.9910604]), 'mean_train_score': array([ 0.99130612]), 'split2_train_score': array([ 0.99358563]), 'mean_score_time': array([ 0.0031172])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.18691128499
####################################################################################
################# Runing the itteration 26  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'mean_fit_time': array([ 0.1328671]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-2.1293045]), 'std_score_time': array([ 0.0001321]), 'params': ({},), 'split3_train_score': array([ 0.98597738]), 'mean_test_score': array([-1.33384677]), 'std_train_score': array([ 0.00448382]), 'std_fit_time': array([ 0.00531208]), 'split1_test_score': array([-0.73696386]), 'std_test_score': array([ 0.51241199]), 'split0_test_score': array([-1.37865309]), 'split3_test_score': array([-1.09046564]), 'split1_train_score': array([ 0.99506474]), 'split0_train_score': array([ 0.99703218]), 'mean_train_score': array([ 0.99173988]), 'split2_train_score': array([ 0.9888852]), 'mean_score_time': array([ 0.0023542])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 213, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.33384677199
####################################################################################
################# Runing the itteration 27  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'mean_fit_time': array([ 0.67178005]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-2.9279606]), 'std_score_time': array([ 0.0024436]), 'params': ({},), 'split3_train_score': array([-0.75901597]), 'mean_test_score': array([-3.21286323]), 'std_train_score': array([ 1.1343077]), 'std_fit_time': array([ 0.20851771]), 'split1_test_score': array([-2.91827913]), 'std_test_score': array([ 1.96837612]), 'split0_test_score': array([-6.25598329]), 'split3_test_score': array([-0.74922992]), 'split1_train_score': array([-3.12353721]), 'split0_train_score': array([-3.6497092]), 'mean_train_score': array([-2.69453559]), 'split2_train_score': array([-3.24587998]), 'mean_score_time': array([ 0.00768977])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3.21286323492
####################################################################################
################# Runing the itteration 28  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'mean_fit_time': array([ 0.89812034]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.21119819]), 'std_score_time': array([  3.62119679e-05]), 'params': ({},), 'split3_train_score': array([ 0.78174038]), 'mean_test_score': array([-0.21410082]), 'std_train_score': array([ 0.00150959]), 'std_fit_time': array([ 0.05330221]), 'split1_test_score': array([-0.23647972]), 'std_test_score': array([ 0.02052343]), 'split0_test_score': array([-0.22656562]), 'split3_test_score': array([-0.18215973]), 'split1_train_score': array([ 0.7818892]), 'split0_train_score': array([ 0.78518259]), 'mean_train_score': array([ 0.78329598]), 'split2_train_score': array([ 0.78437174]), 'mean_score_time': array([ 0.00652635])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.21410081525
####################################################################################
################# Runing the itteration 29  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'mean_fit_time': array([ 0.37675291]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.318995]), 'std_score_time': array([ 0.0009372]), 'params': ({},), 'split3_train_score': array([ 0.99025412]), 'mean_test_score': array([-0.27222145]), 'std_train_score': array([ 0.0022894]), 'std_fit_time': array([ 0.0153571]), 'split1_test_score': array([-0.29952787]), 'std_test_score': array([ 0.03883994]), 'split0_test_score': array([-0.24853876]), 'split3_test_score': array([-0.22182415]), 'split1_train_score': array([ 0.99322832]), 'split0_train_score': array([ 0.98886801]), 'mean_train_score': array([ 0.9917426]), 'split2_train_score': array([ 0.99461996]), 'mean_score_time': array([ 0.00711107])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.27222144697
####################################################################################
################# Runing the itteration 30  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'mean_fit_time': array([ 0.72229362]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.05752168]), 'std_score_time': array([ 0.00011934]), 'params': ({},), 'split3_train_score': array([ 0.20443498]), 'mean_test_score': array([-0.05587193]), 'std_train_score': array([ 0.0292774]), 'std_fit_time': array([ 0.03973229]), 'split1_test_score': array([-0.06798106]), 'std_test_score': array([ 0.00881518]), 'split0_test_score': array([-0.04321218]), 'split3_test_score': array([-0.0547728]), 'split1_train_score': array([ 0.27486418]), 'split0_train_score': array([ 0.20202481]), 'mean_train_score': array([ 0.22647681]), 'split2_train_score': array([ 0.22458327]), 'mean_score_time': array([ 0.00338829])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.055871932185
####################################################################################
################# Runing the itteration 31  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'mean_fit_time': array([ 0.84627038]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.13304896]), 'std_score_time': array([ 0.00031753]), 'params': ({},), 'split3_train_score': array([ 0.74912375]), 'mean_test_score': array([-0.19568257]), 'std_train_score': array([ 0.01288565]), 'std_fit_time': array([ 0.01482155]), 'split1_test_score': array([-0.20652218]), 'std_test_score': array([ 0.04959679]), 'split0_test_score': array([-0.26878969]), 'split3_test_score': array([-0.17436943]), 'split1_train_score': array([ 0.78186486]), 'split0_train_score': array([ 0.77926489]), 'mean_train_score': array([ 0.76970254]), 'split2_train_score': array([ 0.76855665]), 'mean_score_time': array([ 0.00567937])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.195682565441
####################################################################################
################# Runing the itteration 32  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'mean_fit_time': array([ 0.04809463]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.00147687]), 'std_score_time': array([ 0.01337679]), 'params': ({},), 'split3_train_score': array([ 0.0109731]), 'mean_test_score': array([-0.00998738]), 'std_train_score': array([ 0.00176957]), 'std_fit_time': array([ 0.00099065]), 'split1_test_score': array([-0.01056498]), 'std_test_score': array([ 0.00582138]), 'split0_test_score': array([-0.00999621]), 'split3_test_score': array([-0.01791147]), 'split1_train_score': array([ 0.00909745]), 'split0_train_score': array([ 0.00836501]), 'mean_train_score': array([ 0.008617]), 'split2_train_score': array([ 0.00603244]), 'mean_score_time': array([ 0.02026343])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.00998738235528
####################################################################################
################# Runing the itteration 33  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'mean_fit_time': array([ 0.16353488]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.09598539]), 'std_score_time': array([ 0.00051009]), 'params': ({},), 'split3_train_score': array([-0.08472461]), 'mean_test_score': array([-0.08731139]), 'std_train_score': array([ 0.00107406]), 'std_fit_time': array([ 0.0796773]), 'split1_test_score': array([-0.08533608]), 'std_test_score': array([ 0.00542667]), 'split0_test_score': array([-0.08111436]), 'split3_test_score': array([-0.08680972]), 'split1_train_score': array([-0.08652569]), 'split0_train_score': array([-0.0843711]), 'mean_train_score': array([-0.08560963]), 'split2_train_score': array([-0.08681712]), 'mean_score_time': array([ 0.00383639])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0873113865057
####################################################################################
################# Runing the itteration 34  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'mean_fit_time': array([ 0.53455448]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.03885987]), 'std_score_time': array([ 0.01170942]), 'params': ({},), 'split3_train_score': array([ 0.01543381]), 'mean_test_score': array([-0.02557454]), 'std_train_score': array([ 0.00171814]), 'std_fit_time': array([ 0.00278596]), 'split1_test_score': array([-0.01903866]), 'std_test_score': array([ 0.00803526]), 'split0_test_score': array([-0.02505167]), 'split3_test_score': array([-0.01934795]), 'split1_train_score': array([ 0.01155531]), 'split0_train_score': array([ 0.0135428]), 'mean_train_score': array([ 0.01291307]), 'split2_train_score': array([ 0.01112036]), 'mean_score_time': array([ 0.02818763])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0255745370272
####################################################################################
################# Runing the itteration 35  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'mean_fit_time': array([ 0.07941049]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.00634193]), 'std_score_time': array([ 0.00099235]), 'params': ({},), 'split3_train_score': array([ 0.00806157]), 'mean_test_score': array([-0.01282844]), 'std_train_score': array([ 0.00095491]), 'std_fit_time': array([ 0.04196421]), 'split1_test_score': array([-0.0094681]), 'std_test_score': array([ 0.01061025]), 'split0_test_score': array([-0.03095153]), 'split3_test_score': array([-0.0045522]), 'split1_train_score': array([ 0.00917027]), 'split0_train_score': array([ 0.01037247]), 'mean_train_score': array([ 0.0094866]), 'split2_train_score': array([ 0.01034209]), 'mean_score_time': array([ 0.00301933])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0128284401793
####################################################################################
################# Runing the itteration 36  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'mean_fit_time': array([ 0.07343471]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.02266279]), 'std_score_time': array([ 0.00410855]), 'params': ({},), 'split3_train_score': array([ 0.01390667]), 'mean_test_score': array([-0.02168892]), 'std_train_score': array([ 0.00125304]), 'std_fit_time': array([ 0.0207407]), 'split1_test_score': array([-0.01995942]), 'std_test_score': array([ 0.00376219]), 'split0_test_score': array([-0.01694856]), 'split3_test_score': array([-0.02718489]), 'split1_train_score': array([ 0.01247802]), 'split0_train_score': array([ 0.01039078]), 'mean_train_score': array([ 0.01230631]), 'split2_train_score': array([ 0.01244977]), 'mean_score_time': array([ 0.00449091])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0216889164596
####################################################################################
################# Runing the itteration 37  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'mean_fit_time': array([ 0.01804531]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.28718399]), 'std_score_time': array([ 0.00747277]), 'params': ({},), 'split3_train_score': array([-0.28619021]), 'mean_test_score': array([-0.29582895]), 'std_train_score': array([ 0.00792109]), 'std_fit_time': array([ 0.00041568]), 'split1_test_score': array([-0.26444703]), 'std_test_score': array([ 0.02311631]), 'split0_test_score': array([-0.32760716]), 'split3_test_score': array([-0.30407762]), 'split1_train_score': array([-0.30229948]), 'split0_train_score': array([-0.28078354]), 'mean_train_score': array([-0.28994384]), 'split2_train_score': array([-0.29050213]), 'mean_score_time': array([ 0.01415163])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29582894995
####################################################################################
################# Runing the itteration 38  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [Ridge] estimatorrun are
{'mean_fit_time': array([ 0.84566426]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.00875457]), 'std_score_time': array([ 0.00220817]), 'params': ({},), 'split3_train_score': array([ 0.01071608]), 'mean_test_score': array([-0.05604876]), 'std_train_score': array([ 0.00081886]), 'std_fit_time': array([ 0.03831414]), 'split1_test_score': array([-0.10236777]), 'std_test_score': array([ 0.04513609]), 'split0_test_score': array([-0.0131405]), 'split3_test_score': array([-0.0999322]), 'split1_train_score': array([ 0.01245689]), 'split0_train_score': array([ 0.01202763]), 'mean_train_score': array([ 0.01202752]), 'split2_train_score': array([ 0.01290949]), 'mean_score_time': array([ 0.00574601])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0560487568539
####################################################################################
################# Runing the itteration 39  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'mean_fit_time': array([ 0.02107191]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.02681105]), 'std_score_time': array([ 0.01680499]), 'params': ({},), 'split3_train_score': array([-39851.98222149]), 'mean_test_score': array([-27819.39392105]), 'std_train_score': array([ 305333.2102948]), 'std_fit_time': array([ 0.00219694]), 'split1_test_score': array([-108381.38791564]), 'std_test_score': array([ 46517.9337993]), 'split0_test_score': array([-887.61116801]), 'split3_test_score': array([-2008.5497895]), 'split1_train_score': array([-741285.80413293]), 'split0_train_score': array([-77029.92947522]), 'mean_train_score': array([-214541.92870814]), 'split2_train_score': array([ 0.0009971]), 'mean_score_time': array([ 0.0229339])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-27819.393921
####################################################################################
################# Runing the itteration 40  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'mean_fit_time': array([ 0.03367203]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.00689071]), 'std_score_time': array([ 0.00637236]), 'params': ({},), 'split3_train_score': array([ 0.00491499]), 'mean_test_score': array([-0.00562495]), 'std_train_score': array([ 0.00020497]), 'std_fit_time': array([ 0.00614444]), 'split1_test_score': array([-0.00259143]), 'std_test_score': array([ 0.00247648]), 'split0_test_score': array([-0.0089751]), 'split3_test_score': array([-0.00404256]), 'split1_train_score': array([ 0.004629]), 'split0_train_score': array([ 0.00478976]), 'mean_train_score': array([ 0.00467506]), 'split2_train_score': array([ 0.00436651]), 'mean_score_time': array([ 0.0081495])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.00562495131964
####################################################################################
################# Runing the itteration 41  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'mean_fit_time': array([ 0.54034907]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([ -1.02840735e+23]), 'std_score_time': array([ 0.0002421]), 'params': ({},), 'split3_train_score': array([ -2.39644091e+24]), 'mean_test_score': array([ -9.63245780e+23]), 'std_train_score': array([  9.57664886e+23]), 'std_fit_time': array([ 0.14528361]), 'split1_test_score': array([-9.22559749]), 'std_test_score': array([  1.25340495e+24]), 'split0_test_score': array([ -6.59936344e+23]), 'split3_test_score': array([ -3.09020604e+24]), 'split1_train_score': array([-15.07646735]), 'split0_train_score': array([ -6.71342553e+23]), 'mean_train_score': array([ -7.96770672e+23]), 'split2_train_score': array([ -1.19299230e+23]), 'mean_score_time': array([ 0.00161654])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-9.63245779709e+23
####################################################################################
################# Runing the itteration 42  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'mean_fit_time': array([ 0.02285093]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.35881614]), 'std_score_time': array([ 0.03600284]), 'params': ({},), 'split3_train_score': array([ 0.19530889]), 'mean_test_score': array([-0.22917627]), 'std_train_score': array([ 0.00461693]), 'std_fit_time': array([ 0.00068496]), 'split1_test_score': array([-0.18883798]), 'std_test_score': array([ 0.07811174]), 'split0_test_score': array([-0.15302376]), 'split3_test_score': array([-0.21602721]), 'split1_train_score': array([ 0.19741686]), 'split0_train_score': array([ 0.19571642]), 'mean_train_score': array([ 0.19352118]), 'split2_train_score': array([ 0.18564255]), 'mean_score_time': array([ 0.33660716])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.229176273124
####################################################################################
################# Runing the itteration 43  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=3649    1
1348    2
909     2
3958    1
2072    ...  1
2549    2
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.4979203448038829}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.21269251930012895}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.1869112849860768}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.009987382355277628}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.3338467719878309}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.27222144697020978}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.055871932184997142}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.087311386505743327}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.22917627312444791}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.025574537027188038}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.40175022, -0.39154775, -0.33991442, .... -0.40589462,
         1.53050738, -0.86304212]])}
        y = 3649    1
1348    2
909     2
3958    1
2072    ...  1
2549    2
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.4979203448038829}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.21269251930012895}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.1869112849860768}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.009987382355277628}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.3338467719878309}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.27222144697020978}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.055871932184997142}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.087311386505743327}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.22917627312444791}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.025574537027188038}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], y=2070     40157856
2413     28649556
1924     470...     67312826
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.4979203448038829}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.21269251930012895}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.1869112849860768}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.009987382355277628}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.3338467719878309}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.27222144697020978}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.055871932184997142}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.087311386505743327}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.22917627312444791}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.025574537027188038}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns]
        y = 2070     40157856
2413     28649556
1924     470...     67312826
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], y=2070     40157856
2413     28649556
1924     470...     67312826
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns]
        y = 2070     40157856
2413     28649556
1924     470...     67312826
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], y=2070     40157856
2413     28649556
1924     470...     67312826
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 12:03:52 2017
PID: 1558                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], 2070     40157856
2413     28649556
1924     470...     67312826
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], 2070     40157856
2413     28649556
1924     470...     67312826
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], y=2070     40157856
2413     28649556
1924     470...     67312826
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns]
        y_test = 2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], y_test=2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns]
        y_test = 2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], y=2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns]
        y = 2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], y=2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64, y_pred=array([  7.44732959e+07,   1.56966005e+07,      ...4744607e+08,   6.40174292e+07,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 2070     40157856
2413     28649556
1924     470...    107597242
Name: worldwide_gross, dtype: int64
        y_pred = array([  7.44732959e+07,   1.56966005e+07,      ...4744607e+08,   6.40174292e+07,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 40157856,  28649556,  47011449, ...,  13800000,     56491,
       107597242]), y_pred=array([  7.44732959e+07,   1.56966005e+07,      ...4744607e+08,   6.40174292e+07,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  7.44732959e+07,   1.56966005e+07,      ...4744607e+08,   6.40174292e+07,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  7.44732959e+07,   1.56966005e+07,      ...4744607e+08,   6.40174292e+07,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  7.44732959e+07,   1.56966005e+07,      ...4744607e+08,   6.40174292e+07,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  7.44732959e+07,   1.56966005e+07,      ...4744607e+08,   6.40174292e+07,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 44  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  27.5s
[CV]  ................................................................
[CV] ................................................. , total=  33.6s
[CV]  ................................................................
[CV] ................................................. , total=  35.8s
[CV]  ................................................................
[CV] ................................................. , total=  36.9s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'mean_fit_time': array([ 33.43747568]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.26649671]), 'std_score_time': array([ 0.00602376]), 'params': ({},), 'split3_train_score': array([-0.28691662]), 'mean_test_score': array([-0.29226675]), 'std_train_score': array([ 0.00608186]), 'std_fit_time': array([ 3.65002242]), 'split1_test_score': array([-0.28431752]), 'std_test_score': array([ 0.01840186]), 'split0_test_score': array([-0.3145455]), 'split3_test_score': array([-0.30370728]), 'split1_train_score': array([-0.29240515]), 'split0_train_score': array([-0.28179706]), 'mean_train_score': array([-0.28980348]), 'split2_train_score': array([-0.29809509]), 'mean_score_time': array([ 0.01667422])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29226675197
####################################################################################
################# Runing the itteration 45  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
GREP_ME***Results of [SVR] estimatorrun are
{'mean_fit_time': array([ 1.77169359]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.1419952]), 'std_score_time': array([ 0.00307313]), 'params': ({},), 'split3_train_score': array([-0.13332192]), 'mean_test_score': array([-0.13154249]), 'std_train_score': array([ 0.0029293]), 'std_fit_time': array([ 0.01242791]), 'split1_test_score': array([-0.14545521]), 'std_test_score': array([ 0.01401094]), 'split0_test_score': array([-0.12899217]), 'split3_test_score': array([-0.10972739]), 'split1_train_score': array([-0.1340647]), 'split0_train_score': array([-0.12656988]), 'mean_train_score': array([-0.13145372]), 'split2_train_score': array([-0.1318584]), 'mean_score_time': array([ 0.43509167])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.131542492345
####################################################################################
################# Runing the itteration 46  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'mean_fit_time': array([ 0.01513404]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.35124766]), 'std_score_time': array([ 0.01352908]), 'params': ({},), 'split3_train_score': array([-0.28784838]), 'mean_test_score': array([-0.29904488]), 'std_train_score': array([ 0.01387828]), 'std_fit_time': array([ 0.00046557]), 'split1_test_score': array([-0.23475364]), 'std_test_score': array([ 0.04174696]), 'split0_test_score': array([-0.3095431]), 'split3_test_score': array([-0.30063513]), 'split1_train_score': array([-0.31316817]), 'split0_train_score': array([-0.28560377]), 'mean_train_score': array([-0.29052525]), 'split2_train_score': array([-0.27548069]), 'mean_score_time': array([ 0.02054328])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.299044883578
####################################################################################
################# Runing the itteration 47  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
GREP_ME***Results of [NuSVR] estimatorrun are
{'mean_fit_time': array([ 1.36583483]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.05166477]), 'std_score_time': array([ 0.00296398]), 'params': ({},), 'split3_train_score': array([-0.05051683]), 'mean_test_score': array([-0.05294498]), 'std_train_score': array([ 0.00206703]), 'std_fit_time': array([ 0.00716358]), 'split1_test_score': array([-0.04642746]), 'std_test_score': array([ 0.00548685]), 'split0_test_score': array([-0.05205306]), 'split3_test_score': array([-0.06163462]), 'split1_train_score': array([-0.05031163]), 'split0_train_score': array([-0.0552387]), 'mean_train_score': array([-0.05238207]), 'split2_train_score': array([-0.05346113]), 'mean_score_time': array([ 0.21541524])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0529449771436
####################################################################################
################# Runing the itteration 48  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'mean_fit_time': array([ 0.15431434]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.9265952]), 'std_score_time': array([ 0.00035555]), 'params': ({},), 'split3_train_score': array([ 0.98926702]), 'mean_test_score': array([-1.01394558]), 'std_train_score': array([ 0.00369693]), 'std_fit_time': array([ 0.00420556]), 'split1_test_score': array([-1.07148728]), 'std_test_score': array([ 0.0534962]), 'split0_test_score': array([-1.02328406]), 'split3_test_score': array([-1.03441579]), 'split1_train_score': array([ 0.99087947]), 'split0_train_score': array([ 0.99576125]), 'mean_train_score': array([ 0.99034136]), 'split2_train_score': array([ 0.9854577]), 'mean_score_time': array([ 0.00209969])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.01394558368
####################################################################################
################# Runing the itteration 49  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'mean_fit_time': array([ 0.04864097]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-1.09010645]), 'std_score_time': array([ 0.00044729]), 'params': ({},), 'split3_train_score': array([ 0.99528285]), 'mean_test_score': array([-1.33859104]), 'std_train_score': array([ 0.00271351]), 'std_fit_time': array([ 0.00463653]), 'split1_test_score': array([-1.40577319]), 'std_test_score': array([ 0.21459826]), 'split0_test_score': array([-1.20394652]), 'split3_test_score': array([-1.65453799]), 'split1_train_score': array([ 0.98820667]), 'split0_train_score': array([ 0.99258721]), 'mean_train_score': array([ 0.99145234]), 'split2_train_score': array([ 0.98973263]), 'mean_score_time': array([ 0.00210333])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 60, 'preprocessor__kw_args': {'pw': 2}, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.33859103838
####################################################################################
################# Runing the itteration 50  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'mean_fit_time': array([ 0.56588078]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-1.23081512]), 'std_score_time': array([ 0.00345137]), 'params': ({},), 'split3_train_score': array([-2.41140449]), 'mean_test_score': array([-2.55460591]), 'std_train_score': array([ 0.73080826]), 'std_fit_time': array([ 0.21701808]), 'split1_test_score': array([-2.68817248]), 'std_test_score': array([ 0.87015196]), 'split0_test_score': array([-3.67416001]), 'split3_test_score': array([-2.62527605]), 'split1_train_score': array([-2.06036638]), 'split0_train_score': array([-3.36501971]), 'mean_train_score': array([-2.29279181]), 'split2_train_score': array([-1.33437664]), 'mean_score_time': array([ 0.00835723])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.55460591491
####################################################################################
################# Runing the itteration 51  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'mean_fit_time': array([ 0.87468928]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.14871008]), 'std_score_time': array([ 0.00129354]), 'params': ({},), 'split3_train_score': array([ 0.77963761]), 'mean_test_score': array([-0.18457558]), 'std_train_score': array([ 0.00443914]), 'std_fit_time': array([ 0.03076002]), 'split1_test_score': array([-0.19715944]), 'std_test_score': array([ 0.03041791]), 'split0_test_score': array([-0.22772269]), 'split3_test_score': array([-0.16471013]), 'split1_train_score': array([ 0.78987606]), 'split0_train_score': array([ 0.78434934]), 'mean_train_score': array([ 0.78610143]), 'split2_train_score': array([ 0.79054272]), 'mean_score_time': array([ 0.00980246])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.184575582977
####################################################################################
################# Runing the itteration 52  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'mean_fit_time': array([ 0.58132511]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.35943991]), 'std_score_time': array([ 0.00031659]), 'params': ({},), 'split3_train_score': array([ 0.98877529]), 'mean_test_score': array([-0.26257522]), 'std_train_score': array([ 0.00163706]), 'std_fit_time': array([ 0.05023602]), 'split1_test_score': array([-0.25446602]), 'std_test_score': array([ 0.05948266]), 'split0_test_score': array([-0.23776084]), 'split3_test_score': array([-0.19863411]), 'split1_train_score': array([ 0.99330283]), 'split0_train_score': array([ 0.99051173]), 'mean_train_score': array([ 0.99070912]), 'split2_train_score': array([ 0.99024663]), 'mean_score_time': array([ 0.00730431])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.262575220463
####################################################################################
################# Runing the itteration 53  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'mean_fit_time': array([ 0.89241153]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.05783942]), 'std_score_time': array([ 0.00138654]), 'params': ({},), 'split3_train_score': array([ 0.23831289]), 'mean_test_score': array([-0.05808111]), 'std_train_score': array([ 0.02626173]), 'std_fit_time': array([ 0.0681231]), 'split1_test_score': array([-0.05707863]), 'std_test_score': array([ 0.00485782]), 'split0_test_score': array([-0.05190039]), 'split3_test_score': array([-0.06550599]), 'split1_train_score': array([ 0.17118844]), 'split0_train_score': array([ 0.18930031]), 'mean_train_score': array([ 0.20497583]), 'split2_train_score': array([ 0.2211017]), 'mean_score_time': array([ 0.00560659])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0580811055237
####################################################################################
################# Runing the itteration 54  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'mean_fit_time': array([ 0.87731504]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.27100165]), 'std_score_time': array([ 0.0001054]), 'params': ({},), 'split3_train_score': array([ 0.7626846]), 'mean_test_score': array([-0.21760406]), 'std_train_score': array([ 0.00745547]), 'std_fit_time': array([ 0.0438876]), 'split1_test_score': array([-0.21211799]), 'std_test_score': array([ 0.04634516]), 'split0_test_score': array([-0.24140991]), 'split3_test_score': array([-0.14588671]), 'split1_train_score': array([ 0.76890256]), 'split0_train_score': array([ 0.77811119]), 'mean_train_score': array([ 0.76698603]), 'split2_train_score': array([ 0.75824579]), 'mean_score_time': array([ 0.00662524])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.217604064941
####################################################################################
################# Runing the itteration 55  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'mean_fit_time': array([ 0.0702405]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.00843978]), 'std_score_time': array([ 0.01307747]), 'params': ({},), 'split3_train_score': array([ 0.0248984]), 'mean_test_score': array([-0.0167415]), 'std_train_score': array([ 0.0008998]), 'std_fit_time': array([ 0.00054975]), 'split1_test_score': array([-0.0113567]), 'std_test_score': array([ 0.00697579]), 'split0_test_score': array([-0.02234548]), 'split3_test_score': array([-0.02482405]), 'split1_train_score': array([ 0.02264174]), 'split0_train_score': array([ 0.02434808]), 'mean_train_score': array([ 0.02376492]), 'split2_train_score': array([ 0.02317146]), 'mean_score_time': array([ 0.02630454])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0167415036204
####################################################################################
################# Runing the itteration 56  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'mean_fit_time': array([ 0.27485919]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.08987509]), 'std_score_time': array([ 0.00066894]), 'params': ({},), 'split3_train_score': array([-0.08285166]), 'mean_test_score': array([-0.08887889]), 'std_train_score': array([ 0.0019259]), 'std_fit_time': array([ 0.07611611]), 'split1_test_score': array([-0.09621071]), 'std_test_score': array([ 0.01016036]), 'split0_test_score': array([-0.07199666]), 'split3_test_score': array([-0.09743308]), 'split1_train_score': array([-0.0813779]), 'split0_train_score': array([-0.08655237]), 'mean_train_score': array([-0.08336627]), 'split2_train_score': array([-0.08268314]), 'mean_score_time': array([ 0.00397223])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0888788864061
####################################################################################
################# Runing the itteration 57  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [Lasso] estimatorrun are
{'mean_fit_time': array([ 1.03555703]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.050436]), 'std_score_time': array([ 0.01072832]), 'params': ({},), 'split3_train_score': array([ 0.0317691]), 'mean_test_score': array([-0.03305262]), 'std_train_score': array([ 0.00241062]), 'std_fit_time': array([ 0.00601502]), 'split1_test_score': array([-0.02668183]), 'std_test_score': array([ 0.01004272]), 'split0_test_score': array([-0.02745221]), 'split3_test_score': array([-0.02764045]), 'split1_train_score': array([ 0.02507674]), 'split0_train_score': array([ 0.02731447]), 'mean_train_score': array([ 0.02810456]), 'split2_train_score': array([ 0.02825793]), 'mean_score_time': array([ 0.02188581])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0330526231717
####################################################################################
################# Runing the itteration 58  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'mean_fit_time': array([ 0.11698776]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.04215057]), 'std_score_time': array([ 0.00325271]), 'params': ({},), 'split3_train_score': array([ 0.02317517]), 'mean_test_score': array([-0.02475861]), 'std_train_score': array([ 0.00255274]), 'std_fit_time': array([ 0.01970807]), 'split1_test_score': array([-0.02052414]), 'std_test_score': array([ 0.01021088]), 'split0_test_score': array([-0.01593511]), 'split3_test_score': array([-0.02042465]), 'split1_train_score': array([ 0.02589604]), 'split0_train_score': array([ 0.02710514]), 'mean_train_score': array([ 0.02661559]), 'split2_train_score': array([ 0.03028601]), 'mean_score_time': array([ 0.00848204])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0247586140395
####################################################################################
################# Runing the itteration 59  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'mean_fit_time': array([ 0.10596144]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.04595944]), 'std_score_time': array([ 0.00526213]), 'params': ({},), 'split3_train_score': array([ 0.03273184]), 'mean_test_score': array([-0.52845248]), 'std_train_score': array([ 0.69090354]), 'std_fit_time': array([ 0.03948678]), 'split1_test_score': array([-0.01258726]), 'std_test_score': array([ 0.85103018]), 'split0_test_score': array([-2.00224266]), 'split3_test_score': array([-0.05302055]), 'split1_train_score': array([ 0.0275632]), 'split0_train_score': array([-1.56598869]), 'mean_train_score': array([-0.36931346]), 'split2_train_score': array([ 0.0284398]), 'mean_score_time': array([ 0.00986636])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.528452475628
####################################################################################
################# Runing the itteration 60  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'mean_fit_time': array([ 0.02833581]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.28488538]), 'std_score_time': array([ 0.00359085]), 'params': ({},), 'split3_train_score': array([-0.27646585]), 'mean_test_score': array([-0.29535856]), 'std_train_score': array([ 0.00914574]), 'std_fit_time': array([ 0.00395756]), 'split1_test_score': array([-0.26122966]), 'std_test_score': array([ 0.03148865]), 'split0_test_score': array([-0.28853059]), 'split3_test_score': array([-0.3467886]), 'split1_train_score': array([-0.3022808]), 'split0_train_score': array([-0.28972898]), 'mean_train_score': array([-0.2898195]), 'split2_train_score': array([-0.29080239]), 'mean_score_time': array([ 0.0131011])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295358555381
####################################################################################
################# Runing the itteration 61  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
GREP_ME***Results of [Ridge] estimatorrun are
{'mean_fit_time': array([ 1.57387012]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.02467071]), 'std_score_time': array([ 0.01438371]), 'params': ({},), 'split3_train_score': array([ 0.02727465]), 'mean_test_score': array([-0.03004431]), 'std_train_score': array([ 0.00059904]), 'std_fit_time': array([ 0.13288003]), 'split1_test_score': array([-0.02767879]), 'std_test_score': array([ 0.00407569]), 'split0_test_score': array([-0.03290715]), 'split3_test_score': array([-0.03492058]), 'split1_train_score': array([ 0.02873061]), 'split0_train_score': array([ 0.02759611]), 'mean_train_score': array([ 0.02771843]), 'split2_train_score': array([ 0.02727236]), 'mean_score_time': array([ 0.02035248])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0300443079281
####################################################################################
################# Runing the itteration 62  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'mean_fit_time': array([ 0.0255416]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.06664512]), 'std_score_time': array([ 0.00494759]), 'params': ({},), 'split3_train_score': array([-0.01868701]), 'mean_test_score': array([-0.06224125]), 'std_train_score': array([ 0.00804496]), 'std_fit_time': array([ 0.00142618]), 'split1_test_score': array([-0.03578339]), 'std_test_score': array([ 0.02071155]), 'split0_test_score': array([-0.05386115]), 'split3_test_score': array([-0.09267536]), 'split1_train_score': array([-0.00342144]), 'split0_train_score': array([-0.00493532]), 'mean_train_score': array([-0.00588668]), 'split2_train_score': array([ 0.00349706]), 'mean_score_time': array([ 0.01597697])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.062241254527
####################################################################################
################# Runing the itteration 63  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'mean_fit_time': array([ 0.04641908]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.0110272]), 'std_score_time': array([ 0.01973625]), 'params': ({},), 'split3_train_score': array([ 0.01046985]), 'mean_test_score': array([-0.01505708]), 'std_train_score': array([ 0.00081152]), 'std_fit_time': array([ 0.00796602]), 'split1_test_score': array([-0.01733386]), 'std_test_score': array([ 0.00257992]), 'split0_test_score': array([-0.01458022]), 'split3_test_score': array([-0.01728706]), 'split1_train_score': array([ 0.0123208]), 'split0_train_score': array([ 0.01044199]), 'mean_train_score': array([ 0.01091544]), 'split2_train_score': array([ 0.01042913]), 'mean_score_time': array([ 0.01765144])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0150570849674
####################################################################################
################# Runing the itteration 64  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'mean_fit_time': array([ 1.67240608]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([ -9.47742743e+18]), 'std_score_time': array([ 0.02035768]), 'params': ({},), 'split3_train_score': array([ -2.18784974e+23]), 'mean_test_score': array([ -4.20662936e+23]), 'std_train_score': array([  6.34046090e+23]), 'std_fit_time': array([ 0.25147899]), 'split1_test_score': array([ -1.07545546e+23]), 'std_test_score': array([  5.51793661e+23]), 'split0_test_score': array([ -1.36793759e+24]), 'split3_test_score': array([ -2.07159129e+23]), 'split1_train_score': array([ -1.58562496e+23]), 'split0_train_score': array([ -1.57837760e+24]), 'mean_train_score': array([ -4.88934300e+23]), 'split2_train_score': array([ -1.21288601e+19]), 'mean_score_time': array([ 0.0236783])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-4.2066293569e+23
####################################################################################
################# Runing the itteration 65  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'mean_fit_time': array([ 0.03621674]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.21870053]), 'std_score_time': array([ 0.07372877]), 'params': ({},), 'split3_train_score': array([ 0.18253275]), 'mean_test_score': array([-0.20712535]), 'std_train_score': array([ 0.00893525]), 'std_fit_time': array([ 0.0064102]), 'split1_test_score': array([-0.22970619]), 'std_test_score': array([ 0.03349611]), 'split0_test_score': array([-0.23042531]), 'split3_test_score': array([-0.14966936]), 'split1_train_score': array([ 0.19043278]), 'split0_train_score': array([ 0.1851699]), 'mean_train_score': array([ 0.19093562]), 'split2_train_score': array([ 0.20560704]), 'mean_score_time': array([ 0.55129373])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.20712534662
####################################################################################
################# Runing the itteration 66  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=3649    1
1348    2
909     2
3958    1
2072    ...  1
2549    2
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.4979203448038829}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.18457558297667223}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.013945583682565}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.009987382355277628}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.3338467719878309}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.262575220463035}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.055871932184997142}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.087311386505743327}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.20712534661967574}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.025574537027188038}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.40175022, -0.39154775, -0.33991442, .... -0.86304212,
        -0.06123763, -0.10636806]])}
        y = 3649    1
1348    2
909     2
3958    1
2072    ...  1
2549    2
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.4979203448038829}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.18457558297667223}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.013945583682565}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.009987382355277628}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.3338467719878309}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.262575220463035}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.055871932184997142}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.087311386505743327}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.20712534661967574}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.025574537027188038}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 116 columns], y=1777     54612337
4062       602920
1716     574...      1405032
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -2.4979203448038829}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.18457558297667223}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.013945583682565}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.009987382355277628}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.3338467719878309}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.262575220463035}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.055871932184997142}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.087311386505743327}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.20712534661967574}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.025574537027188038}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 116 columns]
        y = 1777     54612337
4062       602920
1716     574...      1405032
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 116 columns], y=1777     54612337
4062       602920
1716     574...      1405032
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 116 columns]
        y = 1777     54612337
4062       602920
1716     574...      1405032
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 116 columns], y=1777     54612337
4062       602920
1716     574...      1405032
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 12:09:50 2017
PID: 3001                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 116 columns], 1777     54612337
4062       602920
1716     574...      1405032
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 116 columns], 1777     54612337
4062       602920
1716     574...      1405032
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 116 columns], y=1777     54612337
4062       602920
1716     574...      1405032
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns]
        y_test = 1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns], y_test=1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns]
        y_test = 1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns], 1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns], 1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns], 1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns], 1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns], y=1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns]
        y = 1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 116 columns], y=1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64, y_pred=array([  4.31903555e+07,              nan,      ...3147390e+07,              nan,   1.50000000e+08]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 1777     54612337
4062       602920
1716     574...     17499242
Name: worldwide_gross, dtype: int64
        y_pred = array([  4.31903555e+07,              nan,      ...3147390e+07,              nan,   1.50000000e+08])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 54612337,    602920,  57467731, ..., 270944428,  17856688,
        17499242]), y_pred=array([  4.31903555e+07,              nan,      ...3147390e+07,              nan,   1.50000000e+08]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  4.31903555e+07,              nan,      ...3147390e+07,              nan,   1.50000000e+08])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  4.31903555e+07,              nan,      ...3147390e+07,              nan,   1.50000000e+08]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  4.31903555e+07,              nan,      ...3147390e+07,              nan,   1.50000000e+08])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  4.31903555e+07,              nan,      ...3147390e+07,              nan,   1.50000000e+08]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 67  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  37.4s
[CV]  ................................................................
[CV] ................................................. , total=  42.9s
[CV]  ................................................................
[CV] ................................................. , total=  44.2s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'mean_fit_time': array([ 42.1758126]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.3026837]), 'std_score_time': array([ 0.00500904]), 'params': ({},), 'split3_train_score': array([-0.29116823]), 'mean_test_score': array([-0.29177815]), 'std_train_score': array([ 0.0035843]), 'std_fit_time': array([ 2.84857441]), 'split1_test_score': array([-0.2761071]), 'std_test_score': array([ 0.01092888]), 'split0_test_score': array([-0.30129861]), 'split3_test_score': array([-0.28702317]), 'split1_train_score': array([-0.29494377]), 'split0_train_score': array([-0.28687162]), 'mean_train_score': array([-0.28974408]), 'split2_train_score': array([-0.2859927]), 'mean_score_time': array([ 0.0129239])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291778145888
####################################################################################
################# Runing the itteration 68  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
GREP_ME***Results of [SVR] estimatorrun are
{'mean_fit_time': array([ 2.59223032]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.16625991]), 'std_score_time': array([ 0.01315222]), 'params': ({},), 'split3_train_score': array([-0.12712727]), 'mean_test_score': array([-0.13461187]), 'std_train_score': array([ 0.00753865]), 'std_fit_time': array([ 0.00941754]), 'split1_test_score': array([-0.1141279]), 'std_test_score': array([ 0.0192602]), 'split0_test_score': array([-0.12942411]), 'split3_test_score': array([-0.12863556]), 'split1_train_score': array([-0.14480924]), 'split0_train_score': array([-0.12669032]), 'mean_train_score': array([-0.13181056]), 'split2_train_score': array([-0.12861543]), 'mean_score_time': array([ 0.68988305])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.1346118714
####################################################################################
################# Runing the itteration 69  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'mean_fit_time': array([ 0.0274052]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.2709312]), 'std_score_time': array([ 0.01560189]), 'params': ({},), 'split3_train_score': array([-0.27560788]), 'mean_test_score': array([-0.29030966]), 'std_train_score': array([ 0.00872422]), 'std_fit_time': array([ 0.0030674]), 'split1_test_score': array([-0.29109617]), 'std_test_score': array([ 0.02668039]), 'split0_test_score': array([-0.26570579]), 'split3_test_score': array([-0.33350548]), 'split1_train_score': array([-0.28904546]), 'split0_train_score': array([-0.2979329]), 'mean_train_score': array([-0.28960629]), 'split2_train_score': array([-0.29583893]), 'mean_score_time': array([ 0.0243116])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290309659956
####################################################################################
################# Runing the itteration 70  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [NuSVR] estimatorrun are
{'mean_fit_time': array([ 1.95915687]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.04261258]), 'std_score_time': array([ 0.00410758]), 'params': ({},), 'split3_train_score': array([-0.05263494]), 'mean_test_score': array([-0.05432018]), 'std_train_score': array([ 0.00074198]), 'std_fit_time': array([ 0.05868789]), 'split1_test_score': array([-0.05850175]), 'std_test_score': array([ 0.0127136]), 'split0_test_score': array([-0.07330929]), 'split3_test_score': array([-0.04285708]), 'split1_train_score': array([-0.05225678]), 'split0_train_score': array([-0.05134437]), 'mean_train_score': array([-0.05241058]), 'split2_train_score': array([-0.05340625]), 'mean_score_time': array([ 0.34504139])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.054320175717
####################################################################################
################# Runing the itteration 71  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'mean_fit_time': array([ 0.14924639]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-1.43411547]), 'std_score_time': array([ 0.00062425]), 'params': ({},), 'split3_train_score': array([ 0.99253608]), 'mean_test_score': array([-1.24193448]), 'std_train_score': array([ 0.00384399]), 'std_fit_time': array([ 0.0097067]), 'split1_test_score': array([-1.41412955]), 'std_test_score': array([ 0.18236063]), 'split0_test_score': array([-1.06484383]), 'split3_test_score': array([-1.05464907]), 'split1_train_score': array([ 0.98734583]), 'split0_train_score': array([ 0.98760458]), 'mean_train_score': array([ 0.99103292]), 'split2_train_score': array([ 0.99664518]), 'mean_score_time': array([ 0.00300902])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.24193447918
####################################################################################
################# Runing the itteration 72  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'mean_fit_time': array([ 0.06501204]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-1.37790022]), 'std_score_time': array([ 0.00012608]), 'params': ({},), 'split3_train_score': array([ 0.99118832]), 'mean_test_score': array([-1.32672814]), 'std_train_score': array([ 0.0026784]), 'std_fit_time': array([ 0.00466279]), 'split1_test_score': array([-2.21369215]), 'std_test_score': array([ 0.55529059]), 'split0_test_score': array([-0.90247714]), 'split3_test_score': array([-0.81284303]), 'split1_train_score': array([ 0.99333547]), 'split0_train_score': array([ 0.99234611]), 'mean_train_score': array([ 0.99080713]), 'split2_train_score': array([ 0.98635863]), 'mean_score_time': array([ 0.0024755])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 115, 'preprocessor__kw_args': {'pw': 1}, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.32672813831
####################################################################################
################# Runing the itteration 73  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'mean_fit_time': array([ 0.98561931]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-3.42761361]), 'std_score_time': array([ 0.00429375]), 'params': ({},), 'split3_train_score': array([-3.04334167]), 'mean_test_score': array([-2.95472899]), 'std_train_score': array([ 0.96847534]), 'std_fit_time': array([ 0.27861642]), 'split1_test_score': array([-1.20744218]), 'std_test_score': array([ 1.09442978]), 'split0_test_score': array([-2.99929836]), 'split3_test_score': array([-4.18456179]), 'split1_train_score': array([-1.21725925]), 'split0_train_score': array([-3.89808194]), 'mean_train_score': array([-2.70989208]), 'split2_train_score': array([-2.68088548]), 'mean_score_time': array([ 0.01248544])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 127, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.95472898738
####################################################################################
################# Runing the itteration 74  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'mean_fit_time': array([ 1.42175472]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.14088403]), 'std_score_time': array([ 0.0020554]), 'params': ({},), 'split3_train_score': array([ 0.79934749]), 'mean_test_score': array([-0.18965368]), 'std_train_score': array([ 0.01140748]), 'std_fit_time': array([ 0.12967817]), 'split1_test_score': array([-0.28831859]), 'std_test_score': array([ 0.05980761]), 'split0_test_score': array([-0.18649812]), 'split3_test_score': array([-0.142914]), 'split1_train_score': array([ 0.77189442]), 'split0_train_score': array([ 0.77329876]), 'mean_train_score': array([ 0.77963245]), 'split2_train_score': array([ 0.77398912]), 'mean_score_time': array([ 0.01292098])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 127, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.189653683873
####################################################################################
################# Runing the itteration 75  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'mean_fit_time': array([ 0.70930713]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.4707287]), 'std_score_time': array([  9.32270569e-05]), 'params': ({},), 'split3_train_score': array([ 0.9877464]), 'mean_test_score': array([-0.32865437]), 'std_train_score': array([ 0.00384512]), 'std_fit_time': array([ 0.02718958]), 'split1_test_score': array([-0.25899125]), 'std_test_score': array([ 0.08474101]), 'split0_test_score': array([-0.31551822]), 'split3_test_score': array([-0.26937932]), 'split1_train_score': array([ 0.99426457]), 'split0_train_score': array([ 0.98655988]), 'mean_train_score': array([ 0.99095891]), 'split2_train_score': array([ 0.9952648]), 'mean_score_time': array([ 0.00696701])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 127, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.328654373075
####################################################################################
################# Runing the itteration 76  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'mean_fit_time': array([ 1.10746652]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.04390502]), 'std_score_time': array([ 0.00071755]), 'params': ({},), 'split3_train_score': array([ 0.2176616]), 'mean_test_score': array([-0.03382606]), 'std_train_score': array([ 0.01283418]), 'std_fit_time': array([ 0.01624223]), 'split1_test_score': array([-0.03480079]), 'std_test_score': array([ 0.00650869]), 'split0_test_score': array([-0.03000575]), 'split3_test_score': array([-0.02659267]), 'split1_train_score': array([ 0.2172296]), 'split0_train_score': array([ 0.19376426]), 'mean_train_score': array([ 0.21442437]), 'split2_train_score': array([ 0.22904202]), 'mean_score_time': array([ 0.00676769])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 127, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0338260596208
####################################################################################
################# Runing the itteration 77  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'mean_fit_time': array([ 1.40991724]), 'rank_test_score': array([1], dtype=int32), 'split2_test_score': array([-0.1874602]), 'std_score_time': array([ 0.00029925]), 'params': ({},), 'split3_train_score': array([ 0.75733481]), 'mean_test_score': array([-0.22836249]), 'std_train_score': array([ 0.00696883]), 'std_fit_time': array([ 0.0545904]), 'split1_test_score': array([-0.26954665]), 'std_test_score': array([ 0.02905065]), 'split0_test_score': array([-0.22640649]), 'split3_test_score': array([-0.23003663]), 'split1_train_score': array([ 0.77292471]), 'split0_train_score': array([ 0.76990956]), 'mean_train_score': array([ 0.76891211]), 'split2_train_score': array([ 0.77547934]), 'mean_score_time': array([ 0.00791115])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__n_features_to_select': 127, 'preprocessor__kw_args': {'pw': 3}, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.228362494568
