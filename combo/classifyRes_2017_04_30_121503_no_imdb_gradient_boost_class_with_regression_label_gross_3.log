#########################################
###Starting all estimators for cl: label_gross_3
#########################################

LogPol True
n_components
[193, 115, 57]
pw_lst
[{'pw': 1}]
####################################################################################
################# Runing the itteration 1  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [193, 115, 57], 'preprocessor__kw_args': [{'pw': 1}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}

LogPol True
n_components
[203, 121, 60]
pw_lst
[{'pw': 1}, {'pw': 2}]
####################################################################################
################# Runing the itteration 2  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [203, 121, 60], 'preprocessor__kw_args': [{'pw': 2}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}

LogPol True
n_components
[213, 127, 63]
pw_lst
[{'pw': 1}, {'pw': 2}, {'pw': 3}]
####################################################################################
################# Runing the itteration 3  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [213, 127, 63], 'preprocessor__kw_args': [{'pw': 3}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
####################################################################################
################# Runing the itteration 4  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.01757105]), 'mean_train_score': array([ 0.21076039]), 'split3_test_score': array([ 0.26252284]), 'std_fit_time': array([ 0.16485943]), 'mean_test_score': array([ 0.11978199]), 'split1_test_score': array([-0.16098967]), 'std_score_time': array([ 0.00214082]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.06883841]), 'std_test_score': array([ 0.17562773]), 'split2_train_score': array([ 0.49603784]), 'split3_train_score': array([ 0.26059425]), 'split2_test_score': array([ 0.27437331]), 'split0_test_score': array([ 0.10322148]), 'mean_score_time': array([ 0.0118162]), 'mean_fit_time': array([ 1.0686506]), 'std_train_score': array([ 0.18796982])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.119781988402
####################################################################################
################# Runing the itteration 5  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.91600509]), 'mean_train_score': array([ 0.92676142]), 'split3_test_score': array([ 0.63496037]), 'std_fit_time': array([ 0.03338]), 'mean_test_score': array([ 0.58553131]), 'split1_test_score': array([ 0.52780671]), 'std_score_time': array([ 0.0012036]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92098506]), 'std_test_score': array([ 0.04730172]), 'split2_train_score': array([ 0.93447582]), 'split3_train_score': array([ 0.93557971]), 'split2_test_score': array([ 0.55005561]), 'split0_test_score': array([ 0.62930256]), 'mean_score_time': array([ 0.01235741]), 'mean_fit_time': array([ 1.297162]), 'std_train_score': array([ 0.00846078])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.585531313238
####################################################################################
################# Runing the itteration 6  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.59204251]), 'std_fit_time': array([ 0.01262917]), 'mean_test_score': array([ 0.55984684]), 'split1_test_score': array([ 0.59055699]), 'std_score_time': array([ 0.00045884]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.03730086]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.50004634]), 'split0_test_score': array([ 0.5567415]), 'mean_score_time': array([ 0.00715077]), 'mean_fit_time': array([ 0.83374554]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.559846835479
####################################################################################
################# Runing the itteration 7  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.76561089]), 'mean_train_score': array([ 0.77825355]), 'split3_test_score': array([ 0.66059042]), 'std_fit_time': array([ 0.02692808]), 'mean_test_score': array([ 0.61610752]), 'split1_test_score': array([ 0.58676087]), 'std_score_time': array([ 0.00161821]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.78980508]), 'std_test_score': array([ 0.02718403]), 'split2_train_score': array([ 0.78370578]), 'split3_train_score': array([ 0.77389245]), 'split2_test_score': array([ 0.60770928]), 'split0_test_score': array([ 0.60936951]), 'mean_score_time': array([ 0.0070681]), 'mean_fit_time': array([ 1.58382094]), 'std_train_score': array([ 0.0092469])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.616107520502
####################################################################################
################# Runing the itteration 8  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93306514]), 'mean_train_score': array([ 0.92708474]), 'split3_test_score': array([ 0.5667826]), 'std_fit_time': array([ 0.01882714]), 'mean_test_score': array([ 0.5968848]), 'split1_test_score': array([ 0.65599543]), 'std_score_time': array([ 0.00092988]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92421828]), 'std_test_score': array([ 0.03673677]), 'split2_train_score': array([ 0.92733532]), 'split3_train_score': array([ 0.92372021]), 'split2_test_score': array([ 0.56538931]), 'split0_test_score': array([ 0.59937186]), 'mean_score_time': array([ 0.00725144]), 'mean_fit_time': array([ 1.22973597]), 'std_train_score': array([ 0.00372037])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.596884799161
####################################################################################
################# Runing the itteration 9  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.60969729]), 'mean_train_score': array([ 0.6158547]), 'split3_test_score': array([ 0.64505954]), 'std_fit_time': array([ 0.0151132]), 'mean_test_score': array([ 0.57700568]), 'split1_test_score': array([ 0.54124758]), 'std_score_time': array([ 0.01292686]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62817083]), 'std_test_score': array([ 0.05089711]), 'split2_train_score': array([ 0.63364952]), 'split3_train_score': array([ 0.59190115]), 'split2_test_score': array([ 0.51652618]), 'split0_test_score': array([ 0.6051894]), 'mean_score_time': array([ 0.02614713]), 'mean_fit_time': array([ 0.23856175]), 'std_train_score': array([ 0.0164319])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.57700567806
####################################################################################
################# Runing the itteration 10  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.3045985]), 'mean_train_score': array([ 0.30330562]), 'split3_test_score': array([ 0.26995506]), 'std_fit_time': array([ 0.04592735]), 'mean_test_score': array([ 0.2908669]), 'split1_test_score': array([ 0.28177053]), 'std_score_time': array([ 0.00130346]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.29988066]), 'std_test_score': array([ 0.01693961]), 'split2_train_score': array([ 0.28585023]), 'split3_train_score': array([ 0.32289308]), 'split2_test_score': array([ 0.31529189]), 'split0_test_score': array([ 0.29645012]), 'mean_score_time': array([ 0.00471741]), 'mean_fit_time': array([ 0.52655768]), 'std_train_score': array([ 0.01324539])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.290866897541
####################################################################################
################# Runing the itteration 11  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.66461674]), 'mean_train_score': array([ 0.65295191]), 'split3_test_score': array([ 0.62311281]), 'std_fit_time': array([ 0.15374698]), 'mean_test_score': array([-50.72884175]), 'split1_test_score': array([-204.53095085]), 'std_score_time': array([ 0.00069812]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65020341]), 'std_test_score': array([ 88.79770943]), 'split2_train_score': array([ 0.65962094]), 'split3_train_score': array([ 0.63736654]), 'split2_test_score': array([ 0.45313339]), 'split0_test_score': array([ 0.53933765]), 'mean_score_time': array([ 0.01214832]), 'mean_fit_time': array([ 1.98398167]), 'std_train_score': array([ 0.0103803])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-50.7288417498
####################################################################################
################# Runing the itteration 12  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.63825539]), 'mean_train_score': array([ 0.63215038]), 'split3_test_score': array([ 0.55622469]), 'std_fit_time': array([ 0.10325091]), 'mean_test_score': array([ 0.57309492]), 'split1_test_score': array([ 0.51294743]), 'std_score_time': array([ 0.00156854]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63430648]), 'std_test_score': array([ 0.04580595]), 'split2_train_score': array([ 0.60515249]), 'split3_train_score': array([ 0.65088714]), 'split2_test_score': array([ 0.63921312]), 'split0_test_score': array([ 0.58399442]), 'mean_score_time': array([ 0.0051108]), 'mean_fit_time': array([ 0.24282163]), 'std_train_score': array([ 0.01674718])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.573094916615
####################################################################################
################# Runing the itteration 13  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.64636643]), 'mean_train_score': array([ 0.6477999]), 'split3_test_score': array([ 0.54022026]), 'std_fit_time': array([ 0.05055225]), 'mean_test_score': array([-32.2475226]), 'split1_test_score': array([-130.59372372]), 'std_score_time': array([ 0.00639515]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63998694]), 'std_test_score': array([ 56.78020682]), 'split2_train_score': array([ 0.65839959]), 'split3_train_score': array([ 0.64644664]), 'split2_test_score': array([ 0.54695971]), 'split0_test_score': array([ 0.51645334]), 'mean_score_time': array([ 0.01057708]), 'mean_fit_time': array([ 0.21915495]), 'std_train_score': array([ 0.00665736])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-32.2475226013
####################################################################################
################# Runing the itteration 14  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28083397]), 'mean_train_score': array([-0.28922076]), 'split3_test_score': array([-0.293749]), 'std_fit_time': array([ 0.01574665]), 'mean_test_score': array([-0.291345]), 'split1_test_score': array([-0.29009165]), 'std_score_time': array([ 0.00474817]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28911162]), 'std_test_score': array([ 0.01948302]), 'split2_train_score': array([-0.298963]), 'split3_train_score': array([-0.28797444]), 'split2_test_score': array([-0.2632893]), 'split0_test_score': array([-0.31825003]), 'mean_score_time': array([ 0.02157432]), 'mean_fit_time': array([ 0.04491764]), 'std_train_score': array([ 0.00645784])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291344997251
####################################################################################
################# Runing the itteration 15  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
[CV]  ................................................................
[CV] ................................................. , total=   3.1s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.65703372]), 'mean_train_score': array([ 0.64597728]), 'split3_test_score': array([ 0.58464198]), 'std_fit_time': array([ 0.03275965]), 'mean_test_score': array([ 0.46527966]), 'split1_test_score': array([ 0.56721735]), 'std_score_time': array([ 0.00111628]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64442103]), 'std_test_score': array([ 0.17981569]), 'split2_train_score': array([ 0.65313457]), 'split3_train_score': array([ 0.62931981]), 'split2_test_score': array([ 0.1543683]), 'split0_test_score': array([ 0.554891]), 'mean_score_time': array([ 0.01332515]), 'mean_fit_time': array([ 3.00747252]), 'std_train_score': array([ 0.01064618])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.465279656638
####################################################################################
################# Runing the itteration 16  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-36332.05894441]), 'mean_train_score': array([-435145.63390202]), 'split3_test_score': array([-20446.05133908]), 'std_fit_time': array([ 0.00056244]), 'mean_test_score': array([-14466.527017]), 'split1_test_score': array([-9171.47880766]), 'std_score_time': array([ 0.00584664]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-37422.80370392]), 'std_test_score': array([ 4536.67683226]), 'split2_train_score': array([-165391.81695257]), 'split3_train_score': array([-1501435.8560072]), 'split2_test_score': array([-17149.12336018]), 'split0_test_score': array([-11099.45456107]), 'mean_score_time': array([ 0.01843464]), 'mean_fit_time': array([ 0.03314728]), 'std_train_score': array([ 617854.69099683])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-14466.527017
####################################################################################
################# Runing the itteration 17  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.6288046]), 'mean_train_score': array([ 0.62303192]), 'split3_test_score': array([ 0.67103114]), 'std_fit_time': array([ 0.01544277]), 'mean_test_score': array([ 0.59005482]), 'split1_test_score': array([ 0.54576782]), 'std_score_time': array([ 0.00240212]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63815168]), 'std_test_score': array([ 0.04796603]), 'split2_train_score': array([ 0.6305308]), 'split3_train_score': array([ 0.59464061]), 'split2_test_score': array([ 0.57409808]), 'split0_test_score': array([ 0.56932223]), 'mean_score_time': array([ 0.00480103]), 'mean_fit_time': array([ 0.07090849]), 'std_train_score': array([ 0.01676477])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.590054817508
####################################################################################
################# Runing the itteration 18  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   5.1s
[CV]  ................................................................
[CV] ................................................. , total=   6.4s
[CV]  ................................................................
[CV] ................................................. , total=   5.4s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -2.11804711e+23]), 'mean_train_score': array([ -2.19422694e+24]), 'split3_test_score': array([ -1.05303687e+19]), 'std_fit_time': array([ 0.66581568]), 'mean_test_score': array([ -1.73443436e+24]), 'split1_test_score': array([ -1.12567325e+22]), 'std_score_time': array([ 0.00379243]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -7.36447643e+21]), 'std_test_score': array([  2.74763533e+24]), 'split2_train_score': array([ -8.55771776e+24]), 'split3_train_score': array([ -2.08316567e+19]), 'split2_test_score': array([ -6.48341128e+24]), 'split0_test_score': array([ -4.43058903e+23]), 'mean_score_time': array([ 0.00738925]), 'mean_fit_time': array([ 5.92107803]), 'std_train_score': array([  3.67494630e+24])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.73443436264e+24
####################################################################################
################# Runing the itteration 19  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.57290193]), 'mean_train_score': array([ 0.58719358]), 'split3_test_score': array([ 0.30342699]), 'std_fit_time': array([ 0.00234361]), 'mean_test_score': array([ 0.33533353]), 'split1_test_score': array([ 0.27824657]), 'std_score_time': array([ 0.03324605]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59235016]), 'std_test_score': array([ 0.04874997]), 'split2_train_score': array([ 0.57931444]), 'split3_train_score': array([ 0.60420779]), 'split2_test_score': array([ 0.35463736]), 'split0_test_score': array([ 0.4050232]), 'mean_score_time': array([ 1.04385132]), 'mean_fit_time': array([ 0.04626453]), 'std_train_score': array([ 0.01206654])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.335333531703
####################################################################################
################# Runing the itteration 20  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.11978198840212616}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58553131323831409}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57700567806043512}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.55984683547946623}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61610752050224438}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29086689754142259}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.33533353170324842}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -50.728841749821264}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309491661509349}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -32.247522601336215}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.11978198840212616}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58553131323831409}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57700567806043512}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.55984683547946623}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61610752050224438}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29086689754142259}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.33533353170324842}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -50.728841749821264}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309491661509349}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -32.247522601336215}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0          0         1          2         ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=3766       2548378
215      397501348
3892      ...    235900000
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.11978198840212616}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58553131323831409}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57700567806043512}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.55984683547946623}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61610752050224438}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29086689754142259}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.33533353170324842}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -50.728841749821264}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309491661509349}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -32.247522601336215}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0          0         1          2         ... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 3766       2548378
215      397501348
3892      ...    235900000
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0          0         1          2         ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=3766       2548378
215      397501348
3892      ...    235900000
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0          0         1          2         ... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 3766       2548378
215      397501348
3892      ...    235900000
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0          0         1          2         ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=3766       2548378
215      397501348
3892      ...    235900000
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 12:19:21 2017
PID: 4498                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0          0         1          2         ... -0.043288 -0.106368  

[4812 rows x 214 columns], 3766       2548378
215      397501348
3892      ...    235900000
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0          0         1          2         ... -0.043288 -0.106368  

[4812 rows x 214 columns], 3766       2548378
215      397501348
3892      ...    235900000
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1          2         ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=3766       2548378
215      397501348
3892      ...    235900000
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns], y_test=3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns], 3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns], 3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns], 3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns], 3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns], y=3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y = 3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0          0         1          2         ... -0.043288 -0.106368  

[1203 rows x 214 columns], y=3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64, y_pred=array([  6274378.2       ,                nan,  ...    nan,  61183811.66666666,                nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 3766       2548378
215      397501348
3892      ...     71880305
Name: worldwide_gross, dtype: int64
        y_pred = array([  6274378.2       ,                nan,  ...    nan,  61183811.66666666,                nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([  2548378, 397501348,   1562800, ...,  52880016,  14378353,
        71880305]), y_pred=array([  6274378.2       ,                nan,  ...    nan,  61183811.66666666,                nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  6274378.2       ,                nan,  ...    nan,  61183811.66666666,                nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  6274378.2       ,                nan,  ...    nan,  61183811.66666666,                nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  6274378.2       ,                nan,  ...    nan,  61183811.66666666,                nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  6274378.2       ,                nan,  ...    nan,  61183811.66666666,                nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 21  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.0min
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28859852]), 'mean_train_score': array([-0.2896515]), 'split3_test_score': array([-0.3120732]), 'std_fit_time': array([ 1.62949149]), 'mean_test_score': array([-0.29298336]), 'split1_test_score': array([-0.23710827]), 'std_score_time': array([ 0.01902064]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.30873043]), 'std_test_score': array([ 0.03453187]), 'split2_train_score': array([-0.27918237]), 'split3_train_score': array([-0.28209467]), 'split2_test_score': array([-0.328794]), 'split0_test_score': array([-0.29395796]), 'mean_score_time': array([ 0.05023581]), 'mean_fit_time': array([ 64.06763124]), 'std_train_score': array([ 0.01153064])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292983359742
####################################################################################
################# Runing the itteration 22  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13461562]), 'mean_train_score': array([-0.13175708]), 'split3_test_score': array([-0.12763131]), 'std_fit_time': array([ 0.15704351]), 'mean_test_score': array([-0.13269141]), 'split1_test_score': array([-0.1482719]), 'std_score_time': array([ 0.05422997]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13017293]), 'std_test_score': array([ 0.01348956]), 'split2_train_score': array([-0.13478234]), 'split3_train_score': array([-0.12745742]), 'split2_test_score': array([-0.11321543]), 'split0_test_score': array([-0.14164703]), 'mean_score_time': array([ 1.16968393]), 'mean_fit_time': array([ 4.05746704]), 'std_train_score': array([ 0.00309516])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132691414584
####################################################################################
################# Runing the itteration 23  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28211808]), 'mean_train_score': array([-0.28953479]), 'split3_test_score': array([-0.26844165]), 'std_fit_time': array([ 0.00814118]), 'mean_test_score': array([-0.29002885]), 'split1_test_score': array([-0.26126708]), 'std_score_time': array([ 0.00498105]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29921532]), 'std_test_score': array([ 0.02539891]), 'split2_train_score': array([-0.28013808]), 'split3_train_score': array([-0.2966677]), 'split2_test_score': array([-0.31833885]), 'split0_test_score': array([-0.31206782]), 'mean_score_time': array([ 0.02148634]), 'mean_fit_time': array([ 0.03928095]), 'std_train_score': array([ 0.00848376])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290028848386
####################################################################################
################# Runing the itteration 24  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05159104]), 'mean_train_score': array([-0.05241742]), 'split3_test_score': array([-0.05332801]), 'std_fit_time': array([ 0.0458057]), 'mean_test_score': array([-0.05288122]), 'split1_test_score': array([-0.05421657]), 'std_score_time': array([ 0.00417455]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05187293]), 'std_test_score': array([ 0.00309641]), 'split2_train_score': array([-0.05184477]), 'split3_train_score': array([-0.05436092]), 'split2_test_score': array([-0.0561603]), 'split0_test_score': array([-0.04782001]), 'mean_score_time': array([ 0.56887656]), 'mean_fit_time': array([ 2.99930918]), 'std_train_score': array([ 0.00112744])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0528812222209
####################################################################################
################# Runing the itteration 25  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.28584712]), 'std_fit_time': array([ 0.01177803]), 'mean_test_score': array([ 0.3497892]), 'split1_test_score': array([ 0.38437861]), 'std_score_time': array([ 0.00012903]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05512366]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.30772636]), 'split0_test_score': array([ 0.4212047]), 'mean_score_time': array([ 0.00239688]), 'mean_fit_time': array([ 0.23184013]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.349789196893
####################################################################################
################# Runing the itteration 26  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.18583883]), 'std_fit_time': array([ 0.01012223]), 'mean_test_score': array([ 0.34311346]), 'split1_test_score': array([ 0.41344491]), 'std_score_time': array([ 0.00029607]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.09261054]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.36602455]), 'split0_test_score': array([ 0.40714556]), 'mean_score_time': array([ 0.00252956]), 'mean_fit_time': array([ 0.11015171]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.343113460475
####################################################################################
################# Runing the itteration 27  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.13999313]), 'mean_train_score': array([ 0.02553378]), 'split3_test_score': array([ 0.05147843]), 'std_fit_time': array([ 0.02378347]), 'mean_test_score': array([-0.06576698]), 'split1_test_score': array([-0.028486]), 'std_score_time': array([ 0.00022205]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.25465164]), 'std_test_score': array([ 0.1341903]), 'split2_train_score': array([-0.19405948]), 'split3_train_score': array([ 0.41085309]), 'split2_test_score': array([-0.29295114]), 'split0_test_score': array([ 0.00689078]), 'mean_score_time': array([ 0.00888234]), 'mean_fit_time': array([ 0.70041156]), 'std_train_score': array([ 0.26846647])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0657669816575
####################################################################################
################# Runing the itteration 28  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.94254315]), 'mean_train_score': array([ 0.94126465]), 'split3_test_score': array([ 0.6418549]), 'std_fit_time': array([ 0.01842642]), 'mean_test_score': array([ 0.63549687]), 'split1_test_score': array([ 0.66628263]), 'std_score_time': array([ 0.00036854]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.94263232]), 'std_test_score': array([ 0.02075469]), 'split2_train_score': array([ 0.94192044]), 'split3_train_score': array([ 0.93796271]), 'split2_test_score': array([ 0.62166898]), 'split0_test_score': array([ 0.61218098]), 'mean_score_time': array([ 0.00636047]), 'mean_fit_time': array([ 0.69212407]), 'std_train_score': array([ 0.001926])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.635496870375
####################################################################################
################# Runing the itteration 29  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.61647027]), 'std_fit_time': array([ 0.01345916]), 'mean_test_score': array([ 0.64829413]), 'split1_test_score': array([ 0.61028696]), 'std_score_time': array([ 0.00040538]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05289411]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.73931515]), 'split0_test_score': array([ 0.62710411]), 'mean_score_time': array([ 0.0058111]), 'mean_fit_time': array([ 0.34325898]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.648294125888
####################################################################################
################# Runing the itteration 30  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.81826739]), 'mean_train_score': array([ 0.81497537]), 'split3_test_score': array([ 0.67516276]), 'std_fit_time': array([ 0.01900564]), 'mean_test_score': array([ 0.66913693]), 'split1_test_score': array([ 0.65474335]), 'std_score_time': array([  7.57049385e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.8078259]), 'std_test_score': array([ 0.03160298]), 'split2_train_score': array([ 0.81336856]), 'split3_train_score': array([ 0.82043964]), 'split2_test_score': array([ 0.71642822]), 'split0_test_score': array([ 0.6302134]), 'mean_score_time': array([ 0.00332522]), 'mean_fit_time': array([ 0.67086637]), 'std_train_score': array([ 0.00485779])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.669136934094
####################################################################################
################# Runing the itteration 31  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92272395]), 'mean_train_score': array([ 0.93067114]), 'split3_test_score': array([ 0.63554071]), 'std_fit_time': array([ 0.01052711]), 'mean_test_score': array([ 0.63885716]), 'split1_test_score': array([ 0.61481234]), 'std_score_time': array([ 0.00020579]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93635794]), 'std_test_score': array([ 0.01801247]), 'split2_train_score': array([ 0.9326756]), 'split3_train_score': array([ 0.93092709]), 'split2_test_score': array([ 0.6396087]), 'split0_test_score': array([ 0.66546691]), 'mean_score_time': array([ 0.00536883]), 'mean_fit_time': array([ 0.69634706]), 'std_train_score': array([ 0.00498951])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.638857163667
####################################################################################
################# Runing the itteration 32  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.60038446]), 'mean_train_score': array([ 0.59895712]), 'split3_test_score': array([ 0.58808179]), 'std_fit_time': array([ 0.00754471]), 'mean_test_score': array([ 0.58197292]), 'split1_test_score': array([ 0.6264172]), 'std_score_time': array([ 0.00135569]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.57862573]), 'std_test_score': array([ 0.03617209]), 'split2_train_score': array([ 0.61943361]), 'split3_train_score': array([ 0.59738469]), 'split2_test_score': array([ 0.52552538]), 'split0_test_score': array([ 0.58786729]), 'mean_score_time': array([ 0.01136535]), 'mean_fit_time': array([ 0.05647111]), 'std_train_score': array([ 0.01446688])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.581972915853
####################################################################################
################# Runing the itteration 33  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.26534648]), 'mean_train_score': array([ 0.26547007]), 'split3_test_score': array([ 0.27471875]), 'std_fit_time': array([ 0.03903565]), 'mean_test_score': array([ 0.2630432]), 'split1_test_score': array([ 0.26005304]), 'std_score_time': array([ 0.00045846]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.26492421]), 'std_test_score': array([ 0.00678297]), 'split2_train_score': array([ 0.26814591]), 'split3_train_score': array([ 0.2634637]), 'split2_test_score': array([ 0.25797336]), 'split0_test_score': array([ 0.25942766]), 'mean_score_time': array([ 0.00314647]), 'mean_fit_time': array([ 0.11444634]), 'std_train_score': array([ 0.0016955])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.263043201942
####################################################################################
################# Runing the itteration 34  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.66423614]), 'mean_train_score': array([ 0.64173547]), 'split3_test_score': array([ 0.56337454]), 'std_fit_time': array([ 0.00451085]), 'mean_test_score': array([ 0.50445639]), 'split1_test_score': array([ 0.66364796]), 'std_score_time': array([ 0.00394327]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62775914]), 'std_test_score': array([ 0.23101354]), 'split2_train_score': array([ 0.61269208]), 'split3_train_score': array([ 0.66225455]), 'split2_test_score': array([ 0.67901202]), 'split0_test_score': array([ 0.11179107]), 'mean_score_time': array([ 0.03760248]), 'mean_fit_time': array([ 0.53532332]), 'std_train_score': array([ 0.02217075])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.504456394363
####################################################################################
################# Runing the itteration 35  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.47848106]), 'mean_train_score': array([ 0.5546707]), 'split3_test_score': array([ 0.53565047]), 'std_fit_time': array([ 0.01249407]), 'mean_test_score': array([ 0.47810738]), 'split1_test_score': array([ 0.43513501]), 'std_score_time': array([ 0.00297782]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.50025199]), 'std_test_score': array([ 0.12610615]), 'split2_train_score': array([ 0.59181008]), 'split3_train_score': array([ 0.64813967]), 'split2_test_score': array([ 0.64162463]), 'split0_test_score': array([ 0.30001941]), 'mean_score_time': array([ 0.00439721]), 'mean_fit_time': array([ 0.05907464]), 'std_train_score': array([ 0.06870596])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.478107381297
####################################################################################
################# Runing the itteration 36  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.66287572]), 'mean_train_score': array([ 0.64635948]), 'split3_test_score': array([ 0.57674865]), 'std_fit_time': array([ 0.00492106]), 'mean_test_score': array([ 0.49011452]), 'split1_test_score': array([ 0.14071348]), 'std_score_time': array([ 0.00158008]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64075944]), 'std_test_score': array([ 0.20637696]), 'split2_train_score': array([ 0.62100999]), 'split3_train_score': array([ 0.66079278]), 'split2_test_score': array([ 0.67742657]), 'split0_test_score': array([ 0.56556937]), 'mean_score_time': array([ 0.00332367]), 'mean_fit_time': array([ 0.06571263]), 'std_train_score': array([ 0.01699311])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.490114515888
####################################################################################
################# Runing the itteration 37  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.2943375]), 'mean_train_score': array([-0.28908439]), 'split3_test_score': array([-0.2966266]), 'std_fit_time': array([ 0.00128673]), 'mean_test_score': array([-0.29007735]), 'split1_test_score': array([-0.2718001]), 'std_score_time': array([ 0.01199507]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29547136]), 'std_test_score': array([ 0.01914731]), 'split2_train_score': array([-0.2799606]), 'split3_train_score': array([-0.28656809]), 'split2_test_score': array([-0.31853287]), 'split0_test_score': array([-0.27334981]), 'mean_score_time': array([ 0.02123219]), 'mean_fit_time': array([ 0.01669937]), 'std_train_score': array([ 0.00628419])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290077348787
####################################################################################
################# Runing the itteration 38  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.6428344]), 'mean_train_score': array([ 0.63780846]), 'split3_test_score': array([ 0.627047]), 'std_fit_time': array([ 0.06775857]), 'mean_test_score': array([ 0.58997892]), 'split1_test_score': array([ 0.59973469]), 'std_score_time': array([ 0.01091916]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64605441]), 'std_test_score': array([ 0.05897642]), 'split2_train_score': array([ 0.62957606]), 'split3_train_score': array([ 0.63276898]), 'split2_test_score': array([ 0.64189102]), 'split0_test_score': array([ 0.49124296]), 'mean_score_time': array([ 0.01020992]), 'mean_fit_time': array([ 0.7973274]), 'std_train_score': array([ 0.00682687])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.589978918032
####################################################################################
################# Runing the itteration 39  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-190.03103198]), 'mean_train_score': array([-103166.37232147]), 'split3_test_score': array([-101646.75803595]), 'std_fit_time': array([ 0.00247378]), 'mean_test_score': array([-27072.55580215]), 'split1_test_score': array([-6596.587722]), 'std_score_time': array([ 0.00991027]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-44504.98079283]), 'std_test_score': array([ 43138.98127592]), 'split2_train_score': array([-21.32624396]), 'split3_train_score': array([-367949.15121711]), 'split2_test_score': array([-8.51893549]), 'split0_test_score': array([-38.35851517]), 'mean_score_time': array([ 0.01797122]), 'mean_fit_time': array([ 0.01821458]), 'std_train_score': array([ 153943.25760769])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-27072.5558022
####################################################################################
################# Runing the itteration 40  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.61762957]), 'mean_train_score': array([ 0.61882803]), 'split3_test_score': array([ 0.5978762]), 'std_fit_time': array([ 0.01246041]), 'mean_test_score': array([ 0.60313386]), 'split1_test_score': array([ 0.62144321]), 'std_score_time': array([ 0.00605158]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.60211849]), 'std_test_score': array([ 0.0317849]), 'split2_train_score': array([ 0.64442356]), 'split3_train_score': array([ 0.61114051]), 'split2_test_score': array([ 0.55422245]), 'split0_test_score': array([ 0.63899357]), 'mean_score_time': array([ 0.00645119]), 'mean_fit_time': array([ 0.04273933]), 'std_train_score': array([ 0.01577082])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.603133857261
####################################################################################
################# Runing the itteration 41  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -8.71425614e+20]), 'mean_train_score': array([ -3.30134683e+21]), 'split3_test_score': array([ -8.07099464e+21]), 'std_fit_time': array([ 0.22759432]), 'mean_test_score': array([ -2.87684856e+21]), 'split1_test_score': array([ -1.99555374e+21]), 'std_score_time': array([ 0.00026269]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -1.72745929e+21]), 'std_test_score': array([  3.08602477e+21]), 'split2_train_score': array([-2.11204374]), 'split3_train_score': array([ -1.06065024e+22]), 'split2_test_score': array([-0.21166751]), 'split0_test_score': array([ -1.44084585e+21]), 'mean_score_time': array([ 0.00202185]), 'mean_fit_time': array([ 0.66933089]), 'std_train_score': array([  4.26162610e+21])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.87684855542e+21
####################################################################################
################# Runing the itteration 42  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.6631715]), 'mean_train_score': array([ 0.66713511]), 'split3_test_score': array([ 0.41210508]), 'std_fit_time': array([ 0.00465627]), 'mean_test_score': array([ 0.48344435]), 'split1_test_score': array([ 0.47507188]), 'std_score_time': array([ 0.02190678]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65452767]), 'std_test_score': array([ 0.0473481]), 'split2_train_score': array([ 0.66754149]), 'split3_train_score': array([ 0.68329977]), 'split2_test_score': array([ 0.50553788]), 'split0_test_score': array([ 0.54106255]), 'mean_score_time': array([ 0.34730548]), 'mean_fit_time': array([ 0.02496558]), 'std_train_score': array([ 0.01044173])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.483444347577
####################################################################################
################# Runing the itteration 43  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.11978198840212616}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34978919689274407}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5819729158532313}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34311346047521701}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29086689754142259}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50445639436312473}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.11978198840212616}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34978919689274407}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5819729158532313}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34311346047521701}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29086689754142259}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50445639436312473}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...5  1.530507 -0.863042  

[4812 rows x 61 columns], y=2702     20606053
3109     11810854
482     2376...     35007180
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.11978198840212616}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34978919689274407}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5819729158532313}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34311346047521701}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29086689754142259}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50445639436312473}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...5  1.530507 -0.863042  

[4812 rows x 61 columns]
        y = 2702     20606053
3109     11810854
482     2376...     35007180
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5  1.530507 -0.863042  

[4812 rows x 61 columns], y=2702     20606053
3109     11810854
482     2376...     35007180
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...5  1.530507 -0.863042  

[4812 rows x 61 columns]
        y = 2702     20606053
3109     11810854
482     2376...     35007180
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5  1.530507 -0.863042  

[4812 rows x 61 columns], y=2702     20606053
3109     11810854
482     2376...     35007180
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 12:27:22 2017
PID: 5807                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5  1.530507 -0.863042  

[4812 rows x 61 columns], 2702     20606053
3109     11810854
482     2376...     35007180
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5  1.530507 -0.863042  

[4812 rows x 61 columns], 2702     20606053
3109     11810854
482     2376...     35007180
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5  1.530507 -0.863042  

[4812 rows x 61 columns], y=2702     20606053
3109     11810854
482     2376...     35007180
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns]
        y_test = 2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], y_test=2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns]
        y_test = 2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], y=2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns]
        y = 2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], y=2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64, y_pred=array([  6.08684735e+07,   3.15000000e+05,   2.4...1108000e+05,              nan,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 2702     20606053
3109     11810854
482     2376...     63706632
Name: worldwide_gross, dtype: int64
        y_pred = array([  6.08684735e+07,   3.15000000e+05,   2.4...1108000e+05,              nan,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 20606053,  11810854, 237685089, ...,         0,  28142379,
        63706632]), y_pred=array([  6.08684735e+07,   3.15000000e+05,   2.4...1108000e+05,              nan,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  6.08684735e+07,   3.15000000e+05,   2.4...1108000e+05,              nan,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  6.08684735e+07,   3.15000000e+05,   2.4...1108000e+05,              nan,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  6.08684735e+07,   3.15000000e+05,   2.4...1108000e+05,              nan,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  6.08684735e+07,   3.15000000e+05,   2.4...1108000e+05,              nan,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 44  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  29.0s
[CV]  ................................................................
[CV] ................................................. , total=  31.0s
[CV]  ................................................................
[CV] ................................................. , total=  30.5s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.27258238]), 'mean_train_score': array([-0.28999687]), 'split3_test_score': array([-0.30324306]), 'std_fit_time': array([ 1.08823354]), 'mean_test_score': array([-0.29425294]), 'split1_test_score': array([-0.23835348]), 'std_score_time': array([ 0.00645933]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.31196491]), 'std_test_score': array([ 0.03808556]), 'split2_train_score': array([-0.28909091]), 'split3_train_score': array([-0.28634928]), 'split2_test_score': array([-0.29035594]), 'split0_test_score': array([-0.34505925]), 'mean_score_time': array([ 0.01366436]), 'mean_fit_time': array([ 30.61791104]), 'std_train_score': array([ 0.014142])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29425293528
####################################################################################
################# Runing the itteration 45  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.12993957]), 'mean_train_score': array([-0.13193246]), 'split3_test_score': array([-0.15939182]), 'std_fit_time': array([ 0.00584822]), 'mean_test_score': array([-0.13484768]), 'split1_test_score': array([-0.09885326]), 'std_score_time': array([ 0.00885375]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13839323]), 'std_test_score': array([ 0.02225418]), 'split2_train_score': array([-0.12991536]), 'split3_train_score': array([-0.12948166]), 'split2_test_score': array([-0.13762097]), 'split0_test_score': array([-0.14352467]), 'mean_score_time': array([ 0.4319883]), 'mean_fit_time': array([ 1.80271745]), 'std_train_score': array([ 0.00373458])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.134847676126
####################################################################################
################# Runing the itteration 46  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.2786587]), 'mean_train_score': array([-0.28974292]), 'split3_test_score': array([-0.31030303]), 'std_fit_time': array([ 0.00164923]), 'mean_test_score': array([-0.29190958]), 'split1_test_score': array([-0.26374657]), 'std_score_time': array([ 0.01769135]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29967093]), 'std_test_score': array([ 0.02599599]), 'split2_train_score': array([-0.29666468]), 'split3_train_score': array([-0.28397736]), 'split2_test_score': array([-0.26919028]), 'split0_test_score': array([-0.32439844]), 'mean_score_time': array([ 0.03622925]), 'mean_fit_time': array([ 0.01770151]), 'std_train_score': array([ 0.00869738])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29190958057
####################################################################################
################# Runing the itteration 47  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05134315]), 'mean_train_score': array([-0.0522318]), 'split3_test_score': array([-0.05949446]), 'std_fit_time': array([ 0.01033889]), 'mean_test_score': array([-0.05290036]), 'split1_test_score': array([-0.03939159]), 'std_score_time': array([ 0.00105164]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05292886]), 'std_test_score': array([ 0.01261165]), 'split2_train_score': array([-0.05503349]), 'split3_train_score': array([-0.04962168]), 'split2_test_score': array([-0.04245914]), 'split0_test_score': array([-0.07025626]), 'mean_score_time': array([ 0.21608329]), 'mean_fit_time': array([ 1.45262283]), 'std_train_score': array([ 0.00199611])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0529003623966
####################################################################################
################# Runing the itteration 48  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.40676277]), 'std_fit_time': array([ 0.00497224]), 'mean_test_score': array([ 0.43838541]), 'split1_test_score': array([ 0.44111529]), 'std_score_time': array([ 0.00023477]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.02636381]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.47886411]), 'split0_test_score': array([ 0.42679949]), 'mean_score_time': array([ 0.00216407]), 'mean_fit_time': array([ 0.12216693]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.438385414055
####################################################################################
################# Runing the itteration 49  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.45615156]), 'std_fit_time': array([ 0.00056512]), 'mean_test_score': array([ 0.34630335]), 'split1_test_score': array([ 0.39438803]), 'std_score_time': array([  8.84327863e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.0865459]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.30677424]), 'split0_test_score': array([ 0.22789958]), 'mean_score_time': array([ 0.0018881]), 'mean_fit_time': array([ 0.04205626]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.346303353708
####################################################################################
################# Runing the itteration 50  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.51292485]), 'mean_train_score': array([ 0.36929913]), 'split3_test_score': array([ 0.37600375]), 'std_fit_time': array([ 0.16676597]), 'mean_test_score': array([ 0.2622401]), 'split1_test_score': array([-0.02421598]), 'std_score_time': array([ 0.00201652]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.0017623]), 'std_test_score': array([ 0.16865975]), 'split2_train_score': array([ 0.55532663]), 'split3_train_score': array([ 0.40718274]), 'split2_test_score': array([ 0.39259686]), 'split0_test_score': array([ 0.30457577]), 'mean_score_time': array([ 0.00806582]), 'mean_fit_time': array([ 0.46236062]), 'std_train_score': array([ 0.21894809])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.262240098083
####################################################################################
################# Runing the itteration 51  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93013715]), 'mean_train_score': array([ 0.92723755]), 'split3_test_score': array([ 0.61172857]), 'std_fit_time': array([ 0.0122834]), 'mean_test_score': array([ 0.56454263]), 'split1_test_score': array([ 0.60217537]), 'std_score_time': array([ 0.00019303]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92553353]), 'std_test_score': array([ 0.04271339]), 'split2_train_score': array([ 0.92812753]), 'split3_train_score': array([ 0.925152]), 'split2_test_score': array([ 0.52751351]), 'split0_test_score': array([ 0.51675306]), 'mean_score_time': array([ 0.00834668]), 'mean_fit_time': array([ 0.69476825]), 'std_train_score': array([ 0.00202811])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.564542627337
####################################################################################
################# Runing the itteration 52  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.62986812]), 'std_fit_time': array([ 0.0072343]), 'mean_test_score': array([ 0.57675623]), 'split1_test_score': array([ 0.5680474]), 'std_score_time': array([ 0.00036364]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05547777]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.48963707]), 'split0_test_score': array([ 0.61947234]), 'mean_score_time': array([ 0.00634128]), 'mean_fit_time': array([ 0.45559472]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.576756233043
####################################################################################
################# Runing the itteration 53  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.77256422]), 'mean_train_score': array([ 0.76278414]), 'split3_test_score': array([ 0.60147439]), 'std_fit_time': array([ 0.01062236]), 'mean_test_score': array([ 0.60294044]), 'split1_test_score': array([ 0.58252376]), 'std_score_time': array([  8.47457112e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.77118973]), 'std_test_score': array([ 0.01778627]), 'split2_train_score': array([ 0.75127143]), 'split3_train_score': array([ 0.75611119]), 'split2_test_score': array([ 0.63130289]), 'split0_test_score': array([ 0.59646073]), 'mean_score_time': array([ 0.00389892]), 'mean_fit_time': array([ 0.87264341]), 'std_train_score': array([ 0.00926519])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.602940441745
####################################################################################
################# Runing the itteration 54  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92309434]), 'mean_train_score': array([ 0.92832715]), 'split3_test_score': array([ 0.55745067]), 'std_fit_time': array([ 0.01777166]), 'mean_test_score': array([ 0.57957551]), 'split1_test_score': array([ 0.61655874]), 'std_score_time': array([ 0.00042478]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92619138]), 'std_test_score': array([ 0.02229111]), 'split2_train_score': array([ 0.93583577]), 'split3_train_score': array([ 0.9281871]), 'split2_test_score': array([ 0.56899039]), 'split0_test_score': array([ 0.57530223]), 'mean_score_time': array([ 0.00597745]), 'mean_fit_time': array([ 0.64536649]), 'std_train_score': array([ 0.00469954])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.579575509177
####################################################################################
################# Runing the itteration 55  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.53309309]), 'mean_train_score': array([ 0.53554564]), 'split3_test_score': array([ 0.51724902]), 'std_fit_time': array([ 0.00411215]), 'mean_test_score': array([ 0.51152335]), 'split1_test_score': array([ 0.51437773]), 'std_score_time': array([ 0.01361715]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.54437435]), 'std_test_score': array([ 0.01998504]), 'split2_train_score': array([ 0.5316417]), 'split3_train_score': array([ 0.53307341]), 'split2_test_score': array([ 0.53480023]), 'split0_test_score': array([ 0.47966644]), 'mean_score_time': array([ 0.03564477]), 'mean_fit_time': array([ 0.08041269]), 'std_train_score': array([ 0.00513113])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.51152335412
####################################################################################
################# Runing the itteration 56  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.18255689]), 'mean_train_score': array([ 0.19084453]), 'split3_test_score': array([ 0.20696683]), 'std_fit_time': array([ 0.06056548]), 'mean_test_score': array([ 0.18708398]), 'split1_test_score': array([ 0.19074328]), 'std_score_time': array([ 0.00055835]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.19342096]), 'std_test_score': array([ 0.0247034]), 'split2_train_score': array([ 0.19670752]), 'split3_train_score': array([ 0.19069275]), 'split2_test_score': array([ 0.14568861]), 'split0_test_score': array([ 0.2049372]), 'mean_score_time': array([ 0.00345755]), 'mean_fit_time': array([ 0.21346641]), 'std_train_score': array([ 0.00523738])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.187083981105
####################################################################################
################# Runing the itteration 57  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.60685808]), 'mean_train_score': array([ 0.60756557]), 'split3_test_score': array([ 0.57403504]), 'std_fit_time': array([ 0.03227126]), 'mean_test_score': array([ 0.5730984]), 'split1_test_score': array([ 0.58150499]), 'std_score_time': array([ 0.0074935]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.60451324]), 'std_test_score': array([ 0.00797019]), 'split2_train_score': array([ 0.61140665]), 'split3_train_score': array([ 0.60748433]), 'split2_test_score': array([ 0.56009312]), 'split0_test_score': array([ 0.57676044]), 'mean_score_time': array([ 0.01709563]), 'mean_fit_time': array([ 1.05490404]), 'std_train_score': array([ 0.0024788])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.573098397759
####################################################################################
################# Runing the itteration 58  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.60843401]), 'mean_train_score': array([ 0.59975815]), 'split3_test_score': array([ 0.58471281]), 'std_fit_time': array([ 0.06144256]), 'mean_test_score': array([ 0.57136661]), 'split1_test_score': array([ 0.57595004]), 'std_score_time': array([ 0.00116683]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.60225381]), 'std_test_score': array([ 0.02447901]), 'split2_train_score': array([ 0.59180223]), 'split3_train_score': array([ 0.59654255]), 'split2_test_score': array([ 0.59431592]), 'split0_test_score': array([ 0.53048767]), 'mean_score_time': array([ 0.00486058]), 'mean_fit_time': array([ 0.15092039]), 'std_train_score': array([ 0.00622767])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.571366610507
####################################################################################
################# Runing the itteration 59  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.60112863]), 'mean_train_score': array([ 0.61111075]), 'split3_test_score': array([ 0.55254688]), 'std_fit_time': array([ 0.04320284]), 'mean_test_score': array([ 0.57315135]), 'split1_test_score': array([ 0.56216869]), 'std_score_time': array([ 0.00519702]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61733541]), 'std_test_score': array([ 0.0214908]), 'split2_train_score': array([ 0.60967218]), 'split3_train_score': array([ 0.61630679]), 'split2_test_score': array([ 0.56890268]), 'split0_test_score': array([ 0.60898713]), 'mean_score_time': array([ 0.00665605]), 'mean_fit_time': array([ 0.13509327]), 'std_train_score': array([ 0.00647027])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.573151348192
####################################################################################
################# Runing the itteration 60  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.29126262]), 'mean_train_score': array([-0.28926062]), 'split3_test_score': array([-0.27652638]), 'std_fit_time': array([ 0.0033129]), 'mean_test_score': array([-0.29130506]), 'split1_test_score': array([-0.32244196]), 'std_score_time': array([ 0.02867257]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27978037]), 'std_test_score': array([ 0.01817839]), 'split2_train_score': array([-0.29095419]), 'split3_train_score': array([-0.29504531]), 'split2_test_score': array([-0.28335404]), 'split0_test_score': array([-0.28289788]), 'mean_score_time': array([ 0.03355384]), 'mean_fit_time': array([ 0.02921015]), 'std_train_score': array([ 0.00570557])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291305062625
####################################################################################
################# Runing the itteration 61  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.61111204]), 'mean_train_score': array([ 0.61027961]), 'split3_test_score': array([ 0.57894928]), 'std_fit_time': array([ 0.10008454]), 'mean_test_score': array([ 0.57096854]), 'split1_test_score': array([ 0.62402022]), 'std_score_time': array([ 0.0025081]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59680515]), 'std_test_score': array([ 0.0399897]), 'split2_train_score': array([ 0.62440987]), 'split3_train_score': array([ 0.60879137]), 'split2_test_score': array([ 0.51167689]), 'split0_test_score': array([ 0.56922776]), 'mean_score_time': array([ 0.00502682]), 'mean_fit_time': array([ 1.66562581]), 'std_train_score': array([ 0.00979966])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.570968540167
####################################################################################
################# Runing the itteration 62  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.61438494]), 'mean_train_score': array([ 0.58639711]), 'split3_test_score': array([ 0.51777777]), 'std_fit_time': array([ 0.00040329]), 'mean_test_score': array([ 0.54707036]), 'split1_test_score': array([ 0.5730811]), 'std_score_time': array([ 0.00654077]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.57914221]), 'std_test_score': array([ 0.03255342]), 'split2_train_score': array([ 0.56828701]), 'split3_train_score': array([ 0.58377429]), 'split2_test_score': array([ 0.58544615]), 'split0_test_score': array([ 0.51197643]), 'mean_score_time': array([ 0.01847237]), 'mean_fit_time': array([ 0.02522159]), 'std_train_score': array([ 0.01710853])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.547070359917
####################################################################################
################# Runing the itteration 63  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.57701756]), 'mean_train_score': array([ 0.58921939]), 'split3_test_score': array([ 0.54740918]), 'std_fit_time': array([ 0.00963646]), 'mean_test_score': array([ 0.56921165]), 'split1_test_score': array([ 0.57817817]), 'std_score_time': array([ 0.00766807]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58982705]), 'std_test_score': array([ 0.02193741]), 'split2_train_score': array([ 0.59328771]), 'split3_train_score': array([ 0.59674523]), 'split2_test_score': array([ 0.55026359]), 'split0_test_score': array([ 0.60099567]), 'mean_score_time': array([ 0.00821292]), 'mean_fit_time': array([ 0.05779177]), 'std_train_score': array([ 0.00745727])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.569211652097
####################################################################################
################# Runing the itteration 64  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -5.37369160e+24]), 'mean_train_score': array([ -2.02025228e+24]), 'split3_test_score': array([ -1.54856378e+24]), 'std_fit_time': array([ 0.31875957]), 'mean_test_score': array([ -2.64968749e+24]), 'split1_test_score': array([ -1.98254703e+20]), 'std_score_time': array([ 0.00049576]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -5.15420392e+20]), 'std_test_score': array([  2.91091807e+24]), 'split2_train_score': array([ -1.83390320e+24]), 'split3_train_score': array([ -8.72898919e+23]), 'split2_test_score': array([ -1.47311250e+24]), 'split0_test_score': array([ -7.57687541e+24]), 'mean_score_time': array([ 0.00201434]), 'mean_fit_time': array([ 1.47137952]), 'std_train_score': array([  2.04181524e+24])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.64968748816e+24
####################################################################################
################# Runing the itteration 65  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.60624404]), 'mean_train_score': array([ 0.61500089]), 'split3_test_score': array([ 0.34045244]), 'std_fit_time': array([ 0.00841846]), 'mean_test_score': array([ 0.39483587]), 'split1_test_score': array([ 0.42013185]), 'std_score_time': array([ 0.08604583]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58966166]), 'std_test_score': array([ 0.04045525]), 'split2_train_score': array([ 0.61782822]), 'split3_train_score': array([ 0.64626964]), 'split2_test_score': array([ 0.44491847]), 'split0_test_score': array([ 0.37384072]), 'mean_score_time': array([ 0.56636918]), 'mean_fit_time': array([ 0.03712201]), 'std_train_score': array([ 0.02064272])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.394835869342
####################################################################################
################# Runing the itteration 66  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.26224009808308285}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5819729158532313}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29086689754142259}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309839775863447}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.03816826,
        -0.05200382, -0.10636806]])}
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.26224009808308285}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5819729158532313}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29086689754142259}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309839775863447}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], y=4592            0
1169    100655892
1776     547...     36265745
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.26224009808308285}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5819729158532313}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29086689754142259}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309839775863447}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns]
        y = 4592            0
1169    100655892
1776     547...     36265745
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], y=4592            0
1169    100655892
1776     547...     36265745
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns]
        y = 4592            0
1169    100655892
1776     547...     36265745
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], y=4592            0
1169    100655892
1776     547...     36265745
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 12:33:06 2017
PID: 7093                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], 4592            0
1169    100655892
1776     547...     36265745
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], 4592            0
1169    100655892
1776     547...     36265745
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], y=4592            0
1169    100655892
1776     547...     36265745
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns]
        y_test = 4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], y_test=4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns]
        y_test = 4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], 4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], 4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], 4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], 4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], y=4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns]
        y = 4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], y=4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64, y_pred=array([               nan,                nan,  ...3333333,                nan,  83386444.5       ]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 4592            0
1169    100655892
1776     547...     57753825
Name: worldwide_gross, dtype: int64
        y_pred = array([               nan,                nan,  ...3333333,                nan,  83386444.5       ])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([        0, 100655892,  54768418, ...,  57051053,  60780981,
        57753825]), y_pred=array([               nan,                nan,  ...3333333,                nan,  83386444.5       ]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([               nan,                nan,  ...3333333,                nan,  83386444.5       ])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([               nan,                nan,  ...3333333,                nan,  83386444.5       ]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([               nan,                nan,  ...3333333,                nan,  83386444.5       ])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([               nan,                nan,  ...3333333,                nan,  83386444.5       ]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 67  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  22.4s
[CV]  ................................................................
[CV] ................................................. , total=  30.1s
[CV]  ................................................................
[CV] ................................................. , total=  27.9s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.27975165]), 'mean_train_score': array([-0.28982453]), 'split3_test_score': array([-0.27800978]), 'std_fit_time': array([ 2.80109025]), 'mean_test_score': array([-0.29266673]), 'split1_test_score': array([-0.29933328]), 'std_score_time': array([ 0.06551407]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28654024]), 'std_test_score': array([ 0.01937935]), 'split2_train_score': array([-0.29578785]), 'split3_train_score': array([-0.29721839]), 'split2_test_score': array([-0.27205456]), 'split0_test_score': array([-0.32126928]), 'mean_score_time': array([ 0.04980564]), 'mean_fit_time': array([ 26.90870315]), 'std_train_score': array([ 0.00711477])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292666725963
####################################################################################
################# Runing the itteration 68  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.1297606]), 'mean_train_score': array([-0.13214328]), 'split3_test_score': array([-0.15428481]), 'std_fit_time': array([ 0.02289992]), 'mean_test_score': array([-0.13495035]), 'split1_test_score': array([-0.14959727]), 'std_score_time': array([ 0.00632697]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13192624]), 'std_test_score': array([ 0.01707347]), 'split2_train_score': array([-0.13444756]), 'split3_train_score': array([-0.13243874]), 'split2_test_score': array([-0.11757747]), 'split0_test_score': array([-0.11834184]), 'mean_score_time': array([ 0.6905908]), 'mean_fit_time': array([ 2.64707917]), 'std_train_score': array([ 0.00166743])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.134950347654
####################################################################################
################# Runing the itteration 69  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.283346]), 'mean_train_score': array([-0.28974712]), 'split3_test_score': array([-0.31190609]), 'std_fit_time': array([ 0.00312234]), 'mean_test_score': array([-0.2918903]), 'split1_test_score': array([-0.30537079]), 'std_score_time': array([ 0.02361429]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28429423]), 'std_test_score': array([ 0.03139598]), 'split2_train_score': array([-0.30916672]), 'split3_train_score': array([-0.28218152]), 'split2_test_score': array([-0.23772909]), 'split0_test_score': array([-0.31255523]), 'mean_score_time': array([ 0.02456397]), 'mean_fit_time': array([ 0.02697116]), 'std_train_score': array([ 0.01123685])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291890301733
####################################################################################
################# Runing the itteration 70  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05435421]), 'mean_train_score': array([-0.05262877]), 'split3_test_score': array([-0.03956452]), 'std_fit_time': array([ 0.0275217]), 'mean_test_score': array([-0.05459284]), 'split1_test_score': array([-0.09253726]), 'std_score_time': array([ 0.00664652]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05098238]), 'std_test_score': array([ 0.02264116]), 'split2_train_score': array([-0.05064493]), 'split3_train_score': array([-0.05453356]), 'split2_test_score': array([-0.0509542]), 'split0_test_score': array([-0.03531539]), 'mean_score_time': array([ 0.34455627]), 'mean_fit_time': array([ 2.05189764]), 'std_train_score': array([ 0.00182013])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0545928431976
####################################################################################
################# Runing the itteration 71  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.39459582]), 'std_fit_time': array([ 0.00283452]), 'mean_test_score': array([ 0.35542354]), 'split1_test_score': array([ 0.38060509]), 'std_score_time': array([  6.60733551e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.04583034]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.36886676]), 'split0_test_score': array([ 0.27762647]), 'mean_score_time': array([ 0.002321]), 'mean_fit_time': array([ 0.11840892]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.355423536308
####################################################################################
################# Runing the itteration 72  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.18195731]), 'std_fit_time': array([ 0.0116681]), 'mean_test_score': array([ 0.31516826]), 'split1_test_score': array([ 0.30256967]), 'std_score_time': array([ 0.00017003]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.08912852]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.42833142]), 'split0_test_score': array([ 0.34781464]), 'mean_score_time': array([ 0.00239187]), 'mean_fit_time': array([ 0.06626666]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.315168261029
####################################################################################
################# Runing the itteration 73  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.26158343]), 'mean_train_score': array([ 0.32986894]), 'split3_test_score': array([ 0.0533631]), 'std_fit_time': array([ 0.23992792]), 'mean_test_score': array([ 0.19961694]), 'split1_test_score': array([ 0.03224205]), 'std_score_time': array([ 0.00311038]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.27050059]), 'std_test_score': array([ 0.17214829]), 'split2_train_score': array([ 0.52123103]), 'split3_train_score': array([ 0.26616071]), 'split2_test_score': array([ 0.45631651]), 'split0_test_score': array([ 0.2565461]), 'mean_score_time': array([ 0.00977713]), 'mean_fit_time': array([ 0.73264384]), 'std_train_score': array([ 0.11052794])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.199616941406
####################################################################################
################# Runing the itteration 74  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92972238]), 'mean_train_score': array([ 0.92203622]), 'split3_test_score': array([ 0.59419736]), 'std_fit_time': array([ 0.0216965]), 'mean_test_score': array([ 0.59130184]), 'split1_test_score': array([ 0.56575434]), 'std_score_time': array([ 0.00086662]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.91697358]), 'std_test_score': array([ 0.03208249]), 'split2_train_score': array([ 0.91949256]), 'split3_train_score': array([ 0.92195637]), 'split2_test_score': array([ 0.64262489]), 'split0_test_score': array([ 0.56263077]), 'mean_score_time': array([ 0.01029044]), 'mean_fit_time': array([ 1.06577933]), 'std_train_score': array([ 0.00477452])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.591301838561
####################################################################################
################# Runing the itteration 75  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.61868322]), 'std_fit_time': array([ 0.0089978]), 'mean_test_score': array([ 0.57991668]), 'split1_test_score': array([ 0.53110556]), 'std_score_time': array([ 0.00037659]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.0319567]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.59357332]), 'split0_test_score': array([ 0.57630461]), 'mean_score_time': array([ 0.00628918]), 'mean_fit_time': array([ 0.58662766]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.579916677879
####################################################################################
################# Runing the itteration 76  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.76934119]), 'mean_train_score': array([ 0.77500575]), 'split3_test_score': array([ 0.62663973]), 'std_fit_time': array([ 0.00755607]), 'mean_test_score': array([ 0.61954319]), 'split1_test_score': array([ 0.59097596]), 'std_score_time': array([ 0.0007217]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.7722112]), 'std_test_score': array([ 0.05152409]), 'split2_train_score': array([ 0.78404092]), 'split3_train_score': array([ 0.77442967]), 'split2_test_score': array([ 0.56127858]), 'split0_test_score': array([ 0.69927847]), 'mean_score_time': array([ 0.00569338]), 'mean_fit_time': array([ 1.09456795]), 'std_train_score': array([ 0.00551958])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.619543186086
####################################################################################
################# Runing the itteration 77  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92628626]), 'mean_train_score': array([ 0.91954279]), 'split3_test_score': array([ 0.60189567]), 'std_fit_time': array([ 0.02362803]), 'mean_test_score': array([ 0.59101693]), 'split1_test_score': array([ 0.60446469]), 'std_score_time': array([ 0.00188053]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92909815]), 'std_test_score': array([ 0.04077049]), 'split2_train_score': array([ 0.91894813]), 'split3_train_score': array([ 0.90383863]), 'split2_test_score': array([ 0.52383617]), 'split0_test_score': array([ 0.6338712]), 'mean_score_time': array([ 0.01011157]), 'mean_fit_time': array([ 1.06779462]), 'std_train_score': array([ 0.00979481])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.591016930175
####################################################################################
################# Runing the itteration 78  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.59393758]), 'mean_train_score': array([ 0.60278911]), 'split3_test_score': array([ 0.60634616]), 'std_fit_time': array([ 0.00707193]), 'mean_test_score': array([ 0.58478964]), 'split1_test_score': array([ 0.61508632]), 'std_score_time': array([ 0.00606822]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59378121]), 'std_test_score': array([ 0.04020886]), 'split2_train_score': array([ 0.62453533]), 'split3_train_score': array([ 0.59890233]), 'split2_test_score': array([ 0.5156192]), 'split0_test_score': array([ 0.60210689]), 'mean_score_time': array([ 0.02968192]), 'mean_fit_time': array([ 0.13286155]), 'std_train_score': array([ 0.01272298])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.584789643783
####################################################################################
################# Runing the itteration 79  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.30098039]), 'mean_train_score': array([ 0.29910807]), 'split3_test_score': array([ 0.31570921]), 'std_fit_time': array([ 0.05596615]), 'mean_test_score': array([ 0.29268668]), 'split1_test_score': array([ 0.28829093]), 'std_score_time': array([ 0.00128237]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.28793504]), 'std_test_score': array([ 0.01650512]), 'split2_train_score': array([ 0.31525716]), 'split3_train_score': array([ 0.29225969]), 'split2_test_score': array([ 0.26983006]), 'split0_test_score': array([ 0.29691651]), 'mean_score_time': array([ 0.00535613]), 'mean_fit_time': array([ 0.41809344]), 'std_train_score': array([ 0.01044073])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.292686677114
####################################################################################
################# Runing the itteration 80  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.64860711]), 'mean_train_score': array([ 0.63518282]), 'split3_test_score': array([-3.69569259]), 'std_fit_time': array([ 0.0204665]), 'mean_test_score': array([-42.08264738]), 'split1_test_score': array([ 0.51673855]), 'std_score_time': array([ 0.00748485]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62290713]), 'std_test_score': array([ 71.41598336]), 'split2_train_score': array([ 0.63008609]), 'split3_train_score': array([ 0.63913097]), 'split2_test_score': array([ 0.59061494]), 'split0_test_score': array([-165.74225041]), 'mean_score_time': array([ 0.01930916]), 'mean_fit_time': array([ 1.13010931]), 'std_train_score': array([ 0.00964972])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-42.0826473768
####################################################################################
################# Runing the itteration 81  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.64622176]), 'mean_train_score': array([ 0.61315387]), 'split3_test_score': array([ 0.52253621]), 'std_fit_time': array([ 0.02040228]), 'mean_test_score': array([ 0.25795861]), 'split1_test_score': array([ 0.61593089]), 'std_score_time': array([ 0.00273766]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58654857]), 'std_test_score': array([ 0.49907872]), 'split2_train_score': array([ 0.58781914]), 'split3_train_score': array([ 0.63202603]), 'split2_test_score': array([-0.60303838]), 'split0_test_score': array([ 0.49640571]), 'mean_score_time': array([ 0.00453663]), 'mean_fit_time': array([ 0.1064769]), 'std_train_score': array([ 0.02645437])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.25795860889
####################################################################################
################# Runing the itteration 82  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.62211126]), 'mean_train_score': array([ 0.6344259]), 'split3_test_score': array([-124.41574726]), 'std_fit_time': array([ 0.01360879]), 'mean_test_score': array([-31.39976284]), 'split1_test_score': array([ 0.6185313]), 'std_score_time': array([ 0.00014462]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62439723]), 'std_test_score': array([ 53.71595024]), 'split2_train_score': array([ 0.6503937]), 'split3_train_score': array([ 0.64080141]), 'split2_test_score': array([ 0.53254204]), 'split0_test_score': array([-2.33437744]), 'mean_score_time': array([ 0.00239813]), 'mean_fit_time': array([ 0.12995684]), 'std_train_score': array([ 0.01170302])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-31.3997628389
####################################################################################
################# Runing the itteration 83  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.30311571]), 'mean_train_score': array([-0.28942857]), 'split3_test_score': array([-0.3068426]), 'std_fit_time': array([ 0.00029769]), 'mean_test_score': array([-0.29323794]), 'split1_test_score': array([-0.33580253]), 'std_score_time': array([ 0.00252018]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27632798]), 'std_test_score': array([ 0.03132092]), 'split2_train_score': array([-0.29405997]), 'split3_train_score': array([-0.28421061]), 'split2_test_score': array([-0.27837593]), 'split0_test_score': array([-0.25193069]), 'mean_score_time': array([ 0.01317292]), 'mean_fit_time': array([ 0.02681869]), 'std_train_score': array([ 0.01009505])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293237937975
####################################################################################
################# Runing the itteration 84  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.6215923]), 'mean_train_score': array([ 0.62963812]), 'split3_test_score': array([ 0.55623555]), 'std_fit_time': array([ 0.15215026]), 'mean_test_score': array([ 0.38211355]), 'split1_test_score': array([-0.13878411]), 'std_score_time': array([ 0.00284076]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64261324]), 'std_test_score': array([ 0.3034276]), 'split2_train_score': array([ 0.61185441]), 'split3_train_score': array([ 0.64249254]), 'split2_test_score': array([ 0.4985202]), 'split0_test_score': array([ 0.61248254]), 'mean_score_time': array([ 0.00511581]), 'mean_fit_time': array([ 1.82440954]), 'std_train_score': array([ 0.01336587])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.382113545269
####################################################################################
################# Runing the itteration 85  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-267083.47675526]), 'mean_train_score': array([-463807.95611808]), 'split3_test_score': array([-114976.26748382]), 'std_fit_time': array([ 0.00121621]), 'mean_test_score': array([-34139.70966973]), 'split1_test_score': array([-10171.54690931]), 'std_score_time': array([ 0.00306419]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-752012.3660287]), 'std_test_score': array([ 46880.55974251]), 'split2_train_score': array([ 0.60575529]), 'split3_train_score': array([-836136.58744366]), 'split2_test_score': array([ 0.55672072]), 'split0_test_score': array([-11411.58100653]), 'mean_score_time': array([ 0.01444787]), 'mean_fit_time': array([ 0.02833462]), 'std_train_score': array([ 344785.90982098])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-34139.7096697
####################################################################################
################# Runing the itteration 86  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.62186344]), 'mean_train_score': array([ 0.61326258]), 'split3_test_score': array([ 0.63237041]), 'std_fit_time': array([ 0.01070799]), 'mean_test_score': array([ 0.57827382]), 'split1_test_score': array([ 0.56292004]), 'std_score_time': array([ 0.00471481]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62704108]), 'std_test_score': array([ 0.03142949]), 'split2_train_score': array([ 0.62384131]), 'split3_train_score': array([ 0.58030449]), 'split2_test_score': array([ 0.55451107]), 'split0_test_score': array([ 0.56329374]), 'mean_score_time': array([ 0.00743204]), 'mean_fit_time': array([ 0.06423205]), 'std_train_score': array([ 0.01911784])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.578273815568
####################################################################################
################# Runing the itteration 87  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.5s
[CV]  ................................................................
[CV] ................................................. , total=   2.6s
[CV]  ................................................................
[CV] ................................................. , total=   2.8s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -5.67316898e+19]), 'mean_train_score': array([ -4.06554921e+22]), 'split3_test_score': array([ -7.69251882e+19]), 'std_fit_time': array([ 0.11716484]), 'mean_test_score': array([ -3.16560100e+22]), 'split1_test_score': array([ -1.11106796e+23]), 'std_score_time': array([ 0.00129327]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -1.35197683e+23]), 'std_test_score': array([  4.62938901e+22]), 'split2_train_score': array([ -2.72929295e+22]), 'split3_train_score': array([ -7.46244290e+19]), 'split2_test_score': array([ -1.53680703e+22]), 'split0_test_score': array([ -7.22481675e+19]), 'mean_score_time': array([ 0.00365788]), 'mean_fit_time': array([ 2.63920248]), 'std_train_score': array([  5.57042415e+22])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3.16560099961e+22
####################################################################################
################# Runing the itteration 88  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.6425869]), 'mean_train_score': array([ 0.62979006]), 'split3_test_score': array([ 0.39041146]), 'std_fit_time': array([ 0.00100644]), 'mean_test_score': array([ 0.43408967]), 'split1_test_score': array([ 0.53742936]), 'std_score_time': array([ 0.02522183]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59901034]), 'std_test_score': array([ 0.06225685]), 'split2_train_score': array([ 0.62980568]), 'split3_train_score': array([ 0.64775731]), 'split2_test_score': array([ 0.42810255]), 'split0_test_score': array([ 0.38041532]), 'mean_score_time': array([ 0.67435181]), 'mean_fit_time': array([ 0.03765404]), 'std_train_score': array([ 0.01893391])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.434089671747
####################################################################################
################# Runing the itteration 89  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.26224009808308285}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309839775863447}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.86304212,
        -0.06123763, -0.10636806]])}
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.26224009808308285}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309839775863447}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], y=4322         72260
511      224922135
1276      ...    345141403
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.26224009808308285}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309839775863447}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns]
        y = 4322         72260
511      224922135
1276      ...    345141403
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], y=4322         72260
511      224922135
1276      ...    345141403
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns]
        y = 4322         72260
511      224922135
1276      ...    345141403
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], y=4322         72260
511      224922135
1276      ...    345141403
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 12:38:49 2017
PID: 8519                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], 4322         72260
511      224922135
1276      ...    345141403
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], 4322         72260
511      224922135
1276      ...    345141403
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], y=4322         72260
511      224922135
1276      ...    345141403
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns]
        y_test = 4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], y_test=4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns]
        y_test = 4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], 4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], 4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], 4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], 4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], y=4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns]
        y = 4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], y=4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64, y_pred=array([        nan,         nan,         nan, ...,  98945238.8,
               nan,         nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 4322         72260
511      224922135
1276      ...    160038407
Name: worldwide_gross, dtype: int64
        y_pred = array([        nan,         nan,         nan, ...,  98945238.8,
               nan,         nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([    72260, 224922135,  90523726, ...,   2154540,     12836,
       160038407]), y_pred=array([        nan,         nan,         nan, ...,  98945238.8,
               nan,         nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([        nan,         nan,         nan, ...,  98945238.8,
               nan,         nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([        nan,         nan,         nan, ...,  98945238.8,
               nan,         nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([        nan,         nan,         nan, ...,  98945238.8,
               nan,         nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([        nan,         nan,         nan, ...,  98945238.8,
               nan,         nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 90  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  55.1s
[CV]  ................................................................
[CV] ................................................. , total=  55.0s
[CV]  ................................................................
[CV] ................................................. , total=  55.2s
[CV]  ................................................................
[CV] ................................................. , total=  56.1s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28032499]), 'mean_train_score': array([-0.28993407]), 'split3_test_score': array([-0.28965274]), 'std_fit_time': array([ 0.45239407]), 'mean_test_score': array([-0.2938151]), 'split1_test_score': array([-0.31533661]), 'std_score_time': array([ 0.01131056]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28168806]), 'std_test_score': array([ 0.02837815]), 'split2_train_score': array([-0.30832175]), 'split3_train_score': array([-0.2894015]), 'split2_test_score': array([-0.24914868]), 'split0_test_score': array([-0.32112237]), 'mean_score_time': array([ 0.0252859]), 'mean_fit_time': array([ 55.3078559]), 'std_train_score': array([ 0.01116603])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293815098416
####################################################################################
################# Runing the itteration 91  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.12786807]), 'mean_train_score': array([-0.13224663]), 'split3_test_score': array([-0.12728029]), 'std_fit_time': array([ 0.02745574]), 'mean_test_score': array([-0.13451535]), 'split1_test_score': array([-0.10879229]), 'std_score_time': array([ 0.01231806]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13712625]), 'std_test_score': array([ 0.02136201]), 'split2_train_score': array([-0.12993353]), 'split3_train_score': array([-0.13405868]), 'split2_test_score': array([-0.13413915]), 'split0_test_score': array([-0.16784969]), 'mean_score_time': array([ 0.74230337]), 'mean_fit_time': array([ 2.77050364]), 'std_train_score': array([ 0.00359223])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.134515352428
####################################################################################
################# Runing the itteration 92  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28150851]), 'mean_train_score': array([-0.29009322]), 'split3_test_score': array([-0.26102916]), 'std_fit_time': array([ 0.0024537]), 'mean_test_score': array([-0.29468201]), 'split1_test_score': array([-0.26576824]), 'std_score_time': array([ 0.00877677]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29769419]), 'std_test_score': array([ 0.03141039]), 'split2_train_score': array([-0.27769432]), 'split3_train_score': array([-0.30347586]), 'split2_test_score': array([-0.32917758]), 'split0_test_score': array([-0.32275307]), 'mean_score_time': array([ 0.02503932]), 'mean_fit_time': array([ 0.02771944]), 'std_train_score': array([ 0.01077381])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.294682012752
####################################################################################
################# Runing the itteration 93  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.5s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.0541632]), 'mean_train_score': array([-0.0522646]), 'split3_test_score': array([-0.04654895]), 'std_fit_time': array([ 0.02751245]), 'mean_test_score': array([-0.05286793]), 'split1_test_score': array([-0.06403335]), 'std_score_time': array([ 0.00406064]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05015912]), 'std_test_score': array([ 0.00870819]), 'split2_train_score': array([-0.05177008]), 'split3_train_score': array([-0.052966]), 'split2_test_score': array([-0.05841309]), 'split0_test_score': array([-0.04247631]), 'mean_score_time': array([ 0.37236744]), 'mean_fit_time': array([ 2.15963382]), 'std_train_score': array([ 0.00148107])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0528679259208
####################################################################################
################# Runing the itteration 94  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.35345788]), 'std_fit_time': array([ 0.00993831]), 'mean_test_score': array([ 0.30330402]), 'split1_test_score': array([ 0.23729292]), 'std_score_time': array([ 0.00010553]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.0447113]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.33356871]), 'split0_test_score': array([ 0.28889655]), 'mean_score_time': array([ 0.00240004]), 'mean_fit_time': array([ 0.19645423]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.303304015053
####################################################################################
################# Runing the itteration 95  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.06248925]), 'std_fit_time': array([ 0.00464068]), 'mean_test_score': array([ 0.28249392]), 'split1_test_score': array([ 0.34823185]), 'std_score_time': array([ 0.0005313]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.12909838]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.32766699]), 'split0_test_score': array([ 0.39158759]), 'mean_score_time': array([ 0.00258696]), 'mean_fit_time': array([ 0.07832491]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.282493920399
####################################################################################
################# Runing the itteration 96  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.23045603]), 'mean_train_score': array([ 0.41046655]), 'split3_test_score': array([ 0.21448889]), 'std_fit_time': array([ 0.05308592]), 'mean_test_score': array([ 0.3100063]), 'split1_test_score': array([ 0.22545046]), 'std_score_time': array([ 0.00050206]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.45091704]), 'std_test_score': array([ 0.10650414]), 'split2_train_score': array([ 0.5057392]), 'split3_train_score': array([ 0.45475395]), 'split2_test_score': array([ 0.48031144]), 'split0_test_score': array([ 0.31977442]), 'mean_score_time': array([ 0.00858456]), 'mean_fit_time': array([ 0.51722747]), 'std_train_score': array([ 0.10615823])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.310006303638
####################################################################################
################# Runing the itteration 97  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92193656]), 'mean_train_score': array([ 0.92354374]), 'split3_test_score': array([ 0.5697293]), 'std_fit_time': array([ 0.05143327]), 'mean_test_score': array([ 0.56991559]), 'split1_test_score': array([ 0.55300066]), 'std_score_time': array([ 0.00109169]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92302453]), 'std_test_score': array([ 0.03177219]), 'split2_train_score': array([ 0.92845094]), 'split3_train_score': array([ 0.92076293]), 'split2_test_score': array([ 0.53600734]), 'split0_test_score': array([ 0.62092508]), 'mean_score_time': array([ 0.0121485]), 'mean_fit_time': array([ 0.82657927]), 'std_train_score': array([ 0.00294389])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.569915593126
####################################################################################
################# Runing the itteration 98  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.59497796]), 'std_fit_time': array([ 0.05450548]), 'mean_test_score': array([ 0.55577235]), 'split1_test_score': array([ 0.62387904]), 'std_score_time': array([ 0.00123343]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.0648269]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.45273734]), 'split0_test_score': array([ 0.55149504]), 'mean_score_time': array([ 0.00848496]), 'mean_fit_time': array([ 0.68823779]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.555772346801
####################################################################################
################# Runing the itteration 99  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.77083858]), 'mean_train_score': array([ 0.76192779]), 'split3_test_score': array([ 0.54594304]), 'std_fit_time': array([ 0.02788197]), 'mean_test_score': array([ 0.58685518]), 'split1_test_score': array([ 0.58901608]), 'std_score_time': array([ 0.00181529]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.74347225]), 'std_test_score': array([ 0.02754105]), 'split2_train_score': array([ 0.76491194]), 'split3_train_score': array([ 0.76848839]), 'split2_test_score': array([ 0.62361953]), 'split0_test_score': array([ 0.58884208]), 'mean_score_time': array([ 0.00776339]), 'mean_fit_time': array([ 1.33240414]), 'std_train_score': array([ 0.01086227])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.586855182586
####################################################################################
################# Runing the itteration 100  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92940494]), 'mean_train_score': array([ 0.93085906]), 'split3_test_score': array([ 0.54992904]), 'std_fit_time': array([ 0.01345692]), 'mean_test_score': array([ 0.56621103]), 'split1_test_score': array([ 0.50214052]), 'std_score_time': array([ 0.00022]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93265187]), 'std_test_score': array([ 0.04642967]), 'split2_train_score': array([ 0.93298875]), 'split3_train_score': array([ 0.92839067]), 'split2_test_score': array([ 0.62901978]), 'split0_test_score': array([ 0.58375479]), 'mean_score_time': array([ 0.00695151]), 'mean_fit_time': array([ 0.77651888]), 'std_train_score': array([ 0.00199732])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.566211031683
####################################################################################
################# Runing the itteration 101  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.54248528]), 'mean_train_score': array([ 0.54792377]), 'split3_test_score': array([ 0.52239811]), 'std_fit_time': array([ 0.00429236]), 'mean_test_score': array([ 0.50345976]), 'split1_test_score': array([ 0.49442847]), 'std_score_time': array([ 0.00380063]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.55437798]), 'std_test_score': array([ 0.02092688]), 'split2_train_score': array([ 0.54310168]), 'split3_train_score': array([ 0.55173012]), 'split2_test_score': array([ 0.47338217]), 'split0_test_score': array([ 0.52363028]), 'mean_score_time': array([ 0.01595479]), 'mean_fit_time': array([ 0.13776445]), 'std_train_score': array([ 0.00521955])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.503459757394
####################################################################################
################# Runing the itteration 102  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.19579434]), 'mean_train_score': array([ 0.19265097]), 'split3_test_score': array([ 0.17632986]), 'std_fit_time': array([ 0.15455113]), 'mean_test_score': array([ 0.181876]), 'split1_test_score': array([ 0.18214633]), 'std_score_time': array([ 0.00186675]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.18966941]), 'std_test_score': array([ 0.01054392]), 'split2_train_score': array([ 0.19279596]), 'split3_train_score': array([ 0.19234417]), 'split2_test_score': array([ 0.17037271]), 'split0_test_score': array([ 0.1986551]), 'mean_score_time': array([ 0.00506926]), 'mean_fit_time': array([ 0.38424951]), 'std_train_score': array([ 0.00217288])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.181875999144
####################################################################################
################# Runing the itteration 103  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.62551014]), 'mean_train_score': array([ 0.61910025]), 'split3_test_score': array([ 0.58469095]), 'std_fit_time': array([ 0.03927704]), 'mean_test_score': array([ 0.56895348]), 'split1_test_score': array([ 0.57541913]), 'std_score_time': array([ 0.01319324]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61782368]), 'std_test_score': array([ 0.01279739]), 'split2_train_score': array([ 0.61860196]), 'split3_train_score': array([ 0.61446522]), 'split2_test_score': array([ 0.56556978]), 'split0_test_score': array([ 0.55013407]), 'mean_score_time': array([ 0.02828676]), 'mean_fit_time': array([ 1.75247931]), 'std_train_score': array([ 0.00401398])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.568953483071
####################################################################################
################# Runing the itteration 104  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.5724142]), 'mean_train_score': array([ 0.6073351]), 'split3_test_score': array([ 0.48373131]), 'std_fit_time': array([ 0.12302015]), 'mean_test_score': array([ 0.53296487]), 'split1_test_score': array([ 0.48357498]), 'std_score_time': array([ 0.00728142]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6275568]), 'std_test_score': array([ 0.04931413]), 'split2_train_score': array([ 0.59737547]), 'split3_train_score': array([ 0.63199392]), 'split2_test_score': array([ 0.58159287]), 'split0_test_score': array([ 0.58296033]), 'mean_score_time': array([ 0.02399683]), 'mean_fit_time': array([ 0.29716396]), 'std_train_score': array([ 0.02416422])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.532964873493
####################################################################################
################# Runing the itteration 105  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.60693318]), 'mean_train_score': array([ 0.62010983]), 'split3_test_score': array([ 0.58241155]), 'std_fit_time': array([ 0.07237344]), 'mean_test_score': array([ 0.55759797]), 'split1_test_score': array([ 0.49017419]), 'std_score_time': array([ 0.00422399]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63777441]), 'std_test_score': array([ 0.04257737]), 'split2_train_score': array([ 0.62147424]), 'split3_train_score': array([ 0.61425748]), 'split2_test_score': array([ 0.55459431]), 'split0_test_score': array([ 0.60321185]), 'mean_score_time': array([ 0.01509637]), 'mean_fit_time': array([ 0.20629174]), 'std_train_score': array([ 0.01142118])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.557597973225
####################################################################################
################# Runing the itteration 106  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.29765774]), 'mean_train_score': array([-0.28915791]), 'split3_test_score': array([-0.28420414]), 'std_fit_time': array([ 0.00125648]), 'mean_test_score': array([-0.29023798]), 'split1_test_score': array([-0.29465585]), 'std_score_time': array([ 0.00248567]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28735932]), 'std_test_score': array([ 0.01748781]), 'split2_train_score': array([-0.28098202]), 'split3_train_score': array([-0.29063254]), 'split2_test_score': array([-0.31519202]), 'split0_test_score': array([-0.26689993]), 'mean_score_time': array([ 0.01443756]), 'mean_fit_time': array([ 0.0323475]), 'std_train_score': array([ 0.00601045])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290237984453
####################################################################################
################# Runing the itteration 107  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.7s
[CV]  ................................................................
[CV] ................................................. , total=   2.9s
[CV]  ................................................................
[CV] ................................................. , total=   2.9s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.60645261]), 'mean_train_score': array([ 0.62006338]), 'split3_test_score': array([ 0.576076]), 'std_fit_time': array([ 0.09339145]), 'mean_test_score': array([ 0.56344987]), 'split1_test_score': array([ 0.51701633]), 'std_score_time': array([ 0.00345563]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63303352]), 'std_test_score': array([ 0.03388123]), 'split2_train_score': array([ 0.62459282]), 'split3_train_score': array([ 0.61617455]), 'split2_test_score': array([ 0.55115778]), 'split0_test_score': array([ 0.60954937]), 'mean_score_time': array([ 0.02674365]), 'mean_fit_time': array([ 2.84851819]), 'std_train_score': array([ 0.00986301])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.563449868059
####################################################################################
################# Runing the itteration 108  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.5946305]), 'mean_train_score': array([ 0.58954153]), 'split3_test_score': array([ 0.56343044]), 'std_fit_time': array([ 0.00416961]), 'mean_test_score': array([ 0.53985105]), 'split1_test_score': array([ 0.5371608]), 'std_score_time': array([ 0.01259166]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59825249]), 'std_test_score': array([ 0.01839774]), 'split2_train_score': array([ 0.58276702]), 'split3_train_score': array([ 0.58251612]), 'split2_test_score': array([ 0.54632546]), 'split0_test_score': array([ 0.51248749]), 'mean_score_time': array([ 0.02434963]), 'mean_fit_time': array([ 0.03449756]), 'std_train_score': array([ 0.00701835])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.539851048652
####################################################################################
################# Runing the itteration 109  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.58068238]), 'mean_train_score': array([ 0.59430124]), 'split3_test_score': array([ 0.50028751]), 'std_fit_time': array([ 0.00716076]), 'mean_test_score': array([ 0.55682208]), 'split1_test_score': array([ 0.65122042]), 'std_score_time': array([ 0.01821572]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.57012556]), 'std_test_score': array([ 0.06580742]), 'split2_train_score': array([ 0.61402336]), 'split3_train_score': array([ 0.61237365]), 'split2_test_score': array([ 0.49046432]), 'split0_test_score': array([ 0.58531609]), 'mean_score_time': array([ 0.01988077]), 'mean_fit_time': array([ 0.07577354]), 'std_train_score': array([ 0.01927116])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.556822082148
####################################################################################
################# Runing the itteration 110  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -5.38852794e+25]), 'mean_train_score': array([ -8.23915963e+25]), 'split3_test_score': array([ -1.39664878e+26]), 'std_fit_time': array([ 0.44131876]), 'mean_test_score': array([ -8.13093375e+25]), 'split1_test_score': array([ -5.32791468e+25]), 'std_score_time': array([ 0.00816719]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -4.74240745e+25]), 'std_test_score': array([  3.69750921e+25]), 'split2_train_score': array([ -7.28876859e+25]), 'split3_train_score': array([ -1.55369345e+26]), 'split2_test_score': array([ -8.63673905e+25]), 'split0_test_score': array([ -4.59259352e+25]), 'mean_score_time': array([ 0.01113611]), 'mean_fit_time': array([ 3.73429435]), 'std_train_score': array([  4.31607862e+25])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-8.13093375457e+25
####################################################################################
################# Runing the itteration 111  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.59074447]), 'mean_train_score': array([ 0.58459721]), 'split3_test_score': array([ 0.36495155]), 'std_fit_time': array([ 0.00544265]), 'mean_test_score': array([ 0.33896734]), 'split1_test_score': array([ 0.3400741]), 'std_score_time': array([ 0.15345939]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.60275766]), 'std_test_score': array([ 0.05930208]), 'split2_train_score': array([ 0.5840418]), 'split3_train_score': array([ 0.56084492]), 'split2_test_score': array([ 0.40611753]), 'split0_test_score': array([ 0.2447262]), 'mean_score_time': array([ 0.88060808]), 'mean_fit_time': array([ 0.0453034]), 'std_train_score': array([ 0.01526492])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.338967342608
####################################################################################
################# Runing the itteration 112  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309839775863447}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309839775863447}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=1933     46598133
4286       105377
4554        ...     25858490
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.48344434757707105}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57309839775863447}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns]
        y = 1933     46598133
4286       105377
4554        ...     25858490
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=1933     46598133
4286       105377
4554        ...     25858490
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns]
        y = 1933     46598133
4286       105377
4554        ...     25858490
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=1933     46598133
4286       105377
4554        ...     25858490
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 12:44:27 2017
PID: 9829                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], 1933     46598133
4286       105377
4554        ...     25858490
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], 1933     46598133
4286       105377
4554        ...     25858490
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=1933     46598133
4286       105377
4554        ...     25858490
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y_test = 1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y_test=1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y_test = 1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y=1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y = 1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y=1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64, y_pred=array([             nan,   6.95820000e+04,      ...        nan,   7.21256222e+07,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 1933     46598133
4286       105377
4554        ...     11614954
Name: worldwide_gross, dtype: int64
        y_pred = array([             nan,   6.95820000e+04,      ...        nan,   7.21256222e+07,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 46598133,    105377,         0, ..., 142051255,  46666955,
        11614954]), y_pred=array([             nan,   6.95820000e+04,      ...        nan,   7.21256222e+07,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([             nan,   6.95820000e+04,      ...        nan,   7.21256222e+07,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([             nan,   6.95820000e+04,      ...        nan,   7.21256222e+07,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([             nan,   6.95820000e+04,      ...        nan,   7.21256222e+07,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([             nan,   6.95820000e+04,      ...        nan,   7.21256222e+07,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 113  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
[CV]  ................................................................
[CV] ................................................. , total= 1.2min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28727477]), 'mean_train_score': array([-0.28944434]), 'split3_test_score': array([-0.29076413]), 'std_fit_time': array([ 2.26255413]), 'mean_test_score': array([-0.29022265]), 'split1_test_score': array([-0.26569513]), 'std_score_time': array([ 0.01072058]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.2974734]), 'std_test_score': array([ 0.01537925]), 'split2_train_score': array([-0.28413197]), 'split3_train_score': array([-0.28889723]), 'split2_test_score': array([-0.30753207]), 'split0_test_score': array([-0.29689927]), 'mean_score_time': array([ 0.01560557]), 'mean_fit_time': array([ 69.21898371]), 'std_train_score': array([ 0.004942])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290222649524
####################################################################################
################# Runing the itteration 114  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13555562]), 'mean_train_score': array([-0.13174728]), 'split3_test_score': array([-0.12816299]), 'std_fit_time': array([ 0.07497192]), 'mean_test_score': array([-0.13206842]), 'split1_test_score': array([-0.13961185]), 'std_score_time': array([ 0.01549087]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.12549428]), 'std_test_score': array([ 0.00913058]), 'split2_train_score': array([-0.13026926]), 'split3_train_score': array([-0.13566995]), 'split2_test_score': array([-0.11896455]), 'split0_test_score': array([-0.14153429]), 'mean_score_time': array([ 1.04069078]), 'mean_fit_time': array([ 3.74254924]), 'std_train_score': array([ 0.00421828])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132068420059
####################################################################################
################# Runing the itteration 115  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.31650149]), 'mean_train_score': array([-0.29026035]), 'split3_test_score': array([-0.29854352]), 'std_fit_time': array([ 0.00134711]), 'mean_test_score': array([-0.29545335]), 'split1_test_score': array([-0.32336763]), 'std_score_time': array([ 0.00944988]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27932267]), 'std_test_score': array([ 0.03942852]), 'split2_train_score': array([-0.27862953]), 'split3_train_score': array([-0.2865877]), 'split2_test_score': array([-0.32969566]), 'split0_test_score': array([-0.23020658]), 'mean_score_time': array([ 0.02832681]), 'mean_fit_time': array([ 0.03054667]), 'std_train_score': array([ 0.01546766])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295453349155
####################################################################################
################# Runing the itteration 116  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05123577]), 'mean_train_score': array([-0.05245292]), 'split3_test_score': array([-0.05207471]), 'std_fit_time': array([ 0.0396959]), 'mean_test_score': array([-0.05278444]), 'split1_test_score': array([-0.05500096]), 'std_score_time': array([ 0.00550923]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05247602]), 'std_test_score': array([ 0.00727927]), 'split2_train_score': array([-0.05397149]), 'split3_train_score': array([-0.05212838]), 'split2_test_score': array([-0.04189696]), 'split0_test_score': array([-0.06216512]), 'mean_score_time': array([ 0.52614743]), 'mean_fit_time': array([ 2.78764492]), 'std_train_score': array([ 0.00098658])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0527844388413
####################################################################################
################# Runing the itteration 117  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.37024977]), 'std_fit_time': array([ 0.0159174]), 'mean_test_score': array([ 0.29501321]), 'split1_test_score': array([ 0.3582379]), 'std_score_time': array([ 0.00053533]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.07554878]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.26813125]), 'split0_test_score': array([ 0.18343395]), 'mean_score_time': array([ 0.00361943]), 'mean_fit_time': array([ 0.14947671]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.295013214405
####################################################################################
################# Runing the itteration 118  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.2020125]), 'std_fit_time': array([ 0.00366448]), 'mean_test_score': array([ 0.25859273]), 'split1_test_score': array([ 0.4052137]), 'std_score_time': array([ 0.00078901]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.09180239]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.26336199]), 'split0_test_score': array([ 0.16378272]), 'mean_score_time': array([ 0.00410068]), 'mean_fit_time': array([ 0.08815068]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.258592729189
####################################################################################
################# Runing the itteration 119  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.40316264]), 'mean_train_score': array([ 0.19246574]), 'split3_test_score': array([ 0.04047811]), 'std_fit_time': array([ 0.10366608]), 'mean_test_score': array([ 0.05706826]), 'split1_test_score': array([-0.31738733]), 'std_score_time': array([ 0.00181085]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.13107079]), 'std_test_score': array([ 0.23773547]), 'split2_train_score': array([ 0.20590626]), 'split3_train_score': array([ 0.02972329]), 'split2_test_score': array([ 0.18505591]), 'split0_test_score': array([ 0.32012633]), 'mean_score_time': array([ 0.00786805]), 'mean_fit_time': array([ 0.46231312]), 'std_train_score': array([ 0.13677379])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.0570682555372
####################################################################################
################# Runing the itteration 120  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93065563]), 'mean_train_score': array([ 0.92786941]), 'split3_test_score': array([ 0.61821389]), 'std_fit_time': array([ 0.01168801]), 'mean_test_score': array([ 0.6079251]), 'split1_test_score': array([ 0.53756947]), 'std_score_time': array([ 0.00027552]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.9351261]), 'std_test_score': array([ 0.05495159]), 'split2_train_score': array([ 0.92299151]), 'split3_train_score': array([ 0.92270441]), 'split2_test_score': array([ 0.68904141]), 'split0_test_score': array([ 0.58687564]), 'mean_score_time': array([ 0.00700825]), 'mean_fit_time': array([ 0.53132731]), 'std_train_score': array([ 0.0052653])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.607925102622
####################################################################################
################# Runing the itteration 121  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.47273698]), 'std_fit_time': array([ 0.01800361]), 'mean_test_score': array([ 0.58081737]), 'split1_test_score': array([ 0.66201664]), 'std_score_time': array([ 0.00045655]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.08455495]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.52368113]), 'split0_test_score': array([ 0.66483472]), 'mean_score_time': array([ 0.0059669]), 'mean_fit_time': array([ 0.30081123]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.580817368912
####################################################################################
################# Runing the itteration 122  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.79723585]), 'mean_train_score': array([ 0.79330151]), 'split3_test_score': array([ 0.62312029]), 'std_fit_time': array([ 0.01045549]), 'mean_test_score': array([ 0.65924176]), 'split1_test_score': array([ 0.65253053]), 'std_score_time': array([ 0.00036438]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.80344965]), 'std_test_score': array([ 0.02588504]), 'split2_train_score': array([ 0.79047978]), 'split3_train_score': array([ 0.78204077]), 'split2_test_score': array([ 0.66628768]), 'split0_test_score': array([ 0.69502855]), 'mean_score_time': array([ 0.00396413]), 'mean_fit_time': array([ 0.58317554]), 'std_train_score': array([ 0.0079566])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.659241760312
####################################################################################
################# Runing the itteration 123  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93301856]), 'mean_train_score': array([ 0.93378951]), 'split3_test_score': array([ 0.64991264]), 'std_fit_time': array([ 0.00798762]), 'mean_test_score': array([ 0.6228771]), 'split1_test_score': array([ 0.58586001]), 'std_score_time': array([ 0.00125579]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93276925]), 'std_test_score': array([ 0.02640037]), 'split2_train_score': array([ 0.93573211]), 'split3_train_score': array([ 0.93363811]), 'split2_test_score': array([ 0.64571329]), 'split0_test_score': array([ 0.61002246]), 'mean_score_time': array([ 0.0062862]), 'mean_fit_time': array([ 0.51967931]), 'std_train_score': array([ 0.00116532])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.622877098327
####################################################################################
################# Runing the itteration 124  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.53477946]), 'mean_train_score': array([ 0.53455035]), 'split3_test_score': array([ 0.50988452]), 'std_fit_time': array([ 0.00693168]), 'mean_test_score': array([ 0.52390986]), 'split1_test_score': array([ 0.52440667]), 'std_score_time': array([ 0.00541481]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.5340799]), 'std_test_score': array([ 0.01046053]), 'split2_train_score': array([ 0.53868064]), 'split3_train_score': array([ 0.53066139]), 'split2_test_score': array([ 0.52203633]), 'split0_test_score': array([ 0.53931193]), 'mean_score_time': array([ 0.0167706]), 'mean_fit_time': array([ 0.06013525]), 'std_train_score': array([ 0.00284856])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.523909863346
####################################################################################
################# Runing the itteration 125  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.19118357]), 'mean_train_score': array([ 0.19170438]), 'split3_test_score': array([ 0.18248765]), 'std_fit_time': array([ 0.02488754]), 'mean_test_score': array([ 0.18783208]), 'split1_test_score': array([ 0.19434923]), 'std_score_time': array([  6.11729238e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.18516875]), 'std_test_score': array([ 0.00611639]), 'split2_train_score': array([ 0.18756269]), 'split3_train_score': array([ 0.20290251]), 'split2_test_score': array([ 0.18100403]), 'split0_test_score': array([ 0.1934874]), 'mean_score_time': array([ 0.00316471]), 'mean_fit_time': array([ 0.1202327]), 'std_train_score': array([ 0.00681061])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.18783207729
####################################################################################
################# Runing the itteration 126  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.60062465]), 'mean_train_score': array([ 0.6108119]), 'split3_test_score': array([ 0.57174517]), 'std_fit_time': array([ 0.02370395]), 'mean_test_score': array([ 0.58641154]), 'split1_test_score': array([ 0.55758268]), 'std_score_time': array([ 0.00811995]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61719325]), 'std_test_score': array([ 0.02463445]), 'split2_train_score': array([ 0.60958295]), 'split3_train_score': array([ 0.61584676]), 'split2_test_score': array([ 0.59340619]), 'split0_test_score': array([ 0.62291214]), 'mean_score_time': array([ 0.03412777]), 'mean_fit_time': array([ 0.52603549]), 'std_train_score': array([ 0.00654526])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.586411544638
####################################################################################
################# Runing the itteration 127  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.6208292]), 'mean_train_score': array([ 0.60011579]), 'split3_test_score': array([ 0.61658646]), 'std_fit_time': array([ 0.05682106]), 'mean_test_score': array([ 0.57931678]), 'split1_test_score': array([ 0.55161671]), 'std_score_time': array([ 0.00169796]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.57918595]), 'std_test_score': array([ 0.03274247]), 'split2_train_score': array([ 0.60308887]), 'split3_train_score': array([ 0.59735916]), 'split2_test_score': array([ 0.60682876]), 'split0_test_score': array([ 0.5422352]), 'mean_score_time': array([ 0.00393635]), 'mean_fit_time': array([ 0.13819844]), 'std_train_score': array([ 0.01486222])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.57931678157
####################################################################################
################# Runing the itteration 128  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.60990451]), 'mean_train_score': array([ 0.61277679]), 'split3_test_score': array([ 0.60002302]), 'std_fit_time': array([ 0.00146169]), 'mean_test_score': array([ 0.58895404]), 'split1_test_score': array([ 0.56766314]), 'std_score_time': array([ 0.00050528]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61792093]), 'std_test_score': array([ 0.0131485]), 'split2_train_score': array([ 0.61483012]), 'split3_train_score': array([ 0.60845159]), 'split2_test_score': array([ 0.5884319]), 'split0_test_score': array([ 0.5996981]), 'mean_score_time': array([ 0.00223243]), 'mean_fit_time': array([ 0.07357419]), 'std_train_score': array([ 0.00379591])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.588954042032
####################################################################################
################# Runing the itteration 129  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.29245013]), 'mean_train_score': array([-0.28908525]), 'split3_test_score': array([-0.28144442]), 'std_fit_time': array([ 0.00201071]), 'mean_test_score': array([-0.28986555]), 'split1_test_score': array([-0.3044403]), 'std_score_time': array([ 0.00991432]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28392735]), 'std_test_score': array([ 0.00941825]), 'split2_train_score': array([-0.28809737]), 'split3_train_score': array([-0.29186613]), 'split2_test_score': array([-0.29191424]), 'split0_test_score': array([-0.28166325]), 'mean_score_time': array([ 0.0246917]), 'mean_fit_time': array([ 0.02075171]), 'std_train_score': array([ 0.00341451])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.289865551129
####################################################################################
################# Runing the itteration 130  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.60415431]), 'mean_train_score': array([ 0.61526773]), 'split3_test_score': array([ 0.6238321]), 'std_fit_time': array([ 0.08050476]), 'mean_test_score': array([ 0.60267123]), 'split1_test_score': array([ 0.58412784]), 'std_score_time': array([ 0.00634311]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61971431]), 'std_test_score': array([ 0.02863486]), 'split2_train_score': array([ 0.62929913]), 'split3_train_score': array([ 0.60790318]), 'split2_test_score': array([ 0.56611511]), 'split0_test_score': array([ 0.63660985]), 'mean_score_time': array([ 0.00935465]), 'mean_fit_time': array([ 0.79545993]), 'std_train_score': array([ 0.00992972])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.602671225988
####################################################################################
################# Runing the itteration 131  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.61509501]), 'mean_train_score': array([ 0.60260475]), 'split3_test_score': array([ 0.60035081]), 'std_fit_time': array([ 0.01382789]), 'mean_test_score': array([ 0.58936609]), 'split1_test_score': array([ 0.6048043]), 'std_score_time': array([ 0.01423823]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59971657]), 'std_test_score': array([ 0.01408306]), 'split2_train_score': array([ 0.6017306]), 'split3_train_score': array([ 0.59387683]), 'split2_test_score': array([ 0.58268309]), 'split0_test_score': array([ 0.56962616]), 'mean_score_time': array([ 0.02908176]), 'mean_fit_time': array([ 0.03145134]), 'std_train_score': array([ 0.00776674])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.589366090441
####################################################################################
################# Runing the itteration 132  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.61873417]), 'mean_train_score': array([ 0.59716827]), 'split3_test_score': array([ 0.55405697]), 'std_fit_time': array([ 0.00598233]), 'mean_test_score': array([ 0.58343943]), 'split1_test_score': array([ 0.61122576]), 'std_score_time': array([ 0.00065467]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58874433]), 'std_test_score': array([ 0.0443791]), 'split2_train_score': array([ 0.57602706]), 'split3_train_score': array([ 0.60516753]), 'split2_test_score': array([ 0.64010043]), 'split0_test_score': array([ 0.52837456]), 'mean_score_time': array([ 0.00273514]), 'mean_fit_time': array([ 0.03524971]), 'std_train_score': array([ 0.01617861])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.583439430494
####################################################################################
################# Runing the itteration 133  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ 0.34263805]), 'mean_train_score': array([ -3.22905702e+23]), 'split3_test_score': array([ -1.25290819e+22]), 'std_fit_time': array([ 0.16752594]), 'mean_test_score': array([ -2.36207702e+23]), 'split1_test_score': array([-441765.95501564]), 'std_score_time': array([ 0.00047029]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-675117.10227754]), 'std_test_score': array([  4.01922620e+23]), 'split2_train_score': array([ -1.27780182e+24]), 'split3_train_score': array([ -1.38209845e+22]), 'split2_test_score': array([ -9.32301725e+23]), 'split0_test_score': array([ 0.36617286]), 'mean_score_time': array([ 0.00165588]), 'mean_fit_time': array([ 0.56778687]), 'std_train_score': array([  5.51338406e+23])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.3620770169e+23
####################################################################################
################# Runing the itteration 134  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.67686294]), 'mean_train_score': array([ 0.67191545]), 'split3_test_score': array([ 0.43503834]), 'std_fit_time': array([ 0.00095773]), 'mean_test_score': array([ 0.5014656]), 'split1_test_score': array([ 0.5567522]), 'std_score_time': array([ 0.02850249]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64931477]), 'std_test_score': array([ 0.04503636]), 'split2_train_score': array([ 0.66892814]), 'split3_train_score': array([ 0.69255596]), 'split2_test_score': array([ 0.48997946]), 'split0_test_score': array([ 0.52409241]), 'mean_score_time': array([ 0.31618327]), 'mean_fit_time': array([ 0.02441782]), 'std_train_score': array([ 0.0155742])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.50146560251
####################################################################################
################# Runing the itteration 135  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50146560251025341}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50146560251025341}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], y=2674     21171695
192     431942139
2930     151...    454161935
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50146560251025341}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns]
        y = 2674     21171695
192     431942139
2930     151...    454161935
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], y=2674     21171695
192     431942139
2930     151...    454161935
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns]
        y = 2674     21171695
192     431942139
2930     151...    454161935
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], y=2674     21171695
192     431942139
2930     151...    454161935
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 12:51:19 2017
PID: 11120                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], 2674     21171695
192     431942139
2930     151...    454161935
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], 2674     21171695
192     431942139
2930     151...    454161935
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], y=2674     21171695
192     431942139
2930     151...    454161935
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns]
        y_test = 2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], y_test=2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns]
        y_test = 2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], 2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], 2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], 2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], 2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], y=2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns]
        y = 2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], y=2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64, y_pred=array([ 23076424.33333333,                nan,  ...    nan,  53929987.25      ,                nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 2674     21171695
192     431942139
2930     151...     18527766
Name: worldwide_gross, dtype: int64
        y_pred = array([ 23076424.33333333,                nan,  ...    nan,  53929987.25      ,                nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 21171695, 431942139,  15171475, ...,  43340302,  56445534,
        18527766]), y_pred=array([ 23076424.33333333,                nan,  ...    nan,  53929987.25      ,                nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([ 23076424.33333333,                nan,  ...    nan,  53929987.25      ,                nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([ 23076424.33333333,                nan,  ...    nan,  53929987.25      ,                nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([ 23076424.33333333,                nan,  ...    nan,  53929987.25      ,                nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([ 23076424.33333333,                nan,  ...    nan,  53929987.25      ,                nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 136  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  19.4s
[CV]  ................................................................
[CV] ................................................. , total=  15.5s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.27605782]), 'mean_train_score': array([-0.289501]), 'split3_test_score': array([-0.2705067]), 'std_fit_time': array([ 2.4665918]), 'mean_test_score': array([-0.29038942]), 'split1_test_score': array([-0.28367367]), 'std_score_time': array([ 0.00412654]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29150615]), 'std_test_score': array([ 0.02426772]), 'split2_train_score': array([-0.29426349]), 'split3_train_score': array([-0.29617656]), 'split2_test_score': array([-0.27574652]), 'split0_test_score': array([-0.33163078]), 'mean_score_time': array([ 0.00911844]), 'mean_fit_time': array([ 19.40694559]), 'std_train_score': array([ 0.007937])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290389420154
####################################################################################
################# Runing the itteration 137  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13527705]), 'mean_train_score': array([-0.13185012]), 'split3_test_score': array([-0.15230062]), 'std_fit_time': array([ 0.02033063]), 'mean_test_score': array([-0.13251325]), 'split1_test_score': array([-0.11760329]), 'std_score_time': array([ 0.00333621]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13256366]), 'std_test_score': array([ 0.01582056]), 'split2_train_score': array([-0.13409245]), 'split3_train_score': array([-0.12546733]), 'split2_test_score': array([-0.14377524]), 'split0_test_score': array([-0.11637383]), 'mean_score_time': array([ 0.42402339]), 'mean_fit_time': array([ 1.78673428]), 'std_train_score': array([ 0.00380858])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.13251324591
####################################################################################
################# Runing the itteration 138  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28724202]), 'mean_train_score': array([-0.28986377]), 'split3_test_score': array([-0.23960758]), 'std_fit_time': array([ 0.0029035]), 'mean_test_score': array([-0.29270082]), 'split1_test_score': array([-0.31178336]), 'std_score_time': array([ 0.02473787]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28326195]), 'std_test_score': array([ 0.03210736]), 'split2_train_score': array([-0.27923285]), 'split3_train_score': array([-0.30971827]), 'split2_test_score': array([-0.32316224]), 'split0_test_score': array([-0.2962501]), 'mean_score_time': array([ 0.02621859]), 'mean_fit_time': array([ 0.02093101]), 'std_train_score': array([ 0.01180757])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292700822619
####################################################################################
################# Runing the itteration 139  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05355438]), 'mean_train_score': array([-0.05275681]), 'split3_test_score': array([-0.04577779]), 'std_fit_time': array([ 0.01588754]), 'mean_test_score': array([-0.05369798]), 'split1_test_score': array([-0.07081405]), 'std_score_time': array([ 0.00073591]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05531567]), 'std_test_score': array([ 0.01618537]), 'split2_train_score': array([-0.05044018]), 'split3_train_score': array([-0.05171702]), 'split2_test_score': array([-0.06712632]), 'split0_test_score': array([-0.03107377]), 'mean_score_time': array([ 0.21122777]), 'mean_fit_time': array([ 1.42635733]), 'std_train_score': array([ 0.00184606])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0536979800489
####################################################################################
################# Runing the itteration 140  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.30417068]), 'std_fit_time': array([ 0.00750244]), 'mean_test_score': array([ 0.28620784]), 'split1_test_score': array([ 0.23039985]), 'std_score_time': array([ 0.00023166]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.06191052]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.37989113]), 'split0_test_score': array([ 0.2303697]), 'mean_score_time': array([ 0.00196707]), 'mean_fit_time': array([ 0.09808338]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.286207840701
####################################################################################
################# Runing the itteration 141  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.32052816]), 'std_fit_time': array([ 0.00480595]), 'mean_test_score': array([ 0.33184119]), 'split1_test_score': array([ 0.36691734]), 'std_score_time': array([ 0.00015011]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.02114969]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.31134063]), 'split0_test_score': array([ 0.32857862]), 'mean_score_time': array([ 0.00207496]), 'mean_fit_time': array([ 0.04453158]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.331841185294
####################################################################################
################# Runing the itteration 142  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.4741923]), 'mean_train_score': array([ 0.29441271]), 'split3_test_score': array([ 0.39675291]), 'std_fit_time': array([ 0.11341352]), 'mean_test_score': array([ 0.22803403]), 'split1_test_score': array([ 0.24521611]), 'std_score_time': array([ 0.00147897]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.3570682]), 'std_test_score': array([ 0.1343637]), 'split2_train_score': array([-0.14056413]), 'split3_train_score': array([ 0.48695445]), 'split2_test_score': array([ 0.02068611]), 'split0_test_score': array([ 0.24948099]), 'mean_score_time': array([ 0.00760901]), 'mean_fit_time': array([ 0.56820679]), 'std_train_score': array([ 0.25618528])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.228034029394
####################################################################################
################# Runing the itteration 143  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92012417]), 'mean_train_score': array([ 0.92261809]), 'split3_test_score': array([ 0.51599792]), 'std_fit_time': array([ 0.02896739]), 'mean_test_score': array([ 0.57079739]), 'split1_test_score': array([ 0.59362299]), 'std_score_time': array([ 0.00054858]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.9145663]), 'std_test_score': array([ 0.03376656]), 'split2_train_score': array([ 0.92501469]), 'split3_train_score': array([ 0.93076721]), 'split2_test_score': array([ 0.57057369]), 'split0_test_score': array([ 0.60299496]), 'mean_score_time': array([ 0.00914669]), 'mean_fit_time': array([ 0.88970351]), 'std_train_score': array([ 0.00598337])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.570797389945
####################################################################################
################# Runing the itteration 144  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.60266636]), 'std_fit_time': array([ 0.02221388]), 'mean_test_score': array([ 0.55414055]), 'split1_test_score': array([ 0.57027116]), 'std_score_time': array([ 0.00021954]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.04778902]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.47474864]), 'split0_test_score': array([ 0.56887603]), 'mean_score_time': array([ 0.00708133]), 'mean_fit_time': array([ 0.55196446]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.554140548021
####################################################################################
################# Runing the itteration 145  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.78144236]), 'mean_train_score': array([ 0.76964744]), 'split3_test_score': array([ 0.55240218]), 'std_fit_time': array([ 0.08563554]), 'mean_test_score': array([ 0.58846054]), 'split1_test_score': array([ 0.6268277]), 'std_score_time': array([ 0.00208036]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.74913613]), 'std_test_score': array([ 0.02654288]), 'split2_train_score': array([ 0.76475797]), 'split3_train_score': array([ 0.7832533]), 'split2_test_score': array([ 0.59195306]), 'split0_test_score': array([ 0.58265921]), 'mean_score_time': array([ 0.00639838]), 'mean_fit_time': array([ 1.03749532]), 'std_train_score': array([ 0.01386416])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.588460537495
####################################################################################
################# Runing the itteration 146  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.91528933]), 'mean_train_score': array([ 0.92761793]), 'split3_test_score': array([ 0.56620038]), 'std_fit_time': array([ 0.01048481]), 'mean_test_score': array([ 0.58096555]), 'split1_test_score': array([ 0.59988933]), 'std_score_time': array([ 0.00014799]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93308994]), 'std_test_score': array([ 0.03001452]), 'split2_train_score': array([ 0.93128076]), 'split3_train_score': array([ 0.93081169]), 'split2_test_score': array([ 0.61773672]), 'split0_test_score': array([ 0.54003577]), 'mean_score_time': array([ 0.00625861]), 'mean_fit_time': array([ 0.85897613]), 'std_train_score': array([ 0.00716857])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.580965552834
####################################################################################
################# Runing the itteration 147  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.61453263]), 'mean_train_score': array([ 0.59467066]), 'split3_test_score': array([ 0.59764862]), 'std_fit_time': array([ 0.00274927]), 'mean_test_score': array([ 0.56648507]), 'split1_test_score': array([ 0.59582189]), 'std_score_time': array([ 0.00973501]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58261212]), 'std_test_score': array([ 0.03419365]), 'split2_train_score': array([ 0.59455254]), 'split3_train_score': array([ 0.58698534]), 'split2_test_score': array([ 0.5587611]), 'split0_test_score': array([ 0.51370868]), 'mean_score_time': array([ 0.03406316]), 'mean_fit_time': array([ 0.10522836]), 'std_train_score': array([ 0.01223708])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.566485072513
####################################################################################
################# Runing the itteration 148  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.25237724]), 'mean_train_score': array([ 0.26225509]), 'split3_test_score': array([ 0.256365]), 'std_fit_time': array([ 0.08430473]), 'mean_test_score': array([ 0.25837589]), 'split1_test_score': array([ 0.22723258]), 'std_score_time': array([ 0.000532]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.26571263]), 'std_test_score': array([ 0.01994331]), 'split2_train_score': array([ 0.26088938]), 'split3_train_score': array([ 0.2700411]), 'split2_test_score': array([ 0.26914815]), 'split0_test_score': array([ 0.28075782]), 'mean_score_time': array([ 0.00397694]), 'mean_fit_time': array([ 0.32427192]), 'std_train_score': array([ 0.0065577])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.258375886416
####################################################################################
################# Runing the itteration 149  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.63147602]), 'mean_train_score': array([ 0.62757646]), 'split3_test_score': array([ 0.5800775]), 'std_fit_time': array([ 0.06815683]), 'mean_test_score': array([ 0.55744283]), 'split1_test_score': array([ 0.50761496]), 'std_score_time': array([ 0.00686006]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61625862]), 'std_test_score': array([ 0.02915485]), 'split2_train_score': array([ 0.63142587]), 'split3_train_score': array([ 0.63114533]), 'split2_test_score': array([ 0.56684764]), 'split0_test_score': array([ 0.5752312]), 'mean_score_time': array([ 0.02766734]), 'mean_fit_time': array([ 1.15024364]), 'std_train_score': array([ 0.00653557])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.557442825363
####################################################################################
################# Runing the itteration 150  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.6036884]), 'mean_train_score': array([ 0.61725915]), 'split3_test_score': array([ 0.54333546]), 'std_fit_time': array([ 0.05152683]), 'mean_test_score': array([ 0.3947347]), 'split1_test_score': array([ 0.57312099]), 'std_score_time': array([ 0.00476868]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62412019]), 'std_test_score': array([ 0.322497]), 'split2_train_score': array([ 0.60735765]), 'split3_train_score': array([ 0.63387038]), 'split2_test_score': array([ 0.62408538]), 'split0_test_score': array([-0.16160302]), 'mean_score_time': array([ 0.00979412]), 'mean_fit_time': array([ 0.13378167]), 'std_train_score': array([ 0.01230053])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.394734701407
####################################################################################
################# Runing the itteration 151  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.63252445]), 'mean_train_score': array([ 0.62682554]), 'split3_test_score': array([ 0.62772948]), 'std_fit_time': array([ 0.03239433]), 'mean_test_score': array([ 0.54464125]), 'split1_test_score': array([ 0.55874]), 'std_score_time': array([ 0.00678665]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63400937]), 'std_test_score': array([ 0.07061483]), 'split2_train_score': array([ 0.6312995]), 'split3_train_score': array([ 0.60946882]), 'split2_test_score': array([ 0.43232674]), 'split0_test_score': array([ 0.55976878]), 'mean_score_time': array([ 0.0122757]), 'mean_fit_time': array([ 0.13738352]), 'std_train_score': array([ 0.01006674])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.544641249487
####################################################################################
################# Runing the itteration 152  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.27915551]), 'mean_train_score': array([-0.28969356]), 'split3_test_score': array([-0.24511307]), 'std_fit_time': array([ 0.00545559]), 'mean_test_score': array([-0.2955758]), 'split1_test_score': array([-0.28604634]), 'std_score_time': array([ 0.00751955]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28995991]), 'std_test_score': array([ 0.0341299]), 'split2_train_score': array([-0.28053392]), 'split3_train_score': array([-0.30912489]), 'split2_test_score': array([-0.31502273]), 'split0_test_score': array([-0.33612107]), 'mean_score_time': array([ 0.01727611]), 'mean_fit_time': array([ 0.0298714]), 'std_train_score': array([ 0.0119645])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295575803198
####################################################################################
################# Runing the itteration 153  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.62948207]), 'mean_train_score': array([ 0.627163]), 'split3_test_score': array([ 0.0467154]), 'std_fit_time': array([ 0.06983518]), 'mean_test_score': array([ 0.4573033]), 'split1_test_score': array([ 0.63700777]), 'std_score_time': array([ 0.00720141]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61057409]), 'std_test_score': array([ 0.23861471]), 'split2_train_score': array([ 0.62709508]), 'split3_train_score': array([ 0.64150076]), 'split2_test_score': array([ 0.5831907]), 'split0_test_score': array([ 0.56229933]), 'mean_score_time': array([ 0.02733999]), 'mean_fit_time': array([ 1.62586838]), 'std_train_score': array([ 0.01102436])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.457303300695
####################################################################################
################# Runing the itteration 154  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.62233769]), 'mean_train_score': array([-373709.95763883]), 'split3_test_score': array([-15843.01624869]), 'std_fit_time': array([ 0.00358436]), 'mean_test_score': array([-36769.52635241]), 'split1_test_score': array([-85384.88009906]), 'std_score_time': array([ 0.00565056]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-421896.96994923]), 'std_test_score': array([ 32541.80382799]), 'split2_train_score': array([-269234.25933357]), 'split3_train_score': array([-803709.22361022]), 'split2_test_score': array([-45850.72894277]), 'split0_test_score': array([ 0.51988086]), 'mean_score_time': array([ 0.01361406]), 'mean_fit_time': array([ 0.02886832]), 'std_train_score': array([ 290601.15537197])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-36769.5263524
####################################################################################
################# Runing the itteration 155  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.60490083]), 'mean_train_score': array([ 0.60971773]), 'split3_test_score': array([ 0.5936964]), 'std_fit_time': array([ 0.00744754]), 'mean_test_score': array([ 0.58255902]), 'split1_test_score': array([ 0.53560131]), 'std_score_time': array([ 0.01611281]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61705019]), 'std_test_score': array([ 0.02759845]), 'split2_train_score': array([ 0.6079468]), 'split3_train_score': array([ 0.6089731]), 'split2_test_score': array([ 0.59430145]), 'split0_test_score': array([ 0.60663691]), 'mean_score_time': array([ 0.01770854]), 'mean_fit_time': array([ 0.05381173]), 'std_train_score': array([ 0.00449049])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.582559015178
####################################################################################
################# Runing the itteration 156  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -1.44076387e+23]), 'mean_train_score': array([ -2.70592012e+23]), 'split3_test_score': array([ -4.16237208e+22]), 'std_fit_time': array([ 0.19649768]), 'mean_test_score': array([ -2.63877388e+23]), 'split1_test_score': array([ -7.16937080e+23]), 'std_score_time': array([ 0.00138241]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -6.80099315e+23]), 'std_test_score': array([  2.65686895e+23]), 'split2_train_score': array([ -2.18994967e+23]), 'split3_train_score': array([ -3.91973811e+22]), 'split2_test_score': array([ -1.71524512e+23]), 'split0_test_score': array([ -1.25424239e+23]), 'mean_score_time': array([ 0.0032509]), 'mean_fit_time': array([ 2.11556017]), 'std_train_score': array([  2.44902105e+23])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.63877388023e+23
####################################################################################
################# Runing the itteration 157  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.62677485]), 'mean_train_score': array([ 0.62424635]), 'split3_test_score': array([ 0.31393809]), 'std_fit_time': array([ 0.0056703]), 'mean_test_score': array([ 0.39094753]), 'split1_test_score': array([ 0.4754749]), 'std_score_time': array([ 0.07725244]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59744802]), 'std_test_score': array([ 0.06460465]), 'split2_train_score': array([ 0.61870371]), 'split3_train_score': array([ 0.65405881]), 'split2_test_score': array([ 0.42956458]), 'split0_test_score': array([ 0.34481256]), 'mean_score_time': array([ 0.60788548]), 'mean_fit_time': array([ 0.05242294]), 'std_train_score': array([ 0.02027343])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.390947533811
####################################################################################
################# Runing the itteration 158  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50146560251025341}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.86304212,
        -0.06123763, -0.10636806]])}
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50146560251025341}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], y=4282        109338
2398      29090445
4129      ...   1123790543
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50146560251025341}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns]
        y = 4282        109338
2398      29090445
4129      ...   1123790543
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], y=4282        109338
2398      29090445
4129      ...   1123790543
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns]
        y = 4282        109338
2398      29090445
4129      ...   1123790543
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], y=4282        109338
2398      29090445
4129      ...   1123790543
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 12:56:57 2017
PID: 12407                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], 4282        109338
2398      29090445
4129      ...   1123790543
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], 4282        109338
2398      29090445
4129      ...   1123790543
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], y=4282        109338
2398      29090445
4129      ...   1123790543
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns]
        y_test = 4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], y_test=4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns]
        y_test = 4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], 4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], 4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], 4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], 4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], y=4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns]
        y = 4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], y=4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64, y_pred=array([               nan,    290875.        ,  ...7142857,                nan,  92961960.        ]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 4282       109338
2398     29090445
4129       4...     52287414
Name: worldwide_gross, dtype: int64
        y_pred = array([               nan,    290875.        ,  ...7142857,                nan,  92961960.        ])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([   109338,  29090445,    407100, ...,  18225165, 631910531,
        52287414]), y_pred=array([               nan,    290875.        ,  ...7142857,                nan,  92961960.        ]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([               nan,    290875.        ,  ...7142857,                nan,  92961960.        ])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([               nan,    290875.        ,  ...7142857,                nan,  92961960.        ]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([               nan,    290875.        ,  ...7142857,                nan,  92961960.        ])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([               nan,    290875.        ,  ...7142857,                nan,  92961960.        ]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 159  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  35.4s
[CV]  ................................................................
[CV] ................................................. , total=  38.5s
[CV]  ................................................................
[CV] ................................................. , total=  38.2s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28539625]), 'mean_train_score': array([-0.29037296]), 'split3_test_score': array([-0.31467367]), 'std_fit_time': array([ 2.49758048]), 'mean_test_score': array([-0.29702489]), 'split1_test_score': array([-0.32108292]), 'std_score_time': array([ 0.89304595]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28266685]), 'std_test_score': array([ 0.02922107]), 'split2_train_score': array([-0.31222621]), 'split3_train_score': array([-0.28120254]), 'split2_test_score': array([-0.24740095]), 'split0_test_score': array([-0.30494202]), 'mean_score_time': array([ 0.53004253]), 'mean_fit_time': array([ 37.46775746]), 'std_train_score': array([ 0.01270643])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.297024891282
####################################################################################
################# Runing the itteration 160  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13064601]), 'mean_train_score': array([-0.13179883]), 'split3_test_score': array([-0.13266867]), 'std_fit_time': array([ 0.04284328]), 'mean_test_score': array([-0.13298497]), 'split1_test_score': array([-0.1331565]), 'std_score_time': array([ 0.03421294]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.1281174]), 'std_test_score': array([ 0.0075705]), 'split2_train_score': array([-0.13512834]), 'split3_train_score': array([-0.13330357]), 'split2_test_score': array([-0.12235432]), 'split0_test_score': array([-0.14376038]), 'mean_score_time': array([ 0.73143101]), 'mean_fit_time': array([ 2.69888401]), 'std_train_score': array([ 0.00265668])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132984966034
####################################################################################
################# Runing the itteration 161  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.27899212]), 'mean_train_score': array([-0.2903278]), 'split3_test_score': array([-0.24261293]), 'std_fit_time': array([ 0.00211631]), 'mean_test_score': array([-0.29738597]), 'split1_test_score': array([-0.33630636]), 'std_score_time': array([ 0.00782269]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27850872]), 'std_test_score': array([ 0.03831621]), 'split2_train_score': array([-0.29428622]), 'split3_train_score': array([-0.30952416]), 'split2_test_score': array([-0.28049302]), 'split0_test_score': array([-0.33013155]), 'mean_score_time': array([ 0.0212096]), 'mean_fit_time': array([ 0.02683043]), 'std_train_score': array([ 0.01277065])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.297385965158
####################################################################################
################# Runing the itteration 162  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05177422]), 'mean_train_score': array([-0.05248185]), 'split3_test_score': array([-0.05016269]), 'std_fit_time': array([ 0.02923483]), 'mean_test_score': array([-0.05303268]), 'split1_test_score': array([-0.05516067]), 'std_score_time': array([ 0.00381518]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05225605]), 'std_test_score': array([ 0.00183939]), 'split2_train_score': array([-0.05177829]), 'split3_train_score': array([-0.05411884]), 'split2_test_score': array([-0.05390015]), 'split0_test_score': array([-0.0529072]), 'mean_score_time': array([ 0.35590959]), 'mean_fit_time': array([ 2.07976198]), 'std_train_score': array([ 0.0009652])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0530326770134
####################################################################################
################# Runing the itteration 163  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.12171178]), 'std_fit_time': array([ 0.00161388]), 'mean_test_score': array([ 0.29874738]), 'split1_test_score': array([ 0.38167569]), 'std_score_time': array([ 0.00039755]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.10697773]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.30624007]), 'split0_test_score': array([ 0.38536196]), 'mean_score_time': array([ 0.00285846]), 'mean_fit_time': array([ 0.15234655]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.298747376348
####################################################################################
################# Runing the itteration 164  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.30429286]), 'std_fit_time': array([ 0.01549841]), 'mean_test_score': array([ 0.30761501]), 'split1_test_score': array([ 0.30840247]), 'std_score_time': array([ 0.00024765]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.00540779]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.31602755]), 'split0_test_score': array([ 0.30173716]), 'mean_score_time': array([ 0.00283611]), 'mean_fit_time': array([ 0.08214879]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.307615009176
####################################################################################
################# Runing the itteration 165  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.56292797]), 'mean_train_score': array([ 0.14189667]), 'split3_test_score': array([-0.40558674]), 'std_fit_time': array([ 0.3031509]), 'mean_test_score': array([ 0.06741791]), 'split1_test_score': array([-0.24595507]), 'std_score_time': array([ 0.00465066]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.19332519]), 'std_test_score': array([ 0.39916977]), 'split2_train_score': array([ 0.60393136]), 'split3_train_score': array([-0.40594745]), 'split2_test_score': array([ 0.51635217]), 'split0_test_score': array([ 0.4048613]), 'mean_score_time': array([ 0.01168007]), 'mean_fit_time': array([ 0.82109058]), 'std_train_score': array([ 0.44812116])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.0674179138794
####################################################################################
################# Runing the itteration 166  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92932783]), 'mean_train_score': array([ 0.93187756]), 'split3_test_score': array([ 0.57970536]), 'std_fit_time': array([ 0.03589769]), 'mean_test_score': array([ 0.60416868]), 'split1_test_score': array([ 0.56193062]), 'std_score_time': array([ 0.00463137]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93714878]), 'std_test_score': array([ 0.0397145]), 'split2_train_score': array([ 0.92752486]), 'split3_train_score': array([ 0.93350879]), 'split2_test_score': array([ 0.60834813]), 'split0_test_score': array([ 0.66669061]), 'mean_score_time': array([ 0.01484483]), 'mean_fit_time': array([ 1.03573513]), 'std_train_score': array([ 0.00373811])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.604168680026
####################################################################################
################# Runing the itteration 167  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.61402027]), 'std_fit_time': array([ 0.02861817]), 'mean_test_score': array([ 0.56983013]), 'split1_test_score': array([ 0.55949162]), 'std_score_time': array([ 0.0002739]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.03885322]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.59416974]), 'split0_test_score': array([ 0.51163889]), 'mean_score_time': array([ 0.00712609]), 'mean_fit_time': array([ 0.75998271]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.569830129687
####################################################################################
################# Runing the itteration 168  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.76653707]), 'mean_train_score': array([ 0.77038039]), 'split3_test_score': array([ 0.55584015]), 'std_fit_time': array([ 0.02752771]), 'mean_test_score': array([ 0.60288219]), 'split1_test_score': array([ 0.6035346]), 'std_score_time': array([ 0.00054863]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.76440124]), 'std_test_score': array([ 0.03012194]), 'split2_train_score': array([ 0.77656018]), 'split3_train_score': array([ 0.77402308]), 'split2_test_score': array([ 0.61303961]), 'split0_test_score': array([ 0.63911441]), 'mean_score_time': array([ 0.00565976]), 'mean_fit_time': array([ 1.4219324]), 'std_train_score': array([ 0.00504927])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.602882194569
####################################################################################
################# Runing the itteration 169  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92732431]), 'mean_train_score': array([ 0.92573722]), 'split3_test_score': array([ 0.63036818]), 'std_fit_time': array([ 0.03411629]), 'mean_test_score': array([ 0.59380739]), 'split1_test_score': array([ 0.62971586]), 'std_score_time': array([ 0.00155784]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.91793312]), 'std_test_score': array([ 0.03682522]), 'split2_train_score': array([ 0.93202656]), 'split3_train_score': array([ 0.92566489]), 'split2_test_score': array([ 0.54828895]), 'split0_test_score': array([ 0.56685655]), 'mean_score_time': array([ 0.00827467]), 'mean_fit_time': array([ 1.0160538]), 'std_train_score': array([ 0.00507405])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.593807386854
####################################################################################
################# Runing the itteration 170  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.5917304]), 'mean_train_score': array([ 0.60806328]), 'split3_test_score': array([ 0.57772195]), 'std_fit_time': array([ 0.00841479]), 'mean_test_score': array([ 0.57007716]), 'split1_test_score': array([ 0.57208443]), 'std_score_time': array([ 0.02190989]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61374144]), 'std_test_score': array([ 0.0158249]), 'split2_train_score': array([ 0.61855862]), 'split3_train_score': array([ 0.60822267]), 'split2_test_score': array([ 0.54412466]), 'split0_test_score': array([ 0.58637762]), 'mean_score_time': array([ 0.02308065]), 'mean_fit_time': array([ 0.17411232]), 'std_train_score': array([ 0.01011412])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.570077164675
####################################################################################
################# Runing the itteration 171  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.27425308]), 'mean_train_score': array([ 0.26741871]), 'split3_test_score': array([ 0.25210023]), 'std_fit_time': array([ 0.06686706]), 'mean_test_score': array([ 0.25839736]), 'split1_test_score': array([ 0.26283824]), 'std_score_time': array([ 0.00221492]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.27059352]), 'std_test_score': array([ 0.01447459]), 'split2_train_score': array([ 0.2540319]), 'split3_train_score': array([ 0.27079633]), 'split2_test_score': array([ 0.23961564]), 'split0_test_score': array([ 0.27903534]), 'mean_score_time': array([ 0.00601792]), 'mean_fit_time': array([ 0.43024224]), 'std_train_score': array([ 0.00786453])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.258397363506
####################################################################################
################# Runing the itteration 172  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.648654]), 'mean_train_score': array([ 0.64206849]), 'split3_test_score': array([ 0.59663253]), 'std_fit_time': array([ 0.06586322]), 'mean_test_score': array([ 0.56140825]), 'split1_test_score': array([ 0.59376513]), 'std_score_time': array([ 0.01808651]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63934883]), 'std_test_score': array([ 0.04072426]), 'split2_train_score': array([ 0.66293651]), 'split3_train_score': array([ 0.61733463]), 'split2_test_score': array([ 0.4955043]), 'split0_test_score': array([ 0.55973103]), 'mean_score_time': array([ 0.0288589]), 'mean_fit_time': array([ 1.85939354]), 'std_train_score': array([ 0.01656807])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.561408248711
####################################################################################
################# Runing the itteration 173  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.61940559]), 'mean_train_score': array([ 0.61899086]), 'split3_test_score': array([ 0.56189205]), 'std_fit_time': array([ 0.05417471]), 'mean_test_score': array([ 0.57346143]), 'split1_test_score': array([ 0.64336937]), 'std_score_time': array([ 0.00126996]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59451401]), 'std_test_score': array([ 0.04459296]), 'split2_train_score': array([ 0.64493415]), 'split3_train_score': array([ 0.61710969]), 'split2_test_score': array([ 0.5194782]), 'split0_test_score': array([ 0.5691061]), 'mean_score_time': array([ 0.00389886]), 'mean_fit_time': array([ 0.14931577]), 'std_train_score': array([ 0.01785974])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.573461429541
####################################################################################
################# Runing the itteration 174  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.61602058]), 'mean_train_score': array([ 0.642058]), 'split3_test_score': array([ 0.59870796]), 'std_fit_time': array([ 0.07374311]), 'mean_test_score': array([ 0.56080087]), 'split1_test_score': array([ 0.54320992]), 'std_score_time': array([ 0.00244047]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65186744]), 'std_test_score': array([ 0.04591401]), 'split2_train_score': array([ 0.65634769]), 'split3_train_score': array([ 0.64399628]), 'split2_test_score': array([ 0.49372346]), 'split0_test_score': array([ 0.60756216]), 'mean_score_time': array([ 0.00504649]), 'mean_fit_time': array([ 0.22712773]), 'std_train_score': array([ 0.01566943])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.560800873295
####################################################################################
################# Runing the itteration 175  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28171783]), 'mean_train_score': array([-0.28962508]), 'split3_test_score': array([-0.33078066]), 'std_fit_time': array([ 0.01583095]), 'mean_test_score': array([-0.29517273]), 'split1_test_score': array([-0.2600448]), 'std_score_time': array([ 0.00748082]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.30152592]), 'std_test_score': array([ 0.0291434]), 'split2_train_score': array([-0.29579092]), 'split3_train_score': array([-0.27946563]), 'split2_test_score': array([-0.27377451]), 'split0_test_score': array([-0.31609093]), 'mean_score_time': array([ 0.01502931]), 'mean_fit_time': array([ 0.04567236]), 'std_train_score': array([ 0.00929229])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29517272739
####################################################################################
################# Runing the itteration 176  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.7s
[CV]  ................................................................
[CV] ................................................. , total=   2.7s
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.65771412]), 'mean_train_score': array([ 0.64324192]), 'split3_test_score': array([ 0.60250638]), 'std_fit_time': array([ 0.20827665]), 'mean_test_score': array([ 0.47432147]), 'split1_test_score': array([ 0.26557741]), 'std_score_time': array([ 0.00475711]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63210722]), 'std_test_score': array([ 0.12615828]), 'split2_train_score': array([ 0.65906926]), 'split3_train_score': array([ 0.62407708]), 'split2_test_score': array([ 0.50022565]), 'split0_test_score': array([ 0.52897643]), 'mean_score_time': array([ 0.01224083]), 'mean_fit_time': array([ 2.89985442]), 'std_train_score': array([ 0.01542094])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.474321466829
####################################################################################
################# Runing the itteration 177  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-7393.31197005]), 'mean_train_score': array([-48015.14013598]), 'split3_test_score': array([-1148.11634036]), 'std_fit_time': array([ 0.00299912]), 'mean_test_score': array([-3196.1057638]), 'split1_test_score': array([-10619.40405657]), 'std_score_time': array([ 0.00592978]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-169703.87338619]), 'std_test_score': array([ 4296.95323627]), 'split2_train_score': array([-1142.4856413]), 'split3_train_score': array([-13820.88954639]), 'split2_test_score': array([-275.38747911]), 'split0_test_score': array([-741.51517915]), 'mean_score_time': array([ 0.01604772]), 'mean_fit_time': array([ 0.03626198]), 'std_train_score': array([ 70399.88145648])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3196.1057638
####################################################################################
################# Runing the itteration 178  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.62333595]), 'mean_train_score': array([ 0.6183322]), 'split3_test_score': array([ 0.63658953]), 'std_fit_time': array([ 0.02740159]), 'mean_test_score': array([ 0.58600478]), 'split1_test_score': array([ 0.58356509]), 'std_score_time': array([ 0.01052292]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61819856]), 'std_test_score': array([ 0.03051127]), 'split2_train_score': array([ 0.6316951]), 'split3_train_score': array([ 0.60009918]), 'split2_test_score': array([ 0.56199507]), 'split0_test_score': array([ 0.56186944]), 'mean_score_time': array([ 0.00863373]), 'mean_fit_time': array([ 0.07782757]), 'std_train_score': array([ 0.01157654])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.586004780369
####################################################################################
################# Runing the itteration 179  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   5.1s
[CV]  ................................................................
[CV] ................................................. , total=   5.2s
[CV]  ................................................................
[CV] ................................................. , total=   5.3s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -9.97764818e+24]), 'mean_train_score': array([ -3.86561204e+25]), 'split3_test_score': array([ -1.84504112e+25]), 'std_fit_time': array([ 0.1640708]), 'mean_test_score': array([ -4.76913042e+25]), 'split1_test_score': array([ -4.18837293e+25]), 'std_score_time': array([ 0.00225171]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -3.39837102e+25]), 'std_test_score': array([  4.32719838e+25]), 'split2_train_score': array([ -9.34835650e+25]), 'split3_train_score': array([ -1.71795582e+25]), 'split2_test_score': array([ -1.19927982e+26]), 'split0_test_score': array([ -1.05030944e+25]), 'mean_score_time': array([ 0.00558007]), 'mean_fit_time': array([ 5.26283127]), 'std_train_score': array([  3.28313021e+25])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-4.76913042104e+25
####################################################################################
################# Runing the itteration 180  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.57919652]), 'mean_train_score': array([ 0.59090331]), 'split3_test_score': array([ 0.39966987]), 'std_fit_time': array([ 0.00429421]), 'mean_test_score': array([ 0.36528547]), 'split1_test_score': array([ 0.34577603]), 'std_score_time': array([ 0.16160628]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59133413]), 'std_test_score': array([ 0.05522653]), 'split2_train_score': array([ 0.59534344]), 'split3_train_score': array([ 0.59773916]), 'split2_test_score': array([ 0.28530028]), 'split0_test_score': array([ 0.43039571]), 'mean_score_time': array([ 0.91282004]), 'mean_fit_time': array([ 0.05331224]), 'std_train_score': array([ 0.00713579])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.365285474858
####################################################################################
################# Runing the itteration 181  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50146560251025341}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50146560251025341}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0          0         1         2         3... -0.043288 -0.106368  

[4812 rows x 204 columns], y=2307     31943401
4796            0
289     3395...     26323969
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31000630363803955}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63549687037488822}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58478964378311238}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64829412588776525}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.66913693409410813}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29268667711435986}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.50146560251025341}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0          0         1         2         3... -0.043288 -0.106368  

[4812 rows x 204 columns]
        y = 2307     31943401
4796            0
289     3395...     26323969
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0          0         1         2         3... -0.043288 -0.106368  

[4812 rows x 204 columns], y=2307     31943401
4796            0
289     3395...     26323969
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0          0         1         2         3... -0.043288 -0.106368  

[4812 rows x 204 columns]
        y = 2307     31943401
4796            0
289     3395...     26323969
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0          0         1         2         3... -0.043288 -0.106368  

[4812 rows x 204 columns], y=2307     31943401
4796            0
289     3395...     26323969
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:03:10 2017
PID: 13694                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0          0         1         2         3... -0.043288 -0.106368  

[4812 rows x 204 columns], 2307     31943401
4796            0
289     3395...     26323969
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0          0         1         2         3... -0.043288 -0.106368  

[4812 rows x 204 columns], 2307     31943401
4796            0
289     3395...     26323969
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1         2         3... -0.043288 -0.106368  

[4812 rows x 204 columns], y=2307     31943401
4796            0
289     3395...     26323969
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns]
        y_test = 2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns], y_test=2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns]
        y_test = 2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns], 2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns], 2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns], 2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns], 2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns], y=2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns]
        y = 2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 204 columns], y=2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64, y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 2307     31943401
4796            0
289     3395...    404561724
Name: worldwide_gross, dtype: int64
        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 31943401,         0, 339504276, ..., 411348924,    463730,
       404561724]), y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 182  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  56.2s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28755885]), 'mean_train_score': array([-0.28933544]), 'split3_test_score': array([-0.30551886]), 'std_fit_time': array([ 3.5256751]), 'mean_test_score': array([-0.28956059]), 'split1_test_score': array([-0.26659343]), 'std_score_time': array([ 0.08446712]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29714145]), 'std_test_score': array([ 0.01424377]), 'split2_train_score': array([-0.28858781]), 'split3_train_score': array([-0.28405368]), 'split2_test_score': array([-0.29151252]), 'split0_test_score': array([-0.29461756]), 'mean_score_time': array([ 0.08596981]), 'mean_fit_time': array([ 61.81419528]), 'std_train_score': array([ 0.00481004])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.289560591534
####################################################################################
################# Runing the itteration 183  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.12868508]), 'mean_train_score': array([-0.13193725]), 'split3_test_score': array([-0.12573277]), 'std_fit_time': array([ 0.05152927]), 'mean_test_score': array([-0.13268782]), 'split1_test_score': array([-0.13235198]), 'std_score_time': array([ 0.01315994]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.12698915]), 'std_test_score': array([ 0.00455044]), 'split2_train_score': array([-0.13233219]), 'split3_train_score': array([-0.13974258]), 'split2_test_score': array([-0.13830328]), 'split0_test_score': array([-0.13436323]), 'mean_score_time': array([ 1.09415174]), 'mean_fit_time': array([ 3.85367882]), 'std_train_score': array([ 0.00490254])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132687817305
####################################################################################
################# Runing the itteration 184  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.2943424]), 'mean_train_score': array([-0.2896128]), 'split3_test_score': array([-0.28898131]), 'std_fit_time': array([ 0.00724283]), 'mean_test_score': array([-0.29074015]), 'split1_test_score': array([-0.27942336]), 'std_score_time': array([ 0.00359626]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29371841]), 'std_test_score': array([ 0.01732033]), 'split2_train_score': array([-0.27979776]), 'split3_train_score': array([-0.29059263]), 'split2_test_score': array([-0.31945144]), 'split0_test_score': array([-0.27510449]), 'mean_score_time': array([ 0.01747477]), 'mean_fit_time': array([ 0.03965932]), 'std_train_score': array([ 0.00584209])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290740147891
####################################################################################
################# Runing the itteration 185  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.04980371]), 'mean_train_score': array([-0.05254604]), 'split3_test_score': array([-0.04837052]), 'std_fit_time': array([ 0.10424871]), 'mean_test_score': array([-0.05355158]), 'split1_test_score': array([-0.0487129]), 'std_score_time': array([ 0.00256626]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05302203]), 'std_test_score': array([ 0.00815386]), 'split2_train_score': array([-0.05335768]), 'split3_train_score': array([-0.05400073]), 'split2_test_score': array([-0.06765783]), 'split0_test_score': array([-0.04946507]), 'mean_score_time': array([ 0.54490525]), 'mean_fit_time': array([ 2.94422299]), 'std_train_score': array([ 0.00162187])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0535515806402
####################################################################################
################# Runing the itteration 186  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.38654822]), 'std_fit_time': array([ 0.00705464]), 'mean_test_score': array([ 0.36337082]), 'split1_test_score': array([ 0.30939262]), 'std_score_time': array([ 0.00012443]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.06139774]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.45344902]), 'split0_test_score': array([ 0.30409343]), 'mean_score_time': array([ 0.00221318]), 'mean_fit_time': array([ 0.17890388]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.363370824575
####################################################################################
################# Runing the itteration 187  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.30792787]), 'std_fit_time': array([ 0.0026611]), 'mean_test_score': array([ 0.31960611]), 'split1_test_score': array([ 0.2457237]), 'std_score_time': array([ 0.00027442]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.0964458]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.24416659]), 'split0_test_score': array([ 0.48060628]), 'mean_score_time': array([ 0.00231665]), 'mean_fit_time': array([ 0.09220582]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.319606109987
####################################################################################
################# Runing the itteration 188  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.48104162]), 'mean_train_score': array([ 0.52460953]), 'split3_test_score': array([ 0.35341434]), 'std_fit_time': array([ 0.1113264]), 'mean_test_score': array([ 0.40366945]), 'split1_test_score': array([ 0.46584765]), 'std_score_time': array([ 0.00128318]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.56149705]), 'std_test_score': array([ 0.11604588]), 'split2_train_score': array([ 0.6587001]), 'split3_train_score': array([ 0.39719933]), 'split2_test_score': array([ 0.55166211]), 'split0_test_score': array([ 0.24375368]), 'mean_score_time': array([ 0.00734842]), 'mean_fit_time': array([ 0.6649127]), 'std_train_score': array([ 0.09678906])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.403669445231
####################################################################################
################# Runing the itteration 189  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93774163]), 'mean_train_score': array([ 0.94357197]), 'split3_test_score': array([ 0.67781651]), 'std_fit_time': array([ 0.02010579]), 'mean_test_score': array([ 0.68632379]), 'split1_test_score': array([ 0.68848471]), 'std_score_time': array([ 0.00028453]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93809782]), 'std_test_score': array([ 0.00590372]), 'split2_train_score': array([ 0.95054782]), 'split3_train_score': array([ 0.94790062]), 'split2_test_score': array([ 0.69409229]), 'split0_test_score': array([ 0.68490163]), 'mean_score_time': array([ 0.00642526]), 'mean_fit_time': array([ 0.83472663]), 'std_train_score': array([ 0.00573059])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.686323786182
####################################################################################
################# Runing the itteration 190  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.66537968]), 'std_fit_time': array([ 0.00534119]), 'mean_test_score': array([ 0.65214634]), 'split1_test_score': array([ 0.63175717]), 'std_score_time': array([ 0.00055142]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.01241824]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.65617592]), 'split0_test_score': array([ 0.65527257]), 'mean_score_time': array([ 0.00594473]), 'mean_fit_time': array([ 0.38385874]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.652146335937
####################################################################################
################# Runing the itteration 191  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.845833]), 'mean_train_score': array([ 0.84089275]), 'split3_test_score': array([ 0.67875027]), 'std_fit_time': array([ 0.05199542]), 'mean_test_score': array([ 0.70070076]), 'split1_test_score': array([ 0.66474709]), 'std_score_time': array([  5.42023547e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.84814534]), 'std_test_score': array([ 0.02981399]), 'split2_train_score': array([ 0.84199272]), 'split3_train_score': array([ 0.82759994]), 'split2_test_score': array([ 0.72242245]), 'split0_test_score': array([ 0.73688325]), 'mean_score_time': array([ 0.00374269]), 'mean_fit_time': array([ 0.79379922]), 'std_train_score': array([ 0.00798303])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.700700763441
####################################################################################
################# Runing the itteration 192  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93719239]), 'mean_train_score': array([ 0.93927731]), 'split3_test_score': array([ 0.61184025]), 'std_fit_time': array([ 0.01571072]), 'mean_test_score': array([ 0.65080605]), 'split1_test_score': array([ 0.70254214]), 'std_score_time': array([ 0.00029731]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.94343242]), 'std_test_score': array([ 0.03278794]), 'split2_train_score': array([ 0.93827731]), 'split3_train_score': array([ 0.93820712]), 'split2_test_score': array([ 0.64786325]), 'split0_test_score': array([ 0.64097856]), 'mean_score_time': array([ 0.00561696]), 'mean_fit_time': array([ 0.86878824]), 'std_train_score': array([ 0.00243706])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.650806051736
####################################################################################
################# Runing the itteration 193  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.6292729]), 'mean_train_score': array([ 0.61432833]), 'split3_test_score': array([ 0.57642733]), 'std_fit_time': array([ 0.00174929]), 'mean_test_score': array([ 0.59912601]), 'split1_test_score': array([ 0.66842821]), 'std_score_time': array([ 0.00516423]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58268107]), 'std_test_score': array([ 0.04199908]), 'split2_train_score': array([ 0.62249919]), 'split3_train_score': array([ 0.62286018]), 'split2_test_score': array([ 0.59387585]), 'split0_test_score': array([ 0.55777263]), 'mean_score_time': array([ 0.01277184]), 'mean_fit_time': array([ 0.06799775]), 'std_train_score': array([ 0.01846919])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.599126007315
####################################################################################
################# Runing the itteration 194  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.29834994]), 'mean_train_score': array([ 0.30301243]), 'split3_test_score': array([ 0.3290294]), 'std_fit_time': array([ 0.03862272]), 'mean_test_score': array([ 0.30213409]), 'split1_test_score': array([ 0.31206449]), 'std_score_time': array([ 0.00067958]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.2969623]), 'std_test_score': array([ 0.02073337]), 'split2_train_score': array([ 0.31036971]), 'split3_train_score': array([ 0.30636779]), 'split2_test_score': array([ 0.27324617]), 'split0_test_score': array([ 0.2941963]), 'mean_score_time': array([ 0.00388259]), 'mean_fit_time': array([ 0.12347823]), 'std_train_score': array([ 0.00556172])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.302134090393
####################################################################################
################# Runing the itteration 195  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.65921574]), 'mean_train_score': array([ 0.66257496]), 'split3_test_score': array([-58.45741015]), 'std_fit_time': array([ 0.00260907]), 'mean_test_score': array([-14.14824266]), 'split1_test_score': array([ 0.6725825]), 'std_score_time': array([ 0.0167151]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65341897]), 'std_test_score': array([ 25.58193211]), 'split2_train_score': array([ 0.66998253]), 'split3_train_score': array([ 0.66768259]), 'split2_test_score': array([ 0.61399569]), 'split0_test_score': array([ 0.57786135]), 'mean_score_time': array([ 0.03759164]), 'mean_fit_time': array([ 0.55703253]), 'std_train_score': array([ 0.00663469])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-14.1482426557
####################################################################################
################# Runing the itteration 196  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.65321215]), 'mean_train_score': array([ 0.64068946]), 'split3_test_score': array([ 0.61290995]), 'std_fit_time': array([ 0.03930807]), 'mean_test_score': array([ 0.62544044]), 'split1_test_score': array([ 0.60393758]), 'std_score_time': array([ 0.00350697]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6405118]), 'std_test_score': array([ 0.03620238]), 'split2_train_score': array([ 0.62203727]), 'split3_train_score': array([ 0.64699661]), 'split2_test_score': array([ 0.68742338]), 'split0_test_score': array([ 0.59749086]), 'mean_score_time': array([ 0.00466561]), 'mean_fit_time': array([ 0.0922057]), 'std_train_score': array([ 0.01166762])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.62544044119
####################################################################################
################# Runing the itteration 197  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.67065953]), 'mean_train_score': array([ 0.66421187]), 'split3_test_score': array([ 0.61988953]), 'std_fit_time': array([ 0.02992144]), 'mean_test_score': array([-1.37005805]), 'split1_test_score': array([-3.37332889]), 'std_score_time': array([ 0.0103446]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65347896]), 'std_test_score': array([ 1.9931641]), 'split2_train_score': array([ 0.66746664]), 'split3_train_score': array([ 0.66524236]), 'split2_test_score': array([ 0.6262943]), 'split0_test_score': array([-3.35308715]), 'mean_score_time': array([ 0.00943542]), 'mean_fit_time': array([ 0.09012681]), 'std_train_score': array([ 0.00648889])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.37005805428
####################################################################################
################# Runing the itteration 198  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.27184402]), 'mean_train_score': array([-0.28947624]), 'split3_test_score': array([-0.30872407]), 'std_fit_time': array([ 0.00256967]), 'mean_test_score': array([-0.29382078]), 'split1_test_score': array([-0.25651977]), 'std_score_time': array([ 0.00399245]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.30129104]), 'std_test_score': array([ 0.03901457]), 'split2_train_score': array([-0.30115063]), 'split3_train_score': array([-0.28361928]), 'split2_test_score': array([-0.25906179]), 'split0_test_score': array([-0.35097747]), 'mean_score_time': array([ 0.01319635]), 'mean_fit_time': array([ 0.02054948]), 'std_train_score': array([ 0.01246074])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293820775982
####################################################################################
################# Runing the itteration 199  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.65643892]), 'mean_train_score': array([ 0.66215665]), 'split3_test_score': array([ 0.23154994]), 'std_fit_time': array([ 0.06113398]), 'mean_test_score': array([ 0.48220435]), 'split1_test_score': array([ 0.58895268]), 'std_score_time': array([ 0.00405777]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64265024]), 'std_test_score': array([ 0.15194792]), 'split2_train_score': array([ 0.66437966]), 'split3_train_score': array([ 0.68515778]), 'split2_test_score': array([ 0.61650867]), 'split0_test_score': array([ 0.49180613]), 'mean_score_time': array([ 0.00636065]), 'mean_fit_time': array([ 0.73265439]), 'std_train_score': array([ 0.0153882])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.482204352054
####################################################################################
################# Runing the itteration 200  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-1912827.13382689]), 'mean_train_score': array([-1053358.7003314]), 'split3_test_score': array([-34783.39394443]), 'std_fit_time': array([ 0.00132467]), 'mean_test_score': array([-37169.37381271]), 'split1_test_score': array([-47973.88426964]), 'std_score_time': array([ 0.00820574]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-458824.15449542]), 'std_test_score': array([ 7245.59180128]), 'split2_train_score': array([-1535692.0608169]), 'split3_train_score': array([-306091.4521864]), 'split2_test_score': array([-38065.41102762]), 'split0_test_score': array([-27854.80600917]), 'mean_score_time': array([ 0.01515102]), 'mean_fit_time': array([ 0.01729959]), 'std_train_score': array([ 686150.69867249])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-37169.3738127
####################################################################################
################# Runing the itteration 201  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.66592864]), 'mean_train_score': array([ 0.64413319]), 'split3_test_score': array([ 0.6476035]), 'std_fit_time': array([ 0.0180864]), 'mean_test_score': array([ 0.61298142]), 'split1_test_score': array([ 0.63438217]), 'std_score_time': array([ 0.01187948]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64364958]), 'std_test_score': array([ 0.03587228]), 'split2_train_score': array([ 0.65245618]), 'split3_train_score': array([ 0.61449835]), 'split2_test_score': array([ 0.61596455]), 'split0_test_score': array([ 0.55397546]), 'mean_score_time': array([ 0.00885999]), 'mean_fit_time': array([ 0.05287945]), 'std_train_score': array([ 0.01885982])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.61298142014
####################################################################################
################# Runing the itteration 202  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -4.92972437e+21]), 'mean_train_score': array([ -4.00355570e+22]), 'split3_test_score': array([ -2.83945146e+23]), 'std_fit_time': array([ 0.12352286]), 'mean_test_score': array([ -7.24159163e+22]), 'split1_test_score': array([-36818919.18642564]), 'std_score_time': array([ 0.00037132]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-53152652.74705884]), 'std_test_score': array([  1.22148770e+23]), 'split2_train_score': array([-1186039.868658]), 'split3_train_score': array([ -1.55212504e+23]), 'split2_test_score': array([-659.94166101]), 'split0_test_score': array([ -5.71851869e+21]), 'mean_score_time': array([ 0.0016011]), 'mean_fit_time': array([ 0.50040311]), 'std_train_score': array([  6.65278892e+22])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-7.24159162788e+22
####################################################################################
################# Runing the itteration 203  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.67545143]), 'mean_train_score': array([ 0.67785668]), 'split3_test_score': array([ 0.45269806]), 'std_fit_time': array([ 0.0004635]), 'mean_test_score': array([ 0.51379791]), 'split1_test_score': array([ 0.51972177]), 'std_score_time': array([ 0.04648548]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67829142]), 'std_test_score': array([ 0.04616298]), 'split2_train_score': array([ 0.65487145]), 'split3_train_score': array([ 0.70281242]), 'split2_test_score': array([ 0.58159539]), 'split0_test_score': array([ 0.50117643]), 'mean_score_time': array([ 0.39038831]), 'mean_fit_time': array([ 0.02297306]), 'std_train_score': array([ 0.01700797])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.513797910753
####################################################################################
################# Runing the itteration 204  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_3', label_fn=<function label_gross_3>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40366944523103626}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.68632378618232748}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.59912600731473409}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65214633593671412}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70070076344113197}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30213409039263722}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51379791075253156}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       3
1       3
2       3
3       3
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40366944523103626}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.68632378618232748}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.59912600731473409}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65214633593671412}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70070076344113197}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30213409039263722}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51379791075253156}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 64 columns], y=1884     48680977
4444         9837
1148    1022...      6719864
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40366944523103626}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.68632378618232748}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43838541405518555}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.59912600731473409}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34630335370783955}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65214633593671412}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70070076344113197}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30213409039263722}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51379791075253156}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58641154463824463}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 64 columns]
        y = 1884     48680977
4444         9837
1148    1022...      6719864
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 64 columns], y=1884     48680977
4444         9837
1148    1022...      6719864
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 64 columns]
        y = 1884     48680977
4444         9837
1148    1022...      6719864
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 64 columns], y=1884     48680977
4444         9837
1148    1022...      6719864
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:12:23 2017
PID: 15149                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 64 columns], 1884     48680977
4444         9837
1148    1022...      6719864
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 64 columns], 1884     48680977
4444         9837
1148    1022...      6719864
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 64 columns], y=1884     48680977
4444         9837
1148    1022...      6719864
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns]
        y_test = 1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], y_test=1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns]
        y_test = 1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], y=1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns]
        y = 1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], y=1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64, y_pred=array([  2.71695500e+07,              nan,      ...        nan,   1.11813502e+08,   2.57543815e+07]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 1884     48680977
4444         9837
1148    1022...     14314407
Name: worldwide_gross, dtype: int64
        y_pred = array([  2.71695500e+07,              nan,      ...        nan,   1.11813502e+08,   2.57543815e+07])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 48680977,      9837, 102236596, ...,  56178935,  46370970,
        14314407]), y_pred=array([  2.71695500e+07,              nan,      ...        nan,   1.11813502e+08,   2.57543815e+07]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  2.71695500e+07,              nan,      ...        nan,   1.11813502e+08,   2.57543815e+07])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  2.71695500e+07,              nan,      ...        nan,   1.11813502e+08,   2.57543815e+07]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  2.71695500e+07,              nan,      ...        nan,   1.11813502e+08,   2.57543815e+07])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  2.71695500e+07,              nan,      ...        nan,   1.11813502e+08,   2.57543815e+07]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 205  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  22.0s
[CV]  ................................................................
[CV] ................................................. , total=  22.9s
[CV]  ................................................................
[CV] ................................................. , total=  23.0s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28643792]), 'mean_train_score': array([-0.2903054]), 'split3_test_score': array([-0.36146715]), 'std_fit_time': array([ 0.87481761]), 'mean_test_score': array([-0.29796125]), 'split1_test_score': array([-0.24746063]), 'std_score_time': array([ 0.72548083]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.30922298]), 'std_test_score': array([ 0.04171069]), 'split2_train_score': array([-0.29357271]), 'split3_train_score': array([-0.27198798]), 'split2_test_score': array([-0.27939116]), 'split0_test_score': array([-0.30352606]), 'mean_score_time': array([ 0.44074357]), 'mean_fit_time': array([ 22.38752353]), 'std_train_score': array([ 0.01340742])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.297961250304
####################################################################################
################# Runing the itteration 206  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.12757901]), 'mean_train_score': array([-0.13213579]), 'split3_test_score': array([-0.1339195]), 'std_fit_time': array([ 0.00985453]), 'mean_test_score': array([-0.13384694]), 'split1_test_score': array([-0.1198336]), 'std_score_time': array([ 0.0074031]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.14077804]), 'std_test_score': array([ 0.00993328]), 'split2_train_score': array([-0.13039157]), 'split3_train_score': array([-0.12979456]), 'split2_test_score': array([-0.1337065]), 'split0_test_score': array([-0.14792817]), 'mean_score_time': array([ 0.45522642]), 'mean_fit_time': array([ 1.89754623]), 'std_train_score': array([ 0.00509844])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.133846941871
####################################################################################
################# Runing the itteration 207  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28370272]), 'mean_train_score': array([-0.29030226]), 'split3_test_score': array([-0.32435818]), 'std_fit_time': array([ 0.00033291]), 'mean_test_score': array([-0.2955772]), 'split1_test_score': array([-0.31805475]), 'std_score_time': array([ 0.01304859]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28161987]), 'std_test_score': array([ 0.03800104]), 'split2_train_score': array([-0.31715402]), 'split3_train_score': array([-0.27873245]), 'split2_test_score': array([-0.2303941]), 'split0_test_score': array([-0.30950177]), 'mean_score_time': array([ 0.03235191]), 'mean_fit_time': array([ 0.01948607]), 'std_train_score': array([ 0.01560301])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295577201161
####################################################################################
################# Runing the itteration 208  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05002367]), 'mean_train_score': array([-0.05225495]), 'split3_test_score': array([-0.05235543]), 'std_fit_time': array([ 0.0437982]), 'mean_test_score': array([-0.05233441]), 'split1_test_score': array([-0.0561203]), 'std_score_time': array([ 0.00547709]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05309403]), 'std_test_score': array([ 0.0031106]), 'split2_train_score': array([-0.05488498]), 'split3_train_score': array([-0.05101713]), 'split2_test_score': array([-0.04750489]), 'split0_test_score': array([-0.05335702]), 'mean_score_time': array([ 0.22685051]), 'mean_fit_time': array([ 1.52521926]), 'std_train_score': array([ 0.00187962])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0523344104166
####################################################################################
################# Runing the itteration 209  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.4333602]), 'std_fit_time': array([ 0.02665292]), 'mean_test_score': array([ 0.45025616]), 'split1_test_score': array([ 0.55023304]), 'std_score_time': array([ 0.00019402]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05861005]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.41077488]), 'split0_test_score': array([ 0.40665651]), 'mean_score_time': array([ 0.00188947]), 'mean_fit_time': array([ 0.17055178]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.450256155472
####################################################################################
################# Runing the itteration 210  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.47122084]), 'std_fit_time': array([ 0.0006444]), 'mean_test_score': array([ 0.47868868]), 'split1_test_score': array([ 0.52265979]), 'std_score_time': array([  8.51927626e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.04057637]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.41610706]), 'split0_test_score': array([ 0.50476702]), 'mean_score_time': array([ 0.00171167]), 'mean_fit_time': array([ 0.04730964]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.478688676371
#########################################
###Finished all estimators for cl: label_gross_3
#########################################
#########################################
#######Printing results for cl: label_gross_3
#########################################
{'MLPRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}, 'score': -0.28956059153389585, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'OrthogonalMatchingPursuit': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.61298142014004275, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'BaggingRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.68632378618232748, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'GradientBoostingRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.70070076344113197, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'SVR': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}, 'score': -0.13206842005870567, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'SGDRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': 0.58936609044097976, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'HuberRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.30213409039263722, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'RandomForestRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.6508060517362837, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'Lasso': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': 0.58641154463824463, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'AdaBoostRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.40366944523103626, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'LinearRegression': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': 0.58895404203245405, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'LinearSVR': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}, 'score': -0.29002884838641285, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'ElasticNet': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.59912600731473409, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'KNeighborsRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.51379791075253156, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'NuSVR': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': -0.052334410416594264, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'LassoLars': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.62544044118987108, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'Ridge': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': 0.60267122598836109, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'ExtraTreesRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.65214633593671412, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'PassiveAggressiveRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': -0.28986555112850648, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'ExtraTreeRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.4786886763706501, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'RANSACRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}, 'score': -2.8768485554150268e+21, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'DecisionTreeRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.45025615547152559, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}}
priting simply sorted numbers, grep them to find the best cfg or cl: label_gross_3
[-2.8768485554150268e+21, -0.29002884838641285, -0.28986555112850648, -0.28956059153389585, -0.13206842005870567, -0.052334410416594264, 0.30213409039263722, 0.40366944523103626, 0.45025615547152559, 0.4786886763706501, 0.51379791075253156, 0.58641154463824463, 0.58895404203245405, 0.58936609044097976, 0.59912600731473409, 0.60267122598836109, 0.61298142014004275, 0.62544044118987108, 0.6508060517362837, 0.65214633593671412, 0.68632378618232748, 0.70070076344113197]
