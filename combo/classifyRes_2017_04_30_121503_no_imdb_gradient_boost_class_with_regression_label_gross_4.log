#########################################
###Starting all estimators for cl: label_gross_4
#########################################

LogPol True
n_components
[193, 115, 57]
pw_lst
[{'pw': 1}]
####################################################################################
################# Runing the itteration 1  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [193, 115, 57], 'preprocessor__kw_args': [{'pw': 1}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}

LogPol True
n_components
[203, 121, 60]
pw_lst
[{'pw': 1}, {'pw': 2}]
####################################################################################
################# Runing the itteration 2  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [203, 121, 60], 'preprocessor__kw_args': [{'pw': 2}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}

LogPol True
n_components
[213, 127, 63]
pw_lst
[{'pw': 1}, {'pw': 2}, {'pw': 3}]
####################################################################################
################# Runing the itteration 3  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [213, 127, 63], 'preprocessor__kw_args': [{'pw': 3}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
####################################################################################
################# Runing the itteration 4  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.44939909]), 'mean_train_score': array([ 0.18373238]), 'split3_test_score': array([-0.51401015]), 'std_fit_time': array([ 0.30088431]), 'mean_test_score': array([ 0.03769805]), 'split1_test_score': array([ 0.03340321]), 'std_score_time': array([ 0.00405801]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.23478198]), 'std_test_score': array([ 0.35689237]), 'split2_train_score': array([ 0.1037365]), 'split3_train_score': array([-0.05298806]), 'split2_test_score': array([ 0.15676782]), 'split0_test_score': array([ 0.47463131]), 'mean_score_time': array([ 0.0129776]), 'mean_fit_time': array([ 1.09625369]), 'std_train_score': array([ 0.18413363])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.0376980457513
####################################################################################
################# Runing the itteration 5  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93985225]), 'mean_train_score': array([ 0.93185475]), 'split3_test_score': array([ 0.61413722]), 'std_fit_time': array([ 0.0150683]), 'mean_test_score': array([ 0.61805036]), 'split1_test_score': array([ 0.63566613]), 'std_score_time': array([ 0.00071624]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93143714]), 'std_test_score': array([ 0.0178887]), 'split2_train_score': array([ 0.92467979]), 'split3_train_score': array([ 0.93144983]), 'split2_test_score': array([ 0.59045641]), 'split0_test_score': array([ 0.63194168]), 'mean_score_time': array([ 0.01260197]), 'mean_fit_time': array([ 1.27210677]), 'std_train_score': array([ 0.00538002])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.618050359538
####################################################################################
################# Runing the itteration 6  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.66393969]), 'std_fit_time': array([ 0.03995608]), 'mean_test_score': array([ 0.62227814]), 'split1_test_score': array([ 0.58208183]), 'std_score_time': array([ 0.00025771]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.03038383]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.60850313]), 'split0_test_score': array([ 0.63458791]), 'mean_score_time': array([ 0.00744933]), 'mean_fit_time': array([ 0.85339081]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.622278140675
####################################################################################
################# Runing the itteration 7  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.78574766]), 'mean_train_score': array([ 0.79446188]), 'split3_test_score': array([ 0.57931637]), 'std_fit_time': array([ 0.02641429]), 'mean_test_score': array([ 0.6522989]), 'split1_test_score': array([ 0.63459237]), 'std_score_time': array([ 0.00028882]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.79447543]), 'std_test_score': array([ 0.05123435]), 'split2_train_score': array([ 0.79512669]), 'split3_train_score': array([ 0.80249772]), 'split2_test_score': array([ 0.6783094]), 'split0_test_score': array([ 0.71697747]), 'mean_score_time': array([ 0.00594264]), 'mean_fit_time': array([ 1.49506068]), 'std_train_score': array([ 0.00593621])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.65229890339
####################################################################################
################# Runing the itteration 8  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.9365241]), 'mean_train_score': array([ 0.93692792]), 'split3_test_score': array([ 0.59807183]), 'std_fit_time': array([ 0.0393426]), 'mean_test_score': array([ 0.62422949]), 'split1_test_score': array([ 0.56438605]), 'std_score_time': array([ 0.00128297]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.94042182]), 'std_test_score': array([ 0.04905857]), 'split2_train_score': array([ 0.92883461]), 'split3_train_score': array([ 0.94193116]), 'split2_test_score': array([ 0.6960694]), 'split0_test_score': array([ 0.63839069]), 'mean_score_time': array([ 0.00879288]), 'mean_fit_time': array([ 1.25775307]), 'std_train_score': array([ 0.00507209])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.624229493956
####################################################################################
################# Runing the itteration 9  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.62260276]), 'mean_train_score': array([ 0.62307984]), 'split3_test_score': array([ 0.64541161]), 'std_fit_time': array([ 0.01568555]), 'mean_test_score': array([ 0.58593006]), 'split1_test_score': array([ 0.53722334]), 'std_score_time': array([ 0.00571893]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63727328]), 'std_test_score': array([ 0.03941615]), 'split2_train_score': array([ 0.63165801]), 'split3_train_score': array([ 0.60078532]), 'split2_test_score': array([ 0.5694502]), 'split0_test_score': array([ 0.59163511]), 'mean_score_time': array([ 0.0155468]), 'mean_fit_time': array([ 0.22357583]), 'std_train_score': array([ 0.01389525])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.585930063981
####################################################################################
################# Runing the itteration 10  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.32084588]), 'mean_train_score': array([ 0.3142761]), 'split3_test_score': array([ 0.2968421]), 'std_fit_time': array([ 0.06672925]), 'mean_test_score': array([ 0.30214802]), 'split1_test_score': array([ 0.32482736]), 'std_score_time': array([ 0.00060522]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.30816664]), 'std_test_score': array([ 0.01733713]), 'split2_train_score': array([ 0.3288178]), 'split3_train_score': array([ 0.29927409]), 'split2_test_score': array([ 0.27751012]), 'split0_test_score': array([ 0.30941249]), 'mean_score_time': array([ 0.00531656]), 'mean_fit_time': array([ 0.44929445]), 'std_train_score': array([ 0.01136891])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.302148016303
####################################################################################
################# Runing the itteration 11  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.65961334]), 'mean_train_score': array([ 0.65333833]), 'split3_test_score': array([ 0.56013959]), 'std_fit_time': array([ 0.01392932]), 'mean_test_score': array([-1.71729459]), 'split1_test_score': array([ 0.59537661]), 'std_score_time': array([ 0.00684999]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65182661]), 'std_test_score': array([ 2.30532414]), 'split2_train_score': array([ 0.64403159]), 'split3_train_score': array([ 0.65788178]), 'split2_test_score': array([-4.31925873]), 'split0_test_score': array([-3.70543583]), 'mean_score_time': array([ 0.01763332]), 'mean_fit_time': array([ 1.88940328]), 'std_train_score': array([ 0.00610163])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.71729458881
####################################################################################
################# Runing the itteration 12  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.63307876]), 'mean_train_score': array([ 0.62368845]), 'split3_test_score': array([-2.90027098]), 'std_fit_time': array([ 0.05628924]), 'mean_test_score': array([-0.28663107]), 'split1_test_score': array([ 0.60023224]), 'std_score_time': array([ 0.01326408]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63745437]), 'std_test_score': array([ 1.50902665]), 'split2_train_score': array([ 0.60309043]), 'split3_train_score': array([ 0.62113025]), 'split2_test_score': array([ 0.56879042]), 'split0_test_score': array([ 0.58472403]), 'mean_score_time': array([ 0.01736754]), 'mean_fit_time': array([ 0.18019724]), 'std_train_score': array([ 0.01330884])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.286631071313
####################################################################################
################# Runing the itteration 13  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.66333547]), 'mean_train_score': array([ 0.65449558]), 'split3_test_score': array([-2.31596524]), 'std_fit_time': array([ 0.04930807]), 'mean_test_score': array([-7.6582813]), 'split1_test_score': array([ 0.53935295]), 'std_score_time': array([ 0.00651606]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6592334]), 'std_test_score': array([ 12.59230709]), 'split2_train_score': array([ 0.66366409]), 'split3_train_score': array([ 0.63174934]), 'split2_test_score': array([ 0.51928709]), 'split0_test_score': array([-29.3758]), 'mean_score_time': array([ 0.01154834]), 'mean_fit_time': array([ 0.25478053]), 'std_train_score': array([ 0.01324806])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-7.65828130026
####################################################################################
################# Runing the itteration 14  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.29637832]), 'mean_train_score': array([-0.28919351]), 'split3_test_score': array([-0.265975]), 'std_fit_time': array([ 0.00097103]), 'mean_test_score': array([-0.29361796]), 'split1_test_score': array([-0.32633076]), 'std_score_time': array([ 0.00387901]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27962564]), 'std_test_score': array([ 0.02591652]), 'split2_train_score': array([-0.28246522]), 'split3_train_score': array([-0.29830487]), 'split2_test_score': array([-0.3115715]), 'split0_test_score': array([-0.2705946]), 'mean_score_time': array([ 0.01300645]), 'mean_fit_time': array([ 0.03596234]), 'std_train_score': array([ 0.00823791])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293617963473
####################################################################################
################# Runing the itteration 15  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.66595722]), 'mean_train_score': array([ 0.65775259]), 'split3_test_score': array([ 0.16288119]), 'std_fit_time': array([ 0.05927155]), 'mean_test_score': array([ 0.39705694]), 'split1_test_score': array([ 0.38457309]), 'std_score_time': array([ 0.00508113]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65638747]), 'std_test_score': array([ 0.14777323]), 'split2_train_score': array([ 0.6414646]), 'split3_train_score': array([ 0.66720107]), 'split2_test_score': array([ 0.48929733]), 'split0_test_score': array([ 0.55147616]), 'mean_score_time': array([ 0.01286179]), 'mean_fit_time': array([ 3.02985007]), 'std_train_score': array([ 0.01029262])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.397056942154
####################################################################################
################# Runing the itteration 16  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-1616138.59581185]), 'mean_train_score': array([-590525.62763358]), 'split3_test_score': array([-14997.19288346]), 'std_fit_time': array([ 0.02937115]), 'mean_test_score': array([-9496.6139032]), 'split1_test_score': array([-7299.89773846]), 'std_score_time': array([ 0.009159]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-694007.55865548]), 'std_test_score': array([ 6395.91905839]), 'split2_train_score': array([ 0.57914292]), 'split3_train_score': array([-51956.9352099]), 'split2_test_score': array([ 0.42542693]), 'split0_test_score': array([-15689.79041783]), 'mean_score_time': array([ 0.02537686]), 'mean_fit_time': array([ 0.05652577]), 'std_train_score': array([ 652182.47214493])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-9496.6139032
####################################################################################
################# Runing the itteration 17  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.6295963]), 'mean_train_score': array([ 0.62703185]), 'split3_test_score': array([ 0.67507881]), 'std_fit_time': array([ 0.0122544]), 'mean_test_score': array([ 0.58956123]), 'split1_test_score': array([ 0.51619959]), 'std_score_time': array([ 0.0164606]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64702961]), 'std_test_score': array([ 0.05770674]), 'split2_train_score': array([ 0.63902502]), 'split3_train_score': array([ 0.59247649]), 'split2_test_score': array([ 0.56688206]), 'split0_test_score': array([ 0.60008445]), 'mean_score_time': array([ 0.01519907]), 'mean_fit_time': array([ 0.07903862]), 'std_train_score': array([ 0.02088298])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.589561229389
####################################################################################
################# Runing the itteration 18  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   5.0s
[CV]  ................................................................
[CV] ................................................. , total=   5.6s
[CV]  ................................................................
[CV] ................................................. , total=   5.8s
[CV]  ................................................................
[CV] ................................................. , total=   6.1s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -5.00297799e+24]), 'mean_train_score': array([ -1.33631851e+25]), 'split3_test_score': array([ -1.50371337e+25]), 'std_fit_time': array([ 0.38231595]), 'mean_test_score': array([ -1.97147597e+25]), 'split1_test_score': array([ -3.61943334e+25]), 'std_score_time': array([ 0.00519989]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -2.33758507e+25]), 'std_test_score': array([  1.05638747e+25]), 'split2_train_score': array([ -1.25613688e+25]), 'split3_train_score': array([ -1.25125429e+25]), 'split2_test_score': array([ -2.02667807e+25]), 'split0_test_score': array([ -7.36079123e+24]), 'mean_score_time': array([ 0.00974941]), 'mean_fit_time': array([ 5.60321951]), 'std_train_score': array([  6.54814930e+24])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.9714759745e+25
####################################################################################
################# Runing the itteration 19  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.59069205]), 'mean_train_score': array([ 0.58805485]), 'split3_test_score': array([ 0.28351061]), 'std_fit_time': array([ 0.00057128]), 'mean_test_score': array([ 0.36863684]), 'split1_test_score': array([ 0.38253564]), 'std_score_time': array([ 0.08310239]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59821019]), 'std_test_score': array([ 0.0823563]), 'split2_train_score': array([ 0.56277123]), 'split3_train_score': array([ 0.60054593]), 'split2_test_score': array([ 0.49686241]), 'split0_test_score': array([ 0.31163869]), 'mean_score_time': array([ 0.98973572]), 'mean_fit_time': array([ 0.04670507]), 'std_train_score': array([ 0.01504472])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.368636837227
####################################################################################
################# Runing the itteration 20  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_4', label_fn=<function label_gross_4>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.037698045751273931}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61805035953824028}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58593006398086289}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.6222781406745459}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65229890338997853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30214801630290933}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.36863683722725887}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.7172945888069058}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.28663107131333809}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -7.6582813002623169}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.037698045751273931}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61805035953824028}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58593006398086289}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.6222781406745459}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65229890338997853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30214801630290933}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.36863683722725887}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.7172945888069058}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.28663107131333809}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -7.6582813002623169}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=3361      7900000
972     126069509
1957     448...     56968169
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.037698045751273931}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61805035953824028}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58593006398086289}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.6222781406745459}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65229890338997853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30214801630290933}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.36863683722725887}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.7172945888069058}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.28663107131333809}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -7.6582813002623169}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 3361      7900000
972     126069509
1957     448...     56968169
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=3361      7900000
972     126069509
1957     448...     56968169
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 3361      7900000
972     126069509
1957     448...     56968169
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=3361      7900000
972     126069509
1957     448...     56968169
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:49:13 2017
PID: 28113                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], 3361      7900000
972     126069509
1957     448...     56968169
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], 3361      7900000
972     126069509
1957     448...     56968169
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=3361      7900000
972     126069509
1957     448...     56968169
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], y_test=3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], 3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], 3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], 3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], 3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], y=3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y = 3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0          0         1         2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], y=3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64, y_pred=array([             nan,   1.55011165e+08,   3.7...1453790e+07,              nan,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 3361      7900000
972     126069509
1957     448...    937008132
Name: worldwide_gross, dtype: int64
        y_pred = array([             nan,   1.55011165e+08,   3.7...1453790e+07,              nan,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([  7900000, 126069509,  44821299, ...,   7094995,  39319801,
       937008132]), y_pred=array([             nan,   1.55011165e+08,   3.7...1453790e+07,              nan,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([             nan,   1.55011165e+08,   3.7...1453790e+07,              nan,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([             nan,   1.55011165e+08,   3.7...1453790e+07,              nan,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([             nan,   1.55011165e+08,   3.7...1453790e+07,              nan,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([             nan,   1.55011165e+08,   3.7...1453790e+07,              nan,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 21  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.0min
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
[CV]  ................................................................
[CV] ................................................. , total= 1.2min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.30197466]), 'mean_train_score': array([-0.28956165]), 'split3_test_score': array([-0.32324419]), 'std_fit_time': array([ 2.67424731]), 'mean_test_score': array([-0.29183984]), 'split1_test_score': array([-0.27846279]), 'std_score_time': array([ 0.01791043]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29299704]), 'std_test_score': array([ 0.02525946]), 'split2_train_score': array([-0.28372204]), 'split3_train_score': array([-0.27955287]), 'split2_test_score': array([-0.30756979]), 'split0_test_score': array([-0.25808259]), 'mean_score_time': array([ 0.04078066]), 'mean_fit_time': array([ 67.50600237]), 'std_train_score': array([ 0.00866259])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291839840387
####################################################################################
################# Runing the itteration 22  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   5.0s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.12862981]), 'mean_train_score': array([-0.13178379]), 'split3_test_score': array([-0.14926489]), 'std_fit_time': array([ 0.02627514]), 'mean_test_score': array([-0.13339604]), 'split1_test_score': array([-0.13657812]), 'std_score_time': array([ 0.00818347]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.1327611]), 'std_test_score': array([ 0.0121902]), 'split2_train_score': array([-0.13813478]), 'split3_train_score': array([-0.12760947]), 'split2_test_score': array([-0.11518182]), 'split0_test_score': array([-0.13255932]), 'mean_score_time': array([ 1.13493198]), 'mean_fit_time': array([ 3.94343108]), 'std_train_score': array([ 0.00414315])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.133396038443
####################################################################################
################# Runing the itteration 23  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.29882616]), 'mean_train_score': array([-0.28958151]), 'split3_test_score': array([-0.30347933]), 'std_fit_time': array([ 0.00461879]), 'mean_test_score': array([-0.29089986]), 'split1_test_score': array([-0.33005805]), 'std_score_time': array([ 0.02773283]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27711381]), 'std_test_score': array([ 0.02759947]), 'split2_train_score': array([-0.29751274]), 'split3_train_score': array([-0.28487335]), 'split2_test_score': array([-0.26793973]), 'split0_test_score': array([-0.26212231]), 'mean_score_time': array([ 0.03829557]), 'mean_fit_time': array([ 0.03546757]), 'std_train_score': array([ 0.00902743])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290899855465
####################################################################################
################# Runing the itteration 24  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.6s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.0509082]), 'mean_train_score': array([-0.05219187]), 'split3_test_score': array([-0.0432066]), 'std_fit_time': array([ 0.04885653]), 'mean_test_score': array([-0.05260298]), 'split1_test_score': array([-0.04256442]), 'std_score_time': array([ 0.00437282]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05510138]), 'std_test_score': array([ 0.00974123]), 'split2_train_score': array([-0.05050542]), 'split3_train_score': array([-0.05225249]), 'split2_test_score': array([-0.06141408]), 'split0_test_score': array([-0.06322681]), 'mean_score_time': array([ 0.56838822]), 'mean_fit_time': array([ 2.95159328]), 'std_train_score': array([ 0.00180006])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0526029779008
####################################################################################
################# Runing the itteration 25  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.32867803]), 'std_fit_time': array([ 0.00296371]), 'mean_test_score': array([ 0.36247926]), 'split1_test_score': array([ 0.29463129]), 'std_score_time': array([ 0.00016862]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05255653]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.4215683]), 'split0_test_score': array([ 0.40503943]), 'mean_score_time': array([ 0.00286734]), 'mean_fit_time': array([ 0.22276938]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.362479262241
####################################################################################
################# Runing the itteration 26  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.34002104]), 'std_fit_time': array([ 0.00188619]), 'mean_test_score': array([ 0.35307106]), 'split1_test_score': array([ 0.39144761]), 'std_score_time': array([ 0.00043382]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.08951156]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.21775892]), 'split0_test_score': array([ 0.46305668]), 'mean_score_time': array([ 0.0031265]), 'mean_fit_time': array([ 0.09690619]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.353071061294
####################################################################################
################# Runing the itteration 27  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.48021639]), 'mean_train_score': array([ 0.49290781]), 'split3_test_score': array([ 0.14475607]), 'std_fit_time': array([ 0.08292432]), 'mean_test_score': array([ 0.34714771]), 'split1_test_score': array([ 0.38866885]), 'std_score_time': array([ 0.00019793]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.41330542]), 'std_test_score': array([ 0.13869054]), 'split2_train_score': array([ 0.65565659]), 'split3_train_score': array([ 0.42245284]), 'split2_test_score': array([ 0.53081625]), 'split0_test_score': array([ 0.32434967]), 'mean_score_time': array([ 0.00899333]), 'mean_fit_time': array([ 0.59310704]), 'std_train_score': array([ 0.09740211])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.347147713577
####################################################################################
################# Runing the itteration 28  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93963686]), 'mean_train_score': array([ 0.93972857]), 'split3_test_score': array([ 0.64535568]), 'std_fit_time': array([ 0.01061661]), 'mean_test_score': array([ 0.69400093]), 'split1_test_score': array([ 0.75232141]), 'std_score_time': array([ 0.00021682]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93415957]), 'std_test_score': array([ 0.03817655]), 'split2_train_score': array([ 0.93740077]), 'split3_train_score': array([ 0.94771706]), 'split2_test_score': array([ 0.69193393]), 'split0_test_score': array([ 0.68639272]), 'mean_score_time': array([ 0.00670874]), 'mean_fit_time': array([ 0.73408365]), 'std_train_score': array([ 0.00500642])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.694000934722
####################################################################################
################# Runing the itteration 29  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.65952649]), 'std_fit_time': array([ 0.00340725]), 'mean_test_score': array([ 0.69412303]), 'split1_test_score': array([ 0.71405344]), 'std_score_time': array([ 0.00024914]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.02064555]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.70017851]), 'split0_test_score': array([ 0.70273369]), 'mean_score_time': array([ 0.00685424]), 'mean_fit_time': array([ 0.35309207]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.694123031041
####################################################################################
################# Runing the itteration 30  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.8284185]), 'mean_train_score': array([ 0.83012507]), 'split3_test_score': array([ 0.62082116]), 'std_fit_time': array([ 0.00304574]), 'mean_test_score': array([ 0.70918591]), 'split1_test_score': array([ 0.74030714]), 'std_score_time': array([  9.91262876e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.82479287]), 'std_test_score': array([ 0.05401293]), 'split2_train_score': array([ 0.83081671]), 'split3_train_score': array([ 0.83647223]), 'split2_test_score': array([ 0.76285079]), 'split0_test_score': array([ 0.71276455]), 'mean_score_time': array([ 0.00352746]), 'mean_fit_time': array([ 0.66458321]), 'std_train_score': array([ 0.00424587])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.709185909373
####################################################################################
################# Runing the itteration 31  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93725052]), 'mean_train_score': array([ 0.9381586]), 'split3_test_score': array([ 0.70140576]), 'std_fit_time': array([ 0.00760834]), 'mean_test_score': array([ 0.68755892]), 'split1_test_score': array([ 0.71777952]), 'std_score_time': array([  9.61284338e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93518427]), 'std_test_score': array([ 0.02761169]), 'split2_train_score': array([ 0.94162171]), 'split3_train_score': array([ 0.93857789]), 'split2_test_score': array([ 0.64346129]), 'split0_test_score': array([ 0.68758912]), 'mean_score_time': array([ 0.00529498]), 'mean_fit_time': array([ 0.6873256]), 'std_train_score': array([ 0.00233668])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.687558924155
####################################################################################
################# Runing the itteration 32  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.60091597]), 'mean_train_score': array([ 0.6171114]), 'split3_test_score': array([ 0.58202188]), 'std_fit_time': array([ 0.00246768]), 'mean_test_score': array([ 0.60551337]), 'split1_test_score': array([ 0.5781159]), 'std_score_time': array([ 0.00616562]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62325232]), 'std_test_score': array([ 0.02762809]), 'split2_train_score': array([ 0.61325601]), 'split3_train_score': array([ 0.63102131]), 'split2_test_score': array([ 0.64605638]), 'split0_test_score': array([ 0.61585933]), 'mean_score_time': array([ 0.01658726]), 'mean_fit_time': array([ 0.0545513]), 'std_train_score': array([ 0.01127334])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.605513370378
####################################################################################
################# Runing the itteration 33  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.28948844]), 'mean_train_score': array([ 0.28369424]), 'split3_test_score': array([ 0.28957005]), 'std_fit_time': array([ 0.0562032]), 'mean_test_score': array([ 0.2811913]), 'split1_test_score': array([ 0.27828477]), 'std_score_time': array([ 0.00016478]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.27195442]), 'std_test_score': array([ 0.02135557]), 'split2_train_score': array([ 0.30983204]), 'split3_train_score': array([ 0.26350203]), 'split2_test_score': array([ 0.24903907]), 'split0_test_score': array([ 0.30787132]), 'mean_score_time': array([ 0.00307244]), 'mean_fit_time': array([ 0.14589375]), 'std_train_score': array([ 0.01776447])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.281191303674
####################################################################################
################# Runing the itteration 34  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.67403197]), 'mean_train_score': array([ 0.66403951]), 'split3_test_score': array([ 0.63656617]), 'std_fit_time': array([ 0.00337664]), 'mean_test_score': array([ 0.58277497]), 'split1_test_score': array([ 0.42299876]), 'std_score_time': array([ 0.01252126]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65648656]), 'std_test_score': array([ 0.09453021]), 'split2_train_score': array([ 0.65810319]), 'split3_train_score': array([ 0.66753631]), 'split2_test_score': array([ 0.66496935]), 'split0_test_score': array([ 0.60656561]), 'mean_score_time': array([ 0.02643079]), 'mean_fit_time': array([ 0.53800583]), 'std_train_score': array([ 0.00714779])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.582774970781
####################################################################################
################# Runing the itteration 35  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.63200981]), 'mean_train_score': array([ 0.64665676]), 'split3_test_score': array([ 0.65139555]), 'std_fit_time': array([ 0.02139391]), 'mean_test_score': array([ 0.62992815]), 'split1_test_score': array([ 0.59346877]), 'std_score_time': array([ 0.00047746]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.66323461]), 'std_test_score': array([ 0.03282884]), 'split2_train_score': array([ 0.66239585]), 'split3_train_score': array([ 0.62898679]), 'split2_test_score': array([ 0.60272243]), 'split0_test_score': array([ 0.67212583]), 'mean_score_time': array([ 0.00266719]), 'mean_fit_time': array([ 0.06107461]), 'std_train_score': array([ 0.01619649])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.629928146275
####################################################################################
################# Runing the itteration 36  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.66042471]), 'mean_train_score': array([ 0.66433814]), 'split3_test_score': array([ 0.62119722]), 'std_fit_time': array([ 0.02499721]), 'mean_test_score': array([ 0.56493739]), 'split1_test_score': array([ 0.62712185]), 'std_score_time': array([ 0.00281346]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67459429]), 'std_test_score': array([ 0.13909976]), 'split2_train_score': array([ 0.65524035]), 'split3_train_score': array([ 0.66709322]), 'split2_test_score': array([ 0.68368766]), 'split0_test_score': array([ 0.32774281]), 'mean_score_time': array([ 0.00659817]), 'mean_fit_time': array([ 0.06598252]), 'std_train_score': array([ 0.00726058])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.564937385983
####################################################################################
################# Runing the itteration 37  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28435994]), 'mean_train_score': array([-0.28898229]), 'split3_test_score': array([-0.30166059]), 'std_fit_time': array([ 0.00029189]), 'mean_test_score': array([-0.29115568]), 'split1_test_score': array([-0.28672398]), 'std_score_time': array([ 0.003528]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.2894581]), 'std_test_score': array([ 0.01217437]), 'split2_train_score': array([-0.29703068]), 'split3_train_score': array([-0.28508043]), 'split2_test_score': array([-0.27321227]), 'split0_test_score': array([-0.3030259]), 'mean_score_time': array([ 0.00938815]), 'mean_fit_time': array([ 0.01725519]), 'std_train_score': array([ 0.00503968])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29115568425
####################################################################################
################# Runing the itteration 38  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.62606514]), 'mean_train_score': array([ 0.66108579]), 'split3_test_score': array([ 0.62599033]), 'std_fit_time': array([ 0.06789968]), 'mean_test_score': array([ 0.60301982]), 'split1_test_score': array([ 0.59216911]), 'std_score_time': array([ 0.00346601]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67365205]), 'std_test_score': array([ 0.08119575]), 'split2_train_score': array([ 0.67771357]), 'split3_train_score': array([ 0.66691239]), 'split2_test_score': array([ 0.48370761]), 'split0_test_score': array([ 0.71021224]), 'mean_score_time': array([ 0.01047814]), 'mean_fit_time': array([ 0.81565523]), 'std_train_score': array([ 0.02058391])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.603019820146
####################################################################################
################# Runing the itteration 39  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-147288.04255776]), 'mean_train_score': array([-55764.32030515]), 'split3_test_score': array([-1052.07079332]), 'std_fit_time': array([ 0.00011335]), 'mean_test_score': array([-2418.35133456]), 'split1_test_score': array([-3298.21831208]), 'std_score_time': array([ 0.00715667]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-56632.49652561]), 'std_test_score': array([ 2054.05430233]), 'split2_train_score': array([-69.62647897]), 'split3_train_score': array([-19067.11565826]), 'split2_test_score': array([-4.73964176]), 'split0_test_score': array([-5318.3765911]), 'mean_score_time': array([ 0.01755512]), 'mean_fit_time': array([ 0.0180673]), 'std_train_score': array([ 56625.80951786])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2418.35133456
####################################################################################
################# Runing the itteration 40  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.62854401]), 'mean_train_score': array([ 0.64578952]), 'split3_test_score': array([ 0.64602947]), 'std_fit_time': array([ 0.00368797]), 'mean_test_score': array([ 0.63235775]), 'split1_test_score': array([ 0.60681604]), 'std_score_time': array([ 0.00343151]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65889397]), 'std_test_score': array([ 0.03579117]), 'split2_train_score': array([ 0.65208964]), 'split3_train_score': array([ 0.64363045]), 'split2_test_score': array([ 0.59238911]), 'split0_test_score': array([ 0.68419639]), 'mean_score_time': array([ 0.00657445]), 'mean_fit_time': array([ 0.03127801]), 'std_train_score': array([ 0.01133013])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.632357753104
####################################################################################
################# Runing the itteration 41  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -1.53553693e+19]), 'mean_train_score': array([ -5.58971593e+22]), 'split3_test_score': array([ -1.13019865e+20]), 'std_fit_time': array([ 0.32571068]), 'mean_test_score': array([ -8.28075444e+22]), 'split1_test_score': array([-340.67737376]), 'std_score_time': array([ 0.00063347]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-287.74335607]), 'std_test_score': array([  1.43356650e+23]), 'split2_train_score': array([ -2.23514881e+23]), 'split3_train_score': array([ -5.84005752e+19]), 'split2_test_score': array([ -3.31108535e+23]), 'split0_test_score': array([ -8.62322512e+18]), 'mean_score_time': array([ 0.00190705]), 'mean_fit_time': array([ 0.71362346]), 'std_train_score': array([  9.67741393e+22])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-8.2807544448e+22
####################################################################################
################# Runing the itteration 42  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.68346221]), 'mean_train_score': array([ 0.68535637]), 'split3_test_score': array([ 0.54442294]), 'std_fit_time': array([ 0.00044706]), 'mean_test_score': array([ 0.52899186]), 'split1_test_score': array([ 0.50639224]), 'std_score_time': array([ 0.01864253]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.68987046]), 'std_test_score': array([ 0.01922559]), 'split2_train_score': array([ 0.6856127]), 'split3_train_score': array([ 0.68248012]), 'split2_test_score': array([ 0.51381529]), 'split0_test_score': array([ 0.55133696]), 'mean_score_time': array([ 0.3252489]), 'mean_fit_time': array([ 0.02153766]), 'std_train_score': array([ 0.00284181])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.528991856315
####################################################################################
################# Runing the itteration 43  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_4', label_fn=<function label_gross_4>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.36247926224064081}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.3530710612936121}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30214801630290933}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.36247926224064081}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.3530710612936121}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30214801630290933}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], y=2832     17394881
2418     28391473
1598     644...    122213085
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.36247926224064081}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.3530710612936121}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30214801630290933}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns]
        y = 2832     17394881
2418     28391473
1598     644...    122213085
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], y=2832     17394881
2418     28391473
1598     644...    122213085
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns]
        y = 2832     17394881
2418     28391473
1598     644...    122213085
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], y=2832     17394881
2418     28391473
1598     644...    122213085
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:59:29 2017
PID: 29441                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], 2832     17394881
2418     28391473
1598     644...    122213085
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], 2832     17394881
2418     28391473
1598     644...    122213085
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], y=2832     17394881
2418     28391473
1598     644...    122213085
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns]
        y_test = 2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns], y_test=2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns]
        y_test = 2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns], 2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns], 2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns], 2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns], 2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns], y=2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns]
        y = 2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 61 columns], y=2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64, y_pred=array([ 18714403.4       ,                nan,  ...       ,  34390453.53846154,                nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 2832      17394881
2418      28391473
1598      ...     61449135
Name: worldwide_gross, dtype: int64
        y_pred = array([ 18714403.4       ,                nan,  ...       ,  34390453.53846154,                nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([17394881, 28391473, 64477051, ...,        0, 27958191, 61449135]), y_pred=array([ 18714403.4       ,                nan,  ...       ,  34390453.53846154,                nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([ 18714403.4       ,                nan,  ...       ,  34390453.53846154,                nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([ 18714403.4       ,                nan,  ...       ,  34390453.53846154,                nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([ 18714403.4       ,                nan,  ...       ,  34390453.53846154,                nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([ 18714403.4       ,                nan,  ...       ,  34390453.53846154,                nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 44  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   8.7s
[CV]  ................................................................
[CV] ................................................. , total=   9.4s
[CV]  ................................................................
[CV] ................................................. , total=  10.1s
[CV]  ................................................................
[CV] ................................................. , total=  10.2s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.29697509]), 'mean_train_score': array([-0.28945899]), 'split3_test_score': array([-0.26335492]), 'std_fit_time': array([ 0.59967666]), 'mean_test_score': array([-0.29033462]), 'split1_test_score': array([-0.30834248]), 'std_score_time': array([ 0.00605916]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28357635]), 'std_test_score': array([ 0.0250076]), 'split2_train_score': array([-0.27902426]), 'split3_train_score': array([-0.29826024]), 'split2_test_score': array([-0.32136377]), 'split0_test_score': array([-0.26827731]), 'mean_score_time': array([ 0.01618344]), 'mean_fit_time': array([ 9.57645762]), 'std_train_score': array([ 0.00832831])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290334621377
####################################################################################
################# Runing the itteration 45  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.14035941]), 'mean_train_score': array([-0.13229345]), 'split3_test_score': array([-0.14202551]), 'std_fit_time': array([ 0.00696404]), 'mean_test_score': array([-0.13414003]), 'split1_test_score': array([-0.14366495]), 'std_score_time': array([ 0.00141231]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.12875583]), 'std_test_score': array([ 0.00908807]), 'split2_train_score': array([-0.13398633]), 'split3_train_score': array([-0.12607222]), 'split2_test_score': array([-0.12183581]), 'split0_test_score': array([-0.12903385]), 'mean_score_time': array([ 0.43411845]), 'mean_fit_time': array([ 1.82092327]), 'std_train_score': array([ 0.00545765])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.134140029971
####################################################################################
################# Runing the itteration 46  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28003641]), 'mean_train_score': array([-0.2897471]), 'split3_test_score': array([-0.29974929]), 'std_fit_time': array([ 0.00243128]), 'mean_test_score': array([-0.29228711]), 'split1_test_score': array([-0.28972305]), 'std_score_time': array([ 0.00670401]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28943217]), 'std_test_score': array([ 0.0226578]), 'split2_train_score': array([-0.30242441]), 'split3_train_score': array([-0.2870954]), 'split2_test_score': array([-0.25837975]), 'split0_test_score': array([-0.32129635]), 'mean_score_time': array([ 0.015737]), 'mean_fit_time': array([ 0.01740241]), 'std_train_score': array([ 0.00809541])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292287109354
####################################################################################
################# Runing the itteration 47  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05189261]), 'mean_train_score': array([-0.05245292]), 'split3_test_score': array([-0.06673173]), 'std_fit_time': array([ 0.00516362]), 'mean_test_score': array([-0.05334787]), 'split1_test_score': array([-0.04177969]), 'std_score_time': array([ 0.0016137]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05296077]), 'std_test_score': array([ 0.0091006]), 'split2_train_score': array([-0.05249185]), 'split3_train_score': array([-0.05246647]), 'split2_test_score': array([-0.04955172]), 'split0_test_score': array([-0.05532834]), 'mean_score_time': array([ 0.22028852]), 'mean_fit_time': array([ 1.46398139]), 'std_train_score': array([ 0.00037867])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0533478690562
####################################################################################
################# Runing the itteration 48  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.27842685]), 'std_fit_time': array([ 0.00332694]), 'mean_test_score': array([ 0.44162738]), 'split1_test_score': array([ 0.4236169]), 'std_score_time': array([ 0.00019358]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.10517178]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.55305238]), 'split0_test_score': array([ 0.5114134]), 'mean_score_time': array([ 0.00183678]), 'mean_fit_time': array([ 0.12362486]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.44162738318
####################################################################################
################# Runing the itteration 49  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.53964061]), 'std_fit_time': array([ 0.00047824]), 'mean_test_score': array([ 0.45560625]), 'split1_test_score': array([ 0.4061145]), 'std_score_time': array([  5.81626509e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05201753]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.41942079]), 'split0_test_score': array([ 0.45724908]), 'mean_score_time': array([ 0.0017662]), 'mean_fit_time': array([ 0.04336554]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.455606245766
####################################################################################
################# Runing the itteration 50  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([-0.06744475]), 'mean_train_score': array([ 0.33071082]), 'split3_test_score': array([ 0.36085326]), 'std_fit_time': array([ 0.18605427]), 'mean_test_score': array([ 0.19346947]), 'split1_test_score': array([ 0.57651067]), 'std_score_time': array([ 0.00282165]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62202835]), 'std_test_score': array([ 0.32060893]), 'split2_train_score': array([ 0.24087378]), 'split3_train_score': array([ 0.52738591]), 'split2_test_score': array([ 0.12433776]), 'split0_test_score': array([-0.28782383]), 'mean_score_time': array([ 0.00737208]), 'mean_fit_time': array([ 0.45839137]), 'std_train_score': array([ 0.2693258])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.193469465383
####################################################################################
################# Runing the itteration 51  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92744911]), 'mean_train_score': array([ 0.92591524]), 'split3_test_score': array([ 0.58063548]), 'std_fit_time': array([ 0.00720347]), 'mean_test_score': array([ 0.58459381]), 'split1_test_score': array([ 0.59782102]), 'std_score_time': array([ 0.00047333]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92751163]), 'std_test_score': array([ 0.01611112]), 'split2_train_score': array([ 0.92241979]), 'split3_train_score': array([ 0.92628041]), 'split2_test_score': array([ 0.60001789]), 'split0_test_score': array([ 0.55990084]), 'mean_score_time': array([ 0.00908309]), 'mean_fit_time': array([ 0.66335034]), 'std_train_score': array([ 0.00207682])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.584593807694
####################################################################################
################# Runing the itteration 52  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.57256118]), 'std_fit_time': array([ 0.00671199]), 'mean_test_score': array([ 0.57498576]), 'split1_test_score': array([ 0.60367424]), 'std_score_time': array([ 0.00048503]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.02592869]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.5343276]), 'split0_test_score': array([ 0.58938002]), 'mean_score_time': array([ 0.00743377]), 'mean_fit_time': array([ 0.45220637]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.574985758682
####################################################################################
################# Runing the itteration 53  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.7595237]), 'mean_train_score': array([ 0.7708314]), 'split3_test_score': array([ 0.65273166]), 'std_fit_time': array([ 0.00685225]), 'mean_test_score': array([ 0.60001571]), 'split1_test_score': array([ 0.54900766]), 'std_score_time': array([ 0.00010965]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.78947334]), 'std_test_score': array([ 0.03990338]), 'split2_train_score': array([ 0.76956549]), 'split3_train_score': array([ 0.76476306]), 'split2_test_score': array([ 0.62137512]), 'split0_test_score': array([ 0.5769484]), 'mean_score_time': array([ 0.00472462]), 'mean_fit_time': array([ 0.84722543]), 'std_train_score': array([ 0.01133373])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.600015711336
####################################################################################
################# Runing the itteration 54  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.91400556]), 'mean_train_score': array([ 0.92459724]), 'split3_test_score': array([ 0.59422595]), 'std_fit_time': array([ 0.00771857]), 'mean_test_score': array([ 0.57818631]), 'split1_test_score': array([ 0.57637323]), 'std_score_time': array([ 0.00019539]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92116979]), 'std_test_score': array([ 0.01406904]), 'split2_train_score': array([ 0.93842509]), 'split3_train_score': array([ 0.92478852]), 'split2_test_score': array([ 0.55641021]), 'split0_test_score': array([ 0.58573585]), 'mean_score_time': array([ 0.00648022]), 'mean_fit_time': array([ 0.66045862]), 'std_train_score': array([ 0.00887662])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.578186310638
####################################################################################
################# Runing the itteration 55  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.53746329]), 'mean_train_score': array([ 0.54144069]), 'split3_test_score': array([ 0.5429468]), 'std_fit_time': array([ 0.00083691]), 'mean_test_score': array([ 0.51501198]), 'split1_test_score': array([ 0.5216432]), 'std_score_time': array([ 0.00656621]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.52885494]), 'std_test_score': array([ 0.02472239]), 'split2_train_score': array([ 0.56130849]), 'split3_train_score': array([ 0.53813602]), 'split2_test_score': array([ 0.475112]), 'split0_test_score': array([ 0.52034591]), 'mean_score_time': array([ 0.01656675]), 'mean_fit_time': array([ 0.08371347]), 'std_train_score': array([ 0.01204026])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.515011977821
####################################################################################
################# Runing the itteration 56  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.20525756]), 'mean_train_score': array([ 0.20380913]), 'split3_test_score': array([ 0.18743785]), 'std_fit_time': array([ 0.03329766]), 'mean_test_score': array([ 0.20059172]), 'split1_test_score': array([ 0.19495228]), 'std_score_time': array([ 0.00026186]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.20392278]), 'std_test_score': array([ 0.02205952]), 'split2_train_score': array([ 0.20825618]), 'split3_train_score': array([ 0.19779999]), 'split2_test_score': array([ 0.18201455]), 'split0_test_score': array([ 0.23796219]), 'mean_score_time': array([ 0.00358677]), 'mean_fit_time': array([ 0.19936258]), 'std_train_score': array([ 0.00380778])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.200591717195
####################################################################################
################# Runing the itteration 57  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.61761878]), 'mean_train_score': array([ 0.60982274]), 'split3_test_score': array([ 0.5422202]), 'std_fit_time': array([ 0.02039709]), 'mean_test_score': array([ 0.56255446]), 'split1_test_score': array([ 0.60712822]), 'std_score_time': array([ 0.01311494]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59614211]), 'std_test_score': array([ 0.03824337]), 'split2_train_score': array([ 0.60110867]), 'split3_train_score': array([ 0.62442139]), 'split2_test_score': array([ 0.59015966]), 'split0_test_score': array([ 0.51070977]), 'mean_score_time': array([ 0.02737576]), 'mean_fit_time': array([ 1.02303064]), 'std_train_score': array([ 0.01158656])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.562554461148
####################################################################################
################# Runing the itteration 58  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.60619047]), 'mean_train_score': array([ 0.6045384]), 'split3_test_score': array([ 0.53401632]), 'std_fit_time': array([ 0.04843016]), 'mean_test_score': array([ 0.57544338]), 'split1_test_score': array([ 0.57846266]), 'std_score_time': array([ 0.0091139]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.60402955]), 'std_test_score': array([ 0.03080116]), 'split2_train_score': array([ 0.58533366]), 'split3_train_score': array([ 0.62259993]), 'split2_test_score': array([ 0.62045377]), 'split0_test_score': array([ 0.56884077]), 'mean_score_time': array([ 0.01297998]), 'mean_fit_time': array([ 0.14211947]), 'std_train_score': array([ 0.01321012])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.575443380764
####################################################################################
################# Runing the itteration 59  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.62453442]), 'mean_train_score': array([ 0.60793266]), 'split3_test_score': array([ 0.57640865]), 'std_fit_time': array([ 0.04819696]), 'mean_test_score': array([ 0.55614594]), 'split1_test_score': array([ 0.5713386]), 'std_score_time': array([ 0.00906653]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6070152]), 'std_test_score': array([ 0.04502334]), 'split2_train_score': array([ 0.59810638]), 'split3_train_score': array([ 0.60207465]), 'split2_test_score': array([ 0.59689247]), 'split0_test_score': array([ 0.47994404]), 'mean_score_time': array([ 0.01451075]), 'mean_fit_time': array([ 0.11923909]), 'std_train_score': array([ 0.01009123])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.55614594118
####################################################################################
################# Runing the itteration 60  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28848742]), 'mean_train_score': array([-0.28989025]), 'split3_test_score': array([-0.33698941]), 'std_fit_time': array([ 0.00091614]), 'mean_test_score': array([-0.29674645]), 'split1_test_score': array([-0.24941528]), 'std_score_time': array([ 0.00742518]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.31203115]), 'std_test_score': array([ 0.03169459]), 'split2_train_score': array([-0.2831021]), 'split3_train_score': array([-0.27594032]), 'split2_test_score': array([-0.30845549]), 'split0_test_score': array([-0.29212561]), 'mean_score_time': array([ 0.01870233]), 'mean_fit_time': array([ 0.02802598]), 'std_train_score': array([ 0.01353576])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.296746446334
####################################################################################
################# Runing the itteration 61  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.60328882]), 'mean_train_score': array([ 0.6112255]), 'split3_test_score': array([ 0.5496005]), 'std_fit_time': array([ 0.08406527]), 'mean_test_score': array([ 0.56710984]), 'split1_test_score': array([ 0.54724403]), 'std_score_time': array([ 0.00604062]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6162702]), 'std_test_score': array([ 0.0211307]), 'split2_train_score': array([ 0.60977011]), 'split3_train_score': array([ 0.61557289]), 'split2_test_score': array([ 0.57189875]), 'split0_test_score': array([ 0.5996961]), 'mean_score_time': array([ 0.02090657]), 'mean_fit_time': array([ 1.56490195]), 'std_train_score': array([ 0.0052311])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.567109843148
####################################################################################
################# Runing the itteration 62  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.58348243]), 'mean_train_score': array([ 0.59007648]), 'split3_test_score': array([ 0.53676674]), 'std_fit_time': array([ 0.00160084]), 'mean_test_score': array([ 0.55536256]), 'split1_test_score': array([ 0.60992741]), 'std_score_time': array([ 0.00571044]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.57796627]), 'std_test_score': array([ 0.04091087]), 'split2_train_score': array([ 0.60093019]), 'split3_train_score': array([ 0.59792701]), 'split2_test_score': array([ 0.50046744]), 'split0_test_score': array([ 0.57428865]), 'mean_score_time': array([ 0.02019554]), 'mean_fit_time': array([ 0.03070509]), 'std_train_score': array([ 0.00961214])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.55536256043
####################################################################################
################# Runing the itteration 63  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.58123924]), 'mean_train_score': array([ 0.58909309]), 'split3_test_score': array([ 0.57231485]), 'std_fit_time': array([ 0.01032623]), 'mean_test_score': array([ 0.57343492]), 'split1_test_score': array([ 0.56145051]), 'std_score_time': array([ 0.00709897]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59608104]), 'std_test_score': array([ 0.01684182]), 'split2_train_score': array([ 0.58951504]), 'split3_train_score': array([ 0.58953705]), 'split2_test_score': array([ 0.55872872]), 'split0_test_score': array([ 0.60124561]), 'mean_score_time': array([ 0.01049024]), 'mean_fit_time': array([ 0.07518417]), 'std_train_score': array([ 0.00526521])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.573434921561
####################################################################################
################# Runing the itteration 64  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -2.52146629e+25]), 'mean_train_score': array([ -6.97491663e+24]), 'split3_test_score': array([ -2.63976148e+24]), 'std_fit_time': array([ 0.28563528]), 'mean_test_score': array([ -7.01213194e+24]), 'split1_test_score': array([ -6.59690611e+22]), 'std_score_time': array([ 0.00190459]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -9.06501688e+22]), 'std_test_score': array([  1.06230572e+25]), 'split2_train_score': array([ -1.78874103e+22]), 'split3_train_score': array([ -2.57646609e+24]), 'split2_test_score': array([ -2.27627671e+22]), 'split0_test_score': array([ -2.53200344e+25]), 'mean_score_time': array([ 0.00451905]), 'mean_fit_time': array([ 1.83367324]), 'std_train_score': array([  1.05809746e+25])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-7.01213193851e+24
####################################################################################
################# Runing the itteration 65  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.63156885]), 'mean_train_score': array([ 0.6343062]), 'split3_test_score': array([ 0.41797702]), 'std_fit_time': array([ 0.00432468]), 'mean_test_score': array([ 0.42677167]), 'split1_test_score': array([ 0.39251818]), 'std_score_time': array([ 0.06052454]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63600942]), 'std_test_score': array([ 0.02833245]), 'split2_train_score': array([ 0.63214668]), 'split3_train_score': array([ 0.63749985]), 'split2_test_score': array([ 0.42556151]), 'split0_test_score': array([ 0.47103]), 'mean_score_time': array([ 0.5483737]), 'mean_fit_time': array([ 0.03852475]), 'std_train_score': array([ 0.00251281])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.426771674987
####################################################################################
################# Runing the itteration 66  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_4', label_fn=<function label_gross_4>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30214801630290933}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.06123763,
        -0.05200382, -0.10636806]])}
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30214801630290933}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], y=927     132440066
1184     98983590
2133     380...     31670620
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30214801630290933}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns]
        y = 927     132440066
1184     98983590
2133     380...     31670620
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], y=927     132440066
1184     98983590
2133     380...     31670620
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns]
        y = 927     132440066
1184     98983590
2133     380...     31670620
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], y=927     132440066
1184     98983590
2133     380...     31670620
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 14:06:37 2017
PID: 30907                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], 927     132440066
1184     98983590
2133     380...     31670620
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], 927     132440066
1184     98983590
2133     380...     31670620
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 116 columns], y=927     132440066
1184     98983590
2133     380...     31670620
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns]
        y_test = 927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], y_test=927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns]
        y_test = 927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], 927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], 927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], 927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], 927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], y=927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns]
        y = 927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 116 columns], y=927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64, y_pred=array([               nan,  60279822.        ,  ...4761904,                nan,                nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 927      132440066
1184      98983590
2133      ...     78353508
Name: worldwide_gross, dtype: int64
        y_pred = array([               nan,  60279822.        ,  ...4761904,                nan,                nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([132440066,  98983590,  38017873, ..., 103028188,  14853898,
        78353508]), y_pred=array([               nan,  60279822.        ,  ...4761904,                nan,                nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([               nan,  60279822.        ,  ...4761904,                nan,                nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([               nan,  60279822.        ,  ...4761904,                nan,                nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([               nan,  60279822.        ,  ...4761904,                nan,                nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([               nan,  60279822.        ,  ...4761904,                nan,                nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 67  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  46.0s
[CV]  ................................................................
[CV] ................................................. , total=  46.0s
[CV]  ................................................................
[CV] ................................................. , total=  47.0s
[CV]  ................................................................
[CV] ................................................. , total=  48.5s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.2860304]), 'mean_train_score': array([-0.28979874]), 'split3_test_score': array([-0.30957272]), 'std_fit_time': array([ 1.04023821]), 'mean_test_score': array([-0.29272051]), 'split1_test_score': array([-0.24982598]), 'std_score_time': array([ 0.02381882]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.30697108]), 'std_test_score': array([ 0.0250759]), 'split2_train_score': array([-0.28274695]), 'split3_train_score': array([-0.28344651]), 'split2_test_score': array([-0.3108488]), 'split0_test_score': array([-0.30063453]), 'mean_score_time': array([ 0.03492349]), 'mean_fit_time': array([ 46.8411088]), 'std_train_score': array([ 0.0099896])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292720506246
####################################################################################
################# Runing the itteration 68  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.2s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.12747378]), 'mean_train_score': array([-0.13166563]), 'split3_test_score': array([-0.14966088]), 'std_fit_time': array([ 0.0244381]), 'mean_test_score': array([-0.13267921]), 'split1_test_score': array([-0.12753463]), 'std_score_time': array([ 0.00627764]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13097269]), 'std_test_score': array([ 0.00983077]), 'split2_train_score': array([-0.13959334]), 'split3_train_score': array([-0.12862271]), 'split2_test_score': array([-0.12584578]), 'split0_test_score': array([-0.12767554]), 'mean_score_time': array([ 0.68320185]), 'mean_fit_time': array([ 2.60085523]), 'std_train_score': array([ 0.00474762])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132679209236
####################################################################################
################# Runing the itteration 69  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28828148]), 'mean_train_score': array([-0.28954914]), 'split3_test_score': array([-0.28070037]), 'std_fit_time': array([ 0.00216489]), 'mean_test_score': array([-0.29062383]), 'split1_test_score': array([-0.30170996]), 'std_score_time': array([ 0.00825472]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28656663]), 'std_test_score': array([ 0.00771377]), 'split2_train_score': array([-0.29099176]), 'split3_train_score': array([-0.2923567]), 'split2_test_score': array([-0.28721797]), 'split0_test_score': array([-0.29286701]), 'mean_score_time': array([ 0.01552683]), 'mean_fit_time': array([ 0.02646875]), 'std_train_score': array([ 0.00226196])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290623827379
####################################################################################
################# Runing the itteration 70  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05167422]), 'mean_train_score': array([-0.05253578]), 'split3_test_score': array([-0.05983105]), 'std_fit_time': array([ 0.01156681]), 'mean_test_score': array([-0.05315073]), 'split1_test_score': array([-0.04891098]), 'std_score_time': array([ 0.00352875]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05541619]), 'std_test_score': array([ 0.00435463]), 'split2_train_score': array([-0.05162359]), 'split3_train_score': array([-0.05142911]), 'split2_test_score': array([-0.0496643]), 'split0_test_score': array([-0.0541966]), 'mean_score_time': array([ 0.34687322]), 'mean_fit_time': array([ 1.98468232]), 'std_train_score': array([ 0.00166552])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0531507319803
####################################################################################
################# Runing the itteration 71  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.31809978]), 'std_fit_time': array([ 0.00554666]), 'mean_test_score': array([ 0.34306535]), 'split1_test_score': array([ 0.45925682]), 'std_score_time': array([ 0.00026362]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.08037322]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.35891214]), 'split0_test_score': array([ 0.23599267]), 'mean_score_time': array([ 0.00258398]), 'mean_fit_time': array([ 0.12031949]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.343065352259
####################################################################################
################# Runing the itteration 72  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.39415657]), 'std_fit_time': array([ 0.0021849]), 'mean_test_score': array([ 0.36264887]), 'split1_test_score': array([ 0.40360814]), 'std_score_time': array([ 0.00050599]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05043588]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.27702418]), 'split0_test_score': array([ 0.37580657]), 'mean_score_time': array([ 0.00288129]), 'mean_fit_time': array([ 0.05911541]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.36264886543
####################################################################################
################# Runing the itteration 73  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.05270806]), 'mean_train_score': array([ 0.36936273]), 'split3_test_score': array([-0.10578685]), 'std_fit_time': array([ 0.24663945]), 'mean_test_score': array([ 0.25417256]), 'split1_test_score': array([ 0.53227979]), 'std_score_time': array([ 0.00430115]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61522425]), 'std_test_score': array([ 0.25669081]), 'split2_train_score': array([ 0.55270659]), 'split3_train_score': array([ 0.256812]), 'split2_test_score': array([ 0.45834139]), 'split0_test_score': array([ 0.13185592]), 'mean_score_time': array([ 0.00978762]), 'mean_fit_time': array([ 0.73455191]), 'std_train_score': array([ 0.22748665])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.254172562751
####################################################################################
################# Runing the itteration 74  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92781322]), 'mean_train_score': array([ 0.93220065]), 'split3_test_score': array([ 0.54890843]), 'std_fit_time': array([ 0.0275603]), 'mean_test_score': array([ 0.61304214]), 'split1_test_score': array([ 0.61970139]), 'std_score_time': array([ 0.00318916]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93463239]), 'std_test_score': array([ 0.04627454]), 'split2_train_score': array([ 0.93744059]), 'split3_train_score': array([ 0.92891639]), 'split2_test_score': array([ 0.60465665]), 'split0_test_score': array([ 0.67890211]), 'mean_score_time': array([ 0.01302332]), 'mean_fit_time': array([ 1.09591228]), 'std_train_score': array([ 0.0039814])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.613042144174
####################################################################################
################# Runing the itteration 75  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.61792927]), 'std_fit_time': array([ 0.0183354]), 'mean_test_score': array([ 0.60333936]), 'split1_test_score': array([ 0.57188205]), 'std_score_time': array([ 0.00032762]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.03076747]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.57683122]), 'split0_test_score': array([ 0.64671491]), 'mean_score_time': array([ 0.00715399]), 'mean_fit_time': array([ 0.60317689]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.6033393622
####################################################################################
################# Runing the itteration 76  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.80429233]), 'mean_train_score': array([ 0.79836108]), 'split3_test_score': array([ 0.72065018]), 'std_fit_time': array([ 0.01720305]), 'mean_test_score': array([ 0.66483014]), 'split1_test_score': array([ 0.67583169]), 'std_score_time': array([ 0.00127629]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.80614649]), 'std_test_score': array([ 0.0369828]), 'split2_train_score': array([ 0.79655924]), 'split3_train_score': array([ 0.78644625]), 'split2_test_score': array([ 0.63057182]), 'split0_test_score': array([ 0.63226688]), 'mean_score_time': array([ 0.00598198]), 'mean_fit_time': array([ 1.05945635]), 'std_train_score': array([ 0.00776212])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.664830141275
####################################################################################
################# Runing the itteration 77  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92970621]), 'mean_train_score': array([ 0.92557001]), 'split3_test_score': array([ 0.56174245]), 'std_fit_time': array([ 0.01735124]), 'mean_test_score': array([ 0.61031726]), 'split1_test_score': array([ 0.63926057]), 'std_score_time': array([ 0.00164548]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.924046]), 'std_test_score': array([ 0.03185773]), 'split2_train_score': array([ 0.92651606]), 'split3_train_score': array([ 0.92201174]), 'split2_test_score': array([ 0.60183362]), 'split0_test_score': array([ 0.63843238]), 'mean_score_time': array([ 0.00958562]), 'mean_fit_time': array([ 1.06767929]), 'std_train_score': array([ 0.00287172])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.610317255177
####################################################################################
################# Runing the itteration 78  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.62291939]), 'mean_train_score': array([ 0.61020228]), 'split3_test_score': array([ 0.595663]), 'std_fit_time': array([ 0.00415011]), 'mean_test_score': array([ 0.58012282]), 'split1_test_score': array([ 0.63126246]), 'std_score_time': array([ 0.01516062]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58958382]), 'std_test_score': array([ 0.03599309]), 'split2_train_score': array([ 0.62334743]), 'split3_train_score': array([ 0.60495847]), 'split2_test_score': array([ 0.53963625]), 'split0_test_score': array([ 0.55392956]), 'mean_score_time': array([ 0.02237827]), 'mean_fit_time': array([ 0.14087403]), 'std_train_score': array([ 0.01402799])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.580122820166
####################################################################################
################# Runing the itteration 79  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.31027208]), 'mean_train_score': array([ 0.31045899]), 'split3_test_score': array([ 0.28361101]), 'std_fit_time': array([ 0.08894761]), 'mean_test_score': array([ 0.30528627]), 'split1_test_score': array([ 0.29261762]), 'std_score_time': array([ 0.00118008]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.30024247]), 'std_test_score': array([ 0.01747144]), 'split2_train_score': array([ 0.31155909]), 'split3_train_score': array([ 0.31976233]), 'split2_test_score': array([ 0.32314415]), 'split0_test_score': array([ 0.3217723]), 'mean_score_time': array([ 0.00406778]), 'mean_fit_time': array([ 0.35901189]), 'std_train_score': array([ 0.00693135])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.305286270075
####################################################################################
################# Runing the itteration 80  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.65158778]), 'mean_train_score': array([ 0.6411077]), 'split3_test_score': array([ 0.51021127]), 'std_fit_time': array([ 0.00794928]), 'mean_test_score': array([-17.38688136]), 'split1_test_score': array([ 0.561676]), 'std_score_time': array([ 0.02702132]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64761574]), 'std_test_score': array([ 31.05704106]), 'split2_train_score': array([ 0.62383936]), 'split3_train_score': array([ 0.64138793]), 'split2_test_score': array([-71.17924252]), 'split0_test_score': array([ 0.55982982]), 'mean_score_time': array([ 0.03850037]), 'mean_fit_time': array([ 1.140939]), 'std_train_score': array([ 0.01061203])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-17.3868813569
####################################################################################
################# Runing the itteration 81  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.62818186]), 'mean_train_score': array([ 0.62926257]), 'split3_test_score': array([ 0.59990142]), 'std_fit_time': array([ 0.01872209]), 'mean_test_score': array([ 0.60542843]), 'split1_test_score': array([ 0.61560788]), 'std_score_time': array([ 0.00172613]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61902075]), 'std_test_score': array([ 0.0071041]), 'split2_train_score': array([ 0.63424841]), 'split3_train_score': array([ 0.63559926]), 'split2_test_score': array([ 0.60843518]), 'split0_test_score': array([ 0.59776924]), 'mean_score_time': array([ 0.00401002]), 'mean_fit_time': array([ 0.11692268]), 'std_train_score': array([ 0.00653978])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.605428432357
####################################################################################
################# Runing the itteration 82  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.66621919]), 'mean_train_score': array([ 0.64410882]), 'split3_test_score': array([ 0.59097524]), 'std_fit_time': array([ 0.0248487]), 'mean_test_score': array([-8.74077013]), 'split1_test_score': array([ 0.5348515]), 'std_score_time': array([ 0.00261226]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65027105]), 'std_test_score': array([ 16.07971924]), 'split2_train_score': array([ 0.62229222]), 'split3_train_score': array([ 0.63765281]), 'split2_test_score': array([ 0.50269983]), 'split0_test_score': array([-36.59160707]), 'mean_score_time': array([ 0.00540149]), 'mean_fit_time': array([ 0.11505377]), 'std_train_score': array([ 0.01615925])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-8.74077012814
####################################################################################
################# Runing the itteration 83  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28919888]), 'mean_train_score': array([-0.28868802]), 'split3_test_score': array([-0.29470881]), 'std_fit_time': array([ 0.01276583]), 'mean_test_score': array([-0.28889006]), 'split1_test_score': array([-0.27728393]), 'std_score_time': array([ 0.00164759]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29269176]), 'std_test_score': array([ 0.00757555]), 'split2_train_score': array([-0.28617752]), 'split3_train_score': array([-0.28668391]), 'split2_test_score': array([-0.29648742]), 'split0_test_score': array([-0.28708008]), 'mean_score_time': array([ 0.01554942]), 'mean_fit_time': array([ 0.04686326]), 'std_train_score': array([ 0.00257925])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.288890058803
####################################################################################
################# Runing the itteration 84  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.6520342]), 'mean_train_score': array([ 0.64316292]), 'split3_test_score': array([ 0.13931611]), 'std_fit_time': array([ 0.03552718]), 'mean_test_score': array([ 0.42076587]), 'split1_test_score': array([ 0.46315861]), 'std_score_time': array([ 0.00070492]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61121198]), 'std_test_score': array([ 0.16653458]), 'split2_train_score': array([ 0.66234849]), 'split3_train_score': array([ 0.647057]), 'split2_test_score': array([ 0.51431528]), 'split0_test_score': array([ 0.56627347]), 'mean_score_time': array([ 0.00613838]), 'mean_fit_time': array([ 1.83419836]), 'std_train_score': array([ 0.01925365])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.42076586771
####################################################################################
################# Runing the itteration 85  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-573229.36843204]), 'mean_train_score': array([-396389.3318225]), 'split3_test_score': array([-50314.25550995]), 'std_fit_time': array([ 0.00453421]), 'mean_test_score': array([-22106.95970681]), 'split1_test_score': array([-13977.19142307]), 'std_score_time': array([ 0.0111876]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-263686.30509768]), 'std_test_score': array([ 16912.99119888]), 'split2_train_score': array([-204479.49469695]), 'split3_train_score': array([-544162.15906335]), 'split2_test_score': array([-18428.18260805]), 'split0_test_score': array([-5708.20928619]), 'mean_score_time': array([ 0.02281493]), 'mean_fit_time': array([ 0.03257018]), 'std_train_score': array([ 163973.08156089])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-22106.9597068
####################################################################################
################# Runing the itteration 86  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.5956464]), 'mean_train_score': array([ 0.6201463]), 'split3_test_score': array([ 0.53614243]), 'std_fit_time': array([ 0.01028822]), 'mean_test_score': array([ 0.59274677]), 'split1_test_score': array([ 0.5819827]), 'std_score_time': array([ 0.00297362]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62646041]), 'std_test_score': array([ 0.04665489]), 'split2_train_score': array([ 0.62603748]), 'split3_train_score': array([ 0.63244091]), 'split2_test_score': array([ 0.58694966]), 'split0_test_score': array([ 0.66591229]), 'mean_score_time': array([ 0.00573462]), 'mean_fit_time': array([ 0.05795974]), 'std_train_score': array([ 0.0143699])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.59274676882
####################################################################################
################# Runing the itteration 87  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -3.67889407e+21]), 'mean_train_score': array([ -4.37086763e+24]), 'split3_test_score': array([ -1.83108361e+20]), 'std_fit_time': array([ 0.23770728]), 'mean_test_score': array([ -5.09230111e+24]), 'split1_test_score': array([ -2.03307669e+25]), 'std_score_time': array([ 0.00108997]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -1.74064536e+25]), 'std_test_score': array([  8.79794334e+24]), 'split2_train_score': array([ -7.32179083e+22]), 'split3_train_score': array([ -1.20143214e+20]), 'split2_test_score': array([ -3.54777129e+22]), 'split0_test_score': array([ -2.77667624e+21]), 'mean_score_time': array([ 0.00360161]), 'mean_fit_time': array([ 2.30288643]), 'std_train_score': array([  7.52615548e+24])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-5.09230110725e+24
####################################################################################
################# Runing the itteration 88  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.63448198]), 'mean_train_score': array([ 0.63961401]), 'split3_test_score': array([ 0.40101791]), 'std_fit_time': array([ 0.00226903]), 'mean_test_score': array([ 0.44059766]), 'split1_test_score': array([ 0.43016838]), 'std_score_time': array([ 0.03355558]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6389838]), 'std_test_score': array([ 0.02751305]), 'split2_train_score': array([ 0.6203611]), 'split3_train_score': array([ 0.66462915]), 'split2_test_score': array([ 0.47274689]), 'split0_test_score': array([ 0.45845745]), 'mean_score_time': array([ 0.63353533]), 'mean_fit_time': array([ 0.04387301]), 'std_train_score': array([ 0.01599349])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.440597660137
####################################################################################
################# Runing the itteration 89  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_4', label_fn=<function label_gross_4>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.06123763,
        -0.03816826, -0.10636806]])}
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0          0         1         2         3... -0.038168 -0.106368  

[4812 rows x 128 columns], y=3665       3652206
1131     103735965
1924      ...    121032272
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0          0         1         2         3... -0.038168 -0.106368  

[4812 rows x 128 columns]
        y = 3665       3652206
1131     103735965
1924      ...    121032272
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0          0         1         2         3... -0.038168 -0.106368  

[4812 rows x 128 columns], y=3665       3652206
1131     103735965
1924      ...    121032272
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0          0         1         2         3... -0.038168 -0.106368  

[4812 rows x 128 columns]
        y = 3665       3652206
1131     103735965
1924      ...    121032272
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0          0         1         2         3... -0.038168 -0.106368  

[4812 rows x 128 columns], y=3665       3652206
1131     103735965
1924      ...    121032272
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 14:14:06 2017
PID: 32221                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0          0         1         2         3... -0.038168 -0.106368  

[4812 rows x 128 columns], 3665       3652206
1131     103735965
1924      ...    121032272
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0          0         1         2         3... -0.038168 -0.106368  

[4812 rows x 128 columns], 3665       3652206
1131     103735965
1924      ...    121032272
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1         2         3... -0.038168 -0.106368  

[4812 rows x 128 columns], y=3665       3652206
1131     103735965
1924      ...    121032272
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns]
        y_test = 3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns], y_test=3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns]
        y_test = 3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns], 3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns], 3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns], 3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns], 3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns], y=3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns]
        y = 3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.038168 -0.106368  

[1203 rows x 128 columns], y=3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64, y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 3665      3652206
1131    103735965
1924     470...     63200000
Name: worldwide_gross, dtype: int64
        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([  3652206, 103735965,  47011449, ..., 150886329, 328711434,
        63200000]), y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 90  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  43.3s
[CV]  ................................................................
[CV] ................................................. , total=  47.4s
[CV]  ................................................................
[CV] ................................................. , total=  47.4s
[CV]  ................................................................
[CV] ................................................. , total=  48.0s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28040667]), 'mean_train_score': array([-0.28963626]), 'split3_test_score': array([-0.27556276]), 'std_fit_time': array([ 1.89442981]), 'mean_test_score': array([-0.29226976]), 'split1_test_score': array([-0.25616318]), 'std_score_time': array([ 0.01770243]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.30157585]), 'std_test_score': array([ 0.02731722]), 'split2_train_score': array([-0.28141723]), 'split3_train_score': array([-0.2951453]), 'split2_test_score': array([-0.31674314]), 'split0_test_score': array([-0.32060997]), 'mean_score_time': array([ 0.03337681]), 'mean_fit_time': array([ 46.50258571]), 'std_train_score': array([ 0.00902276])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292269763953
####################################################################################
################# Runing the itteration 91  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13077822]), 'mean_train_score': array([-0.1318538]), 'split3_test_score': array([-0.14267227]), 'std_fit_time': array([ 0.02269995]), 'mean_test_score': array([-0.13253477]), 'split1_test_score': array([-0.14213167]), 'std_score_time': array([ 0.00487643]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13160823]), 'std_test_score': array([ 0.01114169]), 'split2_train_score': array([-0.13264249]), 'split3_train_score': array([-0.13238624]), 'split2_test_score': array([-0.12998044]), 'split0_test_score': array([-0.11535468]), 'mean_score_time': array([ 0.73994046]), 'mean_fit_time': array([ 2.82078731]), 'std_train_score': array([ 0.00072847])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132534768023
####################################################################################
################# Runing the itteration 92  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28754963]), 'mean_train_score': array([-0.28996444]), 'split3_test_score': array([-0.24972924]), 'std_fit_time': array([ 0.00736174]), 'mean_test_score': array([-0.29511354]), 'split1_test_score': array([-0.29742681]), 'std_score_time': array([ 0.01062006]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28677974]), 'std_test_score': array([ 0.0312925]), 'split2_train_score': array([-0.27929879]), 'split3_train_score': array([-0.30622959]), 'split2_test_score': array([-0.33814602]), 'split0_test_score': array([-0.29515209]), 'mean_score_time': array([ 0.02127445]), 'mean_fit_time': array([ 0.03500682]), 'std_train_score': array([ 0.00992831])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295113539199
####################################################################################
################# Runing the itteration 93  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.5s
[CV]  ................................................................
[CV] ................................................. , total=   2.6s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.04936892]), 'mean_train_score': array([-0.05254372]), 'split3_test_score': array([-0.05798088]), 'std_fit_time': array([ 0.01844805]), 'mean_test_score': array([-0.05341427]), 'split1_test_score': array([-0.03938751]), 'std_score_time': array([ 0.00643381]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05362003]), 'std_test_score': array([ 0.01012691]), 'split2_train_score': array([-0.05357383]), 'split3_train_score': array([-0.05361209]), 'split2_test_score': array([-0.0495459]), 'split0_test_score': array([-0.06674278]), 'mean_score_time': array([ 0.37254333]), 'mean_fit_time': array([ 2.19844949]), 'std_train_score': array([ 0.00183305])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0534142681482
####################################################################################
################# Runing the itteration 94  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.3408963]), 'std_fit_time': array([ 0.02586712]), 'mean_test_score': array([ 0.37183399]), 'split1_test_score': array([ 0.41945721]), 'std_score_time': array([  8.93841357e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.03115683]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.37959519]), 'split0_test_score': array([ 0.34738724]), 'mean_score_time': array([ 0.00214678]), 'mean_fit_time': array([ 0.20556754]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.371833985503
####################################################################################
################# Runing the itteration 95  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.42010845]), 'std_fit_time': array([ 0.00075192]), 'mean_test_score': array([ 0.37132666]), 'split1_test_score': array([ 0.32437109]), 'std_score_time': array([ 0.00024686]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.04912004]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.32008981]), 'split0_test_score': array([ 0.4207373]), 'mean_score_time': array([ 0.0020889]), 'mean_fit_time': array([ 0.07260752]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.371326661924
####################################################################################
################# Runing the itteration 96  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.36735841]), 'mean_train_score': array([ 0.44796682]), 'split3_test_score': array([ 0.40777861]), 'std_fit_time': array([ 0.2497714]), 'mean_test_score': array([ 0.33857363]), 'split1_test_score': array([ 0.46286128]), 'std_score_time': array([ 0.00326533]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.50318695]), 'std_test_score': array([ 0.11760029]), 'split2_train_score': array([ 0.34126754]), 'split3_train_score': array([ 0.5800544]), 'split2_test_score': array([ 0.15137604]), 'split0_test_score': array([ 0.33227858]), 'mean_score_time': array([ 0.00958514]), 'mean_fit_time': array([ 0.62833023]), 'std_train_score': array([ 0.0979526])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.338573628115
####################################################################################
################# Runing the itteration 97  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93094899]), 'mean_train_score': array([ 0.92808206]), 'split3_test_score': array([ 0.60150272]), 'std_fit_time': array([ 0.04844806]), 'mean_test_score': array([ 0.55906315]), 'split1_test_score': array([ 0.57288103]), 'std_score_time': array([ 0.00096886]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.9240903]), 'std_test_score': array([ 0.03004986]), 'split2_train_score': array([ 0.92767481]), 'split3_train_score': array([ 0.92961413]), 'split2_test_score': array([ 0.53526322]), 'split0_test_score': array([ 0.52660565]), 'mean_score_time': array([ 0.01143813]), 'mean_fit_time': array([ 0.82304293]), 'std_train_score': array([ 0.00258198])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.559063153093
####################################################################################
################# Runing the itteration 98  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.53744868]), 'std_fit_time': array([ 0.00899011]), 'mean_test_score': array([ 0.56501432]), 'split1_test_score': array([ 0.55857055]), 'std_score_time': array([ 0.00027437]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.01860926]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.58367913]), 'split0_test_score': array([ 0.58035893]), 'mean_score_time': array([ 0.00780249]), 'mean_fit_time': array([ 0.64256817]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.565014323881
####################################################################################
################# Runing the itteration 99  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.76470588]), 'mean_train_score': array([ 0.76327205]), 'split3_test_score': array([ 0.58625807]), 'std_fit_time': array([ 0.02876425]), 'mean_test_score': array([ 0.60617667]), 'split1_test_score': array([ 0.58795512]), 'std_score_time': array([ 0.00255314]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.76033243]), 'std_test_score': array([ 0.01927762]), 'split2_train_score': array([ 0.75890077]), 'split3_train_score': array([ 0.76914914]), 'split2_test_score': array([ 0.62914514]), 'split0_test_score': array([ 0.62134836]), 'mean_score_time': array([ 0.0069707]), 'mean_fit_time': array([ 1.28093201]), 'std_train_score': array([ 0.00401078])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.606176671969
####################################################################################
################# Runing the itteration 100  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92632832]), 'mean_train_score': array([ 0.92249133]), 'split3_test_score': array([ 0.56957661]), 'std_fit_time': array([ 0.04160446]), 'mean_test_score': array([ 0.57962375]), 'split1_test_score': array([ 0.55187897]), 'std_score_time': array([ 0.00036756]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92199582]), 'std_test_score': array([ 0.028112]), 'split2_train_score': array([ 0.91406308]), 'split3_train_score': array([ 0.92757809]), 'split2_test_score': array([ 0.62659378]), 'split0_test_score': array([ 0.57044565]), 'mean_score_time': array([ 0.00709456]), 'mean_fit_time': array([ 0.82115585]), 'std_train_score': array([ 0.00528863])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.579623754377
####################################################################################
################# Runing the itteration 101  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.54854525]), 'mean_train_score': array([ 0.54590971]), 'split3_test_score': array([ 0.53842441]), 'std_fit_time': array([ 0.00927628]), 'mean_test_score': array([ 0.51408952]), 'split1_test_score': array([ 0.50698157]), 'std_score_time': array([ 0.00735662]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.55217417]), 'std_test_score': array([ 0.01633804]), 'split2_train_score': array([ 0.54077749]), 'split3_train_score': array([ 0.54214193]), 'split2_test_score': array([ 0.51723683]), 'split0_test_score': array([ 0.49371526]), 'mean_score_time': array([ 0.02983475]), 'mean_fit_time': array([ 0.14626706]), 'std_train_score': array([ 0.00465632])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.514089516605
####################################################################################
################# Runing the itteration 102  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.2034522]), 'mean_train_score': array([ 0.20285233]), 'split3_test_score': array([ 0.17875708]), 'std_fit_time': array([ 0.05820166]), 'mean_test_score': array([ 0.19525683]), 'split1_test_score': array([ 0.19970831]), 'std_score_time': array([ 0.00159572]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.1893401]), 'std_test_score': array([ 0.00968748]), 'split2_train_score': array([ 0.20805344]), 'split3_train_score': array([ 0.21056356]), 'split2_test_score': array([ 0.20359954]), 'split0_test_score': array([ 0.19896237]), 'mean_score_time': array([ 0.00462711]), 'mean_fit_time': array([ 0.26363307]), 'std_train_score': array([ 0.00820754])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.195256828458
####################################################################################
################# Runing the itteration 103  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.62535844]), 'mean_train_score': array([ 0.61980131]), 'split3_test_score': array([ 0.6037622]), 'std_fit_time': array([ 0.00977925]), 'mean_test_score': array([ 0.55759462]), 'split1_test_score': array([ 0.56657556]), 'std_score_time': array([ 0.0029563]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62399722]), 'std_test_score': array([ 0.03136953]), 'split2_train_score': array([ 0.62272565]), 'split3_train_score': array([ 0.60712393]), 'split2_test_score': array([ 0.54010519]), 'split0_test_score': array([ 0.51993553]), 'mean_score_time': array([ 0.03222525]), 'mean_fit_time': array([ 1.6999492]), 'std_train_score': array([ 0.00737826])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.557594620767
####################################################################################
################# Runing the itteration 104  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.60105606]), 'mean_train_score': array([ 0.61069304]), 'split3_test_score': array([ 0.56099262]), 'std_fit_time': array([ 0.06637084]), 'mean_test_score': array([ 0.56596895]), 'split1_test_score': array([ 0.52564759]), 'std_score_time': array([ 0.00345877]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62003679]), 'std_test_score': array([ 0.02624529]), 'split2_train_score': array([ 0.60889114]), 'split3_train_score': array([ 0.61278818]), 'split2_test_score': array([ 0.58234307]), 'split0_test_score': array([ 0.59489252]), 'mean_score_time': array([ 0.01167327]), 'mean_fit_time': array([ 0.17467314]), 'std_train_score': array([ 0.00685225])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.565968949135
####################################################################################
################# Runing the itteration 105  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.63432131]), 'mean_train_score': array([ 0.61891193]), 'split3_test_score': array([ 0.56298553]), 'std_fit_time': array([ 0.0156208]), 'mean_test_score': array([ 0.56146212]), 'split1_test_score': array([ 0.60749994]), 'std_score_time': array([ 0.01241766]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.60580382]), 'std_test_score': array([ 0.03754145]), 'split2_train_score': array([ 0.6157997]), 'split3_train_score': array([ 0.61972288]), 'split2_test_score': array([ 0.57221124]), 'split0_test_score': array([ 0.50315177]), 'mean_score_time': array([ 0.0213809]), 'mean_fit_time': array([ 0.22608817]), 'std_train_score': array([ 0.01024226])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.561462120258
####################################################################################
################# Runing the itteration 106  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28022609]), 'mean_train_score': array([-0.28921634]), 'split3_test_score': array([-0.28026454]), 'std_fit_time': array([ 0.00096228]), 'mean_test_score': array([-0.29307065]), 'split1_test_score': array([-0.317929]), 'std_score_time': array([ 0.00782628]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28048683]), 'std_test_score': array([ 0.02847638]), 'split2_train_score': array([-0.30405425]), 'split3_train_score': array([-0.2920982]), 'split2_test_score': array([-0.2524826]), 'split0_test_score': array([-0.32160647]), 'mean_score_time': array([ 0.01975864]), 'mean_fit_time': array([ 0.0359199]), 'std_train_score': array([ 0.00981705])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293070652828
####################################################################################
################# Runing the itteration 107  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.6s
[CV]  ................................................................
[CV] ................................................. , total=   2.7s
[CV]  ................................................................
[CV] ................................................. , total=   2.9s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.62015585]), 'mean_train_score': array([ 0.61904491]), 'split3_test_score': array([ 0.60010533]), 'std_fit_time': array([ 0.15174356]), 'mean_test_score': array([ 0.56526301]), 'split1_test_score': array([ 0.58576749]), 'std_score_time': array([ 0.0110346]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61420333]), 'std_test_score': array([ 0.03255796]), 'split2_train_score': array([ 0.63365734]), 'split3_train_score': array([ 0.60816312]), 'split2_test_score': array([ 0.51441604]), 'split0_test_score': array([ 0.56076318]), 'mean_score_time': array([ 0.02867907]), 'mean_fit_time': array([ 2.76849222]), 'std_train_score': array([ 0.00944208])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.565263008052
####################################################################################
################# Runing the itteration 108  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.58650703]), 'mean_train_score': array([ 0.57707749]), 'split3_test_score': array([ 0.56780215]), 'std_fit_time': array([ 0.00509321]), 'mean_test_score': array([ 0.53317138]), 'split1_test_score': array([ 0.59242469]), 'std_score_time': array([ 0.01035679]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.55263574]), 'std_test_score': array([ 0.04856959]), 'split2_train_score': array([ 0.59912752]), 'split3_train_score': array([ 0.57003968]), 'split2_test_score': array([ 0.49885199]), 'split0_test_score': array([ 0.47360666]), 'mean_score_time': array([ 0.02427906]), 'mean_fit_time': array([ 0.03802812]), 'std_train_score': array([ 0.01747892])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.533171375589
####################################################################################
################# Runing the itteration 109  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.58852755]), 'mean_train_score': array([ 0.59278552]), 'split3_test_score': array([ 0.5710443]), 'std_fit_time': array([ 0.01745465]), 'mean_test_score': array([ 0.56236271]), 'split1_test_score': array([ 0.57069233]), 'std_score_time': array([ 0.01915804]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59215512]), 'std_test_score': array([ 0.01495191]), 'split2_train_score': array([ 0.59897237]), 'split3_train_score': array([ 0.59148705]), 'split2_test_score': array([ 0.53646752]), 'split0_test_score': array([ 0.57124669]), 'mean_score_time': array([ 0.0300014]), 'mean_fit_time': array([ 0.0716514]), 'std_train_score': array([ 0.00382396])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.562362710859
####################################################################################
################# Runing the itteration 110  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   5.8s
[CV]  ................................................................
[CV] ................................................. , total=   6.1s
[CV]  ................................................................
[CV] ................................................. , total=   6.2s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -1.98660770e+26]), 'mean_train_score': array([ -9.67772257e+25]), 'split3_test_score': array([ -9.29204124e+25]), 'std_fit_time': array([ 0.31823752]), 'mean_test_score': array([ -9.61418065e+25]), 'split1_test_score': array([ -3.58667009e+25]), 'std_score_time': array([ 0.00986072]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -3.01289069e+25]), 'std_test_score': array([  4.48568621e+25]), 'split2_train_score': array([ -8.04612407e+25]), 'split3_train_score': array([ -7.78579847e+25]), 'split2_test_score': array([ -9.33271872e+25]), 'split0_test_score': array([ -1.62452925e+26]), 'mean_score_time': array([ 0.0128665]), 'mean_fit_time': array([ 5.86727524]), 'std_train_score': array([  6.21417816e+25])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-9.61418064763e+25
####################################################################################
################# Runing the itteration 111  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.57634608]), 'mean_train_score': array([ 0.5907519]), 'split3_test_score': array([ 0.35662362]), 'std_fit_time': array([ 0.00835547]), 'mean_test_score': array([ 0.31318939]), 'split1_test_score': array([ 0.30661232]), 'std_score_time': array([ 0.14127373]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.57401492]), 'std_test_score': array([ 0.03367753]), 'split2_train_score': array([ 0.62256772]), 'split3_train_score': array([ 0.59007886]), 'split2_test_score': array([ 0.26371496]), 'split0_test_score': array([ 0.32580666]), 'mean_score_time': array([ 0.88801557]), 'mean_fit_time': array([ 0.0603413]), 'std_train_score': array([ 0.0193672])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.313189389853
####################################################################################
################# Runing the itteration 112  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_4', label_fn=<function label_gross_4>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 194 columns], y=3686      3438735
3232     10051516
419     2679...     82000000
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58277497078128038}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 194 columns]
        y = 3686      3438735
3232     10051516
419     2679...     82000000
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 194 columns], y=3686      3438735
3232     10051516
419     2679...     82000000
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 194 columns]
        y = 3686      3438735
3232     10051516
419     2679...     82000000
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 194 columns], y=3686      3438735
3232     10051516
419     2679...     82000000
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 14:21:04 2017
PID: 1076                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 194 columns], 3686      3438735
3232     10051516
419     2679...     82000000
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 194 columns], 3686      3438735
3232     10051516
419     2679...     82000000
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 194 columns], y=3686      3438735
3232     10051516
419     2679...     82000000
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y_test = 3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y_test=3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y_test = 3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y=3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y = 3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y=3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64, y_pred=array([       nan,        nan,        nan, ...,        nan,  29362594.,
              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 3686      3438735
3232     10051516
419     2679...    174122780
Name: worldwide_gross, dtype: int64
        y_pred = array([       nan,        nan,        nan, ...,        nan,  29362594.,
              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([  3438735,  10051516, 267985456, ...,  19184820, 213463976,
       174122780]), y_pred=array([       nan,        nan,        nan, ...,        nan,  29362594.,
              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([       nan,        nan,        nan, ...,        nan,  29362594.,
              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([       nan,        nan,        nan, ...,        nan,  29362594.,
              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([       nan,        nan,        nan, ...,        nan,  29362594.,
              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([       nan,        nan,        nan, ...,        nan,  29362594.,
              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 113  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.0min
[CV]  ................................................................
[CV] ................................................. , total=  59.0s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.27701606]), 'mean_train_score': array([-0.29059574]), 'split3_test_score': array([-0.28831927]), 'std_fit_time': array([ 1.63887519]), 'mean_test_score': array([-0.30133915]), 'split1_test_score': array([-0.32903371]), 'std_score_time': array([ 0.09122004]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27754953]), 'std_test_score': array([ 0.04753449]), 'split2_train_score': array([-0.31765308]), 'split3_train_score': array([-0.29016427]), 'split2_test_score': array([-0.23078025]), 'split0_test_score': array([-0.35722338]), 'mean_score_time': array([ 0.11504292]), 'mean_fit_time': array([ 61.47777027]), 'std_train_score': array([ 0.01648406])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.301339151144
####################################################################################
################# Runing the itteration 114  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13266502]), 'mean_train_score': array([-0.13201215]), 'split3_test_score': array([-0.13749761]), 'std_fit_time': array([ 0.06141285]), 'mean_test_score': array([-0.13308496]), 'split1_test_score': array([-0.12570346]), 'std_score_time': array([ 0.01603782]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13951889]), 'std_test_score': array([ 0.00894432]), 'split2_train_score': array([-0.12656651]), 'split3_train_score': array([-0.12929817]), 'split2_test_score': array([-0.14556116]), 'split0_test_score': array([-0.12357762]), 'mean_score_time': array([ 1.04867417]), 'mean_fit_time': array([ 3.73002082]), 'std_train_score': array([ 0.00484247])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.133084962437
####################################################################################
################# Runing the itteration 115  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28218745]), 'mean_train_score': array([-0.28979044]), 'split3_test_score': array([-0.26479787]), 'std_fit_time': array([ 0.00587093]), 'mean_test_score': array([-0.29311146]), 'split1_test_score': array([-0.25100461]), 'std_score_time': array([ 0.0049511]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.30297505]), 'std_test_score': array([ 0.03589355]), 'split2_train_score': array([-0.27480935]), 'split3_train_score': array([-0.2991899]), 'split2_test_score': array([-0.33536524]), 'split0_test_score': array([-0.3212781]), 'mean_score_time': array([ 0.01496977]), 'mean_fit_time': array([ 0.0395115]), 'std_train_score': array([ 0.01166643])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293111455123
####################################################################################
################# Runing the itteration 116  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05091775]), 'mean_train_score': array([-0.05228115]), 'split3_test_score': array([-0.06165936]), 'std_fit_time': array([ 0.02809886]), 'mean_test_score': array([-0.05319284]), 'split1_test_score': array([-0.03843587]), 'std_score_time': array([ 0.01393236]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05463026]), 'std_test_score': array([ 0.01065954]), 'split2_train_score': array([-0.05076025]), 'split3_train_score': array([-0.05281634]), 'split2_test_score': array([-0.06486063]), 'split0_test_score': array([-0.04781551]), 'mean_score_time': array([ 0.52911609]), 'mean_fit_time': array([ 2.80776387]), 'std_train_score': array([ 0.0015793])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0531928444239
####################################################################################
################# Runing the itteration 117  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.38144738]), 'std_fit_time': array([ 0.00231694]), 'mean_test_score': array([ 0.29248916]), 'split1_test_score': array([ 0.22759299]), 'std_score_time': array([ 0.00024379]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.07018589]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.34083058]), 'split0_test_score': array([ 0.22008568]), 'mean_score_time': array([ 0.00252956]), 'mean_fit_time': array([ 0.14627439]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.292489155741
####################################################################################
################# Runing the itteration 118  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([-0.12277273]), 'std_fit_time': array([ 0.00274947]), 'mean_test_score': array([ 0.18670877]), 'split1_test_score': array([ 0.43913916]), 'std_score_time': array([ 0.00026027]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.20728132]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.28849708]), 'split0_test_score': array([ 0.14197159]), 'mean_score_time': array([ 0.00252825]), 'mean_fit_time': array([ 0.08293486]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.186708772476
####################################################################################
################# Runing the itteration 119  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.12478472]), 'mean_train_score': array([ 0.38145943]), 'split3_test_score': array([ 0.01626168]), 'std_fit_time': array([ 0.09924409]), 'mean_test_score': array([ 0.2790379]), 'split1_test_score': array([ 0.35615236]), 'std_score_time': array([ 0.00167075]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.44628751]), 'std_test_score': array([ 0.1628063]), 'split2_train_score': array([ 0.62741348]), 'split3_train_score': array([ 0.32735201]), 'split2_test_score': array([ 0.45490623]), 'split0_test_score': array([ 0.28883132]), 'mean_score_time': array([ 0.0072372]), 'mean_fit_time': array([ 0.4059965]), 'std_train_score': array([ 0.18269209])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.279037898988
####################################################################################
################# Runing the itteration 120  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93821151]), 'mean_train_score': array([ 0.93738758]), 'split3_test_score': array([ 0.55048936]), 'std_fit_time': array([ 0.01726218]), 'mean_test_score': array([ 0.62864263]), 'split1_test_score': array([ 0.66436377]), 'std_score_time': array([  9.64811236e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93318215]), 'std_test_score': array([ 0.04656036]), 'split2_train_score': array([ 0.9358485]), 'split3_train_score': array([ 0.94230817]), 'split2_test_score': array([ 0.63594301]), 'split0_test_score': array([ 0.66377439]), 'mean_score_time': array([ 0.00642931]), 'mean_fit_time': array([ 0.54160571]), 'std_train_score': array([ 0.00335207])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.628642630719
####################################################################################
################# Runing the itteration 121  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.61081824]), 'std_fit_time': array([ 0.02369507]), 'mean_test_score': array([ 0.59823191]), 'split1_test_score': array([ 0.59153949]), 'std_score_time': array([ 0.00028801]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.06303352]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.68380707]), 'split0_test_score': array([ 0.50676286]), 'mean_score_time': array([ 0.00601822]), 'mean_fit_time': array([ 0.3182627]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.598231912882
####################################################################################
################# Runing the itteration 122  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.80286509]), 'mean_train_score': array([ 0.80309796]), 'split3_test_score': array([ 0.68907769]), 'std_fit_time': array([ 0.00381608]), 'mean_test_score': array([ 0.66200492]), 'split1_test_score': array([ 0.66808774]), 'std_score_time': array([ 0.00018868]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.8004496]), 'std_test_score': array([ 0.02538378]), 'split2_train_score': array([ 0.81162725]), 'split3_train_score': array([ 0.7974499]), 'split2_test_score': array([ 0.67050463]), 'split0_test_score': array([ 0.62034962]), 'mean_score_time': array([ 0.00390518]), 'mean_fit_time': array([ 0.55865127]), 'std_train_score': array([ 0.00528483])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.662004919102
####################################################################################
################# Runing the itteration 123  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93238176]), 'mean_train_score': array([ 0.93759914]), 'split3_test_score': array([ 0.65290447]), 'std_fit_time': array([ 0.00437411]), 'mean_test_score': array([ 0.62291452]), 'split1_test_score': array([ 0.63541914]), 'std_score_time': array([ 0.00025346]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93832782]), 'std_test_score': array([ 0.0313706]), 'split2_train_score': array([ 0.94045041]), 'split3_train_score': array([ 0.93923658]), 'split2_test_score': array([ 0.57022045]), 'split0_test_score': array([ 0.63311405]), 'mean_score_time': array([ 0.00582212]), 'mean_fit_time': array([ 0.53217989]), 'std_train_score': array([ 0.00310496])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.622914523894
####################################################################################
################# Runing the itteration 124  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.54974176]), 'mean_train_score': array([ 0.53848106]), 'split3_test_score': array([ 0.54942309]), 'std_fit_time': array([ 0.00506768]), 'mean_test_score': array([ 0.52939456]), 'split1_test_score': array([ 0.53448943]), 'std_score_time': array([ 0.01313499]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.53739347]), 'std_test_score': array([ 0.0136909]), 'split2_train_score': array([ 0.5391169]), 'split3_train_score': array([ 0.52767213]), 'split2_test_score': array([ 0.51871311]), 'split0_test_score': array([ 0.51495262]), 'mean_score_time': array([ 0.01696426]), 'mean_fit_time': array([ 0.04770792]), 'std_train_score': array([ 0.0078298])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.529394564183
####################################################################################
################# Runing the itteration 125  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.21250353]), 'mean_train_score': array([ 0.20704508]), 'split3_test_score': array([ 0.18439065]), 'std_fit_time': array([ 0.01287257]), 'mean_test_score': array([ 0.20488001]), 'split1_test_score': array([ 0.20656433]), 'std_score_time': array([ 0.00038835]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.2084442]), 'std_test_score': array([ 0.01431326]), 'split2_train_score': array([ 0.19319264]), 'split3_train_score': array([ 0.21403993]), 'split2_test_score': array([ 0.22477089]), 'split0_test_score': array([ 0.20379417]), 'mean_score_time': array([ 0.00322527]), 'mean_fit_time': array([ 0.12948608]), 'std_train_score': array([ 0.00825485])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.20488000939
####################################################################################
################# Runing the itteration 126  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.60896916]), 'mean_train_score': array([ 0.60870421]), 'split3_test_score': array([ 0.63053254]), 'std_fit_time': array([ 0.00650657]), 'mean_test_score': array([ 0.58877321]), 'split1_test_score': array([ 0.58439793]), 'std_score_time': array([ 0.01129739]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61038899]), 'std_test_score': array([ 0.02795426]), 'split2_train_score': array([ 0.61866582]), 'split3_train_score': array([ 0.59679287]), 'split2_test_score': array([ 0.5518604]), 'split0_test_score': array([ 0.58830195]), 'mean_score_time': array([ 0.01932085]), 'mean_fit_time': array([ 0.51299006]), 'std_train_score': array([ 0.00781061])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.588773205938
####################################################################################
################# Runing the itteration 127  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.59630092]), 'mean_train_score': array([ 0.58911911]), 'split3_test_score': array([ 0.46456521]), 'std_fit_time': array([ 0.0067561]), 'mean_test_score': array([ 0.57125833]), 'split1_test_score': array([ 0.56753742]), 'std_score_time': array([ 0.00277772]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61252833]), 'std_test_score': array([ 0.06700419]), 'split2_train_score': array([ 0.58700727]), 'split3_train_score': array([ 0.56063995]), 'split2_test_score': array([ 0.6417191]), 'split0_test_score': array([ 0.61121158]), 'mean_score_time': array([ 0.00387621]), 'mean_fit_time': array([ 0.06624949]), 'std_train_score': array([ 0.01880886])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.571258326644
####################################################################################
################# Runing the itteration 128  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.63287066]), 'mean_train_score': array([ 0.60933277]), 'split3_test_score': array([ 0.59459626]), 'std_fit_time': array([ 0.01909955]), 'mean_test_score': array([ 0.59143555]), 'split1_test_score': array([ 0.63268932]), 'std_score_time': array([ 0.00434154]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.5920371]), 'std_test_score': array([ 0.03480911]), 'split2_train_score': array([ 0.60563745]), 'split3_train_score': array([ 0.60678586]), 'split2_test_score': array([ 0.60200415]), 'split0_test_score': array([ 0.53645247]), 'mean_score_time': array([ 0.00987315]), 'mean_fit_time': array([ 0.09170175]), 'std_train_score': array([ 0.01477595])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.591435548031
####################################################################################
################# Runing the itteration 129  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28666113]), 'mean_train_score': array([-0.28930818]), 'split3_test_score': array([-0.30765494]), 'std_fit_time': array([ 0.00025826]), 'mean_test_score': array([-0.29343723]), 'split1_test_score': array([-0.31080895]), 'std_score_time': array([ 0.01059894]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28170885]), 'std_test_score': array([ 0.02039231]), 'split2_train_score': array([-0.30414046]), 'split3_train_score': array([-0.28472226]), 'split2_test_score': array([-0.25946946]), 'split0_test_score': array([-0.29581559]), 'mean_score_time': array([ 0.02700168]), 'mean_fit_time': array([ 0.01813269]), 'std_train_score': array([ 0.00874334])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293437231323
####################################################################################
################# Runing the itteration 130  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.60735335]), 'mean_train_score': array([ 0.60776558]), 'split3_test_score': array([ 0.57146704]), 'std_fit_time': array([ 0.03945749]), 'mean_test_score': array([ 0.58791919]), 'split1_test_score': array([ 0.62194981]), 'std_score_time': array([ 0.00785818]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59663146]), 'std_test_score': array([ 0.02173568]), 'split2_train_score': array([ 0.6141516]), 'split3_train_score': array([ 0.61292589]), 'split2_test_score': array([ 0.56675049]), 'split0_test_score': array([ 0.59150943]), 'mean_score_time': array([ 0.0185622]), 'mean_fit_time': array([ 0.7469759]), 'std_train_score': array([ 0.00692006])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.587919194241
####################################################################################
################# Runing the itteration 131  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.59216731]), 'mean_train_score': array([ 0.59404292]), 'split3_test_score': array([ 0.57801394]), 'std_fit_time': array([ 0.00042928]), 'mean_test_score': array([ 0.57226677]), 'split1_test_score': array([ 0.51709164]), 'std_score_time': array([ 0.01096348]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61127961]), 'std_test_score': array([ 0.03766509]), 'split2_train_score': array([ 0.58115531]), 'split3_train_score': array([ 0.59156943]), 'split2_test_score': array([ 0.62320812]), 'split0_test_score': array([ 0.57075338]), 'mean_score_time': array([ 0.02104843]), 'mean_fit_time': array([ 0.01887065]), 'std_train_score': array([ 0.01087233])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.572266770479
####################################################################################
################# Runing the itteration 132  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.59257845]), 'mean_train_score': array([ 0.59291643]), 'split3_test_score': array([ 0.59457315]), 'std_fit_time': array([ 0.00714383]), 'mean_test_score': array([ 0.58598345]), 'split1_test_score': array([ 0.62784042]), 'std_score_time': array([ 0.00195603]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58153396]), 'std_test_score': array([ 0.03004983]), 'split2_train_score': array([ 0.61055803]), 'split3_train_score': array([ 0.58699529]), 'split2_test_score': array([ 0.54473285]), 'split0_test_score': array([ 0.57678739]), 'mean_score_time': array([ 0.00440514]), 'mean_fit_time': array([ 0.03979969]), 'std_train_score': array([ 0.01090827])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.585983450042
####################################################################################
################# Runing the itteration 133  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([-0.41858109]), 'mean_train_score': array([ -3.84333558e+19]), 'split3_test_score': array([-4435390.06906754]), 'std_fit_time': array([ 0.11468254]), 'mean_test_score': array([ -5.17761444e+19]), 'split1_test_score': array([ -2.07104577e+20]), 'std_score_time': array([ 0.00026484]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -1.53733423e+20]), 'std_test_score': array([  8.96789127e+19]), 'split2_train_score': array([-0.08799611]), 'split3_train_score': array([-2550561.24333716]), 'split2_test_score': array([ 0.14156755]), 'split0_test_score': array([ 0.07909238]), 'mean_score_time': array([ 0.00177944]), 'mean_fit_time': array([ 0.37219411]), 'std_train_score': array([  6.65685249e+19])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-5.17761443628e+19
####################################################################################
################# Runing the itteration 134  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.70259846]), 'mean_train_score': array([ 0.67628058]), 'split3_test_score': array([ 0.48398597]), 'std_fit_time': array([ 0.00562286]), 'mean_test_score': array([ 0.46713249]), 'split1_test_score': array([ 0.48804125]), 'std_score_time': array([ 0.02528476]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6737004]), 'std_test_score': array([ 0.01995985]), 'split2_train_score': array([ 0.66582021]), 'split3_train_score': array([ 0.66300326]), 'split2_test_score': array([ 0.45717812]), 'split0_test_score': array([ 0.43932463]), 'mean_score_time': array([ 0.32058758]), 'mean_fit_time': array([ 0.02975762]), 'std_train_score': array([ 0.01569232])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.467132493314
####################################################################################
################# Runing the itteration 135  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_4', label_fn=<function label_gross_4>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], y=643      187707495
3511       5656388
2914      ...      6537179
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns]
        y = 643      187707495
3511       5656388
2914      ...      6537179
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], y=643      187707495
3511       5656388
2914      ...      6537179
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns]
        y = 643      187707495
3511       5656388
2914      ...      6537179
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], y=643      187707495
3511       5656388
2914      ...      6537179
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 14:29:28 2017
PID: 2398                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], 643      187707495
3511       5656388
2914      ...      6537179
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], 643      187707495
3511       5656388
2914      ...      6537179
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 58 columns], y=643      187707495
3511       5656388
2914      ...      6537179
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns]
        y_test = 643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], y_test=643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns]
        y_test = 643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], 643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], 643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], 643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], 643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], y=643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns]
        y = 643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 58 columns], y=643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64, y_pred=array([             nan,   3.93991572e+07,      ...6195162e+08,   7.43625420e+07,   2.26583955e+07]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 643     187707495
3511      5656388
2914     155...     25878153
Name: worldwide_gross, dtype: int64
        y_pred = array([             nan,   3.93991572e+07,      ...6195162e+08,   7.43625420e+07,   2.26583955e+07])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([187707495,   5656388,  15505922, ..., 233700000, 319700000,
        25878153]), y_pred=array([             nan,   3.93991572e+07,      ...6195162e+08,   7.43625420e+07,   2.26583955e+07]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([             nan,   3.93991572e+07,      ...6195162e+08,   7.43625420e+07,   2.26583955e+07])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([             nan,   3.93991572e+07,      ...6195162e+08,   7.43625420e+07,   2.26583955e+07]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([             nan,   3.93991572e+07,      ...6195162e+08,   7.43625420e+07,   2.26583955e+07])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([             nan,   3.93991572e+07,      ...6195162e+08,   7.43625420e+07,   2.26583955e+07]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 136  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  24.2s
[CV]  ................................................................
[CV] ................................................. , total=  24.8s
[CV]  ................................................................
[CV] ................................................. , total=  19.6s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.29060549]), 'mean_train_score': array([-0.29006949]), 'split3_test_score': array([-0.25405412]), 'std_fit_time': array([ 2.54168597]), 'mean_test_score': array([-0.29542157]), 'split1_test_score': array([-0.31302726]), 'std_score_time': array([ 0.00216787]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28406159]), 'std_test_score': array([ 0.02552229]), 'split2_train_score': array([-0.28265071]), 'split3_train_score': array([-0.30296019]), 'split2_test_score': array([-0.31959089]), 'split0_test_score': array([-0.29501402]), 'mean_score_time': array([ 0.01103574]), 'mean_fit_time': array([ 21.95747536]), 'std_train_score': array([ 0.00802481])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295421570944
####################################################################################
################# Runing the itteration 137  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.12700598]), 'mean_train_score': array([-0.13186393]), 'split3_test_score': array([-0.13103675]), 'std_fit_time': array([ 0.01002363]), 'mean_test_score': array([-0.13249349]), 'split1_test_score': array([-0.15057459]), 'std_score_time': array([ 0.00444501]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13070317]), 'std_test_score': array([ 0.01307479]), 'split2_train_score': array([-0.13496746]), 'split3_train_score': array([-0.13477911]), 'split2_test_score': array([-0.11377535]), 'split0_test_score': array([-0.13458729]), 'mean_score_time': array([ 0.42352921]), 'mean_fit_time': array([ 1.78256959]), 'std_train_score': array([ 0.00328166])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132493494003
####################################################################################
################# Runing the itteration 138  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.27882761]), 'mean_train_score': array([-0.29024252]), 'split3_test_score': array([-0.24144882]), 'std_fit_time': array([ 0.00237709]), 'mean_test_score': array([-0.29629945]), 'split1_test_score': array([-0.31451141]), 'std_score_time': array([ 0.00768711]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28129204]), 'std_test_score': array([ 0.03479124]), 'split2_train_score': array([-0.28866509]), 'split3_train_score': array([-0.31218536]), 'split2_test_score': array([-0.29424404]), 'split0_test_score': array([-0.33499352]), 'mean_score_time': array([ 0.01981199]), 'mean_fit_time': array([ 0.02072293]), 'std_train_score': array([ 0.01317562])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.296299449528
####################################################################################
################# Runing the itteration 139  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05026625]), 'mean_train_score': array([-0.05198816]), 'split3_test_score': array([-0.05994299]), 'std_fit_time': array([ 0.00645306]), 'mean_test_score': array([-0.05289891]), 'split1_test_score': array([-0.04200192]), 'std_score_time': array([ 0.00182796]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05037413]), 'std_test_score': array([ 0.01155072]), 'split2_train_score': array([-0.05527658]), 'split3_train_score': array([-0.05203567]), 'split2_test_score': array([-0.04144833]), 'split0_test_score': array([-0.06820241]), 'mean_score_time': array([ 0.21356189]), 'mean_fit_time': array([ 1.43555588]), 'std_train_score': array([ 0.00202398])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0528989118784
####################################################################################
################# Runing the itteration 140  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.40241114]), 'std_fit_time': array([ 0.00211488]), 'mean_test_score': array([ 0.39245891]), 'split1_test_score': array([ 0.32213906]), 'std_score_time': array([ 0.0001424]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.07559585]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.51206553]), 'split0_test_score': array([ 0.3332199]), 'mean_score_time': array([ 0.00179052]), 'mean_fit_time': array([ 0.09453517]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.392458908679
####################################################################################
################# Runing the itteration 141  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.28453719]), 'std_fit_time': array([ 0.0004654]), 'mean_test_score': array([ 0.32077639]), 'split1_test_score': array([ 0.30124454]), 'std_score_time': array([  4.84246564e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05987661]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.42312954]), 'split0_test_score': array([ 0.27419427]), 'mean_score_time': array([ 0.00169003]), 'mean_fit_time': array([ 0.04016185]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.32077638543
####################################################################################
################# Runing the itteration 142  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.05701696]), 'mean_train_score': array([ 0.19053968]), 'split3_test_score': array([-0.53074035]), 'std_fit_time': array([ 0.22564164]), 'mean_test_score': array([ 0.02693223]), 'split1_test_score': array([ 0.49104144]), 'std_score_time': array([ 0.00316856]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61272642]), 'std_test_score': array([ 0.4493906]), 'split2_train_score': array([ 0.55046485]), 'split3_train_score': array([-0.45804951]), 'split2_test_score': array([ 0.445893]), 'split0_test_score': array([-0.29846516]), 'mean_score_time': array([ 0.00821805]), 'mean_fit_time': array([ 0.59887379]), 'std_train_score': array([ 0.43193866])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.0269322322034
####################################################################################
################# Runing the itteration 143  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92245292]), 'mean_train_score': array([ 0.92980318]), 'split3_test_score': array([ 0.5725934]), 'std_fit_time': array([ 0.01675443]), 'mean_test_score': array([ 0.57676238]), 'split1_test_score': array([ 0.53414725]), 'std_score_time': array([  8.54398851e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92993713]), 'std_test_score': array([ 0.04436626]), 'split2_train_score': array([ 0.9400811]), 'split3_train_score': array([ 0.92674158]), 'split2_test_score': array([ 0.55042691]), 'split0_test_score': array([ 0.64988196]), 'mean_score_time': array([ 0.00804281]), 'mean_fit_time': array([ 0.90183365]), 'std_train_score': array([ 0.00650102])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.576762377445
####################################################################################
################# Runing the itteration 144  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.55552748]), 'std_fit_time': array([ 0.03186569]), 'mean_test_score': array([ 0.56458264]), 'split1_test_score': array([ 0.56938905]), 'std_score_time': array([ 0.00049496]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.02622464]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.53039719]), 'split0_test_score': array([ 0.60301681]), 'mean_score_time': array([ 0.00732404]), 'mean_fit_time': array([ 0.56206822]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.564582635289
####################################################################################
################# Runing the itteration 145  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.78501479]), 'mean_train_score': array([ 0.78448779]), 'split3_test_score': array([ 0.63976875]), 'std_fit_time': array([ 0.05160178]), 'mean_test_score': array([ 0.61626415]), 'split1_test_score': array([ 0.59733956]), 'std_score_time': array([ 0.00042796]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.76864124]), 'std_test_score': array([ 0.02153127]), 'split2_train_score': array([ 0.79777378]), 'split3_train_score': array([ 0.78652136]), 'split2_test_score': array([ 0.59237221]), 'split0_test_score': array([ 0.63557608]), 'mean_score_time': array([ 0.00409687]), 'mean_fit_time': array([ 0.98283356]), 'std_train_score': array([ 0.01039283])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.616264146513
####################################################################################
################# Runing the itteration 146  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93331566]), 'mean_train_score': array([ 0.93055706]), 'split3_test_score': array([ 0.49797207]), 'std_fit_time': array([ 0.01366338]), 'mean_test_score': array([ 0.58123726]), 'split1_test_score': array([ 0.67773191]), 'std_score_time': array([ 0.00031418]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93115518]), 'std_test_score': array([ 0.06703969]), 'split2_train_score': array([ 0.93143696]), 'split3_train_score': array([ 0.92632043]), 'split2_test_score': array([ 0.54593925]), 'split0_test_score': array([ 0.60330582]), 'mean_score_time': array([ 0.00645274]), 'mean_fit_time': array([ 0.87262976]), 'std_train_score': array([ 0.00258316])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.581237260759
####################################################################################
################# Runing the itteration 147  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.61406514]), 'mean_train_score': array([ 0.60080906]), 'split3_test_score': array([ 0.5791402]), 'std_fit_time': array([ 0.00855026]), 'mean_test_score': array([ 0.57347427]), 'split1_test_score': array([ 0.59352476]), 'std_score_time': array([ 0.00429622]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58440097]), 'std_test_score': array([ 0.02043483]), 'split2_train_score': array([ 0.60112126]), 'split3_train_score': array([ 0.60364888]), 'split2_test_score': array([ 0.58189443]), 'split0_test_score': array([ 0.5393377]), 'mean_score_time': array([ 0.01293379]), 'mean_fit_time': array([ 0.10358596]), 'std_train_score': array([ 0.0106432])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.573474270036
####################################################################################
################# Runing the itteration 148  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.27408225]), 'mean_train_score': array([ 0.27363858]), 'split3_test_score': array([ 0.25941911]), 'std_fit_time': array([ 0.10177633]), 'mean_test_score': array([ 0.2691012]), 'split1_test_score': array([ 0.27602139]), 'std_score_time': array([ 0.0008367]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.27240303]), 'std_test_score': array([ 0.01626171]), 'split2_train_score': array([ 0.28109999]), 'split3_train_score': array([ 0.26696904]), 'split2_test_score': array([ 0.24912416]), 'split0_test_score': array([ 0.29184014]), 'mean_score_time': array([ 0.00436074]), 'mean_fit_time': array([ 0.25730634]), 'std_train_score': array([ 0.00504675])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.269101198896
####################################################################################
################# Runing the itteration 149  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.65462853]), 'mean_train_score': array([ 0.63423626]), 'split3_test_score': array([ 0.3964676]), 'std_fit_time': array([ 0.00732003]), 'mean_test_score': array([ 0.54528993]), 'split1_test_score': array([ 0.60400018]), 'std_score_time': array([ 0.00985638]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63269314]), 'std_test_score': array([ 0.09470906]), 'split2_train_score': array([ 0.61592363]), 'split3_train_score': array([ 0.63369974]), 'split2_test_score': array([ 0.64613194]), 'split0_test_score': array([ 0.53456001]), 'mean_score_time': array([ 0.01789713]), 'mean_fit_time': array([ 1.06426013]), 'std_train_score': array([ 0.01372831])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.545289934505
####################################################################################
################# Runing the itteration 150  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.64166419]), 'mean_train_score': array([ 0.61957425]), 'split3_test_score': array([ 0.57862516]), 'std_fit_time': array([ 0.0498252]), 'mean_test_score': array([ 0.02970575]), 'split1_test_score': array([-1.61187156]), 'std_score_time': array([ 0.00132252]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.5809926]), 'std_test_score': array([ 0.94856757]), 'split2_train_score': array([ 0.61932915]), 'split3_train_score': array([ 0.63631106]), 'split2_test_score': array([ 0.63118248]), 'split0_test_score': array([ 0.52088692]), 'mean_score_time': array([ 0.00667101]), 'mean_fit_time': array([ 0.15541476]), 'std_train_score': array([ 0.02375232])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.0297057482448
####################################################################################
################# Runing the itteration 151  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.63793947]), 'mean_train_score': array([ 0.63255089]), 'split3_test_score': array([ 0.52503344]), 'std_fit_time': array([ 0.03604193]), 'mean_test_score': array([ 0.57476574]), 'split1_test_score': array([ 0.563145]), 'std_score_time': array([ 0.00322314]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64277927]), 'std_test_score': array([ 0.04113018]), 'split2_train_score': array([ 0.61663003]), 'split3_train_score': array([ 0.6328548]), 'split2_test_score': array([ 0.63917893]), 'split0_test_score': array([ 0.57170558]), 'mean_score_time': array([ 0.00626153]), 'mean_fit_time': array([ 0.12031233]), 'std_train_score': array([ 0.00983899])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.574765738332
####################################################################################
################# Runing the itteration 152  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28553901]), 'mean_train_score': array([-0.28877865]), 'split3_test_score': array([-0.26502924]), 'std_fit_time': array([ 0.00433064]), 'mean_test_score': array([-0.28951567]), 'split1_test_score': array([-0.28636417]), 'std_score_time': array([ 0.00193923]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28947572]), 'std_test_score': array([ 0.01614712]), 'split2_train_score': array([-0.28287375]), 'split3_train_score': array([-0.29722611]), 'split2_test_score': array([-0.30840776]), 'split0_test_score': array([-0.2982615]), 'mean_score_time': array([ 0.01313895]), 'mean_fit_time': array([ 0.03053141]), 'std_train_score': array([ 0.00541314])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.289515666033
####################################################################################
################# Runing the itteration 153  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.64843014]), 'mean_train_score': array([ 0.63624998]), 'split3_test_score': array([ 0.39273211]), 'std_fit_time': array([ 0.13931389]), 'mean_test_score': array([ 0.54688721]), 'split1_test_score': array([ 0.65122781]), 'std_score_time': array([ 0.00162118]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61541899]), 'std_test_score': array([ 0.09642896]), 'split2_train_score': array([ 0.63683178]), 'split3_train_score': array([ 0.64431902]), 'split2_test_score': array([ 0.59731581]), 'split0_test_score': array([ 0.54627311]), 'mean_score_time': array([ 0.00520182]), 'mean_fit_time': array([ 1.71153218]), 'std_train_score': array([ 0.01272531])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.54688720839
####################################################################################
################# Runing the itteration 154  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-180743.36540329]), 'mean_train_score': array([-332383.27810487]), 'split3_test_score': array([-9.73510251]), 'std_fit_time': array([ 0.00343435]), 'mean_test_score': array([-79628.11298975]), 'split1_test_score': array([-291520.71023261]), 'std_score_time': array([ 0.01020098]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-1148615.10466103]), 'std_test_score': array([ 122830.02428246]), 'split2_train_score': array([-91.1918399]), 'split3_train_score': array([-83.45051526]), 'split2_test_score': array([-17.58421851]), 'split0_test_score': array([-26964.42240538]), 'mean_score_time': array([ 0.02970892]), 'mean_fit_time': array([ 0.02921689]), 'std_train_score': array([ 476988.01447672])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-79628.1129898
####################################################################################
################# Runing the itteration 155  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.61230869]), 'mean_train_score': array([ 0.61584223]), 'split3_test_score': array([ 0.64586125]), 'std_fit_time': array([ 0.00680635]), 'mean_test_score': array([ 0.58595312]), 'split1_test_score': array([ 0.48810319]), 'std_score_time': array([ 0.00191844]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64610989]), 'std_test_score': array([ 0.0590575]), 'split2_train_score': array([ 0.61247415]), 'split3_train_score': array([ 0.59247616]), 'split2_test_score': array([ 0.59910283]), 'split0_test_score': array([ 0.61074523]), 'mean_score_time': array([ 0.0117721]), 'mean_fit_time': array([ 0.04697859]), 'std_train_score': array([ 0.01927391])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.585953124755
####################################################################################
################# Runing the itteration 156  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   2.1s
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -2.39834528e+22]), 'mean_train_score': array([ -5.13839575e+23]), 'split3_test_score': array([-2.33237036]), 'std_fit_time': array([ 0.20234427]), 'mean_test_score': array([ -3.27505004e+23]), 'split1_test_score': array([ -1.86586169e+23]), 'std_score_time': array([ 0.0063513]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -1.68021106e+23]), 'std_test_score': array([  4.51996607e+23]), 'split2_train_score': array([ -1.40868411e+24]), 'split3_train_score': array([ -4.54669632e+23]), 'split2_test_score': array([ -1.10040776e+24]), 'split0_test_score': array([ -2.30260857e+22]), 'mean_score_time': array([ 0.00663912]), 'mean_fit_time': array([ 2.17530715]), 'std_train_score': array([  5.39397176e+23])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3.27505004393e+23
####################################################################################
################# Runing the itteration 157  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.63014057]), 'mean_train_score': array([ 0.63691022]), 'split3_test_score': array([ 0.48773844]), 'std_fit_time': array([ 0.00513328]), 'mean_test_score': array([ 0.43890154]), 'split1_test_score': array([ 0.4252916]), 'std_score_time': array([ 0.08615288]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64287697]), 'std_test_score': array([ 0.02859551]), 'split2_train_score': array([ 0.65110271]), 'split3_train_score': array([ 0.62352061]), 'split2_test_score': array([ 0.42761539]), 'split0_test_score': array([ 0.41496073]), 'mean_score_time': array([ 0.59356242]), 'mean_fit_time': array([ 0.03879374]), 'std_train_score': array([ 0.01074871])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.438901540107
####################################################################################
################# Runing the itteration 158  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_4', label_fn=<function label_gross_4>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.03816826,
        -0.05200382, -0.10636806]])}
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 122 columns], y=505     227200000
1719     57293371
1738     564...    200700000
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 122 columns]
        y = 505     227200000
1719     57293371
1738     564...    200700000
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 122 columns], y=505     227200000
1719     57293371
1738     564...    200700000
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 122 columns]
        y = 505     227200000
1719     57293371
1738     564...    200700000
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 122 columns], y=505     227200000
1719     57293371
1738     564...    200700000
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 14:36:40 2017
PID: 3836                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 122 columns], 505     227200000
1719     57293371
1738     564...    200700000
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 122 columns], 505     227200000
1719     57293371
1738     564...    200700000
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[4812 rows x 122 columns], y=505     227200000
1719     57293371
1738     564...    200700000
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns]
        y_test = 505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns], y_test=505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns]
        y_test = 505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns], 505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns], 505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns], 505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns], 505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns], y=505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns]
        y = 505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.052004 -0.106368  

[1203 rows x 122 columns], y=505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64, y_pred=array([        nan,         nan,  48870927. , ...,  33519774.9,
         1671515. ,         nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 505     227200000
1719     57293371
1738     564...      2956000
Name: worldwide_gross, dtype: int64
        y_pred = array([        nan,         nan,  48870927. , ...,  33519774.9,
         1671515. ,         nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([227200000,  57293371,  56445534, ...,   7824358,   7301115,
         2956000]), y_pred=array([        nan,         nan,  48870927. , ...,  33519774.9,
         1671515. ,         nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([        nan,         nan,  48870927. , ...,  33519774.9,
         1671515. ,         nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([        nan,         nan,  48870927. , ...,  33519774.9,
         1671515. ,         nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([        nan,         nan,  48870927. , ...,  33519774.9,
         1671515. ,         nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([        nan,         nan,  48870927. , ...,  33519774.9,
         1671515. ,         nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 159  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  35.8s
[CV]  ................................................................
[CV] ................................................. , total=  38.6s
[CV]  ................................................................
[CV] ................................................. , total=  39.9s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28929388]), 'mean_train_score': array([-0.28964483]), 'split3_test_score': array([-0.26882905]), 'std_fit_time': array([ 1.87096618]), 'mean_test_score': array([-0.29295114]), 'split1_test_score': array([-0.28922724]), 'std_score_time': array([ 0.00335539]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28948585]), 'std_test_score': array([ 0.01969717]), 'split2_train_score': array([-0.28241752]), 'split3_train_score': array([-0.29738206]), 'split2_test_score': array([-0.32373342]), 'split0_test_score': array([-0.29001483]), 'mean_score_time': array([ 0.0115214]), 'mean_fit_time': array([ 38.74602157]), 'std_train_score': array([ 0.00529734])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292951137117
####################################################################################
################# Runing the itteration 160  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13099412]), 'mean_train_score': array([-0.13173485]), 'split3_test_score': array([-0.12769752]), 'std_fit_time': array([ 0.04406419]), 'mean_test_score': array([-0.13251972]), 'split1_test_score': array([-0.11937383]), 'std_score_time': array([ 0.02662664]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13662031]), 'std_test_score': array([ 0.01224461]), 'split2_train_score': array([-0.13191657]), 'split3_train_score': array([-0.12740839]), 'split2_test_score': array([-0.1304986]), 'split0_test_score': array([-0.15250894]), 'mean_score_time': array([ 0.72836852]), 'mean_fit_time': array([ 2.69278264]), 'std_train_score': array([ 0.00328511])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132519720432
####################################################################################
################# Runing the itteration 161  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28458968]), 'mean_train_score': array([-0.29074176]), 'split3_test_score': array([-0.24309896]), 'std_fit_time': array([ 0.00540481]), 'mean_test_score': array([-0.2983602]), 'split1_test_score': array([-0.33990747]), 'std_score_time': array([ 0.02703981]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27612369]), 'std_test_score': array([ 0.03493365]), 'split2_train_score': array([-0.28591427]), 'split3_train_score': array([-0.31633942]), 'split2_test_score': array([-0.3032905]), 'split0_test_score': array([-0.30714386]), 'mean_score_time': array([ 0.03014797]), 'mean_fit_time': array([ 0.02885389]), 'std_train_score': array([ 0.01524861])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29836019647
####################################################################################
################# Runing the itteration 162  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05133048]), 'mean_train_score': array([-0.05211518]), 'split3_test_score': array([-0.03819873]), 'std_fit_time': array([ 0.02619656]), 'mean_test_score': array([-0.05243741]), 'split1_test_score': array([-0.05427675]), 'std_score_time': array([ 0.0033548]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05140685]), 'std_test_score': array([ 0.01078135]), 'split2_train_score': array([-0.05533006]), 'split3_train_score': array([-0.05039334]), 'split2_test_score': array([-0.04909885]), 'split0_test_score': array([-0.06817529]), 'mean_score_time': array([ 0.35405725]), 'mean_fit_time': array([ 2.06855053]), 'std_train_score': array([ 0.00189853])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0524374056922
####################################################################################
################# Runing the itteration 163  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.26073228]), 'std_fit_time': array([ 0.01331575]), 'mean_test_score': array([ 0.36182111]), 'split1_test_score': array([ 0.44435116]), 'std_score_time': array([  6.69031804e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.06558194]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.37020922]), 'split0_test_score': array([ 0.37199176]), 'mean_score_time': array([ 0.00217354]), 'mean_fit_time': array([ 0.1686042]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.361821108365
####################################################################################
################# Runing the itteration 164  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.42273436]), 'std_fit_time': array([ 0.00076862]), 'mean_test_score': array([ 0.37381316]), 'split1_test_score': array([ 0.3035936]), 'std_score_time': array([  4.50955917e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.04367962]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.37810807]), 'split0_test_score': array([ 0.39081664]), 'mean_score_time': array([ 0.00199407]), 'mean_fit_time': array([ 0.06414813]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.373813164656
####################################################################################
################# Runing the itteration 165  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.37227935]), 'mean_train_score': array([ 0.10311802]), 'split3_test_score': array([-0.04536392]), 'std_fit_time': array([ 0.17006305]), 'mean_test_score': array([-0.04310696]), 'split1_test_score': array([-0.52464644]), 'std_score_time': array([ 0.00438433]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.11685305]), 'std_test_score': array([ 0.29566439]), 'split2_train_score': array([-0.00414089]), 'split3_train_score': array([ 0.16118669]), 'split2_test_score': array([ 0.17936342]), 'split0_test_score': array([ 0.21821907]), 'mean_score_time': array([ 0.01569027]), 'mean_fit_time': array([ 0.99349618]), 'std_train_score': array([ 0.18419523])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0431069647314
####################################################################################
################# Runing the itteration 166  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92461861]), 'mean_train_score': array([ 0.92750669]), 'split3_test_score': array([ 0.56494569]), 'std_fit_time': array([ 0.02871134]), 'mean_test_score': array([ 0.61025326]), 'split1_test_score': array([ 0.68577812]), 'std_score_time': array([ 0.00254301]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.91920409]), 'std_test_score': array([ 0.05374105]), 'split2_train_score': array([ 0.93261688]), 'split3_train_score': array([ 0.93358719]), 'split2_test_score': array([ 0.55428462]), 'split0_test_score': array([ 0.6360046]), 'mean_score_time': array([ 0.01406091]), 'mean_fit_time': array([ 1.06345159]), 'std_train_score': array([ 0.0059237])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.610253259665
####################################################################################
################# Runing the itteration 167  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.63815979]), 'std_fit_time': array([ 0.03096987]), 'mean_test_score': array([ 0.58861633]), 'split1_test_score': array([ 0.57503468]), 'std_score_time': array([ 0.00044704]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.03131006]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.58846292]), 'split0_test_score': array([ 0.55280794]), 'mean_score_time': array([ 0.0079214]), 'mean_fit_time': array([ 0.74928761]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.588616332422
####################################################################################
################# Runing the itteration 168  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.79558381]), 'mean_train_score': array([ 0.78763312]), 'split3_test_score': array([ 0.60859445]), 'std_fit_time': array([ 0.04127184]), 'mean_test_score': array([ 0.62461272]), 'split1_test_score': array([ 0.60477008]), 'std_score_time': array([ 0.00146323]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.77791883]), 'std_test_score': array([ 0.01816702]), 'split2_train_score': array([ 0.79002114]), 'split3_train_score': array([ 0.78700871]), 'split2_test_score': array([ 0.6388795]), 'split0_test_score': array([ 0.64620685]), 'mean_score_time': array([ 0.00817323]), 'mean_fit_time': array([ 1.476255]), 'std_train_score': array([ 0.00639674])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.624612720935
####################################################################################
################# Runing the itteration 169  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92678204]), 'mean_train_score': array([ 0.92983187]), 'split3_test_score': array([ 0.57867381]), 'std_fit_time': array([ 0.02396913]), 'mean_test_score': array([ 0.60310121]), 'split1_test_score': array([ 0.54980102]), 'std_score_time': array([ 0.00213176]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.9346707]), 'std_test_score': array([ 0.04071278]), 'split2_train_score': array([ 0.92640951]), 'split3_train_score': array([ 0.93146521]), 'split2_test_score': array([ 0.65123118]), 'split0_test_score': array([ 0.63269885]), 'mean_score_time': array([ 0.01141107]), 'mean_fit_time': array([ 1.05910546]), 'std_train_score': array([ 0.00343133])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.603101213891
####################################################################################
################# Runing the itteration 170  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.62219494]), 'mean_train_score': array([ 0.61391897]), 'split3_test_score': array([ 0.52662402]), 'std_fit_time': array([ 0.00753245]), 'mean_test_score': array([ 0.57480575]), 'split1_test_score': array([ 0.59022383]), 'std_score_time': array([ 0.0110829]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59454648]), 'std_test_score': array([ 0.03139226]), 'split2_train_score': array([ 0.6090331]), 'split3_train_score': array([ 0.62990137]), 'split2_test_score': array([ 0.61175417]), 'split0_test_score': array([ 0.57062099]), 'mean_score_time': array([ 0.02924597]), 'mean_fit_time': array([ 0.18275064]), 'std_train_score': array([ 0.01344521])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.574805753263
####################################################################################
################# Runing the itteration 171  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.28455916]), 'mean_train_score': array([ 0.27793233]), 'split3_test_score': array([ 0.27232481]), 'std_fit_time': array([ 0.03554516]), 'mean_test_score': array([ 0.2697176]), 'split1_test_score': array([ 0.25695947]), 'std_score_time': array([ 0.00045092]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.27797109]), 'std_test_score': array([ 0.00925314]), 'split2_train_score': array([ 0.28288723]), 'split3_train_score': array([ 0.26631182]), 'split2_test_score': array([ 0.26700224]), 'split0_test_score': array([ 0.28258389]), 'mean_score_time': array([ 0.00402945]), 'mean_fit_time': array([ 0.35676736]), 'std_train_score': array([ 0.00713274])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.26971760332
####################################################################################
################# Runing the itteration 172  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.6506844]), 'mean_train_score': array([ 0.64499402]), 'split3_test_score': array([ 0.55441148]), 'std_fit_time': array([ 0.0096075]), 'mean_test_score': array([ 0.54038131]), 'split1_test_score': array([ 0.59706635]), 'std_score_time': array([ 0.0004461]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64543694]), 'std_test_score': array([ 0.0638908]), 'split2_train_score': array([ 0.62857177]), 'split3_train_score': array([ 0.65528298]), 'split2_test_score': array([ 0.43285108]), 'split0_test_score': array([ 0.57719632]), 'mean_score_time': array([ 0.04144806]), 'mean_fit_time': array([ 1.81226557]), 'std_train_score': array([ 0.01010111])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.540381306667
####################################################################################
################# Runing the itteration 173  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.63350563]), 'mean_train_score': array([ 0.62107715]), 'split3_test_score': array([ 0.54464933]), 'std_fit_time': array([ 0.08824301]), 'mean_test_score': array([ 0.58014742]), 'split1_test_score': array([ 0.599915]), 'std_score_time': array([ 0.01123351]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63966271]), 'std_test_score': array([ 0.02795956]), 'split2_train_score': array([ 0.57532795]), 'split3_train_score': array([ 0.6358123]), 'split2_test_score': array([ 0.56200931]), 'split0_test_score': array([ 0.61401605]), 'mean_score_time': array([ 0.01641905]), 'mean_fit_time': array([ 0.18623751]), 'std_train_score': array([ 0.02650473])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.580147424248
####################################################################################
################# Runing the itteration 174  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.63033397]), 'mean_train_score': array([ 0.64115134]), 'split3_test_score': array([-0.02920409]), 'std_fit_time': array([ 0.03451195]), 'mean_test_score': array([ 0.41498098]), 'split1_test_score': array([ 0.54050275]), 'std_score_time': array([ 0.01089361]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.66377552]), 'std_test_score': array([ 0.25695775]), 'split2_train_score': array([ 0.6142462]), 'split3_train_score': array([ 0.65624968]), 'split2_test_score': array([ 0.58614279]), 'split0_test_score': array([ 0.56248245]), 'mean_score_time': array([ 0.01605988]), 'mean_fit_time': array([ 0.19804806]), 'std_train_score': array([ 0.0198791])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.414980975142
####################################################################################
################# Runing the itteration 175  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.29585249]), 'mean_train_score': array([-0.28894057]), 'split3_test_score': array([-0.31304889]), 'std_fit_time': array([ 0.00432133]), 'mean_test_score': array([-0.290941]), 'split1_test_score': array([-0.30079271]), 'std_score_time': array([ 0.00720667]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28552499]), 'std_test_score': array([ 0.01661392]), 'split2_train_score': array([-0.29277724]), 'split3_train_score': array([-0.28160757]), 'split2_test_score': array([-0.27690636]), 'split0_test_score': array([-0.27301605]), 'mean_score_time': array([ 0.01883787]), 'mean_fit_time': array([ 0.03841865]), 'std_train_score': array([ 0.00565539])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290941001529
####################################################################################
################# Runing the itteration 176  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.63382345]), 'mean_train_score': array([ 0.64985976]), 'split3_test_score': array([ 0.57771133]), 'std_fit_time': array([ 0.0974773]), 'mean_test_score': array([ 0.57303577]), 'split1_test_score': array([ 0.5785312]), 'std_score_time': array([ 0.00636146]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65187554]), 'std_test_score': array([ 0.02229168]), 'split2_train_score': array([ 0.66393623]), 'split3_train_score': array([ 0.64980383]), 'split2_test_score': array([ 0.53725915]), 'split0_test_score': array([ 0.59864142]), 'mean_score_time': array([ 0.0266698]), 'mean_fit_time': array([ 2.932971]), 'std_train_score': array([ 0.01071654])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.573035772441
####################################################################################
################# Runing the itteration 177  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-318991.21808447]), 'mean_train_score': array([-96139.82767017]), 'split3_test_score': array([-3620.04422034]), 'std_fit_time': array([ 0.00045549]), 'mean_test_score': array([-7882.78309919]), 'split1_test_score': array([-16.44043088]), 'std_score_time': array([ 0.00295656]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-1153.59664665]), 'std_test_score': array([ 11584.37200295]), 'split2_train_score': array([-671.39614456]), 'split3_train_score': array([-63743.099805]), 'split2_test_score': array([-105.66393804]), 'split0_test_score': array([-27788.98380751]), 'mean_score_time': array([ 0.02319211]), 'mean_fit_time': array([ 0.03497666]), 'std_train_score': array([ 131195.36547452])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-7882.78309919
####################################################################################
################# Runing the itteration 178  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.62092961]), 'mean_train_score': array([ 0.62625075]), 'split3_test_score': array([ 0.49558945]), 'std_fit_time': array([ 0.02677999]), 'mean_test_score': array([ 0.5833467]), 'split1_test_score': array([ 0.56060381]), 'std_score_time': array([ 0.01363503]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63132947]), 'std_test_score': array([ 0.06498219]), 'split2_train_score': array([ 0.59712462]), 'split3_train_score': array([ 0.65561928]), 'split2_test_score': array([ 0.67442294]), 'split0_test_score': array([ 0.60277058]), 'mean_score_time': array([ 0.0208602]), 'mean_fit_time': array([ 0.08277762]), 'std_train_score': array([ 0.02100565])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.583346698426
####################################################################################
################# Runing the itteration 179  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
[CV]  ................................................................
[CV] ................................................. , total=   4.3s
[CV]  ................................................................
[CV] ................................................. , total=   4.8s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -4.29939480e+25]), 'mean_train_score': array([ -5.94609598e+25]), 'split3_test_score': array([ -1.08623699e+26]), 'std_fit_time': array([ 0.6135647]), 'mean_test_score': array([ -5.79852183e+25]), 'split1_test_score': array([ -4.81484828e+25]), 'std_score_time': array([ 0.00164245]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -3.99830244e+25]), 'std_test_score': array([  3.47297988e+25]), 'split2_train_score': array([ -1.11734242e+25]), 'split3_train_score': array([ -1.43693443e+26]), 'split2_test_score': array([ -1.17848556e+25]), 'split0_test_score': array([ -6.33838353e+25]), 'mean_score_time': array([ 0.00507826]), 'mean_fit_time': array([ 4.37180424]), 'std_train_score': array([  5.01930017e+25])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-5.79852182524e+25
####################################################################################
################# Runing the itteration 180  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.58850524]), 'mean_train_score': array([ 0.58968431]), 'split3_test_score': array([ 0.35545558]), 'std_fit_time': array([ 0.00119047]), 'mean_test_score': array([ 0.34918365]), 'split1_test_score': array([ 0.41171886]), 'std_score_time': array([ 0.099632]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.55932536]), 'std_test_score': array([ 0.03994154]), 'split2_train_score': array([ 0.60766363]), 'split3_train_score': array([ 0.60324302]), 'split2_test_score': array([ 0.32044163]), 'split0_test_score': array([ 0.30911854]), 'mean_score_time': array([ 0.88371891]), 'mean_fit_time': array([ 0.05167508]), 'std_train_score': array([ 0.01890867])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.349183652226
####################################################################################
################# Runing the itteration 181  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_4', label_fn=<function label_gross_4>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], y=1094    107822813
882     141200000
3883      16...            0
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69400093472171676}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60551337037759378}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.69412303104116813}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70918590937271853}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.30528627007538972}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52899185631528078}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns]
        y = 1094    107822813
882     141200000
3883      16...            0
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], y=1094    107822813
882     141200000
3883      16...            0
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns]
        y = 1094    107822813
882     141200000
3883      16...            0
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], y=1094    107822813
882     141200000
3883      16...            0
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 14:44:27 2017
PID: 5155                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], 1094    107822813
882     141200000
3883      16...            0
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], 1094    107822813
882     141200000
3883      16...            0
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], y=1094    107822813
882     141200000
3883      16...            0
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns]
        y_test = 1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], y_test=1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns]
        y_test = 1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], 1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], 1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], 1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], 1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], y=1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns]
        y = 1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], y=1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64, y_pred=array([  1.72450423e+08,              nan,      ...        nan,              nan,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 1094    107822813
882     141200000
3883      16...     29934477
Name: worldwide_gross, dtype: int64
        y_pred = array([  1.72450423e+08,              nan,      ...        nan,              nan,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([107822813, 141200000,   1615787, ...,   1158877, 339504276,
        29934477]), y_pred=array([  1.72450423e+08,              nan,      ...        nan,              nan,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  1.72450423e+08,              nan,      ...        nan,              nan,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  1.72450423e+08,              nan,      ...        nan,              nan,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  1.72450423e+08,              nan,      ...        nan,              nan,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  1.72450423e+08,              nan,      ...        nan,              nan,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 182  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.0min
[CV]  ................................................................
[CV] ................................................. , total= 1.0min
[CV]  ................................................................
[CV] ................................................. , total= 1.0min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.27755129]), 'mean_train_score': array([-0.28955436]), 'split3_test_score': array([-0.25950699]), 'std_fit_time': array([ 0.93053502]), 'mean_test_score': array([-0.29168922]), 'split1_test_score': array([-0.30083106]), 'std_score_time': array([ 0.34038782]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28584348]), 'std_test_score': array([ 0.02680859]), 'split2_train_score': array([-0.29462354]), 'split3_train_score': array([-0.30019912]), 'split2_test_score': array([-0.27591381]), 'split0_test_score': array([-0.33050504]), 'mean_score_time': array([ 0.21284795]), 'mean_fit_time': array([ 61.17538297]), 'std_train_score': array([ 0.00861469])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291689224341
####################################################################################
################# Runing the itteration 183  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   4.9s
[CV]  ................................................................
[CV] ................................................. , total=   4.9s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13163841]), 'mean_train_score': array([-0.13199067]), 'split3_test_score': array([-0.13908155]), 'std_fit_time': array([ 0.06481642]), 'mean_test_score': array([-0.13227148]), 'split1_test_score': array([-0.13608909]), 'std_score_time': array([ 0.01244821]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13486249]), 'std_test_score': array([ 0.00698565]), 'split2_train_score': array([-0.12959418]), 'split3_train_score': array([-0.13186758]), 'split2_test_score': array([-0.13319351]), 'split0_test_score': array([-0.12072178]), 'mean_score_time': array([ 1.0907836]), 'mean_fit_time': array([ 3.8769508]), 'std_train_score': array([ 0.00187948])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132271480952
####################################################################################
################# Runing the itteration 184  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.29076503]), 'mean_train_score': array([-0.2894211]), 'split3_test_score': array([-0.28618102]), 'std_fit_time': array([ 0.00368405]), 'mean_test_score': array([-0.28946892]), 'split1_test_score': array([-0.29073582]), 'std_score_time': array([ 0.01015312]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28900797]), 'std_test_score': array([ 0.00405416]), 'split2_train_score': array([-0.28739156]), 'split3_train_score': array([-0.29051983]), 'split2_test_score': array([-0.29554338]), 'split0_test_score': array([-0.28541548]), 'mean_score_time': array([ 0.02267623]), 'mean_fit_time': array([ 0.03493327]), 'std_train_score': array([ 0.00135121])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.289468923843
####################################################################################
################# Runing the itteration 185  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05515336]), 'mean_train_score': array([-0.05258123]), 'split3_test_score': array([-0.04421172]), 'std_fit_time': array([ 0.01755405]), 'mean_test_score': array([-0.05267922]), 'split1_test_score': array([-0.04037713]), 'std_score_time': array([ 0.00833252]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05274101]), 'std_test_score': array([ 0.01048762]), 'split2_train_score': array([-0.04972271]), 'split3_train_score': array([-0.05270783]), 'split2_test_score': array([-0.06227903]), 'split0_test_score': array([-0.06384902]), 'mean_score_time': array([ 0.55369848]), 'mean_fit_time': array([ 2.87268972]), 'std_train_score': array([ 0.00192539])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0526792238045
####################################################################################
################# Runing the itteration 186  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.33606091]), 'std_fit_time': array([ 0.00274806]), 'mean_test_score': array([ 0.32741605]), 'split1_test_score': array([ 0.225985]), 'std_score_time': array([ 0.00060053]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.07231277]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.31791228]), 'split0_test_score': array([ 0.42970599]), 'mean_score_time': array([ 0.00345933]), 'mean_fit_time': array([ 0.18335766]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.327416046005
####################################################################################
################# Runing the itteration 187  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.26310415]), 'std_fit_time': array([ 0.0031615]), 'mean_test_score': array([ 0.32272594]), 'split1_test_score': array([ 0.41864478]), 'std_score_time': array([ 0.00045825]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.13077425]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.47039914]), 'split0_test_score': array([ 0.13875568]), 'mean_score_time': array([ 0.00348026]), 'mean_fit_time': array([ 0.09564883]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.322725935572
####################################################################################
################# Runing the itteration 188  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.53266496]), 'mean_train_score': array([ 0.27158294]), 'split3_test_score': array([ 0.35634485]), 'std_fit_time': array([ 0.07248277]), 'mean_test_score': array([ 0.19235895]), 'split1_test_score': array([ 0.02500485]), 'std_score_time': array([ 0.00091657]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.10200761]), 'std_test_score': array([ 0.21483698]), 'split2_train_score': array([-0.13497632]), 'split3_train_score': array([ 0.58663552]), 'split2_test_score': array([-0.06062857]), 'split0_test_score': array([ 0.44871467]), 'mean_score_time': array([ 0.00867236]), 'mean_fit_time': array([ 0.74723297]), 'std_train_score': array([ 0.30061112])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.192358951109
####################################################################################
################# Runing the itteration 189  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.95175027]), 'mean_train_score': array([ 0.94828308]), 'split3_test_score': array([ 0.69692282]), 'std_fit_time': array([ 0.0110981]), 'mean_test_score': array([ 0.70236898]), 'split1_test_score': array([ 0.68111275]), 'std_score_time': array([ 0.00010467]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.94782492]), 'std_test_score': array([ 0.02796948]), 'split2_train_score': array([ 0.94581268]), 'split3_train_score': array([ 0.94774444]), 'split2_test_score': array([ 0.74956667]), 'split0_test_score': array([ 0.68187369]), 'mean_score_time': array([ 0.00652266]), 'mean_fit_time': array([ 0.85250795]), 'std_train_score': array([ 0.0021578])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.702368982195
####################################################################################
################# Runing the itteration 190  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.75985681]), 'std_fit_time': array([ 0.00382102]), 'mean_test_score': array([ 0.70735046]), 'split1_test_score': array([ 0.69812929]), 'std_score_time': array([ 0.00025399]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.03611981]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.65887681]), 'split0_test_score': array([ 0.71253892]), 'mean_score_time': array([ 0.00644231]), 'mean_fit_time': array([ 0.38677663]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.707350459463
####################################################################################
################# Runing the itteration 191  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.85562605]), 'mean_train_score': array([ 0.85810322]), 'split3_test_score': array([ 0.71378798]), 'std_fit_time': array([ 0.01343285]), 'mean_test_score': array([ 0.7230952]), 'split1_test_score': array([ 0.72954899]), 'std_score_time': array([  4.97046989e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.86155526]), 'std_test_score': array([ 0.02029098]), 'split2_train_score': array([ 0.86808414]), 'split3_train_score': array([ 0.84714742]), 'split2_test_score': array([ 0.69700329]), 'split0_test_score': array([ 0.75204052]), 'mean_score_time': array([ 0.00344419]), 'mean_fit_time': array([ 0.76744616]), 'std_train_score': array([ 0.00770878])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.723095195983
####################################################################################
################# Runing the itteration 192  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.94554824]), 'mean_train_score': array([ 0.94297013]), 'split3_test_score': array([ 0.66091323]), 'std_fit_time': array([ 0.01262986]), 'mean_test_score': array([ 0.67433417]), 'split1_test_score': array([ 0.66891387]), 'std_score_time': array([ 0.00057536]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.94514163]), 'std_test_score': array([ 0.00983662]), 'split2_train_score': array([ 0.94007485]), 'split3_train_score': array([ 0.94111581]), 'split2_test_score': array([ 0.68389398]), 'split0_test_score': array([ 0.68361562]), 'mean_score_time': array([ 0.00582117]), 'mean_fit_time': array([ 0.86706489]), 'std_train_score': array([ 0.00240745])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.674334174509
####################################################################################
################# Runing the itteration 193  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.6465582]), 'mean_train_score': array([ 0.63064]), 'split3_test_score': array([ 0.59898558]), 'std_fit_time': array([ 0.00666126]), 'mean_test_score': array([ 0.62284261]), 'split1_test_score': array([ 0.66070943]), 'std_score_time': array([ 0.01078456]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61741328]), 'std_test_score': array([ 0.04188296]), 'split2_train_score': array([ 0.61859398]), 'split3_train_score': array([ 0.63999455]), 'split2_test_score': array([ 0.6654136]), 'split0_test_score': array([ 0.56626183]), 'mean_score_time': array([ 0.02571648]), 'mean_fit_time': array([ 0.07308042]), 'std_train_score': array([ 0.01285447])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.622842613578
####################################################################################
################# Runing the itteration 194  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.31573598]), 'mean_train_score': array([ 0.32486835]), 'split3_test_score': array([ 0.30503459]), 'std_fit_time': array([ 0.05988155]), 'mean_test_score': array([ 0.32475773]), 'split1_test_score': array([ 0.36100321]), 'std_score_time': array([ 0.0009133]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.31869358]), 'std_test_score': array([ 0.02377749]), 'split2_train_score': array([ 0.32848905]), 'split3_train_score': array([ 0.33655478]), 'split2_test_score': array([ 0.3019665]), 'split0_test_score': array([ 0.33102663]), 'mean_score_time': array([ 0.00357699]), 'mean_fit_time': array([ 0.13217586]), 'std_train_score': array([ 0.00823423])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.324757731103
####################################################################################
################# Runing the itteration 195  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.66370674]), 'mean_train_score': array([ 0.67513822]), 'split3_test_score': array([ 0.54992843]), 'std_fit_time': array([ 0.00361419]), 'mean_test_score': array([-12.17014304]), 'split1_test_score': array([ 0.5848308]), 'std_score_time': array([ 0.00453991]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65831715]), 'std_test_score': array([ 22.13401896]), 'split2_train_score': array([ 0.67830714]), 'split3_train_score': array([ 0.70022184]), 'split2_test_score': array([-50.5072813]), 'split0_test_score': array([ 0.6919499]), 'mean_score_time': array([ 0.03086472]), 'mean_fit_time': array([ 0.55633807]), 'std_train_score': array([ 0.01622388])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-12.1701430417
####################################################################################
################# Runing the itteration 196  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.64508791]), 'mean_train_score': array([ 0.66265177]), 'split3_test_score': array([ 0.66157459]), 'std_fit_time': array([ 0.01109193]), 'mean_test_score': array([-7.40098299]), 'split1_test_score': array([-31.51349993]), 'std_score_time': array([ 0.00061477]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65212126]), 'std_test_score': array([ 13.92152803]), 'split2_train_score': array([ 0.69440026]), 'split3_train_score': array([ 0.65899765]), 'split2_test_score': array([ 0.53217016]), 'split0_test_score': array([ 0.71582324]), 'mean_score_time': array([ 0.00584596]), 'mean_fit_time': array([ 0.12805641]), 'std_train_score': array([ 0.01897828])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-7.4009829867
####################################################################################
################# Runing the itteration 197  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.66298911]), 'mean_train_score': array([ 0.66880911]), 'split3_test_score': array([ 0.60973161]), 'std_fit_time': array([ 0.01116401]), 'mean_test_score': array([-1.13337197]), 'split1_test_score': array([-2.02768642]), 'std_score_time': array([ 0.00352075]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.66549432]), 'std_test_score': array([ 1.87390065]), 'split2_train_score': array([ 0.67415569]), 'split3_train_score': array([ 0.67259732]), 'split2_test_score': array([-3.77672854]), 'split0_test_score': array([ 0.66119547]), 'mean_score_time': array([ 0.00603825]), 'mean_fit_time': array([ 0.07014573]), 'std_train_score': array([ 0.00468499])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.13337197025
####################################################################################
################# Runing the itteration 198  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.29473686]), 'mean_train_score': array([-0.28915342]), 'split3_test_score': array([-0.26958739]), 'std_fit_time': array([ 0.00215195]), 'mean_test_score': array([-0.29356908]), 'split1_test_score': array([-0.31472231]), 'std_score_time': array([ 0.02064542]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28152674]), 'std_test_score': array([ 0.02155852]), 'split2_train_score': array([-0.2830175]), 'split3_train_score': array([-0.29733257]), 'split2_test_score': array([-0.31538551]), 'split0_test_score': array([-0.27458113]), 'mean_score_time': array([ 0.02453601]), 'mean_fit_time': array([ 0.01979446]), 'std_train_score': array([ 0.0069622])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293569083742
####################################################################################
################# Runing the itteration 199  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.66800973]), 'mean_train_score': array([ 0.67607849]), 'split3_test_score': array([ 0.48126793]), 'std_fit_time': array([ 0.14544184]), 'mean_test_score': array([ 0.52192228]), 'split1_test_score': array([ 0.64359543]), 'std_score_time': array([ 0.00283224]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67009509]), 'std_test_score': array([ 0.15475417]), 'split2_train_score': array([ 0.68421783]), 'split3_train_score': array([ 0.6819913]), 'split2_test_score': array([ 0.28640486]), 'split0_test_score': array([ 0.6764209]), 'mean_score_time': array([ 0.00941491]), 'mean_fit_time': array([ 0.86405128]), 'std_train_score': array([ 0.00710838])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.521922280993
####################################################################################
################# Runing the itteration 200  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-1239239.99770046]), 'mean_train_score': array([-650060.51258318]), 'split3_test_score': array([-5395.90954764]), 'std_fit_time': array([ 0.00086033]), 'mean_test_score': array([-16425.2817489]), 'split1_test_score': array([-30214.81493672]), 'std_score_time': array([ 0.00925322]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-310556.2640322]), 'std_test_score': array([ 8887.92380782]), 'split2_train_score': array([-369381.281332]), 'split3_train_score': array([-681064.50726808]), 'split2_test_score': array([-14613.20737445]), 'split0_test_score': array([-15477.19513679]), 'mean_score_time': array([ 0.02490532]), 'mean_fit_time': array([ 0.01897097]), 'std_train_score': array([ 368149.9962683])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-16425.2817489
####################################################################################
################# Runing the itteration 201  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.66797496]), 'mean_train_score': array([ 0.65738529]), 'split3_test_score': array([ 0.665207]), 'std_fit_time': array([ 0.01519865]), 'mean_test_score': array([ 0.64927042]), 'split1_test_score': array([ 0.63899745]), 'std_score_time': array([ 0.01457826]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.66177772]), 'std_test_score': array([ 0.02564867]), 'split2_train_score': array([ 0.64547585]), 'split3_train_score': array([ 0.65431264]), 'split2_test_score': array([ 0.68002336]), 'split0_test_score': array([ 0.61285386]), 'mean_score_time': array([ 0.01436484]), 'mean_fit_time': array([ 0.05351388]), 'std_train_score': array([ 0.008407])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.649270417357
####################################################################################
################# Runing the itteration 202  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([-8176.94615119]), 'mean_train_score': array([ -1.47531624e+19]), 'split3_test_score': array([ -7.08181109e+19]), 'std_fit_time': array([ 0.20888333]), 'mean_test_score': array([ -1.77045277e+19]), 'split1_test_score': array([-2386.34513633]), 'std_score_time': array([ 0.00031266]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-767.65188324]), 'std_test_score': array([  3.06651415e+19]), 'split2_train_score': array([-32107.82763354]), 'split3_train_score': array([ -5.90126496e+19]), 'split2_test_score': array([-238.35459841]), 'split0_test_score': array([-4873.17401077]), 'mean_score_time': array([ 0.00310314]), 'mean_fit_time': array([ 0.93845737]), 'std_train_score': array([  2.55532269e+19])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.77045277273e+19
####################################################################################
################# Runing the itteration 203  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.71961334]), 'mean_train_score': array([ 0.70332864]), 'split3_test_score': array([ 0.50433339]), 'std_fit_time': array([ 0.00079255]), 'mean_test_score': array([ 0.54452477]), 'split1_test_score': array([ 0.55665035]), 'std_score_time': array([ 0.02138982]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.70408804]), 'std_test_score': array([ 0.03215488]), 'split2_train_score': array([ 0.68190722]), 'split3_train_score': array([ 0.70770597]), 'split2_test_score': array([ 0.59001817]), 'split0_test_score': array([ 0.52709718]), 'mean_score_time': array([ 0.35951251]), 'mean_fit_time': array([ 0.02345502]), 'std_train_score': array([ 0.0136364])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.544524771291
####################################################################################
################# Runing the itteration 204  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_4', label_fn=<function label_gross_4>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.702368982194845}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.62284261357796433}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70735045946278563}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.72309519598308003}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32475773110261097}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54452477129135834}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       4
1       4
2       4
3       4
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.702368982194845}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.62284261357796433}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70735045946278563}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.72309519598308003}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32475773110261097}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54452477129135834}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], y=3106      11831131
3906       1429453
3715      ...            0
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34714771357682056}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.702368982194845}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.44162738317964045}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.62284261357796433}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.45560624576647185}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70735045946278563}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.72309519598308003}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32475773110261097}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54452477129135834}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58877320593842597}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns]
        y = 3106      11831131
3906       1429453
3715      ...            0
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], y=3106      11831131
3906       1429453
3715      ...            0
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns]
        y = 3106      11831131
3906       1429453
3715      ...            0
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], y=3106      11831131
3906       1429453
3715      ...            0
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 14:56:10 2017
PID: 6468                                    Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], 3106      11831131
3906       1429453
3715      ...            0
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], 3106      11831131
3906       1429453
3715      ...            0
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], y=3106      11831131
3906       1429453
3715      ...            0
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns]
        y_test = 3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], y_test=3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns]
        y_test = 3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], y=3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns]
        y = 3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0          0         1         2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], y=3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64, y_pred=array([               nan,  31666428.66666667,  ...    nan,                nan,                nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 3106      11831131
3906       1429453
3715      ...     25928721
Name: worldwide_gross, dtype: int64
        y_pred = array([               nan,  31666428.66666667,  ...    nan,                nan,                nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([11831131,  1429453,  3100000, ...,   458054,  1513388, 25928721]), y_pred=array([               nan,  31666428.66666667,  ...    nan,                nan,                nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([               nan,  31666428.66666667,  ...    nan,                nan,                nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([               nan,  31666428.66666667,  ...    nan,                nan,                nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([               nan,  31666428.66666667,  ...    nan,                nan,                nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([               nan,  31666428.66666667,  ...    nan,                nan,                nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 205  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  20.3s
[CV]  ................................................................
[CV] ................................................. , total=  25.3s
[CV]  ................................................................
[CV] ................................................. , total=  27.2s
[CV]  ................................................................
[CV] ................................................. , total=  27.3s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28504303]), 'mean_train_score': array([-0.28955723]), 'split3_test_score': array([-0.27449213]), 'std_fit_time': array([ 2.83644827]), 'mean_test_score': array([-0.29188849]), 'split1_test_score': array([-0.31350014]), 'std_score_time': array([ 0.00596477]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28145958]), 'std_test_score': array([ 0.02009973]), 'split2_train_score': array([-0.29662402]), 'split3_train_score': array([-0.29510228]), 'split2_test_score': array([-0.26931848]), 'split0_test_score': array([-0.31024319]), 'mean_score_time': array([ 0.01091474]), 'mean_fit_time': array([ 25.03744167]), 'std_train_score': array([ 0.0064544])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29188848575
####################################################################################
################# Runing the itteration 206  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.1259847]), 'mean_train_score': array([-0.13188527]), 'split3_test_score': array([-0.14130027]), 'std_fit_time': array([ 0.05468705]), 'mean_test_score': array([-0.13354204]), 'split1_test_score': array([-0.11956399]), 'std_score_time': array([ 0.00344816]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13276105]), 'std_test_score': array([ 0.01600214]), 'split2_train_score': array([-0.13715562]), 'split3_train_score': array([-0.13163972]), 'split2_test_score': array([-0.11729536]), 'split0_test_score': array([-0.15600855]), 'mean_score_time': array([ 0.44841027]), 'mean_fit_time': array([ 1.99278349]), 'std_train_score': array([ 0.00398185])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.133542040566
####################################################################################
################# Runing the itteration 207  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.29124064]), 'mean_train_score': array([-0.28955565]), 'split3_test_score': array([-0.31267898]), 'std_fit_time': array([ 0.00075029]), 'mean_test_score': array([-0.29073239]), 'split1_test_score': array([-0.29395518]), 'std_score_time': array([ 0.01029042]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28789804]), 'std_test_score': array([ 0.01480208]), 'split2_train_score': array([-0.29628066]), 'split3_train_score': array([-0.28280326]), 'split2_test_score': array([-0.27233317]), 'split0_test_score': array([-0.28396221]), 'mean_score_time': array([ 0.02430552]), 'mean_fit_time': array([ 0.01986182]), 'std_train_score': array([ 0.00490936])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290732385534
####################################################################################
################# Runing the itteration 208  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05415751]), 'mean_train_score': array([-0.05218574]), 'split3_test_score': array([-0.04147355]), 'std_fit_time': array([ 0.06036073]), 'mean_test_score': array([-0.0523385]), 'split1_test_score': array([-0.04707424]), 'std_score_time': array([ 0.00375432]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05277707]), 'std_test_score': array([ 0.01450863]), 'split2_train_score': array([-0.049737]), 'split3_train_score': array([-0.05207137]), 'split2_test_score': array([-0.07722817]), 'split0_test_score': array([-0.04357805]), 'mean_score_time': array([ 0.22632855]), 'mean_fit_time': array([ 1.62196302]), 'std_train_score': array([ 0.00160054])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0523385039932
####################################################################################
################# Runing the itteration 209  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.58221009]), 'std_fit_time': array([ 0.00628958]), 'mean_test_score': array([ 0.51742162]), 'split1_test_score': array([ 0.47507559]), 'std_score_time': array([ 0.0002374]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05045356]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.46181751]), 'split0_test_score': array([ 0.55058328]), 'mean_score_time': array([ 0.00219548]), 'mean_fit_time': array([ 0.16149753]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.517421617785
####################################################################################
################# Runing the itteration 210  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.51101967]), 'std_fit_time': array([ 0.00383997]), 'mean_test_score': array([ 0.46811306]), 'split1_test_score': array([ 0.36081282]), 'std_score_time': array([ 0.00028421]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.06570454]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.53064761]), 'split0_test_score': array([ 0.46997212]), 'mean_score_time': array([ 0.002666]), 'mean_fit_time': array([ 0.05498058]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.468113056769
#########################################
###Finished all estimators for cl: label_gross_4
#########################################
#########################################
#######Printing results for cl: label_gross_4
#########################################
{'MLPRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}, 'score': -0.29033462137724481, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'OrthogonalMatchingPursuit': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.64927041735671776, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'BaggingRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.702368982194845, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'GradientBoostingRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.72309519598308003, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'SVR': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}, 'score': -0.13227148095191327, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'SGDRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': 0.57226677047927066, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'HuberRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.32475773110261097, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'RandomForestRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}, 'score': 0.68755892415548259, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'Lasso': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': 0.58877320593842597, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'AdaBoostRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}, 'score': 0.34714771357682056, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'LinearRegression': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': 0.59143554803076559, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'LinearSVR': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}, 'score': -0.28946892384295986, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'ElasticNet': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.62284261357796433, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'KNeighborsRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.54452477129135834, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'NuSVR': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': -0.052338503993199552, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'LassoLars': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}, 'score': 0.62992814627535487, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'Ridge': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}, 'score': 0.60301982014595945, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'ExtraTreesRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.70735045946278563, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'PassiveAggressiveRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}, 'score': -0.28889005880323282, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'ExtraTreeRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.46811305676858811, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'RANSACRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': -1.7704527727253266e+19, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'DecisionTreeRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.51742161778532092, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}}
priting simply sorted numbers, grep them to find the best cfg or cl: label_gross_4
[-1.7704527727253266e+19, -0.29033462137724481, -0.28946892384295986, -0.28889005880323282, -0.13227148095191327, -0.052338503993199552, 0.32475773110261097, 0.34714771357682056, 0.46811305676858811, 0.51742161778532092, 0.54452477129135834, 0.57226677047927066, 0.58877320593842597, 0.59143554803076559, 0.60301982014595945, 0.62284261357796433, 0.62992814627535487, 0.64927041735671776, 0.68755892415548259, 0.702368982194845, 0.70735045946278563, 0.72309519598308003]
