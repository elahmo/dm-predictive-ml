#########################################
###Starting all estimators for cl: label_gross_2
#########################################

LogPol True
n_components
[193, 115, 57]
pw_lst
[{'pw': 1}]
####################################################################################
################# Runing the itteration 1  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [193, 115, 57], 'preprocessor__kw_args': [{'pw': 1}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}

LogPol True
n_components
[203, 121, 60]
pw_lst
[{'pw': 1}, {'pw': 2}]
####################################################################################
################# Runing the itteration 2  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [203, 121, 60], 'preprocessor__kw_args': [{'pw': 2}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}

LogPol True
n_components
[213, 127, 63]
pw_lst
[{'pw': 1}, {'pw': 2}, {'pw': 3}]
####################################################################################
################# Runing the itteration 3  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'reducer__n_features_to_select': [213, 127, 63], 'preprocessor__kw_args': [{'pw': 3}], 'reducer__step': [0.1]}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
Starting precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
Finished precomp pipline for {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
####################################################################################
################# Runing the itteration 4  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([-0.11725818]), 'mean_train_score': array([ 0.42443396]), 'split3_test_score': array([ 0.41359254]), 'std_fit_time': array([ 0.34893669]), 'mean_test_score': array([ 0.37474064]), 'split1_test_score': array([ 0.57536975]), 'std_score_time': array([ 0.00469913]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65661407]), 'std_test_score': array([ 0.20370805]), 'split2_train_score': array([ 0.56405648]), 'split3_train_score': array([ 0.59432346]), 'split2_test_score': array([ 0.47357597]), 'split0_test_score': array([ 0.0364243]), 'mean_score_time': array([ 0.01015049]), 'mean_fit_time': array([ 0.7953611]), 'std_train_score': array([ 0.31452141])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.374740642265
####################################################################################
################# Runing the itteration 5  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93345433]), 'mean_train_score': array([ 0.92567831]), 'split3_test_score': array([ 0.63754916]), 'std_fit_time': array([ 0.03847637]), 'mean_test_score': array([ 0.59463186]), 'split1_test_score': array([ 0.58713391]), 'std_score_time': array([ 0.00304566]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92361377]), 'std_test_score': array([ 0.0265265]), 'split2_train_score': array([ 0.92649501]), 'split3_train_score': array([ 0.91915014]), 'split2_test_score': array([ 0.58894805]), 'split0_test_score': array([ 0.56489633]), 'mean_score_time': array([ 0.01479942]), 'mean_fit_time': array([ 1.26011533]), 'std_train_score': array([ 0.00519646])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.594631864131
####################################################################################
################# Runing the itteration 6  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.54095097]), 'std_fit_time': array([ 0.00963213]), 'mean_test_score': array([ 0.56708851]), 'split1_test_score': array([ 0.61099551]), 'std_score_time': array([ 0.0002572]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.02815359]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.57237464]), 'split0_test_score': array([ 0.54403293]), 'mean_score_time': array([ 0.00704235]), 'mean_fit_time': array([ 0.81764454]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.567088512938
####################################################################################
################# Runing the itteration 7  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.76975675]), 'mean_train_score': array([ 0.77101495]), 'split3_test_score': array([ 0.65886924]), 'std_fit_time': array([ 0.02613461]), 'mean_test_score': array([ 0.61784799]), 'split1_test_score': array([ 0.56837105]), 'std_score_time': array([ 0.00054821]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.77683114]), 'std_test_score': array([ 0.0389287]), 'split2_train_score': array([ 0.76675406]), 'split3_train_score': array([ 0.77071787]), 'split2_test_score': array([ 0.65285987]), 'split0_test_score': array([ 0.5912918]), 'mean_score_time': array([ 0.00771463]), 'mean_fit_time': array([ 1.58119947]), 'std_train_score': array([ 0.00366246])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.617847991398
####################################################################################
################# Runing the itteration 8  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93291446]), 'mean_train_score': array([ 0.92394282]), 'split3_test_score': array([ 0.60115447]), 'std_fit_time': array([ 0.01347274]), 'mean_test_score': array([ 0.58034438]), 'split1_test_score': array([ 0.54753743]), 'std_score_time': array([ 0.00146491]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92743055]), 'std_test_score': array([ 0.04058561]), 'split2_train_score': array([ 0.91300687]), 'split3_train_score': array([ 0.92241942]), 'split2_test_score': array([ 0.63638005]), 'split0_test_score': array([ 0.53630559]), 'mean_score_time': array([ 0.00978869]), 'mean_fit_time': array([ 1.20962954]), 'std_train_score': array([ 0.00732411])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.580344384668
####################################################################################
################# Runing the itteration 9  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.62520427]), 'mean_train_score': array([ 0.61725408]), 'split3_test_score': array([ 0.61867171]), 'std_fit_time': array([ 0.00886516]), 'mean_test_score': array([ 0.58290401]), 'split1_test_score': array([ 0.5454166]), 'std_score_time': array([ 0.01130032]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62739103]), 'std_test_score': array([ 0.02806584]), 'split2_train_score': array([ 0.61833896]), 'split3_train_score': array([ 0.59808207]), 'split2_test_score': array([ 0.59900613]), 'split0_test_score': array([ 0.56852161]), 'mean_score_time': array([ 0.03036684]), 'mean_fit_time': array([ 0.24607921]), 'std_train_score': array([ 0.01156186])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.582904013903
####################################################################################
################# Runing the itteration 10  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.31526334]), 'mean_train_score': array([ 0.30361063]), 'split3_test_score': array([ 0.27364549]), 'std_fit_time': array([ 0.09711465]), 'mean_test_score': array([ 0.29177244]), 'split1_test_score': array([ 0.28722137]), 'std_score_time': array([ 0.00128305]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.30280343]), 'std_test_score': array([ 0.01541415]), 'split2_train_score': array([ 0.28879538]), 'split3_train_score': array([ 0.30758037]), 'split2_test_score': array([ 0.31622517]), 'split0_test_score': array([ 0.28999774]), 'mean_score_time': array([ 0.00571364]), 'mean_fit_time': array([ 0.58785731]), 'std_train_score': array([ 0.0096396])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.291772444577
####################################################################################
################# Runing the itteration 11  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.6454622]), 'mean_train_score': array([ 0.66299391]), 'split3_test_score': array([ 0.57886016]), 'std_fit_time': array([ 0.02313343]), 'mean_test_score': array([-1.35486832]), 'split1_test_score': array([-0.46518632]), 'std_score_time': array([ 0.00207157]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67748926]), 'std_test_score': array([ 2.80513661]), 'split2_train_score': array([ 0.66375783]), 'split3_train_score': array([ 0.66526634]), 'split2_test_score': array([-6.15467792]), 'split0_test_score': array([ 0.6215308]), 'mean_score_time': array([ 0.01174504]), 'mean_fit_time': array([ 1.903117]), 'std_train_score': array([ 0.01143704])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.35486831978
####################################################################################
################# Runing the itteration 12  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.67435807]), 'mean_train_score': array([ 0.62581086]), 'split3_test_score': array([ 0.47136748]), 'std_fit_time': array([ 0.0983309]), 'mean_test_score': array([ 0.4995613]), 'split1_test_score': array([ 0.63161211]), 'std_score_time': array([ 0.00202748]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.59403711]), 'std_test_score': array([ 0.08740644]), 'split2_train_score': array([ 0.64973467]), 'split3_train_score': array([ 0.5851136]), 'split2_test_score': array([ 0.38875114]), 'split0_test_score': array([ 0.50651448]), 'mean_score_time': array([ 0.00469327]), 'mean_fit_time': array([ 0.16555655]), 'std_train_score': array([ 0.03739993])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.499561301757
####################################################################################
################# Runing the itteration 13  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.67779853]), 'mean_train_score': array([ 0.67075357]), 'split3_test_score': array([ 0.62543517]), 'std_fit_time': array([ 0.04963513]), 'mean_test_score': array([-1.92605685]), 'split1_test_score': array([ 0.2717651]), 'std_score_time': array([ 0.00271841]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.66841843]), 'std_test_score': array([ 4.17196879]), 'split2_train_score': array([ 0.66915929]), 'split3_train_score': array([ 0.66763802]), 'split2_test_score': array([-9.14853655]), 'split0_test_score': array([ 0.54710887]), 'mean_score_time': array([ 0.0063051]), 'mean_fit_time': array([ 0.23353767]), 'std_train_score': array([ 0.00410283])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.92605685195
####################################################################################
################# Runing the itteration 14  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.2840802]), 'mean_train_score': array([-0.28969752]), 'split3_test_score': array([-0.28280183]), 'std_fit_time': array([ 0.01698754]), 'mean_test_score': array([-0.29318929]), 'split1_test_score': array([-0.32000321]), 'std_score_time': array([ 0.01331682]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28031223]), 'std_test_score': array([ 0.02414182]), 'split2_train_score': array([-0.30273837]), 'split3_train_score': array([-0.29165927]), 'split2_test_score': array([-0.25880822]), 'split0_test_score': array([-0.31114388]), 'mean_score_time': array([ 0.02416819]), 'mean_fit_time': array([ 0.05140883]), 'std_train_score': array([ 0.00856665])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293189287734
####################################################################################
################# Runing the itteration 15  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.9s
[CV]  ................................................................
[CV] ................................................. , total=   3.1s
[CV]  ................................................................
[CV] ................................................. , total=   3.2s
[CV]  ................................................................
[CV] ................................................. , total=   3.1s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.63359407]), 'mean_train_score': array([ 0.66371172]), 'split3_test_score': array([ 0.09964841]), 'std_fit_time': array([ 0.14509291]), 'mean_test_score': array([ 0.47049618]), 'split1_test_score': array([ 0.58632208]), 'std_score_time': array([ 0.03322012]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67138617]), 'std_test_score': array([ 0.21807535]), 'split2_train_score': array([ 0.67120694]), 'split3_train_score': array([ 0.67865969]), 'split2_test_score': array([ 0.53984506]), 'split0_test_score': array([ 0.65616917]), 'mean_score_time': array([ 0.02671814]), 'mean_fit_time': array([ 3.04107577]), 'std_train_score': array([ 0.01764646])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.470496180512
####################################################################################
################# Runing the itteration 16  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-251580.4113193]), 'mean_train_score': array([-298547.0046183]), 'split3_test_score': array([-8130.99656851]), 'std_fit_time': array([ 0.00072521]), 'mean_test_score': array([-12046.20441308]), 'split1_test_score': array([-6967.27242858]), 'std_score_time': array([ 0.00180852]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-327063.22709121]), 'std_test_score': array([ 7949.59621356]), 'split2_train_score': array([-536449.90330025]), 'split3_train_score': array([-79094.47676245]), 'split2_test_score': array([-25795.64271718]), 'split0_test_score': array([-7290.90593803]), 'mean_score_time': array([ 0.0131821]), 'mean_fit_time': array([ 0.03824157]), 'std_train_score': array([ 164146.45671917])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-12046.2044131
####################################################################################
################# Runing the itteration 17  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.6482808]), 'mean_train_score': array([ 0.63843861]), 'split3_test_score': array([ 0.62491043]), 'std_fit_time': array([ 0.00343516]), 'mean_test_score': array([ 0.6083522]), 'split1_test_score': array([ 0.5773345]), 'std_score_time': array([ 0.01051158]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65020659]), 'std_test_score': array([ 0.03453621]), 'split2_train_score': array([ 0.61934681]), 'split3_train_score': array([ 0.63592023]), 'split2_test_score': array([ 0.65699563]), 'split0_test_score': array([ 0.57416824]), 'mean_score_time': array([ 0.00949591]), 'mean_fit_time': array([ 0.0780887]), 'std_train_score': array([ 0.01231049])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.608352200844
####################################################################################
################# Runing the itteration 18  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   6.3s
[CV]  ................................................................
[CV] ................................................. , total=   6.6s
[CV]  ................................................................
[CV] ................................................. , total=   6.8s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -1.07300738e+26]), 'mean_train_score': array([ -2.68465370e+25]), 'split3_test_score': array([ -5.08134838e+21]), 'std_fit_time': array([ 0.21178371]), 'mean_test_score': array([ -3.65126391e+25]), 'split1_test_score': array([ -5.67508333e+22]), 'std_score_time': array([ 0.00493259]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -7.15695367e+22]), 'std_test_score': array([  6.32004474e+25]), 'split2_train_score': array([ -8.68675492e+21]), 'split3_train_score': array([ -5.15403819e+21]), 'split2_test_score': array([ -9.70478611e+21]), 'split0_test_score': array([ -1.45979020e+26]), 'mean_score_time': array([ 0.01089954]), 'mean_fit_time': array([ 6.5744006]), 'std_train_score': array([  4.64502619e+25])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3.65126391369e+25
####################################################################################
################# Runing the itteration 19  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.57973801]), 'mean_train_score': array([ 0.58675414]), 'split3_test_score': array([ 0.43388032]), 'std_fit_time': array([ 0.0008705]), 'mean_test_score': array([ 0.3652232]), 'split1_test_score': array([ 0.34279811]), 'std_score_time': array([ 0.05548317]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.5876269]), 'std_test_score': array([ 0.0397561]), 'split2_train_score': array([ 0.59865089]), 'split3_train_score': array([ 0.58100073]), 'split2_test_score': array([ 0.33781739]), 'split0_test_score': array([ 0.34639698]), 'mean_score_time': array([ 1.00390059]), 'mean_fit_time': array([ 0.04932511]), 'std_train_score': array([ 0.0074937])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.365223200407
####################################################################################
################# Runing the itteration 20  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_2', label_fn=<function label_gross_2>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5946318641313082}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56708851293750684}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61784799139764635}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29177244457716056}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.36522320040671913}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.3548683197785094}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.4995613017572953}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.9260568519472796}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5946318641313082}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56708851293750684}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61784799139764635}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29177244457716056}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.36522320040671913}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.3548683197785094}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.4995613017572953}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.9260568519472796}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=2056      41059418
2945      14942422
1376      ...     22913677
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5946318641313082}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56708851293750684}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61784799139764635}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29177244457716056}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.36522320040671913}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.3548683197785094}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.4995613017572953}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -1.9260568519472796}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 2056      41059418
2945      14942422
1376      ...     22913677
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=2056      41059418
2945      14942422
1376      ...     22913677
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 2056      41059418
2945      14942422
1376      ...     22913677
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=2056      41059418
2945      14942422
1376      ...     22913677
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:17:08 2017
PID: 16442                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], 2056      41059418
2945      14942422
1376      ...     22913677
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], 2056      41059418
2945      14942422
1376      ...     22913677
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 214 columns], y=2056      41059418
2945      14942422
1376      ...     22913677
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], y_test=2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], 2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], 2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], 2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], 2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], y=2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y = 2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 214 columns], y=2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64, y_pred=array([ 38183712.        ,                nan,  ...    nan,                nan,                nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 2056      41059418
2945      14942422
1376      ...        26608
Name: worldwide_gross, dtype: int64
        y_pred = array([ 38183712.        ,                nan,  ...    nan,                nan,                nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([41059418, 14942422, 81198894, ..., 42137871,  6049171,    26608]), y_pred=array([ 38183712.        ,                nan,  ...    nan,                nan,                nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([ 38183712.        ,                nan,  ...    nan,                nan,                nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([ 38183712.        ,                nan,  ...    nan,                nan,                nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([ 38183712.        ,                nan,  ...    nan,                nan,                nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([ 38183712.        ,                nan,  ...    nan,                nan,                nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 21  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  58.5s
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.2845893]), 'mean_train_score': array([-0.28971142]), 'split3_test_score': array([-0.30203014]), 'std_fit_time': array([ 3.74929878]), 'mean_test_score': array([-0.29268599]), 'split1_test_score': array([-0.30033165]), 'std_score_time': array([ 0.00612526]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28682783]), 'std_test_score': array([ 0.01780079]), 'split2_train_score': array([-0.30232314]), 'split3_train_score': array([-0.2851054]), 'split2_test_score': array([-0.26208478]), 'split0_test_score': array([-0.30629739]), 'mean_score_time': array([ 0.01417196]), 'mean_fit_time': array([ 64.88963848]), 'std_train_score': array([ 0.0073284])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292685989334
####################################################################################
################# Runing the itteration 22  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13158382]), 'mean_train_score': array([-0.13178916]), 'split3_test_score': array([-0.15631405]), 'std_fit_time': array([ 0.06841405]), 'mean_test_score': array([-0.13316377]), 'split1_test_score': array([-0.1177488]), 'std_score_time': array([ 0.01733693]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.1372777]), 'std_test_score': array([ 0.01433251]), 'split2_train_score': array([-0.13113284]), 'split3_train_score': array([-0.12716226]), 'split2_test_score': array([-0.13231355]), 'split0_test_score': array([-0.12627869]), 'mean_score_time': array([ 1.1394515]), 'mean_fit_time': array([ 4.00274312]), 'std_train_score': array([ 0.00360573])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.133163771481
####################################################################################
################# Runing the itteration 23  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.30457016]), 'mean_train_score': array([-0.28980838]), 'split3_test_score': array([-0.28419895]), 'std_fit_time': array([ 0.00276405]), 'mean_test_score': array([-0.29216806]), 'split1_test_score': array([-0.33429408]), 'std_score_time': array([ 0.00578564]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27717103]), 'std_test_score': array([ 0.03051407]), 'split2_train_score': array([-0.28611692]), 'split3_train_score': array([-0.29137538]), 'split2_test_score': array([-0.3006139]), 'split0_test_score': array([-0.24956531]), 'mean_score_time': array([ 0.01729882]), 'mean_fit_time': array([ 0.04483271]), 'std_train_score': array([ 0.00992088])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292168058974
####################################################################################
################# Runing the itteration 24  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.6s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05205597]), 'mean_train_score': array([-0.05240405]), 'split3_test_score': array([-0.03579538]), 'std_fit_time': array([ 0.042376]), 'mean_test_score': array([-0.05329173]), 'split1_test_score': array([-0.05784923]), 'std_score_time': array([ 0.00370396]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05176501]), 'std_test_score': array([ 0.01014947]), 'split2_train_score': array([-0.05140345]), 'split3_train_score': array([-0.05439177]), 'split2_test_score': array([-0.06061168]), 'split0_test_score': array([-0.05891063]), 'mean_score_time': array([ 0.5678004]), 'mean_fit_time': array([ 2.97962177]), 'std_train_score': array([ 0.00117066])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0532917313512
####################################################################################
################# Runing the itteration 25  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([-0.10814201]), 'std_fit_time': array([ 0.01992725]), 'mean_test_score': array([ 0.2941926]), 'split1_test_score': array([ 0.41175522]), 'std_score_time': array([ 0.00029476]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.23268692]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.4237108]), 'split0_test_score': array([ 0.44944639]), 'mean_score_time': array([ 0.00372064]), 'mean_fit_time': array([ 0.24180651]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.294192599892
####################################################################################
################# Runing the itteration 26  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.34064991]), 'std_fit_time': array([ 0.00935091]), 'mean_test_score': array([ 0.31207878]), 'split1_test_score': array([ 0.4518386]), 'std_score_time': array([ 0.00040517]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.09524123]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.19819125]), 'split0_test_score': array([ 0.25763538]), 'mean_score_time': array([ 0.00336361]), 'mean_fit_time': array([ 0.1097613]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.312078784861
####################################################################################
################# Runing the itteration 27  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.49388321]), 'mean_train_score': array([ 0.47792328]), 'split3_test_score': array([ 0.52859391]), 'std_fit_time': array([ 0.16050519]), 'mean_test_score': array([ 0.36423031]), 'split1_test_score': array([ 0.39344345]), 'std_score_time': array([ 0.0021764]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.42096743]), 'std_test_score': array([ 0.1291233]), 'split2_train_score': array([ 0.34488944]), 'split3_train_score': array([ 0.65195304]), 'split2_test_score': array([ 0.16722586]), 'split0_test_score': array([ 0.36765803]), 'mean_score_time': array([ 0.00886905]), 'mean_fit_time': array([ 0.5495131]), 'std_train_score': array([ 0.11344938])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.364230312134
####################################################################################
################# Runing the itteration 28  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93453521]), 'mean_train_score': array([ 0.9336799]), 'split3_test_score': array([ 0.65422755]), 'std_fit_time': array([ 0.0193294]), 'mean_test_score': array([ 0.61642692]), 'split1_test_score': array([ 0.63182552]), 'std_score_time': array([ 0.00027526]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93521537]), 'std_test_score': array([ 0.02854944]), 'split2_train_score': array([ 0.93721932]), 'split3_train_score': array([ 0.9277497]), 'split2_test_score': array([ 0.5803616]), 'split0_test_score': array([ 0.59929299]), 'mean_score_time': array([ 0.00702894]), 'mean_fit_time': array([ 0.70113373]), 'std_train_score': array([ 0.00356315])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.61642691504
####################################################################################
################# Runing the itteration 29  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.57306112]), 'std_fit_time': array([ 0.03951469]), 'mean_test_score': array([ 0.5781263]), 'split1_test_score': array([ 0.52095883]), 'std_score_time': array([ 0.00084002]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.03781312]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.62488072]), 'split0_test_score': array([ 0.59360453]), 'mean_score_time': array([ 0.00658202]), 'mean_fit_time': array([ 0.36293429]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.578126300582
####################################################################################
################# Runing the itteration 30  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.79725262]), 'mean_train_score': array([ 0.80304213]), 'split3_test_score': array([ 0.60696926]), 'std_fit_time': array([ 0.0229349]), 'mean_test_score': array([ 0.65568334]), 'split1_test_score': array([ 0.64270639]), 'std_score_time': array([ 0.00047753]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.81345113]), 'std_test_score': array([ 0.03448039]), 'split2_train_score': array([ 0.79774151]), 'split3_train_score': array([ 0.80372327]), 'split2_test_score': array([ 0.69900349]), 'split0_test_score': array([ 0.67405424]), 'mean_score_time': array([ 0.0046674]), 'mean_fit_time': array([ 0.7005043]), 'std_train_score': array([ 0.00652737])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.655683343607
####################################################################################
################# Runing the itteration 31  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93671613]), 'mean_train_score': array([ 0.93532977]), 'split3_test_score': array([ 0.60587062]), 'std_fit_time': array([ 0.00736066]), 'mean_test_score': array([ 0.61933919]), 'split1_test_score': array([ 0.69496908]), 'std_score_time': array([ 0.00016916]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93420611]), 'std_test_score': array([ 0.04425861]), 'split2_train_score': array([ 0.93765614]), 'split3_train_score': array([ 0.93274069]), 'split2_test_score': array([ 0.58925869]), 'split0_test_score': array([ 0.58725839]), 'mean_score_time': array([ 0.00572991]), 'mean_fit_time': array([ 0.67678285]), 'std_train_score': array([ 0.00195576])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.619339194899
####################################################################################
################# Runing the itteration 32  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.61394783]), 'mean_train_score': array([ 0.5954061]), 'split3_test_score': array([ 0.61671128]), 'std_fit_time': array([ 0.00599172]), 'mean_test_score': array([ 0.57859912]), 'split1_test_score': array([ 0.54960526]), 'std_score_time': array([ 0.01139821]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61321364]), 'std_test_score': array([ 0.035479]), 'split2_train_score': array([ 0.58857262]), 'split3_train_score': array([ 0.56589033]), 'split2_test_score': array([ 0.61078425]), 'split0_test_score': array([ 0.53729568]), 'mean_score_time': array([ 0.01948297]), 'mean_fit_time': array([ 0.0618642]), 'std_train_score': array([ 0.01986694])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.578599118849
####################################################################################
################# Runing the itteration 33  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.26827508]), 'mean_train_score': array([ 0.26054262]), 'split3_test_score': array([ 0.26571538]), 'std_fit_time': array([ 0.01962584]), 'mean_test_score': array([ 0.25552966]), 'split1_test_score': array([ 0.25996377]), 'std_score_time': array([ 0.00035075]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.25815707]), 'std_test_score': array([ 0.01090226]), 'split2_train_score': array([ 0.26895601]), 'split3_train_score': array([ 0.24678232]), 'split2_test_score': array([ 0.23714822]), 'split0_test_score': array([ 0.25929126]), 'mean_score_time': array([ 0.00335461]), 'mean_fit_time': array([ 0.15573198]), 'std_train_score': array([ 0.00902237])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.255529659015
####################################################################################
################# Runing the itteration 34  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.69812768]), 'mean_train_score': array([ 0.67498558]), 'split3_test_score': array([ 0.69780153]), 'std_fit_time': array([ 0.00677213]), 'mean_test_score': array([ 0.51915744]), 'split1_test_score': array([ 0.65187768]), 'std_score_time': array([ 0.02118977]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6763129]), 'std_test_score': array([ 0.25998883]), 'split2_train_score': array([ 0.67278873]), 'split3_train_score': array([ 0.652713]), 'split2_test_score': array([ 0.65705196]), 'split0_test_score': array([ 0.06989861]), 'mean_score_time': array([ 0.03097326]), 'mean_fit_time': array([ 0.53664929]), 'std_train_score': array([ 0.01611065])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.519157444481
####################################################################################
################# Runing the itteration 35  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.66515028]), 'mean_train_score': array([ 0.66503098]), 'split3_test_score': array([ 0.67862294]), 'std_fit_time': array([ 0.02987962]), 'mean_test_score': array([ 0.64303841]), 'split1_test_score': array([ 0.60596935]), 'std_score_time': array([ 0.00592063]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67400694]), 'std_test_score': array([ 0.02627337]), 'split2_train_score': array([ 0.67010438]), 'split3_train_score': array([ 0.65086232]), 'split2_test_score': array([ 0.63604493]), 'split0_test_score': array([ 0.65151643]), 'mean_score_time': array([ 0.00804627]), 'mean_fit_time': array([ 0.07174551]), 'std_train_score': array([ 0.00876174])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.643038412577
####################################################################################
################# Runing the itteration 36  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.65425451]), 'mean_train_score': array([ 0.66849233]), 'split3_test_score': array([ 0.63740518]), 'std_fit_time': array([ 0.01582913]), 'mean_test_score': array([ 0.61835876]), 'split1_test_score': array([ 0.58658058]), 'std_score_time': array([ 0.00015497]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67890794]), 'std_test_score': array([ 0.01963591]), 'split2_train_score': array([ 0.66988116]), 'split3_train_score': array([ 0.6709257]), 'split2_test_score': array([ 0.61806851]), 'split0_test_score': array([ 0.63138077]), 'mean_score_time': array([ 0.0020346]), 'mean_fit_time': array([ 0.08715904]), 'std_train_score': array([ 0.00893099])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.61835876069
####################################################################################
################# Runing the itteration 37  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.30462729]), 'mean_train_score': array([-0.28966947]), 'split3_test_score': array([-0.30152852]), 'std_fit_time': array([ 0.00010185]), 'mean_test_score': array([-0.2929057]), 'split1_test_score': array([-0.32179278]), 'std_score_time': array([ 0.01172075]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27922626]), 'std_test_score': array([ 0.02473611]), 'split2_train_score': array([-0.28957817]), 'split3_train_score': array([-0.28524616]), 'split2_test_score': array([-0.29458585]), 'split0_test_score': array([-0.25371564]), 'mean_score_time': array([ 0.02106208]), 'mean_fit_time': array([ 0.01931632]), 'std_train_score': array([ 0.00938578])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292905697394
####################################################################################
################# Runing the itteration 38  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] .................................GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.68285659]), 'mean_train_score': array([ 0.66907128]), 'split3_test_score': array([ 0.68346784]), 'std_fit_time': array([ 0.08839185]), 'mean_test_score': array([ 0.64642803]), 'split1_test_score': array([ 0.64166482]), 'std_score_time': array([ 0.00953305]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6730595]), 'std_test_score': array([ 0.02452972]), 'split2_train_score': array([ 0.66498531]), 'split3_train_score': array([ 0.65538373]), 'split2_test_score': array([ 0.64596299]), 'split0_test_score': array([ 0.61461646]), 'mean_score_time': array([ 0.01378143]), 'mean_fit_time': array([ 0.78349316]), 'std_train_score': array([ 0.01012404])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.646428027928
####################################################################################
################# Runing the itteration 39  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-58271.70758916]), 'mean_train_score': array([-31393.01415052]), 'split3_test_score': array([-1703.39614527]), 'std_fit_time': array([ 0.00213241]), 'mean_test_score': array([-2810.54146382]), 'split1_test_score': array([ 0.45883525]), 'std_score_time': array([ 0.01273399]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-3.47461186]), 'std_test_score': array([ 3941.06563158]), 'split2_train_score': array([-141.90740367]), 'split3_train_score': array([-67154.96699738]), 'split2_test_score': array([-9.12231952]), 'split0_test_score': array([-9530.10622575]), 'mean_score_time': array([ 0.02187949]), 'mean_fit_time': array([ 0.02268136]), 'std_train_score': array([ 31477.43754557])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2810.54146382
####################################################################################
################# Runing the itteration 40  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.67103384]), 'mean_train_score': array([ 0.65453557]), 'split3_test_score': array([ 0.63943589]), 'std_fit_time': array([ 0.00359007]), 'mean_test_score': array([ 0.61493762]), 'split1_test_score': array([ 0.63306667]), 'std_score_time': array([ 0.00045729]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.65823732]), 'std_test_score': array([ 0.03279012]), 'split2_train_score': array([ 0.66057247]), 'split3_train_score': array([ 0.62829864]), 'split2_test_score': array([ 0.6287195]), 'split0_test_score': array([ 0.5585284]), 'mean_score_time': array([ 0.00224733]), 'mean_fit_time': array([ 0.04962212]), 'std_train_score': array([ 0.01589589])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.614937615042
####################################################################################
################# Runing the itteration 41  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([-2.89767892]), 'mean_train_score': array([ -2.59150714e+20]), 'split3_test_score': array([ 0.00030298]), 'std_fit_time': array([ 0.38464081]), 'mean_test_score': array([ -1.28057196e+20]), 'split1_test_score': array([ -5.12228782e+20]), 'std_score_time': array([ 0.00105348]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -1.03660285e+21]), 'std_test_score': array([  2.21801569e+20]), 'split2_train_score': array([-38.01758663]), 'split3_train_score': array([-1.96203787]), 'split2_test_score': array([-44.54990702]), 'split0_test_score': array([-145.2664209]), 'mean_score_time': array([ 0.0027743]), 'mean_fit_time': array([ 1.01939332]), 'std_train_score': array([  4.48862203e+20])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.28057195512e+20
####################################################################################
################# Runing the itteration 42  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.67939165]), 'mean_train_score': array([ 0.68854856]), 'split3_test_score': array([ 0.45942825]), 'std_fit_time': array([ 0.00678909]), 'mean_test_score': array([ 0.51317104]), 'split1_test_score': array([ 0.52488978]), 'std_score_time': array([ 0.0412128]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.69235923]), 'std_test_score': array([ 0.03162808]), 'split2_train_score': array([ 0.6794033]), 'split3_train_score': array([ 0.70304005]), 'split2_test_score': array([ 0.52737442]), 'split0_test_score': array([ 0.5409917]), 'mean_score_time': array([ 0.30498457]), 'mean_fit_time': array([ 0.02901638]), 'std_train_score': array([ 0.00989961])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.513171040121
####################################################################################
################# Runing the itteration 43  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_2', label_fn=<function label_gross_2>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29419259989222679}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31207878486056184}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57812630058200631}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29177244457716056}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51915744448053525}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29419259989222679}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31207878486056184}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57812630058200631}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29177244457716056}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51915744448053525}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], y=1547     68541786
1890     48543388
2557     246...      9413956
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29419259989222679}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31207878486056184}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57812630058200631}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29177244457716056}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51915744448053525}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns]
        y = 1547     68541786
1890     48543388
2557     246...      9413956
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], y=1547     68541786
1890     48543388
2557     246...      9413956
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns]
        y = 1547     68541786
1890     48543388
2557     246...      9413956
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], y=1547     68541786
1890     48543388
2557     246...      9413956
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:20:54 2017
PID: 17720                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], 1547     68541786
1890     48543388
2557     246...      9413956
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], 1547     68541786
1890     48543388
2557     246...      9413956
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[4812 rows x 61 columns], y=1547     68541786
1890     48543388
2557     246...      9413956
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns]
        y_test = 1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], y_test=1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns]
        y_test = 1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], 1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], y=1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns]
        y = 1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...5 -0.650627  1.148997  

[1203 rows x 61 columns], y=1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64, y_pred=array([  8.01793193e+07,              nan,      ...6077947e+07,   1.03881292e+08,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 1547     68541786
1890     48543388
2557     246...     28142379
Name: worldwide_gross, dtype: int64
        y_pred = array([  8.01793193e+07,              nan,      ...6077947e+07,   1.03881292e+08,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 68541786,  48543388,  24600000, ..., 302710615, 137047376,
        28142379]), y_pred=array([  8.01793193e+07,              nan,      ...6077947e+07,   1.03881292e+08,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  8.01793193e+07,              nan,      ...6077947e+07,   1.03881292e+08,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  8.01793193e+07,              nan,      ...6077947e+07,   1.03881292e+08,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  8.01793193e+07,              nan,      ...6077947e+07,   1.03881292e+08,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  8.01793193e+07,              nan,      ...6077947e+07,   1.03881292e+08,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 44  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  30.7s
[CV]  ................................................................
[CV] ................................................. , total=  34.9s
[CV]  ................................................................
[CV] ................................................. , total=  35.6s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28503143]), 'mean_train_score': array([-0.28992009]), 'split3_test_score': array([-0.2567718]), 'std_fit_time': array([ 2.21512594]), 'mean_test_score': array([-0.29452435]), 'split1_test_score': array([-0.33536338]), 'std_score_time': array([ 0.00839957]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27857552]), 'std_test_score': array([ 0.02903861]), 'split2_train_score': array([-0.2932281]), 'split3_train_score': array([-0.3028453]), 'split2_test_score': array([-0.28125256]), 'split0_test_score': array([-0.30470968]), 'mean_score_time': array([ 0.02260435]), 'mean_fit_time': array([ 34.37236434]), 'std_train_score': array([ 0.00909124])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.294524354062
####################################################################################
################# Runing the itteration 45  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.14591836]), 'mean_train_score': array([-0.13220288]), 'split3_test_score': array([-0.15830778]), 'std_fit_time': array([ 0.02736225]), 'mean_test_score': array([-0.13498231]), 'split1_test_score': array([-0.12912674]), 'std_score_time': array([ 0.00280213]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13156712]), 'std_test_score': array([ 0.01351829]), 'split2_train_score': array([-0.12730402]), 'split3_train_score': array([-0.12402202]), 'split2_test_score': array([-0.12632795]), 'split0_test_score': array([-0.12616676]), 'mean_score_time': array([ 0.43383223]), 'mean_fit_time': array([ 1.83965957]), 'std_train_score': array([ 0.00835829])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.134982307672
####################################################################################
################# Runing the itteration 46  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28199819]), 'mean_train_score': array([-0.29011178]), 'split3_test_score': array([-0.25381486]), 'std_fit_time': array([ 0.0008299]), 'mean_test_score': array([-0.29389322]), 'split1_test_score': array([-0.31108174]), 'std_score_time': array([ 0.00146289]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28330551]), 'std_test_score': array([ 0.02472923]), 'split2_train_score': array([-0.2883269]), 'split3_train_score': array([-0.30681653]), 'split2_test_score': array([-0.29345442]), 'split0_test_score': array([-0.31722186]), 'mean_score_time': array([ 0.01226431]), 'mean_fit_time': array([ 0.01909643]), 'std_train_score': array([ 0.00992963])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293893218043
####################################################################################
################# Runing the itteration 47  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05590479]), 'mean_train_score': array([-0.05242515]), 'split3_test_score': array([-0.04862606]), 'std_fit_time': array([ 0.00744238]), 'mean_test_score': array([-0.05304346]), 'split1_test_score': array([-0.04754345]), 'std_score_time': array([ 0.00210335]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05149746]), 'std_test_score': array([ 0.0099369]), 'split2_train_score': array([-0.04957062]), 'split3_train_score': array([-0.05272773]), 'split2_test_score': array([-0.07016824]), 'split0_test_score': array([-0.0458361]), 'mean_score_time': array([ 0.21989399]), 'mean_fit_time': array([ 1.44192839]), 'std_train_score': array([ 0.00230263])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0530434601966
####################################################################################
################# Runing the itteration 48  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.39632374]), 'std_fit_time': array([ 0.00265378]), 'mean_test_score': array([ 0.33320598]), 'split1_test_score': array([ 0.30853325]), 'std_score_time': array([  7.19932328e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.03727794]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.30333043]), 'split0_test_score': array([ 0.32463651]), 'mean_score_time': array([ 0.00186551]), 'mean_fit_time': array([ 0.1208542]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.333205982415
####################################################################################
################# Runing the itteration 49  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.26322555]), 'std_fit_time': array([ 0.00737024]), 'mean_test_score': array([ 0.35148918]), 'split1_test_score': array([ 0.4328553]), 'std_score_time': array([ 0.00037608]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.06072483]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.34238166]), 'split0_test_score': array([ 0.36749419]), 'mean_score_time': array([ 0.00225139]), 'mean_fit_time': array([ 0.05191261]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.351489175376
####################################################################################
################# Runing the itteration 50  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.05301201]), 'mean_train_score': array([ 0.03381323]), 'split3_test_score': array([-0.75650722]), 'std_fit_time': array([ 0.12660332]), 'mean_test_score': array([-0.20077789]), 'split1_test_score': array([ 0.05608721]), 'std_score_time': array([ 0.00245439]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.15296342]), 'std_test_score': array([ 0.40999889]), 'split2_train_score': array([ 0.16467711]), 'split3_train_score': array([-0.23539961]), 'split2_test_score': array([ 0.30426755]), 'split0_test_score': array([-0.40695908]), 'mean_score_time': array([ 0.00942719]), 'mean_fit_time': array([ 0.58626872]), 'std_train_score': array([ 0.161374])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.200777885324
####################################################################################
################# Runing the itteration 51  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92781225]), 'mean_train_score': array([ 0.92487803]), 'split3_test_score': array([ 0.55912395]), 'std_fit_time': array([ 0.01682812]), 'mean_test_score': array([ 0.55710903]), 'split1_test_score': array([ 0.54607557]), 'std_score_time': array([ 0.00018611]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92988817]), 'std_test_score': array([ 0.00772454]), 'split2_train_score': array([ 0.9214365]), 'split3_train_score': array([ 0.92037521]), 'split2_test_score': array([ 0.56762705]), 'split0_test_score': array([ 0.55560957]), 'mean_score_time': array([ 0.00836283]), 'mean_fit_time': array([ 0.67174149]), 'std_train_score': array([ 0.00405681])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.557109033055
####################################################################################
################# Runing the itteration 52  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.63392963]), 'std_fit_time': array([ 0.00506362]), 'mean_test_score': array([ 0.57172245]), 'split1_test_score': array([ 0.58079159]), 'std_score_time': array([ 0.001501]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.04205558]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.55315102]), 'split0_test_score': array([ 0.51901755]), 'mean_score_time': array([ 0.00761402]), 'mean_fit_time': array([ 0.45931661]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.571722448731
####################################################################################
################# Runing the itteration 53  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.76538442]), 'mean_train_score': array([ 0.76697211]), 'split3_test_score': array([ 0.63731106]), 'std_fit_time': array([ 0.02084893]), 'mean_test_score': array([ 0.60841421]), 'split1_test_score': array([ 0.59583991]), 'std_score_time': array([ 0.00015998]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.76686461]), 'std_test_score': array([ 0.01703264]), 'split2_train_score': array([ 0.76919513]), 'split3_train_score': array([ 0.76644429]), 'split2_test_score': array([ 0.59612442]), 'split0_test_score': array([ 0.60438146]), 'mean_score_time': array([ 0.00425112]), 'mean_fit_time': array([ 0.87395155]), 'std_train_score': array([ 0.00139218])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.608414213055
####################################################################################
################# Runing the itteration 54  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92858975]), 'mean_train_score': array([ 0.93013055]), 'split3_test_score': array([ 0.59273776]), 'std_fit_time': array([ 0.00751607]), 'mean_test_score': array([ 0.58964719]), 'split1_test_score': array([ 0.59374296]), 'std_score_time': array([ 0.00021489]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92958333]), 'std_test_score': array([ 0.01760925]), 'split2_train_score': array([ 0.92821226]), 'split3_train_score': array([ 0.93413687]), 'split2_test_score': array([ 0.61042813]), 'split0_test_score': array([ 0.56167992]), 'mean_score_time': array([ 0.00562024]), 'mean_fit_time': array([ 0.66011184]), 'std_train_score': array([ 0.00236664])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.589647193153
####################################################################################
################# Runing the itteration 55  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.53335927]), 'mean_train_score': array([ 0.54499793]), 'split3_test_score': array([ 0.52188896]), 'std_fit_time': array([ 0.01317036]), 'mean_test_score': array([ 0.51657998]), 'split1_test_score': array([ 0.49067319]), 'std_score_time': array([ 0.00274207]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.55610544]), 'std_test_score': array([ 0.01650961]), 'split2_train_score': array([ 0.55536836]), 'split3_train_score': array([ 0.53515865]), 'split2_test_score': array([ 0.51742407]), 'split0_test_score': array([ 0.53633369]), 'mean_score_time': array([ 0.01450229]), 'mean_fit_time': array([ 0.09381902]), 'std_train_score': array([ 0.01076095])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.516579975338
####################################################################################
################# Runing the itteration 56  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.19618307]), 'mean_train_score': array([ 0.19249569]), 'split3_test_score': array([ 0.20216116]), 'std_fit_time': array([ 0.07491244]), 'mean_test_score': array([ 0.18591511]), 'split1_test_score': array([ 0.16399604]), 'std_score_time': array([ 0.00067294]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.1942017]), 'std_test_score': array([ 0.01419859]), 'split2_train_score': array([ 0.19341607]), 'split3_train_score': array([ 0.18618191]), 'split2_test_score': array([ 0.18395953]), 'split0_test_score': array([ 0.1935437]), 'mean_score_time': array([ 0.00371557]), 'mean_fit_time': array([ 0.2000652]), 'std_train_score': array([ 0.00378213])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.185915107378
####################################################################################
################# Runing the itteration 57  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.61289886]), 'mean_train_score': array([ 0.62587585]), 'split3_test_score': array([ 0.56029967]), 'std_fit_time': array([ 0.01401096]), 'mean_test_score': array([ 0.58383923]), 'split1_test_score': array([ 0.5634834]), 'std_score_time': array([ 0.00713079]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63313663]), 'std_test_score': array([ 0.02446603]), 'split2_train_score': array([ 0.62218774]), 'split3_train_score': array([ 0.63528016]), 'split2_test_score': array([ 0.59058045]), 'split0_test_score': array([ 0.6209934]), 'mean_score_time': array([ 0.02521539]), 'mean_fit_time': array([ 1.01516086]), 'std_train_score': array([ 0.00898839])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.583839229967
####################################################################################
################# Runing the itteration 58  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.62637798]), 'mean_train_score': array([ 0.62057499]), 'split3_test_score': array([ 0.61798796]), 'std_fit_time': array([ 0.05099101]), 'mean_test_score': array([ 0.58805138]), 'split1_test_score': array([ 0.56628672]), 'std_score_time': array([ 0.00201356]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63071919]), 'std_test_score': array([ 0.02478954]), 'split2_train_score': array([ 0.61760123]), 'split3_train_score': array([ 0.60760158]), 'split2_test_score': array([ 0.60693058]), 'split0_test_score': array([ 0.56100028]), 'mean_score_time': array([ 0.00775421]), 'mean_fit_time': array([ 0.13062853]), 'std_train_score': array([ 0.00885624])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.588051384698
####################################################################################
################# Runing the itteration 59  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.62480628]), 'mean_train_score': array([ 0.62542464]), 'split3_test_score': array([ 0.54400647]), 'std_fit_time': array([ 0.00855899]), 'mean_test_score': array([ 0.58098385]), 'split1_test_score': array([ 0.60105661]), 'std_score_time': array([ 0.00057487]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62077619]), 'std_test_score': array([ 0.02247919]), 'split2_train_score': array([ 0.62184563]), 'split3_train_score': array([ 0.63427047]), 'split2_test_score': array([ 0.59678908]), 'split0_test_score': array([ 0.58208324]), 'mean_score_time': array([ 0.00488943]), 'mean_fit_time': array([ 0.11383116]), 'std_train_score': array([ 0.00531621])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.580983848339
####################################################################################
################# Runing the itteration 60  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.29377634]), 'mean_train_score': array([-0.28933983]), 'split3_test_score': array([-0.29546034]), 'std_fit_time': array([ 0.00053761]), 'mean_test_score': array([-0.28996875]), 'split1_test_score': array([-0.30046032]), 'std_score_time': array([ 0.00936089]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28631903]), 'std_test_score': array([ 0.00902233]), 'split2_train_score': array([-0.29004501]), 'split3_train_score': array([-0.28721894]), 'split2_test_score': array([-0.287346]), 'split0_test_score': array([-0.27660834]), 'mean_score_time': array([ 0.02057379]), 'mean_fit_time': array([ 0.02637649]), 'std_train_score': array([ 0.00290703])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.289968749144
####################################################################################
################# Runing the itteration 61  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.61311186]), 'mean_train_score': array([ 0.62228938]), 'split3_test_score': array([ 0.56152073]), 'std_fit_time': array([ 0.0922036]), 'mean_test_score': array([ 0.58512632]), 'split1_test_score': array([ 0.57107021]), 'std_score_time': array([ 0.00603414]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63009815]), 'std_test_score': array([ 0.01986665]), 'split2_train_score': array([ 0.61878499]), 'split3_train_score': array([ 0.62716252]), 'split2_test_score': array([ 0.59638303]), 'split0_test_score': array([ 0.6115313]), 'mean_score_time': array([ 0.01731229]), 'mean_fit_time': array([ 1.58527637]), 'std_train_score': array([ 0.00673112])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.585126320109
####################################################################################
################# Runing the itteration 62  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.58792202]), 'mean_train_score': array([ 0.60175961]), 'split3_test_score': array([ 0.53886709]), 'std_fit_time': array([ 0.00431309]), 'mean_test_score': array([ 0.56760096]), 'split1_test_score': array([ 0.56361814]), 'std_score_time': array([ 0.00730274]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.5997974]), 'std_test_score': array([ 0.02084801]), 'split2_train_score': array([ 0.60559201]), 'split3_train_score': array([ 0.61372702]), 'split2_test_score': array([ 0.57050812]), 'split0_test_score': array([ 0.5974105]), 'mean_score_time': array([ 0.01759464]), 'mean_fit_time': array([ 0.02905142]), 'std_train_score': array([ 0.00939728])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.567600963055
####################################################################################
################# Runing the itteration 63  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.58882317]), 'mean_train_score': array([ 0.59982223]), 'split3_test_score': array([ 0.5665986]), 'std_fit_time': array([ 0.00443426]), 'mean_test_score': array([ 0.58292522]), 'split1_test_score': array([ 0.58743353]), 'std_score_time': array([ 0.01154774]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.60132255]), 'std_test_score': array([ 0.01744054]), 'split2_train_score': array([ 0.60373301]), 'split3_train_score': array([ 0.6054102]), 'split2_test_score': array([ 0.5680983]), 'split0_test_score': array([ 0.60957046]), 'mean_score_time': array([ 0.0167405]), 'mean_fit_time': array([ 0.04444683]), 'std_train_score': array([ 0.0065144])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.582925221644
####################################################################################
################# Runing the itteration 64  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
[CV]  ................................................................
[CV] ................................................. , total=   2.1s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -1.11788805e+22]), 'mean_train_score': array([ -1.60413602e+24]), 'split3_test_score': array([ -6.16947288e+23]), 'std_fit_time': array([ 0.41574055]), 'mean_test_score': array([ -1.74502122e+24]), 'split1_test_score': array([ -1.36859017e+24]), 'std_score_time': array([ 0.00257748]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -9.81822333e+23]), 'std_test_score': array([  1.93040719e+24]), 'split2_train_score': array([ -4.61267061e+24]), 'split3_train_score': array([ -8.10872251e+23]), 'split2_test_score': array([ -4.98322111e+24]), 'split0_test_score': array([ -1.13263107e+22]), 'mean_score_time': array([ 0.00398076]), 'mean_fit_time': array([ 1.62730795]), 'std_train_score': array([  1.77519961e+24])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.7450212187e+24
####################################################################################
################# Runing the itteration 65  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.62817689]), 'mean_train_score': array([ 0.62487987]), 'split3_test_score': array([ 0.37255819]), 'std_fit_time': array([ 0.00666181]), 'mean_test_score': array([ 0.41287141]), 'split1_test_score': array([ 0.36308435]), 'std_score_time': array([ 0.05182234]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63639278]), 'std_test_score': array([ 0.04517555]), 'split2_train_score': array([ 0.60098887]), 'split3_train_score': array([ 0.63396091]), 'split2_test_score': array([ 0.45748219]), 'split0_test_score': array([ 0.45836089]), 'mean_score_time': array([ 0.53256518]), 'mean_fit_time': array([ 0.03978449]), 'std_train_score': array([ 0.01411261])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.412871407425
####################################################################################
################# Runing the itteration 66  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_2', label_fn=<function label_gross_2>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.33320598241470417}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57812630058200631}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29177244457716056}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58383922996690341}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.86304212,
        -0.06123763, -0.05200382]])}
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.33320598241470417}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57812630058200631}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29177244457716056}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58383922996690341}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1          2         3... -0.061238 -0.052004  

[4812 rows x 116 columns], y=294     336069511
4710            0
3996       9...    234723148
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.33320598241470417}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.57812630058200631}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29177244457716056}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58383922996690341}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1          2         3... -0.061238 -0.052004  

[4812 rows x 116 columns]
        y = 294     336069511
4710            0
3996       9...    234723148
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1          2         3... -0.061238 -0.052004  

[4812 rows x 116 columns], y=294     336069511
4710            0
3996       9...    234723148
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1          2         3... -0.061238 -0.052004  

[4812 rows x 116 columns]
        y = 294     336069511
4710            0
3996       9...    234723148
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1          2         3... -0.061238 -0.052004  

[4812 rows x 116 columns], y=294     336069511
4710            0
3996       9...    234723148
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:23:30 2017
PID: 18992                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1          2         3... -0.061238 -0.052004  

[4812 rows x 116 columns], 294     336069511
4710            0
3996       9...    234723148
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1          2         3... -0.061238 -0.052004  

[4812 rows x 116 columns], 294     336069511
4710            0
3996       9...    234723148
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1          2         3... -0.061238 -0.052004  

[4812 rows x 116 columns], y=294     336069511
4710            0
3996       9...    234723148
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns]
        y_test = 294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns], y_test=294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns]
        y_test = 294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns], 294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns], 294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns], 294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns], 294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns], y=294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns]
        y = 294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 116 columns], y=294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64, y_pred=array([        nan,         nan,         nan, ...,         nan,
               nan,  30193861.2]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 294     336069511
4710            0
3996       9...    104283753
Name: worldwide_gross, dtype: int64
        y_pred = array([        nan,         nan,         nan, ...,         nan,
               nan,  30193861.2])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([336069511,         0,    909822, ...,  17489009, 127630030,
       104283753]), y_pred=array([        nan,         nan,         nan, ...,         nan,
               nan,  30193861.2]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([        nan,         nan,         nan, ...,         nan,
               nan,  30193861.2])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([        nan,         nan,         nan, ...,         nan,
               nan,  30193861.2]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([        nan,         nan,         nan, ...,         nan,
               nan,  30193861.2])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([        nan,         nan,         nan, ...,         nan,
               nan,  30193861.2]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 67  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  52.7s
[CV]  ................................................................
[CV] ................................................. , total=  55.0s
[CV]  ................................................................
[CV] ................................................. , total=  55.0s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.30509303]), 'mean_train_score': array([-0.28956798]), 'split3_test_score': array([-0.30709716]), 'std_fit_time': array([ 1.42717232]), 'mean_test_score': array([-0.29113376]), 'split1_test_score': array([-0.32603468]), 'std_score_time': array([ 0.17209648]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27860786]), 'std_test_score': array([ 0.02983411]), 'split2_train_score': array([-0.29092516]), 'split3_train_score': array([-0.28364587]), 'split2_test_score': array([-0.28562397]), 'split0_test_score': array([-0.24577921]), 'mean_score_time': array([ 0.181279]), 'mean_fit_time': array([ 54.57001305]), 'std_train_score': array([ 0.00997578])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291133756656
####################################################################################
################# Runing the itteration 68  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.2s
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13709252]), 'mean_train_score': array([-0.13205266]), 'split3_test_score': array([-0.11238584]), 'std_fit_time': array([ 0.04078997]), 'mean_test_score': array([-0.13541791]), 'split1_test_score': array([-0.13917491]), 'std_score_time': array([ 0.00593134]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.12894508]), 'std_test_score': array([ 0.02008589]), 'split2_train_score': array([-0.12904328]), 'split3_train_score': array([-0.13312976]), 'split2_test_score': array([-0.1660723]), 'split0_test_score': array([-0.12403861]), 'mean_score_time': array([ 0.68098217]), 'mean_fit_time': array([ 2.59518516]), 'std_train_score': array([ 0.00336429])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.135417913846
####################################################################################
################# Runing the itteration 69  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.29335468]), 'mean_train_score': array([-0.2900641]), 'split3_test_score': array([-0.29762847]), 'std_fit_time': array([ 0.00132963]), 'mean_test_score': array([-0.29377922]), 'split1_test_score': array([-0.33786696]), 'std_score_time': array([ 0.00662831]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27651051]), 'std_test_score': array([ 0.02855966]), 'split2_train_score': array([-0.3034364]), 'split3_train_score': array([-0.28695481]), 'split2_test_score': array([-0.26100465]), 'split0_test_score': array([-0.27861679]), 'mean_score_time': array([ 0.0188458]), 'mean_fit_time': array([ 0.02790195]), 'std_train_score': array([ 0.00978537])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293779216519
####################################################################################
################# Runing the itteration 70  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.04983434]), 'mean_train_score': array([-0.05211298]), 'split3_test_score': array([-0.05856748]), 'std_fit_time': array([ 0.05730025]), 'mean_test_score': array([-0.05244299]), 'split1_test_score': array([-0.0540674]), 'std_score_time': array([ 0.00435004]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05431697]), 'std_test_score': array([ 0.00618023]), 'split2_train_score': array([-0.05416237]), 'split3_train_score': array([-0.05013822]), 'split2_test_score': array([-0.05499545]), 'split0_test_score': array([-0.04214165]), 'mean_score_time': array([ 0.34557062]), 'mean_fit_time': array([ 2.00604582]), 'std_train_score': array([ 0.00213011])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0524429933536
####################################################################################
################# Runing the itteration 71  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.28267527]), 'std_fit_time': array([ 0.00240181]), 'mean_test_score': array([ 0.28958812]), 'split1_test_score': array([ 0.25648397]), 'std_score_time': array([ 0.00012661]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.02525642]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.29217258]), 'split0_test_score': array([ 0.32702066]), 'mean_score_time': array([ 0.0019213]), 'mean_fit_time': array([ 0.11914033]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.289588118652
####################################################################################
################# Runing the itteration 72  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.33960045]), 'std_fit_time': array([ 0.00408645]), 'mean_test_score': array([ 0.32356868]), 'split1_test_score': array([ 0.3939643]), 'std_score_time': array([  4.13443183e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05006193]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.30356467]), 'split0_test_score': array([ 0.2571453]), 'mean_score_time': array([ 0.00207675]), 'mean_fit_time': array([ 0.06581247]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.323568679036
####################################################################################
################# Runing the itteration 73  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.11265578]), 'mean_train_score': array([ 0.2424399]), 'split3_test_score': array([ 0.54277421]), 'std_fit_time': array([ 0.31385618]), 'mean_test_score': array([ 0.1256346]), 'split1_test_score': array([ 0.10410187]), 'std_score_time': array([ 0.00538224]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.35433603]), 'std_test_score': array([ 0.25142212]), 'split2_train_score': array([-0.10901405]), 'split3_train_score': array([ 0.61178182]), 'split2_test_score': array([-0.08025657]), 'split0_test_score': array([-0.06408111]), 'mean_score_time': array([ 0.01342833]), 'mean_fit_time': array([ 0.84141362]), 'std_train_score': array([ 0.26893214])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.125634600519
####################################################################################
################# Runing the itteration 74  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93328611]), 'mean_train_score': array([ 0.93018787]), 'split3_test_score': array([ 0.57491999]), 'std_fit_time': array([ 0.00285714]), 'mean_test_score': array([ 0.59155609]), 'split1_test_score': array([ 0.6575152]), 'std_score_time': array([ 0.00179544]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93002048]), 'std_test_score': array([ 0.04683136]), 'split2_train_score': array([ 0.93206482]), 'split3_train_score': array([ 0.92538006]), 'split2_test_score': array([ 0.60516312]), 'split0_test_score': array([ 0.52862607]), 'mean_score_time': array([ 0.01155609]), 'mean_fit_time': array([ 1.07363623]), 'std_train_score': array([ 0.00301103])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.591556092155
####################################################################################
################# Runing the itteration 75  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.60691046]), 'std_fit_time': array([ 0.00592697]), 'mean_test_score': array([ 0.60719902]), 'split1_test_score': array([ 0.61265402]), 'std_score_time': array([ 0.00022545]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.02248286]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.57316163]), 'split0_test_score': array([ 0.63606996]), 'mean_score_time': array([ 0.00677943]), 'mean_fit_time': array([ 0.56790161]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.60719901665
####################################################################################
################# Runing the itteration 76  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.78247695]), 'mean_train_score': array([ 0.77802295]), 'split3_test_score': array([ 0.63132525]), 'std_fit_time': array([ 0.01570987]), 'mean_test_score': array([ 0.60707134]), 'split1_test_score': array([ 0.60728009]), 'std_score_time': array([ 0.00086352]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.77178272]), 'std_test_score': array([ 0.02456107]), 'split2_train_score': array([ 0.77777224]), 'split3_train_score': array([ 0.7800599]), 'split2_test_score': array([ 0.62245775]), 'split0_test_score': array([ 0.56722229]), 'mean_score_time': array([ 0.00630599]), 'mean_fit_time': array([ 1.10990798]), 'std_train_score': array([ 0.00396833])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.607071344156
####################################################################################
################# Runing the itteration 77  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92525869]), 'mean_train_score': array([ 0.93042016]), 'split3_test_score': array([ 0.64189543]), 'std_fit_time': array([ 0.01716056]), 'mean_test_score': array([ 0.62207447]), 'split1_test_score': array([ 0.61091727]), 'std_score_time': array([ 0.0005935]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93481625]), 'std_test_score': array([ 0.02446422]), 'split2_train_score': array([ 0.93594878]), 'split3_train_score': array([ 0.92565692]), 'split2_test_score': array([ 0.58741844]), 'split0_test_score': array([ 0.64806673]), 'mean_score_time': array([ 0.00768077]), 'mean_fit_time': array([ 1.02993268]), 'std_train_score': array([ 0.00498047])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.622074467869
####################################################################################
################# Runing the itteration 78  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.60222081]), 'mean_train_score': array([ 0.60764624]), 'split3_test_score': array([ 0.54499864]), 'std_fit_time': array([ 0.00730951]), 'mean_test_score': array([ 0.57908245]), 'split1_test_score': array([ 0.54120736]), 'std_score_time': array([ 0.00397466]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62103273]), 'std_test_score': array([ 0.03762701]), 'split2_train_score': array([ 0.58853111]), 'split3_train_score': array([ 0.61880032]), 'split2_test_score': array([ 0.63051985]), 'split0_test_score': array([ 0.59960394]), 'mean_score_time': array([ 0.01617396]), 'mean_fit_time': array([ 0.14396822]), 'std_train_score': array([ 0.01321396])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.579082446072
####################################################################################
################# Runing the itteration 79  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.30278453]), 'mean_train_score': array([ 0.29969825]), 'split3_test_score': array([ 0.27669685]), 'std_fit_time': array([ 0.07458511]), 'mean_test_score': array([ 0.29228315]), 'split1_test_score': array([ 0.2645456]), 'std_score_time': array([ 0.00056422]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.31294357]), 'std_test_score': array([ 0.02348521]), 'split2_train_score': array([ 0.29127301]), 'split3_train_score': array([ 0.29179189]), 'split2_test_score': array([ 0.32524634]), 'split0_test_score': array([ 0.30264383]), 'mean_score_time': array([ 0.00364661]), 'mean_fit_time': array([ 0.27835608]), 'std_train_score': array([ 0.00892271])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.292283153675
####################################################################################
################# Runing the itteration 80  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.65129724]), 'mean_train_score': array([ 0.66017778]), 'split3_test_score': array([-9.31914618]), 'std_fit_time': array([ 0.01782558]), 'mean_test_score': array([-1.86663465]), 'split1_test_score': array([ 0.58286824]), 'std_score_time': array([ 0.01125998]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67731049]), 'std_test_score': array([ 4.30276688]), 'split2_train_score': array([ 0.64445747]), 'split3_train_score': array([ 0.66764593]), 'split2_test_score': array([ 0.6256157]), 'split0_test_score': array([ 0.64412363]), 'mean_score_time': array([ 0.03041381]), 'mean_fit_time': array([ 1.12771314]), 'std_train_score': array([ 0.01299322])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.86663465483
####################################################################################
################# Runing the itteration 81  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.63159363]), 'mean_train_score': array([ 0.64156784]), 'split3_test_score': array([ 0.54386906]), 'std_fit_time': array([ 0.01799785]), 'mean_test_score': array([ 0.60066124]), 'split1_test_score': array([ 0.62606341]), 'std_score_time': array([ 0.00233684]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62293189]), 'std_test_score': array([ 0.03304269]), 'split2_train_score': array([ 0.64420076]), 'split3_train_score': array([ 0.66754509]), 'split2_test_score': array([ 0.61776877]), 'split0_test_score': array([ 0.61494371]), 'mean_score_time': array([ 0.00683224]), 'mean_fit_time': array([ 0.10077554]), 'std_train_score': array([ 0.01679683])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.60066123861
####################################################################################
################# Runing the itteration 82  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.66372346]), 'mean_train_score': array([ 0.66000379]), 'split3_test_score': array([-43.1494167]), 'std_fit_time': array([ 0.05101929]), 'mean_test_score': array([-10.33269045]), 'split1_test_score': array([ 0.62460434]), 'std_score_time': array([ 0.00485165]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62660929]), 'std_test_score': array([ 18.94674908]), 'split2_train_score': array([ 0.66818298]), 'split3_train_score': array([ 0.68149944]), 'split2_test_score': array([ 0.59758165]), 'split0_test_score': array([ 0.5964689]), 'mean_score_time': array([ 0.00776815]), 'mean_fit_time': array([ 0.17274082]), 'std_train_score': array([ 0.02035922])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-10.3326904519
####################################################################################
################# Runing the itteration 83  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28605525]), 'mean_train_score': array([-0.28953747]), 'split3_test_score': array([-0.30566415]), 'std_fit_time': array([ 0.00313948]), 'mean_test_score': array([-0.2920353]), 'split1_test_score': array([-0.30047032]), 'std_score_time': array([ 0.00310264]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.2866762]), 'std_test_score': array([ 0.0175298]), 'split2_train_score': array([-0.29937275]), 'split3_train_score': array([-0.28604569]), 'split2_test_score': array([-0.26191314]), 'split0_test_score': array([-0.30009361]), 'mean_score_time': array([ 0.01852494]), 'mean_fit_time': array([ 0.0311386]), 'std_train_score': array([ 0.00568414])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292035303901
####################################################################################
################# Runing the itteration 84  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.63263622]), 'mean_train_score': array([ 0.66082999]), 'split3_test_score': array([ 0.57614222]), 'std_fit_time': array([ 0.08763048]), 'mean_test_score': array([ 0.60597882]), 'split1_test_score': array([ 0.55887854]), 'std_score_time': array([ 0.00381057]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6822124]), 'std_test_score': array([ 0.05179188]), 'split2_train_score': array([ 0.66037985]), 'split3_train_score': array([ 0.6680915]), 'split2_test_score': array([ 0.59617047]), 'split0_test_score': array([ 0.69272403]), 'mean_score_time': array([ 0.0125469]), 'mean_fit_time': array([ 1.80105633]), 'std_train_score': array([ 0.01806259])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.60597881663
####################################################################################
################# Runing the itteration 85  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-186293.72205608]), 'mean_train_score': array([-225308.65379107]), 'split3_test_score': array([-14529.70957865]), 'std_fit_time': array([ 0.00383607]), 'mean_test_score': array([-9081.96933219]), 'split1_test_score': array([ 0.6158473]), 'std_score_time': array([ 0.00714166]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6012085]), 'std_test_score': array([ 7892.43464709]), 'split2_train_score': array([-138950.1083074]), 'split3_train_score': array([-575991.38600931]), 'split2_test_score': array([-2825.21003041]), 'split0_test_score': array([-18973.57356702]), 'mean_score_time': array([ 0.01673698]), 'mean_fit_time': array([ 0.03316748]), 'std_train_score': array([ 213730.32210057])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-9081.96933219
####################################################################################
################# Runing the itteration 86  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.64989961]), 'mean_train_score': array([ 0.64226361]), 'split3_test_score': array([ 0.58292542]), 'std_fit_time': array([ 0.01395834]), 'mean_test_score': array([ 0.60413284]), 'split1_test_score': array([ 0.59780733]), 'std_score_time': array([ 0.00117829]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64680353]), 'std_test_score': array([ 0.0350385]), 'split2_train_score': array([ 0.61495097]), 'split3_train_score': array([ 0.65740032]), 'split2_test_score': array([ 0.66285477]), 'split0_test_score': array([ 0.57294382]), 'mean_score_time': array([ 0.00487667]), 'mean_fit_time': array([ 0.06128055]), 'std_train_score': array([ 0.01623283])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.604132836089
####################################################################################
################# Runing the itteration 87  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -1.00390602e+19]), 'mean_train_score': array([ -4.26368451e+22]), 'split3_test_score': array([ -9.96152393e+18]), 'std_fit_time': array([ 0.24378263]), 'mean_test_score': array([ -4.56465647e+22]), 'split1_test_score': array([ -1.82564402e+23]), 'std_score_time': array([ 0.00097373]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -1.70522968e+23]), 'std_test_score': array([  7.90495501e+22]), 'split2_train_score': array([ -4.51351493e+18]), 'split3_train_score': array([ -9.86033097e+18]), 'split2_test_score': array([ -4.59357830e+18]), 'split0_test_score': array([ -7.30206245e+18]), 'mean_score_time': array([ 0.00517094]), 'mean_fit_time': array([ 2.44326508]), 'std_train_score': array([  7.38350873e+22])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-4.56465647148e+22
####################################################################################
################# Runing the itteration 88  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.63768929]), 'mean_train_score': array([ 0.63460826]), 'split3_test_score': array([ 0.39508408]), 'std_fit_time': array([ 0.00159684]), 'mean_test_score': array([ 0.42018606]), 'split1_test_score': array([ 0.47748873]), 'std_score_time': array([ 0.03604755]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62935291]), 'std_test_score': array([ 0.03334835]), 'split2_train_score': array([ 0.62606765]), 'split3_train_score': array([ 0.6453232]), 'split2_test_score': array([ 0.40123066]), 'split0_test_score': array([ 0.40694078]), 'mean_score_time': array([ 0.63940632]), 'mean_fit_time': array([ 0.0399614]), 'std_train_score': array([ 0.00749772])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.420186062479
####################################################################################
################# Runing the itteration 89  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_2', label_fn=<function label_gross_2>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.33320598241470417}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58383922996690341}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.86304212,
        -0.06123763, -0.05200382]])}
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.33320598241470417}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58383922996690341}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 128 columns], y=1880      49238525
69       746100054
3245      ...      1353824
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.33320598241470417}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58383922996690341}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 128 columns]
        y = 1880      49238525
69       746100054
3245      ...      1353824
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 128 columns], y=1880      49238525
69       746100054
3245      ...      1353824
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 128 columns]
        y = 1880      49238525
69       746100054
3245      ...      1353824
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 128 columns], y=1880      49238525
69       746100054
3245      ...      1353824
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:26:29 2017
PID: 20266                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 128 columns], 1880      49238525
69       746100054
3245      ...      1353824
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 128 columns], 1880      49238525
69       746100054
3245      ...      1353824
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 128 columns], y=1880      49238525
69       746100054
3245      ...      1353824
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns]
        y_test = 1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns], y_test=1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns]
        y_test = 1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns], 1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns], 1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns], 1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns], 1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns], y=1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns]
        y = 1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.061238 -0.052004  

[1203 rows x 128 columns], y=1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64, y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 1880      49238525
69       746100054
3245      ...      9000000
Name: worldwide_gross, dtype: int64
        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 49238525, 746100054,   9813309, ..., 807458779,     33598,
         9000000]), y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 90  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  45.8s
[CV]  ................................................................
[CV] ................................................. , total=  52.3s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.280881]), 'mean_train_score': array([-0.29033249]), 'split3_test_score': array([-0.24810195]), 'std_fit_time': array([ 2.87296712]), 'mean_test_score': array([-0.29726868]), 'split1_test_score': array([-0.29331056]), 'std_score_time': array([ 0.02181752]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28802555]), 'std_test_score': array([ 0.03126069]), 'split2_train_score': array([-0.28119555]), 'split3_train_score': array([-0.31122786]), 'split2_test_score': array([-0.31814056]), 'split0_test_score': array([-0.32952164]), 'mean_score_time': array([ 0.02355391]), 'mean_fit_time': array([ 50.37706625]), 'std_train_score': array([ 0.0123971])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.297268677286
####################################################################################
################# Runing the itteration 91  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13103935]), 'mean_train_score': array([-0.1317696]), 'split3_test_score': array([-0.12611992]), 'std_fit_time': array([ 0.01439406]), 'mean_test_score': array([-0.13295437]), 'split1_test_score': array([-0.12362922]), 'std_score_time': array([ 0.00898126]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.12842544]), 'std_test_score': array([ 0.01912677]), 'split2_train_score': array([-0.1348153]), 'split3_train_score': array([-0.13279831]), 'split2_test_score': array([-0.11654847]), 'split0_test_score': array([-0.16551987]), 'mean_score_time': array([ 0.73381186]), 'mean_fit_time': array([ 2.80022579]), 'std_train_score': array([ 0.00234794])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.13295437143
####################################################################################
################# Runing the itteration 92  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28682875]), 'mean_train_score': array([-0.29004623]), 'split3_test_score': array([-0.29464016]), 'std_fit_time': array([ 0.00025686]), 'mean_test_score': array([-0.29402716]), 'split1_test_score': array([-0.28828446]), 'std_score_time': array([ 0.0011205]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29001543]), 'std_test_score': array([ 0.00923709]), 'split2_train_score': array([-0.29506171]), 'split3_train_score': array([-0.28827904]), 'split2_test_score': array([-0.28445151]), 'split0_test_score': array([-0.30873252]), 'mean_score_time': array([ 0.01424718]), 'mean_fit_time': array([ 0.02709806]), 'std_train_score': array([ 0.0031077])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.294027159581
####################################################################################
################# Runing the itteration 93  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.5s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05256109]), 'mean_train_score': array([-0.05226085]), 'split3_test_score': array([-0.0545617]), 'std_fit_time': array([ 0.01095913]), 'mean_test_score': array([-0.05290366]), 'split1_test_score': array([-0.06973545]), 'std_score_time': array([ 0.00151412]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.0500561]), 'std_test_score': array([ 0.01069065]), 'split2_train_score': array([-0.05413757]), 'split3_train_score': array([-0.05228865]), 'split2_test_score': array([-0.04337174]), 'split0_test_score': array([-0.04394576]), 'mean_score_time': array([ 0.36762977]), 'mean_fit_time': array([ 2.11920297]), 'std_train_score': array([ 0.0014555])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0529036637764
####################################################################################
################# Runing the itteration 94  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.420176]), 'std_fit_time': array([ 0.00768341]), 'mean_test_score': array([ 0.3908827]), 'split1_test_score': array([ 0.32736996]), 'std_score_time': array([ 0.00034156]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.09664159]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.28173686]), 'split0_test_score': array([ 0.53424798]), 'mean_score_time': array([ 0.0025149]), 'mean_fit_time': array([ 0.19892108]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.390882699883
####################################################################################
################# Runing the itteration 95  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.21439649]), 'std_fit_time': array([ 0.00067776]), 'mean_test_score': array([ 0.28959979]), 'split1_test_score': array([ 0.21749407]), 'std_score_time': array([  8.02784954e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.08158837]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.31364632]), 'split0_test_score': array([ 0.41286228]), 'mean_score_time': array([ 0.00238812]), 'mean_fit_time': array([ 0.07316148]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.289599789327
####################################################################################
################# Runing the itteration 96  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.50357248]), 'mean_train_score': array([ 0.41295809]), 'split3_test_score': array([ 0.47661044]), 'std_fit_time': array([ 0.16191836]), 'mean_test_score': array([ 0.32325265]), 'split1_test_score': array([ 0.04555214]), 'std_score_time': array([ 0.00183868]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.17410809]), 'std_test_score': array([ 0.16643067]), 'split2_train_score': array([ 0.39424779]), 'split3_train_score': array([ 0.57990399]), 'split2_test_score': array([ 0.42028036]), 'split0_test_score': array([ 0.35056767]), 'mean_score_time': array([ 0.00834441]), 'mean_fit_time': array([ 0.68309355]), 'std_train_score': array([ 0.15287356])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.323252653029
####################################################################################
################# Runing the itteration 97  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92801483]), 'mean_train_score': array([ 0.92887565]), 'split3_test_score': array([ 0.55549364]), 'std_fit_time': array([ 0.03407307]), 'mean_test_score': array([ 0.56817105]), 'split1_test_score': array([ 0.5767139]), 'std_score_time': array([ 0.00050423]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92521762]), 'std_test_score': array([ 0.02018346]), 'split2_train_score': array([ 0.93195403]), 'split3_train_score': array([ 0.9303161]), 'split2_test_score': array([ 0.59657503]), 'split0_test_score': array([ 0.54390161]), 'mean_score_time': array([ 0.0117808]), 'mean_fit_time': array([ 0.83275396]), 'std_train_score': array([ 0.00253345])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.568171045521
####################################################################################
################# Runing the itteration 98  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.46564704]), 'std_fit_time': array([ 0.01572237]), 'mean_test_score': array([ 0.54753415]), 'split1_test_score': array([ 0.64153618]), 'std_score_time': array([ 0.00034441]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.07315091]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.48767631]), 'split0_test_score': array([ 0.59527705]), 'mean_score_time': array([ 0.00709158]), 'mean_fit_time': array([ 0.68633085]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.547534146722
####################################################################################
################# Runing the itteration 99  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.76160213]), 'mean_train_score': array([ 0.76383721]), 'split3_test_score': array([ 0.61739092]), 'std_fit_time': array([ 0.00890606]), 'mean_test_score': array([ 0.58721333]), 'split1_test_score': array([ 0.5986027]), 'std_score_time': array([ 0.00308059]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.76769199]), 'std_test_score': array([ 0.02528248]), 'split2_train_score': array([ 0.76675408]), 'split3_train_score': array([ 0.75930063]), 'split2_test_score': array([ 0.58449232]), 'split0_test_score': array([ 0.5483674]), 'mean_score_time': array([ 0.00969553]), 'mean_fit_time': array([ 1.28960669]), 'std_train_score': array([ 0.00349799])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.587213334673
####################################################################################
################# Runing the itteration 100  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92685925]), 'mean_train_score': array([ 0.92040658]), 'split3_test_score': array([ 0.61545318]), 'std_fit_time': array([ 0.02078321]), 'mean_test_score': array([ 0.55268714]), 'split1_test_score': array([ 0.5657517]), 'std_score_time': array([ 0.00023882]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.91953119]), 'std_test_score': array([ 0.04612784]), 'split2_train_score': array([ 0.91953401]), 'split3_train_score': array([ 0.91570189]), 'split2_test_score': array([ 0.5423917]), 'split0_test_score': array([ 0.48715199]), 'mean_score_time': array([ 0.00653589]), 'mean_fit_time': array([ 0.78685451]), 'std_train_score': array([ 0.00404038])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.552687141233
####################################################################################
################# Runing the itteration 101  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.54703211]), 'mean_train_score': array([ 0.55101655]), 'split3_test_score': array([ 0.53826577]), 'std_fit_time': array([ 0.00495527]), 'mean_test_score': array([ 0.5160309]), 'split1_test_score': array([ 0.50572163]), 'std_score_time': array([ 0.03733748]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.55703894]), 'std_test_score': array([ 0.02187744]), 'split2_train_score': array([ 0.55172349]), 'split3_train_score': array([ 0.54827164]), 'split2_test_score': array([ 0.48514113]), 'split0_test_score': array([ 0.53499508]), 'mean_score_time': array([ 0.03858852]), 'mean_fit_time': array([ 0.13174593]), 'std_train_score': array([ 0.00387876])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.516030901594
####################################################################################
################# Runing the itteration 102  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.19672806]), 'mean_train_score': array([ 0.193826]), 'split3_test_score': array([ 0.19103139]), 'std_fit_time': array([ 0.07807724]), 'mean_test_score': array([ 0.18857054]), 'split1_test_score': array([ 0.23339935]), 'std_score_time': array([ 0.00035181]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.19568111]), 'std_test_score': array([ 0.03233098]), 'split2_train_score': array([ 0.19201313]), 'split3_train_score': array([ 0.19088169]), 'split2_test_score': array([ 0.1878095]), 'split0_test_score': array([ 0.14204191]), 'mean_score_time': array([ 0.0044446]), 'mean_fit_time': array([ 0.42057759]), 'std_train_score': array([ 0.00244023])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.188570535955
####################################################################################
################# Runing the itteration 103  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.63154745]), 'mean_train_score': array([ 0.63227334]), 'split3_test_score': array([ 0.60982844]), 'std_fit_time': array([ 0.05252236]), 'mean_test_score': array([ 0.57075101]), 'split1_test_score': array([ 0.53923285]), 'std_score_time': array([ 0.00636317]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63999849]), 'std_test_score': array([ 0.02651879]), 'split2_train_score': array([ 0.63627309]), 'split3_train_score': array([ 0.62127433]), 'split2_test_score': array([ 0.55548282]), 'split0_test_score': array([ 0.57845995]), 'mean_score_time': array([ 0.02048606]), 'mean_fit_time': array([ 1.7351172]), 'std_train_score': array([ 0.00702106])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.570751014279
####################################################################################
################# Runing the itteration 104  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.6219919]), 'mean_train_score': array([ 0.61884413]), 'split3_test_score': array([ 0.61031757]), 'std_fit_time': array([ 0.09405674]), 'mean_test_score': array([ 0.57957112]), 'split1_test_score': array([ 0.56936488]), 'std_score_time': array([ 0.00579224]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62814529]), 'std_test_score': array([ 0.01805051]), 'split2_train_score': array([ 0.61924282]), 'split3_train_score': array([ 0.60599652]), 'split2_test_score': array([ 0.57392821]), 'split0_test_score': array([ 0.56467382]), 'mean_score_time': array([ 0.00784659]), 'mean_fit_time': array([ 0.20327508]), 'std_train_score': array([ 0.00808764])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.579571119836
####################################################################################
################# Runing the itteration 105  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.62646706]), 'mean_train_score': array([ 0.62758016]), 'split3_test_score': array([ 0.5496361]), 'std_fit_time': array([ 0.04831696]), 'mean_test_score': array([ 0.56882918]), 'split1_test_score': array([ 0.56095865]), 'std_score_time': array([ 0.00131854]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62973685]), 'std_test_score': array([ 0.01436178]), 'split2_train_score': array([ 0.6265315]), 'split3_train_score': array([ 0.62758524]), 'split2_test_score': array([ 0.57858581]), 'split0_test_score': array([ 0.58613617]), 'mean_score_time': array([ 0.00620222]), 'mean_fit_time': array([ 0.18777519]), 'std_train_score': array([ 0.00132193])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.568829179675
####################################################################################
################# Runing the itteration 106  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28166397]), 'mean_train_score': array([-0.29001773]), 'split3_test_score': array([-0.23788731]), 'std_fit_time': array([ 0.00389319]), 'mean_test_score': array([-0.29618473]), 'split1_test_score': array([-0.34427792]), 'std_score_time': array([ 0.00633229]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27651139]), 'std_test_score': array([ 0.03922791]), 'split2_train_score': array([-0.29063305]), 'split3_train_score': array([-0.31126249]), 'split2_test_score': array([-0.28729204]), 'split0_test_score': array([-0.31528164]), 'mean_score_time': array([ 0.01796144]), 'mean_fit_time': array([ 0.0377571]), 'std_train_score': array([ 0.01326579])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.296184727742
####################################################################################
################# Runing the itteration 107  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.63377734]), 'mean_train_score': array([ 0.62506959]), 'split3_test_score': array([ 0.56039227]), 'std_fit_time': array([ 0.25728316]), 'mean_test_score': array([ 0.56006444]), 'split1_test_score': array([ 0.60239284]), 'std_score_time': array([ 0.00302412]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6091187]), 'std_test_score': array([ 0.03424963]), 'split2_train_score': array([ 0.62874874]), 'split3_train_score': array([ 0.62863358]), 'split2_test_score': array([ 0.57028448]), 'split0_test_score': array([ 0.50718818]), 'mean_score_time': array([ 0.00878882]), 'mean_fit_time': array([ 2.58274162]), 'std_train_score': array([ 0.00944052])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.560064443157
####################################################################################
################# Runing the itteration 108  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.59025077]), 'mean_train_score': array([ 0.59115976]), 'split3_test_score': array([ 0.52283897]), 'std_fit_time': array([ 0.00074223]), 'mean_test_score': array([ 0.52396418]), 'split1_test_score': array([ 0.53456231]), 'std_score_time': array([ 0.00717813]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58207596]), 'std_test_score': array([ 0.02165058]), 'split2_train_score': array([ 0.58956905]), 'split3_train_score': array([ 0.60274326]), 'split2_test_score': array([ 0.48993151]), 'split0_test_score': array([ 0.54852392]), 'mean_score_time': array([ 0.01643169]), 'mean_fit_time': array([ 0.03287119]), 'std_train_score': array([ 0.00741703])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.523964176659
####################################################################################
################# Runing the itteration 109  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.59083554]), 'mean_train_score': array([ 0.60665896]), 'split3_test_score': array([ 0.55425162]), 'std_fit_time': array([ 0.01209391]), 'mean_test_score': array([ 0.57772513]), 'split1_test_score': array([ 0.57521321]), 'std_score_time': array([ 0.00800062]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.60733426]), 'std_test_score': array([ 0.02602221]), 'split2_train_score': array([ 0.61434928]), 'split3_train_score': array([ 0.61411674]), 'split2_test_score': array([ 0.56060401]), 'split0_test_score': array([ 0.62083166]), 'mean_score_time': array([ 0.00820231]), 'mean_fit_time': array([ 0.07505697]), 'std_train_score': array([ 0.00956028])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.577725126068
####################################################################################
################# Runing the itteration 110  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   5.1s
[CV]  ................................................................
[CV] ................................................. , total=   5.1s
[CV]  ................................................................
[CV] ................................................. , total=   5.4s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -2.00122839e+26]), 'mean_train_score': array([ -9.42671639e+25]), 'split3_test_score': array([ -7.27929498e+25]), 'std_fit_time': array([ 0.33125881]), 'mean_test_score': array([ -9.52255439e+25]), 'split1_test_score': array([ -5.04059386e+25]), 'std_score_time': array([ 0.00539295]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -4.01300629e+25]), 'std_test_score': array([  3.58833626e+25]), 'split2_train_score': array([ -8.76390425e+25]), 'split3_train_score': array([ -4.91767111e+25]), 'split2_test_score': array([ -1.15121833e+26]), 'split0_test_score': array([ -1.42581454e+26]), 'mean_score_time': array([ 0.01231104]), 'mean_fit_time': array([ 5.36274904]), 'std_train_score': array([  6.36657887e+25])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-9.52255439058e+25
####################################################################################
################# Runing the itteration 111  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.60064464]), 'mean_train_score': array([ 0.58482605]), 'split3_test_score': array([ 0.33411044]), 'std_fit_time': array([ 0.00490083]), 'mean_test_score': array([ 0.3232604]), 'split1_test_score': array([ 0.39224163]), 'std_score_time': array([ 0.14723655]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58566592]), 'std_test_score': array([ 0.04544321]), 'split2_train_score': array([ 0.58453175]), 'split3_train_score': array([ 0.56846188]), 'split2_test_score': array([ 0.2932869]), 'split0_test_score': array([ 0.27340264]), 'mean_score_time': array([ 0.85871422]), 'mean_fit_time': array([ 0.04650491]), 'std_train_score': array([ 0.01138865])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.323260402777
####################################################################################
################# Runing the itteration 112  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_2', label_fn=<function label_gross_2>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58383922996690341}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58383922996690341}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=47      848998877
2958     14683763
2864     167...     90717684
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37474064226464632}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58383922996690341}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns]
        y = 47      848998877
2958     14683763
2864     167...     90717684
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=47      848998877
2958     14683763
2864     167...     90717684
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns]
        y = 47      848998877
2958     14683763
2864     167...     90717684
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=47      848998877
2958     14683763
2864     167...     90717684
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:29:24 2017
PID: 21540                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], 47      848998877
2958     14683763
2864     167...     90717684
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], 47      848998877
2958     14683763
2864     167...     90717684
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=47      848998877
2958     14683763
2864     167...     90717684
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y_test = 47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y_test=47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y_test = 47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y=47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y = 47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y=47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64, y_pred=array([               nan,                nan,  ...    nan,                nan,  50249501.66666666]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 47      848998877
2958     14683763
2864     167...     77635035
Name: worldwide_gross, dtype: int64
        y_pred = array([               nan,                nan,  ...    nan,                nan,  50249501.66666666])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([848998877,  14683763,  16723377, ...,  65454793, 386116343,
        77635035]), y_pred=array([               nan,                nan,  ...    nan,                nan,  50249501.66666666]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([               nan,                nan,  ...    nan,                nan,  50249501.66666666])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([               nan,                nan,  ...    nan,                nan,  50249501.66666666]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([               nan,                nan,  ...    nan,                nan,  50249501.66666666])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([               nan,                nan,  ...    nan,                nan,  50249501.66666666]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 113  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.2min
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28632715]), 'mean_train_score': array([-0.28957974]), 'split3_test_score': array([-0.29498996]), 'std_fit_time': array([ 2.68177399]), 'mean_test_score': array([-0.29147453]), 'split1_test_score': array([-0.2597127]), 'std_score_time': array([ 0.00321779]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.30097491]), 'std_test_score': array([ 0.01946274]), 'split2_train_score': array([-0.2818724]), 'split3_train_score': array([-0.28914448]), 'split2_test_score': array([-0.31249308]), 'split0_test_score': array([-0.29870239]), 'mean_score_time': array([ 0.01319569]), 'mean_fit_time': array([ 70.46476769]), 'std_train_score': array([ 0.00707146])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291474530928
####################################################################################
################# Runing the itteration 114  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   4.8s
[CV]  ................................................................
[CV] ................................................. , total=   4.7s
[CV]  ................................................................
[CV] ................................................. , total=   4.7s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.12915176]), 'mean_train_score': array([-0.13198888]), 'split3_test_score': array([-0.13072344]), 'std_fit_time': array([ 0.02743553]), 'mean_test_score': array([-0.13340177]), 'split1_test_score': array([-0.14783785]), 'std_score_time': array([ 0.00763253]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13335765]), 'std_test_score': array([ 0.00926825]), 'split2_train_score': array([-0.13997786]), 'split3_train_score': array([-0.12546824]), 'split2_test_score': array([-0.12209584]), 'split0_test_score': array([-0.13294996]), 'mean_score_time': array([ 1.03896558]), 'mean_fit_time': array([ 3.68531424]), 'std_train_score': array([ 0.00539132])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.133401772983
####################################################################################
################# Runing the itteration 115  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.29205976]), 'mean_train_score': array([-0.28981379]), 'split3_test_score': array([-0.28847975]), 'std_fit_time': array([ 0.00123524]), 'mean_test_score': array([-0.29212118]), 'split1_test_score': array([-0.34583374]), 'std_score_time': array([ 0.00170549]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27350914]), 'std_test_score': array([ 0.03391358]), 'split2_train_score': array([-0.30379324]), 'split3_train_score': array([-0.28989303]), 'split2_test_score': array([-0.25210787]), 'split0_test_score': array([-0.28206337]), 'mean_score_time': array([ 0.01350963]), 'mean_fit_time': array([ 0.03504938]), 'std_train_score': array([ 0.01079719])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292121181746
####################################################################################
################# Runing the itteration 116  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05185244]), 'mean_train_score': array([-0.05256661]), 'split3_test_score': array([-0.05723772]), 'std_fit_time': array([ 0.02947133]), 'mean_test_score': array([-0.05349673]), 'split1_test_score': array([-0.04292567]), 'std_score_time': array([ 0.00425129]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05528081]), 'std_test_score': array([ 0.01199642]), 'split2_train_score': array([-0.0522524]), 'split3_train_score': array([-0.05088077]), 'split2_test_score': array([-0.04230714]), 'split0_test_score': array([-0.07151637]), 'mean_score_time': array([ 0.51542819]), 'mean_fit_time': array([ 2.80358422]), 'std_train_score': array([ 0.00164452])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0534967266177
####################################################################################
################# Runing the itteration 117  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.20025753]), 'std_fit_time': array([ 0.0027588]), 'mean_test_score': array([ 0.3042113]), 'split1_test_score': array([ 0.41206953]), 'std_score_time': array([ 0.00033562]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.0946959]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.3841793]), 'split0_test_score': array([ 0.22033886]), 'mean_score_time': array([ 0.00259876]), 'mean_fit_time': array([ 0.14265925]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.304211303801
####################################################################################
################# Runing the itteration 118  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.22044445]), 'std_fit_time': array([ 0.00177924]), 'mean_test_score': array([ 0.31327202]), 'split1_test_score': array([ 0.33539314]), 'std_score_time': array([ 0.00035278]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.0651573]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.29677984]), 'split0_test_score': array([ 0.40047064]), 'mean_score_time': array([ 0.00261873]), 'mean_fit_time': array([ 0.08269233]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.313272018307
####################################################################################
################# Runing the itteration 119  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.61972454]), 'mean_train_score': array([ 0.48197833]), 'split3_test_score': array([ 0.53683178]), 'std_fit_time': array([ 0.10609502]), 'mean_test_score': array([ 0.39045219]), 'split1_test_score': array([ 0.43120923]), 'std_score_time': array([ 0.00162654]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.41791327]), 'std_test_score': array([ 0.17405664]), 'split2_train_score': array([ 0.24742211]), 'split3_train_score': array([ 0.6428534]), 'split2_test_score': array([ 0.09615436]), 'split0_test_score': array([ 0.49761339]), 'mean_score_time': array([ 0.00561231]), 'mean_fit_time': array([ 0.34168178]), 'std_train_score': array([ 0.16122636])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.390452189891
####################################################################################
################# Runing the itteration 120  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.9288336]), 'mean_train_score': array([ 0.92670284]), 'split3_test_score': array([ 0.57151537]), 'std_fit_time': array([ 0.00899447]), 'mean_test_score': array([ 0.59575287]), 'split1_test_score': array([ 0.60405908]), 'std_score_time': array([ 0.0004551]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92507722]), 'std_test_score': array([ 0.0143519]), 'split2_train_score': array([ 0.92470694]), 'split3_train_score': array([ 0.9281936]), 'split2_test_score': array([ 0.59921545]), 'split0_test_score': array([ 0.60822157]), 'mean_score_time': array([ 0.00642359]), 'mean_fit_time': array([ 0.50879705]), 'std_train_score': array([ 0.00182953])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.595752868831
####################################################################################
################# Runing the itteration 121  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.60376287]), 'std_fit_time': array([ 0.00459472]), 'mean_test_score': array([ 0.59929385]), 'split1_test_score': array([ 0.60017831]), 'std_score_time': array([ 0.00046619]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.00541589]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.59020451]), 'split0_test_score': array([ 0.60302974]), 'mean_score_time': array([ 0.00577372]), 'mean_fit_time': array([ 0.28227884]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.599293854709
####################################################################################
################# Runing the itteration 122  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.77756523]), 'mean_train_score': array([ 0.77608406]), 'split3_test_score': array([ 0.64905995]), 'std_fit_time': array([ 0.01238443]), 'mean_test_score': array([ 0.63536994]), 'split1_test_score': array([ 0.62927575]), 'std_score_time': array([  2.89629512e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.77824742]), 'std_test_score': array([ 0.0110527]), 'split2_train_score': array([ 0.77850549]), 'split3_train_score': array([ 0.77001808]), 'split2_test_score': array([ 0.64241741]), 'split0_test_score': array([ 0.62072665]), 'mean_score_time': array([ 0.00330913]), 'mean_fit_time': array([ 0.56257784]), 'std_train_score': array([ 0.003519])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.635369938184
####################################################################################
################# Runing the itteration 123  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93498686]), 'mean_train_score': array([ 0.93142473]), 'split3_test_score': array([ 0.61196691]), 'std_fit_time': array([ 0.02136219]), 'mean_test_score': array([ 0.58660791]), 'split1_test_score': array([ 0.61292989]), 'std_score_time': array([ 0.00016439]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93314569]), 'std_test_score': array([ 0.0321227]), 'split2_train_score': array([ 0.92677863]), 'split3_train_score': array([ 0.93078773]), 'split2_test_score': array([ 0.53378517]), 'split0_test_score': array([ 0.58774967]), 'mean_score_time': array([ 0.00526065]), 'mean_fit_time': array([ 0.51672596]), 'std_train_score': array([ 0.00306767])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.58660791116
####################################################################################
################# Runing the itteration 124  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.53350808]), 'mean_train_score': array([ 0.53917869]), 'split3_test_score': array([ 0.57322298]), 'std_fit_time': array([ 0.00135999]), 'mean_test_score': array([ 0.52883522]), 'split1_test_score': array([ 0.52156015]), 'std_score_time': array([ 0.00562991]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.54114867]), 'std_test_score': array([ 0.03234166]), 'split2_train_score': array([ 0.54850076]), 'split3_train_score': array([ 0.53355723]), 'split2_test_score': array([ 0.48314904]), 'split0_test_score': array([ 0.53740869]), 'mean_score_time': array([ 0.02466732]), 'mean_fit_time': array([ 0.03970784]), 'std_train_score': array([ 0.00621567])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.528835217346
####################################################################################
################# Runing the itteration 125  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.18330339]), 'mean_train_score': array([ 0.18931815]), 'split3_test_score': array([ 0.1437054]), 'std_fit_time': array([ 0.07587419]), 'mean_test_score': array([ 0.18961661]), 'split1_test_score': array([ 0.20412135]), 'std_score_time': array([ 0.00090241]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.18568472]), 'std_test_score': array([ 0.02665716]), 'split2_train_score': array([ 0.19417136]), 'split3_train_score': array([ 0.19411312]), 'split2_test_score': array([ 0.20925736]), 'split0_test_score': array([ 0.20138232]), 'mean_score_time': array([ 0.00330508]), 'mean_fit_time': array([ 0.1640178]), 'std_train_score': array([ 0.00489706])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.189616608696
####################################################################################
################# Runing the itteration 126  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.64866005]), 'mean_train_score': array([ 0.63788102]), 'split3_test_score': array([ 0.61538287]), 'std_fit_time': array([ 0.00235943]), 'mean_test_score': array([ 0.60480322]), 'split1_test_score': array([ 0.60052392]), 'std_score_time': array([ 0.00939563]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64292233]), 'std_test_score': array([ 0.03562856]), 'split2_train_score': array([ 0.62569144]), 'split3_train_score': array([ 0.63425027]), 'split2_test_score': array([ 0.65128917]), 'split0_test_score': array([ 0.55201693]), 'mean_score_time': array([ 0.01667845]), 'mean_fit_time': array([ 0.50885981]), 'std_train_score': array([ 0.00870877])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.604803220584
####################################################################################
################# Runing the itteration 127  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.62466055]), 'mean_train_score': array([ 0.62636406]), 'split3_test_score': array([ 0.62234924]), 'std_fit_time': array([ 0.03103502]), 'mean_test_score': array([ 0.59961409]), 'split1_test_score': array([ 0.54440238]), 'std_score_time': array([ 0.00294285]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63783708]), 'std_test_score': array([ 0.03199721]), 'split2_train_score': array([ 0.62101483]), 'split3_train_score': array([ 0.62194377]), 'split2_test_score': array([ 0.61469003]), 'split0_test_score': array([ 0.61701471]), 'mean_score_time': array([ 0.0037474]), 'mean_fit_time': array([ 0.07914042]), 'std_train_score': array([ 0.00675806])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.599614094392
####################################################################################
################# Runing the itteration 128  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.64475592]), 'mean_train_score': array([ 0.63577427]), 'split3_test_score': array([ 0.61597554]), 'std_fit_time': array([ 0.03188782]), 'mean_test_score': array([ 0.60900354]), 'split1_test_score': array([ 0.58322604]), 'std_score_time': array([ 0.00668451]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64504856]), 'std_test_score': array([ 0.0340016]), 'split2_train_score': array([ 0.62117412]), 'split3_train_score': array([ 0.63211847]), 'split2_test_score': array([ 0.66161812]), 'split0_test_score': array([ 0.57519448]), 'mean_score_time': array([ 0.00679123]), 'mean_fit_time': array([ 0.08995575]), 'std_train_score': array([ 0.00991478])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.609003543345
####################################################################################
################# Runing the itteration 129  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28641792]), 'mean_train_score': array([-0.28947592]), 'split3_test_score': array([-0.25265806]), 'std_fit_time': array([ 0.0005838]), 'mean_test_score': array([-0.29100461]), 'split1_test_score': array([-0.30314733]), 'std_score_time': array([ 0.0022264]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28471974]), 'std_test_score': array([ 0.0224632]), 'split2_train_score': array([-0.28314589]), 'split3_train_score': array([-0.30362012]), 'split2_test_score': array([-0.30945242]), 'split0_test_score': array([-0.29876062]), 'mean_score_time': array([ 0.01571554]), 'mean_fit_time': array([ 0.01764059]), 'std_train_score': array([ 0.00824773])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291004608472
####################################################################################
################# Runing the itteration 130  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.63460045]), 'mean_train_score': array([ 0.63212339]), 'split3_test_score': array([ 0.63320178]), 'std_fit_time': array([ 0.0471003]), 'mean_test_score': array([ 0.60576272]), 'split1_test_score': array([ 0.61187802]), 'std_score_time': array([ 0.01026699]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62893822]), 'std_test_score': array([ 0.01849044]), 'split2_train_score': array([ 0.64035633]), 'split3_train_score': array([ 0.62459857]), 'split2_test_score': array([ 0.58630795]), 'split0_test_score': array([ 0.59166314]), 'mean_score_time': array([ 0.01387841]), 'mean_fit_time': array([ 0.68922883]), 'std_train_score': array([ 0.00593054])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.605762722753
####################################################################################
################# Runing the itteration 131  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([ 0.6035075]), 'mean_train_score': array([ 0.60792654]), 'split3_test_score': array([ 0.62949932]), 'std_fit_time': array([ 0.00018157]), 'mean_test_score': array([ 0.59702711]), 'split1_test_score': array([ 0.59321645]), 'std_score_time': array([ 0.01202638]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.60374427]), 'std_test_score': array([ 0.02271693]), 'split2_train_score': array([ 0.6225886]), 'split3_train_score': array([ 0.60186578]), 'split2_test_score': array([ 0.5656006]), 'split0_test_score': array([ 0.59979208]), 'mean_score_time': array([ 0.02930635]), 'mean_fit_time': array([ 0.01822621]), 'std_train_score': array([ 0.008496])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.597027112434
####################################################################################
################# Runing the itteration 132  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.6109162]), 'mean_train_score': array([ 0.61647931]), 'split3_test_score': array([ 0.58004496]), 'std_fit_time': array([ 0.00775185]), 'mean_test_score': array([ 0.61198667]), 'split1_test_score': array([ 0.61727209]), 'std_score_time': array([ 0.01068342]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61238625]), 'std_test_score': array([ 0.01876785]), 'split2_train_score': array([ 0.61281569]), 'split3_train_score': array([ 0.62979909]), 'split2_test_score': array([ 0.62366555]), 'split0_test_score': array([ 0.62696409]), 'mean_score_time': array([ 0.0082289]), 'mean_fit_time': array([ 0.04823226]), 'std_train_score': array([ 0.00772237])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.611986670364
####################################################################################
################# Runing the itteration 133  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -1.92616849e+22]), 'mean_train_score': array([ -7.44495004e+21]), 'split3_test_score': array([ -7.98968677e+21]), 'std_fit_time': array([ 0.12401043]), 'mean_test_score': array([ -9.36214758e+21]), 'split1_test_score': array([ 0.51284813]), 'std_score_time': array([ 0.00021253]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.49650702]), 'std_test_score': array([  1.20526228e+22]), 'split2_train_score': array([-169179.4880449]), 'split3_train_score': array([ -1.05181153e+22]), 'split2_test_score': array([-202997.17391077]), 'split0_test_score': array([ -2.94589036e+22]), 'mean_score_time': array([ 0.00158632]), 'mean_fit_time': array([ 0.64924437]), 'std_train_score': array([  8.06123639e+21])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-9.36214758463e+21
####################################################################################
################# Runing the itteration 134  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.68537147]), 'mean_train_score': array([ 0.68558487]), 'split3_test_score': array([ 0.51248297]), 'std_fit_time': array([ 0.00087294]), 'mean_test_score': array([ 0.50201072]), 'split1_test_score': array([ 0.52768691]), 'std_score_time': array([ 0.0263442]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.68534315]), 'std_test_score': array([ 0.02757259]), 'split2_train_score': array([ 0.69927011]), 'split3_train_score': array([ 0.67235475]), 'split2_test_score': array([ 0.45548741]), 'split0_test_score': array([ 0.51238561]), 'mean_score_time': array([ 0.30944985]), 'mean_fit_time': array([ 0.02383059]), 'std_train_score': array([ 0.00951874])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.502010724883
####################################################################################
################# Runing the itteration 135  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_2', label_fn=<function label_gross_2>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39045218989106184}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39045218989106184}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 58 columns], y=2269     33175076
476     239373970
2483     265...    187500000
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39045218989106184}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 58 columns]
        y = 2269     33175076
476     239373970
2483     265...    187500000
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 58 columns], y=2269     33175076
476     239373970
2483     265...    187500000
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 58 columns]
        y = 2269     33175076
476     239373970
2483     265...    187500000
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 58 columns], y=2269     33175076
476     239373970
2483     265...    187500000
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:32:44 2017
PID: 22827                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 58 columns], 2269     33175076
476     239373970
2483     265...    187500000
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 58 columns], 2269     33175076
476     239373970
2483     265...    187500000
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 58 columns], y=2269     33175076
476     239373970
2483     265...    187500000
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns]
        y_test = 2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns], y_test=2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns]
        y_test = 2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns], 2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns], 2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns], 2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns], 2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns], y=2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns]
        y = 2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...5  1.530507 -0.863042  

[1203 rows x 58 columns], y=2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64, y_pred=array([  2.38118325e+07,              nan,   5.0...        nan,   6.11782468e+07,   1.13855348e+08]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 2269     33175076
476     239373970
2483     265...    136998907
Name: worldwide_gross, dtype: int64
        y_pred = array([  2.38118325e+07,              nan,   5.0...        nan,   6.11782468e+07,   1.13855348e+08])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 33175076, 239373970,  26570048, ...,  66015869,    266967,
       136998907]), y_pred=array([  2.38118325e+07,              nan,   5.0...        nan,   6.11782468e+07,   1.13855348e+08]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  2.38118325e+07,              nan,   5.0...        nan,   6.11782468e+07,   1.13855348e+08])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  2.38118325e+07,              nan,   5.0...        nan,   6.11782468e+07,   1.13855348e+08]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  2.38118325e+07,              nan,   5.0...        nan,   6.11782468e+07,   1.13855348e+08])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  2.38118325e+07,              nan,   5.0...        nan,   6.11782468e+07,   1.13855348e+08]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 136  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  16.1s
[CV]  ................................................................
[CV] ................................................. , total=  18.8s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28070474]), 'mean_train_score': array([-0.29003655]), 'split3_test_score': array([-0.26317117]), 'std_fit_time': array([ 2.28449763]), 'mean_test_score': array([-0.29513014]), 'split1_test_score': array([-0.32902147]), 'std_score_time': array([ 0.0088826]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27991566]), 'std_test_score': array([ 0.0301372]), 'split2_train_score': array([-0.2980323]), 'split3_train_score': array([-0.30149351]), 'split2_test_score': array([-0.26713492]), 'split0_test_score': array([-0.32119298]), 'mean_score_time': array([ 0.01458633]), 'mean_fit_time': array([ 19.52652198]), 'std_train_score': array([ 0.009807])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295130135962
####################################################################################
################# Runing the itteration 137  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.13779424]), 'mean_train_score': array([-0.13185673]), 'split3_test_score': array([-0.13649299]), 'std_fit_time': array([ 0.00510721]), 'mean_test_score': array([-0.13304653]), 'split1_test_score': array([-0.13926195]), 'std_score_time': array([ 0.00457688]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13044238]), 'std_test_score': array([ 0.01546713]), 'split2_train_score': array([-0.12870473]), 'split3_train_score': array([-0.13048559]), 'split2_test_score': array([-0.14894892]), 'split0_test_score': array([-0.10748224]), 'mean_score_time': array([ 0.42142099]), 'mean_fit_time': array([ 1.76035434]), 'std_train_score': array([ 0.00350248])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.133046525409
####################################################################################
################# Runing the itteration 138  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28061464]), 'mean_train_score': array([-0.28989211]), 'split3_test_score': array([-0.28946484]), 'std_fit_time': array([ 0.00069993]), 'mean_test_score': array([-0.29230143]), 'split1_test_score': array([-0.25873819]), 'std_score_time': array([ 0.00987827]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.30327262]), 'std_test_score': array([ 0.02211464]), 'split2_train_score': array([-0.28570857]), 'split3_train_score': array([-0.2899726]), 'split2_test_score': array([-0.30157894]), 'split0_test_score': array([-0.31942375]), 'mean_score_time': array([ 0.01946318]), 'mean_fit_time': array([ 0.01617199]), 'std_train_score': array([ 0.00840562])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29230143249
####################################################################################
################# Runing the itteration 139  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.0518569]), 'mean_train_score': array([-0.05235431]), 'split3_test_score': array([-0.05546833]), 'std_fit_time': array([ 0.01252503]), 'mean_test_score': array([-0.05248385]), 'split1_test_score': array([-0.05626404]), 'std_score_time': array([ 0.00244326]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05238724]), 'std_test_score': array([ 0.00609803]), 'split2_train_score': array([-0.0535523]), 'split3_train_score': array([-0.05162078]), 'split2_test_score': array([-0.05626622]), 'split0_test_score': array([-0.04193679]), 'mean_score_time': array([ 0.21103978]), 'mean_fit_time': array([ 1.41145992]), 'std_train_score': array([ 0.00074527])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.05248384728
####################################################################################
################# Runing the itteration 140  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.33606076]), 'std_fit_time': array([ 0.00487827]), 'mean_test_score': array([ 0.24266921]), 'split1_test_score': array([ 0.22096373]), 'std_score_time': array([ 0.00015259]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.09199691]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.31192415]), 'split0_test_score': array([ 0.10172819]), 'mean_score_time': array([ 0.00180167]), 'mean_fit_time': array([ 0.09628016]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.242669208648
####################################################################################
################# Runing the itteration 141  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.39048887]), 'std_fit_time': array([ 0.00127893]), 'mean_test_score': array([ 0.31955619]), 'split1_test_score': array([ 0.39787635]), 'std_score_time': array([  4.86231808e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.09288339]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.32305016]), 'split0_test_score': array([ 0.16680936]), 'mean_score_time': array([ 0.00156909]), 'mean_fit_time': array([ 0.04029971]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.319556187477
####################################################################################
################# Runing the itteration 142  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.10118899]), 'mean_train_score': array([ 0.3575018]), 'split3_test_score': array([ 0.46838939]), 'std_fit_time': array([ 0.18400439]), 'mean_test_score': array([ 0.2550228]), 'split1_test_score': array([ 0.27768373]), 'std_score_time': array([ 0.00284891]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.30307845]), 'std_test_score': array([ 0.18561299]), 'split2_train_score': array([ 0.50058682]), 'split3_train_score': array([ 0.52515296]), 'split2_test_score': array([ 0.31577621]), 'split0_test_score': array([-0.04175814]), 'mean_score_time': array([ 0.00772762]), 'mean_fit_time': array([ 0.59424669]), 'std_train_score': array([ 0.17120046])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.255022799341
####################################################################################
################# Runing the itteration 143  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92132322]), 'mean_train_score': array([ 0.92399363]), 'split3_test_score': array([ 0.62170374]), 'std_fit_time': array([ 0.01355896]), 'mean_test_score': array([ 0.57921146]), 'split1_test_score': array([ 0.53800993]), 'std_score_time': array([ 0.00045422]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92299144]), 'std_test_score': array([ 0.02977064]), 'split2_train_score': array([ 0.91993587]), 'split3_train_score': array([ 0.93172399]), 'split2_test_score': array([ 0.58310324]), 'split0_test_score': array([ 0.57402891]), 'mean_score_time': array([ 0.00854731]), 'mean_fit_time': array([ 0.83429641]), 'std_train_score': array([ 0.00459237])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.579211455939
####################################################################################
################# Runing the itteration 144  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.5650226]), 'std_fit_time': array([ 0.00646267]), 'mean_test_score': array([ 0.56348642]), 'split1_test_score': array([ 0.56326672]), 'std_score_time': array([ 0.00018244]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.02971392]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.52082582]), 'split0_test_score': array([ 0.60483051]), 'mean_score_time': array([ 0.00642532]), 'mean_fit_time': array([ 0.50093412]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.56348641518
####################################################################################
################# Runing the itteration 145  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.7653623]), 'mean_train_score': array([ 0.76791363]), 'split3_test_score': array([ 0.63645208]), 'std_fit_time': array([ 0.05464117]), 'mean_test_score': array([ 0.62030706]), 'split1_test_score': array([ 0.59120143]), 'std_score_time': array([ 0.00197564]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.78298581]), 'std_test_score': array([ 0.01732666]), 'split2_train_score': array([ 0.76347015]), 'split3_train_score': array([ 0.75983625]), 'split2_test_score': array([ 0.62891621]), 'split0_test_score': array([ 0.62465851]), 'mean_score_time': array([ 0.00576514]), 'mean_fit_time': array([ 0.99524617]), 'std_train_score': array([ 0.00892564])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.62030705593
####################################################################################
################# Runing the itteration 146  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.92618652]), 'mean_train_score': array([ 0.92583067]), 'split3_test_score': array([ 0.55836487]), 'std_fit_time': array([ 0.03288681]), 'mean_test_score': array([ 0.57279158]), 'split1_test_score': array([ 0.59977439]), 'std_score_time': array([ 0.00024295]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92112335]), 'std_test_score': array([ 0.01869417]), 'split2_train_score': array([ 0.91931316]), 'split3_train_score': array([ 0.93669966]), 'split2_test_score': array([ 0.58034931]), 'split0_test_score': array([ 0.55267773]), 'mean_score_time': array([ 0.00552428]), 'mean_fit_time': array([ 0.8697558]), 'std_train_score': array([ 0.006762])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.572791576441
####################################################################################
################# Runing the itteration 147  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.59464559]), 'mean_train_score': array([ 0.59894715]), 'split3_test_score': array([ 0.64078466]), 'std_fit_time': array([ 0.00295891]), 'mean_test_score': array([ 0.57082008]), 'split1_test_score': array([ 0.52810511]), 'std_score_time': array([ 0.00549079]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61699588]), 'std_test_score': array([ 0.04884844]), 'split2_train_score': array([ 0.61676414]), 'split3_train_score': array([ 0.56738298]), 'split2_test_score': array([ 0.52216815]), 'split0_test_score': array([ 0.59222239]), 'mean_score_time': array([ 0.02028722]), 'mean_fit_time': array([ 0.10116041]), 'std_train_score': array([ 0.02035929])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.570820079275
####################################################################################
################# Runing the itteration 148  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.25300742]), 'mean_train_score': array([ 0.26414137]), 'split3_test_score': array([ 0.2531588]), 'std_fit_time': array([ 0.05258756]), 'mean_test_score': array([ 0.25419928]), 'split1_test_score': array([ 0.23076204]), 'std_score_time': array([ 0.00118517]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.28806886]), 'std_test_score': array([ 0.01527271]), 'split2_train_score': array([ 0.24872408]), 'split3_train_score': array([ 0.26676512]), 'split2_test_score': array([ 0.27288239]), 'split0_test_score': array([ 0.2599939]), 'mean_score_time': array([ 0.00487971]), 'mean_fit_time': array([ 0.26453429]), 'std_train_score': array([ 0.01533841])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.254199283148
####################################################################################
################# Runing the itteration 149  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.63308485]), 'mean_train_score': array([ 0.63777874]), 'split3_test_score': array([ 0.59742287]), 'std_fit_time': array([ 0.00804651]), 'mean_test_score': array([ 0.58191101]), 'split1_test_score': array([ 0.61152127]), 'std_score_time': array([ 0.00851284]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63280018]), 'std_test_score': array([ 0.04476013]), 'split2_train_score': array([ 0.64713568]), 'split3_train_score': array([ 0.63809424]), 'split2_test_score': array([ 0.50513515]), 'split0_test_score': array([ 0.61356474]), 'mean_score_time': array([ 0.01666075]), 'mean_fit_time': array([ 1.07041585]), 'std_train_score': array([ 0.00579807])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.58191100733
####################################################################################
################# Runing the itteration 150  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.63026953]), 'mean_train_score': array([ 0.62421003]), 'split3_test_score': array([ 0.62971395]), 'std_fit_time': array([ 0.03922495]), 'mean_test_score': array([ 0.58923102]), 'split1_test_score': array([ 0.62568633]), 'std_score_time': array([ 0.00152361]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63792025]), 'std_test_score': array([ 0.05853]), 'split2_train_score': array([ 0.59401905]), 'split3_train_score': array([ 0.63463128]), 'split2_test_score': array([ 0.48841033]), 'split0_test_score': array([ 0.61311349]), 'mean_score_time': array([ 0.00422359]), 'mean_fit_time': array([ 0.11639386]), 'std_train_score': array([ 0.01764076])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.589231023212
####################################################################################
################# Runing the itteration 151  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.67193856]), 'mean_train_score': array([ 0.64511677]), 'split3_test_score': array([ 0.6326658]), 'std_fit_time': array([ 0.02832449]), 'mean_test_score': array([ 0.57490454]), 'split1_test_score': array([ 0.51416951]), 'std_score_time': array([ 0.00428284]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6641677]), 'std_test_score': array([ 0.0518787]), 'split2_train_score': array([ 0.6357536]), 'split3_train_score': array([ 0.60860721]), 'split2_test_score': array([ 0.61961221]), 'split0_test_score': array([ 0.53317065]), 'mean_score_time': array([ 0.007864]), 'mean_fit_time': array([ 0.14141583]), 'std_train_score': array([ 0.02501481])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.574904542338
####################################################################################
################# Runing the itteration 152  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.30191022]), 'mean_train_score': array([-0.28939571]), 'split3_test_score': array([-0.29317751]), 'std_fit_time': array([ 0.00161623]), 'mean_test_score': array([-0.2904965]), 'split1_test_score': array([-0.30272104]), 'std_score_time': array([ 0.00666923]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28483125]), 'std_test_score': array([ 0.02129115]), 'split2_train_score': array([-0.28284984]), 'split3_train_score': array([-0.28799151]), 'split2_test_score': array([-0.31084242]), 'split0_test_score': array([-0.25524501]), 'mean_score_time': array([ 0.01583046]), 'mean_fit_time': array([ 0.02845621]), 'std_train_score': array([ 0.00745432])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290496495291
####################################################################################
################# Runing the itteration 153  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.64106679]), 'mean_train_score': array([ 0.64489877]), 'split3_test_score': array([ 0.58337627]), 'std_fit_time': array([ 0.05391275]), 'mean_test_score': array([ 0.57018738]), 'split1_test_score': array([ 0.64106711]), 'std_score_time': array([ 0.00203791]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.62260462]), 'std_test_score': array([ 0.04907688]), 'split2_train_score': array([ 0.66654602]), 'split3_train_score': array([ 0.64937764]), 'split2_test_score': array([ 0.50691028]), 'split0_test_score': array([ 0.54939586]), 'mean_score_time': array([ 0.00571007]), 'mean_fit_time': array([ 1.7252928]), 'std_train_score': array([ 0.01581437])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.570187380365
####################################################################################
################# Runing the itteration 154  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-570247.76606559]), 'mean_train_score': array([-157663.85846707]), 'split3_test_score': array([ 0.53956057]), 'std_fit_time': array([ 0.00203768]), 'mean_test_score': array([-16573.56235933]), 'split1_test_score': array([-3733.12186329]), 'std_score_time': array([ 0.01046882]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-58746.19985344]), 'std_test_score': array([ 26516.44275592]), 'split2_train_score': array([-1661.93739698]), 'split3_train_score': array([ 0.46944774]), 'split2_test_score': array([-133.59029957]), 'split0_test_score': array([-62428.07683503]), 'mean_score_time': array([ 0.03079528]), 'mean_fit_time': array([ 0.02795875]), 'std_train_score': array([ 239376.70295439])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-16573.5623593
####################################################################################
################# Runing the itteration 155  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.62171426]), 'mean_train_score': array([ 0.62963254]), 'split3_test_score': array([ 0.63269999]), 'std_fit_time': array([ 0.02239969]), 'mean_test_score': array([ 0.59424007]), 'split1_test_score': array([ 0.56857417]), 'std_score_time': array([ 0.00790345]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64009483]), 'std_test_score': array([ 0.04180174]), 'split2_train_score': array([ 0.63540366]), 'split3_train_score': array([ 0.62131743]), 'split2_test_score': array([ 0.53900765]), 'split0_test_score': array([ 0.63667847]), 'mean_score_time': array([ 0.00712317]), 'mean_fit_time': array([ 0.06796587]), 'std_train_score': array([ 0.00828561])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.594240070076
####################################################################################
################# Runing the itteration 156  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -1.19755373e+22]), 'mean_train_score': array([ -8.63174475e+24]), 'split3_test_score': array([ -2.45907063e+25]), 'std_fit_time': array([ 0.41115814]), 'mean_test_score': array([ -9.54414289e+24]), 'split1_test_score': array([ -1.35179641e+25]), 'std_score_time': array([ 0.00110091]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -1.19229377e+25]), 'std_test_score': array([  1.02844445e+25]), 'split2_train_score': array([ -6.15341579e+22]), 'split3_train_score': array([ -2.25305316e+25]), 'split2_test_score': array([ -5.99746148e+22]), 'split0_test_score': array([ -7.92650213e+21]), 'mean_score_time': array([ 0.00364977]), 'mean_fit_time': array([ 1.67571062]), 'std_train_score': array([  9.37759507e+24])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-9.54414289367e+24
####################################################################################
################# Runing the itteration 157  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.63018043]), 'mean_train_score': array([ 0.62876562]), 'split3_test_score': array([ 0.49339673]), 'std_fit_time': array([ 0.00121203]), 'mean_test_score': array([ 0.42603223]), 'split1_test_score': array([ 0.35577719]), 'std_score_time': array([ 0.04671573]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63814103]), 'std_test_score': array([ 0.0526813]), 'split2_train_score': array([ 0.62459859]), 'split3_train_score': array([ 0.62214241]), 'split2_test_score': array([ 0.45596744]), 'split0_test_score': array([ 0.39898756]), 'mean_score_time': array([ 0.57186782]), 'mean_fit_time': array([ 0.03562623]), 'std_train_score': array([ 0.00614677])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.426032232004
####################################################################################
################# Runing the itteration 158  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_2', label_fn=<function label_gross_2>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39045218989106184}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.86304212,
        -0.06123763, -0.05200382]])}
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39045218989106184}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 122 columns], y=3204     10400000
1414     78208812
1770     551...       378650
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39045218989106184}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 122 columns]
        y = 3204     10400000
1414     78208812
1770     551...       378650
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 122 columns], y=3204     10400000
1414     78208812
1770     551...       378650
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 122 columns]
        y = 3204     10400000
1414     78208812
1770     551...       378650
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 122 columns], y=3204     10400000
1414     78208812
1770     551...       378650
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:35:00 2017
PID: 24237                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 122 columns], 3204     10400000
1414     78208812
1770     551...       378650
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 122 columns], 3204     10400000
1414     78208812
1770     551...       378650
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.052004  

[4812 rows x 122 columns], y=3204     10400000
1414     78208812
1770     551...       378650
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns]
        y_test = 3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns], y_test=3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns]
        y_test = 3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns], 3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns], 3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns], 3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns], 3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns], y=3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns]
        y = 3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1          2         3... -0.061238 -0.052004  

[1203 rows x 122 columns], y=3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64, y_pred=array([             nan,   6.75415397e+07,      ...        nan,   1.57852532e+08,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 3204     10400000
1414     78208812
1770     551...     94894448
Name: worldwide_gross, dtype: int64
        y_pred = array([             nan,   6.75415397e+07,      ...        nan,   1.57852532e+08,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([10400000, 78208812, 55193251, ...,  2000093, 55696705, 94894448]), y_pred=array([             nan,   6.75415397e+07,      ...        nan,   1.57852532e+08,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([             nan,   6.75415397e+07,      ...        nan,   1.57852532e+08,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([             nan,   6.75415397e+07,      ...        nan,   1.57852532e+08,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([             nan,   6.75415397e+07,      ...        nan,   1.57852532e+08,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([             nan,   6.75415397e+07,      ...        nan,   1.57852532e+08,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 159  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  41.3s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.28552135]), 'mean_train_score': array([-0.28969887]), 'split3_test_score': array([-0.31050373]), 'std_fit_time': array([ 0.71780093]), 'mean_test_score': array([-0.29259721]), 'split1_test_score': array([-0.27273076]), 'std_score_time': array([ 0.00460468]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29683085]), 'std_test_score': array([ 0.01461151]), 'split2_train_score': array([-0.29112228]), 'split3_train_score': array([-0.28532098]), 'split2_test_score': array([-0.28530842]), 'split0_test_score': array([-0.30184593]), 'mean_score_time': array([ 0.0128448]), 'mean_fit_time': array([ 42.25047642]), 'std_train_score': array([ 0.00473046])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292597211517
####################################################################################
################# Runing the itteration 160  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.1315512]), 'mean_train_score': array([-0.13193044]), 'split3_test_score': array([-0.13692433]), 'std_fit_time': array([ 0.01065589]), 'mean_test_score': array([-0.13240032]), 'split1_test_score': array([-0.12407946]), 'std_score_time': array([ 0.00255782]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.13226956]), 'std_test_score': array([ 0.00496081]), 'split2_train_score': array([-0.13600654]), 'split3_train_score': array([-0.12789445]), 'split2_test_score': array([-0.13517253]), 'split0_test_score': array([-0.13342498]), 'mean_score_time': array([ 0.71191084]), 'mean_fit_time': array([ 2.65076119]), 'std_train_score': array([ 0.00287935])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132400324709
####################################################################################
################# Runing the itteration 161  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.29750727]), 'mean_train_score': array([-0.28963155]), 'split3_test_score': array([-0.27834022]), 'std_fit_time': array([ 0.00073115]), 'mean_test_score': array([-0.29040165]), 'split1_test_score': array([-0.32594252]), 'std_score_time': array([ 0.00152497]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.27804735]), 'std_test_score': array([ 0.02186208]), 'split2_train_score': array([-0.28961353]), 'split3_train_score': array([-0.29335804]), 'split2_test_score': array([-0.28932794]), 'split0_test_score': array([-0.26799591]), 'mean_score_time': array([ 0.01284719]), 'mean_fit_time': array([ 0.02612013]), 'std_train_score': array([ 0.00724755])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290401646417
####################################################################################
################# Runing the itteration 162  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05134543]), 'mean_train_score': array([-0.05235477]), 'split3_test_score': array([-0.07041477]), 'std_fit_time': array([ 0.01815038]), 'mean_test_score': array([-0.05375354]), 'split1_test_score': array([-0.05038378]), 'std_score_time': array([ 0.00243083]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05397617]), 'std_test_score': array([ 0.0114467]), 'split2_train_score': array([-0.0539462]), 'split3_train_score': array([-0.05015128]), 'split2_test_score': array([-0.03853972]), 'split0_test_score': array([-0.05567589]), 'mean_score_time': array([ 0.35729444]), 'mean_fit_time': array([ 2.02213275]), 'std_train_score': array([ 0.001661])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.053753539613
####################################################################################
################# Runing the itteration 163  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.2518655]), 'std_fit_time': array([ 0.00360299]), 'mean_test_score': array([ 0.30814438]), 'split1_test_score': array([ 0.29927031]), 'std_score_time': array([  2.97414038e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.06305872]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.41330561]), 'split0_test_score': array([ 0.26813607]), 'mean_score_time': array([ 0.0018869]), 'mean_fit_time': array([ 0.15342665]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.308144375853
####################################################################################
################# Runing the itteration 164  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.36387626]), 'std_fit_time': array([ 0.00695993]), 'mean_test_score': array([ 0.33329315]), 'split1_test_score': array([ 0.28809682]), 'std_score_time': array([ 0.00015168]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.0286438]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.35052598]), 'split0_test_score': array([ 0.33067353]), 'mean_score_time': array([ 0.00196356]), 'mean_fit_time': array([ 0.06990421]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.333293147157
####################################################################################
################# Runing the itteration 165  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.51727642]), 'mean_train_score': array([ 0.32861809]), 'split3_test_score': array([ 0.24408455]), 'std_fit_time': array([ 0.35449512]), 'mean_test_score': array([ 0.20998437]), 'split1_test_score': array([ 0.54123096]), 'std_score_time': array([ 0.00381473]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58281816]), 'std_test_score': array([ 0.36184259]), 'split2_train_score': array([-0.20834857]), 'split3_train_score': array([ 0.42272635]), 'split2_test_score': array([-0.38867819]), 'split0_test_score': array([ 0.44330014]), 'mean_score_time': array([ 0.00914466]), 'mean_fit_time': array([ 0.8328191]), 'std_train_score': array([ 0.31519803])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.209984365758
####################################################################################
################# Runing the itteration 166  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.92874212]), 'mean_train_score': array([ 0.93106727]), 'split3_test_score': array([ 0.61816708]), 'std_fit_time': array([ 0.01777119]), 'mean_test_score': array([ 0.57947127]), 'split1_test_score': array([ 0.60790305]), 'std_score_time': array([ 0.00394414]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.92889597]), 'std_test_score': array([ 0.05227379]), 'split2_train_score': array([ 0.93665285]), 'split3_train_score': array([ 0.92997815]), 'split2_test_score': array([ 0.6023495]), 'split0_test_score': array([ 0.48946543]), 'mean_score_time': array([ 0.01776618]), 'mean_fit_time': array([ 1.03142512]), 'std_train_score': array([ 0.00325982])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.579471266468
####################################################################################
################# Runing the itteration 167  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.60954583]), 'std_fit_time': array([ 0.00842436]), 'mean_test_score': array([ 0.59484357]), 'split1_test_score': array([ 0.57539319]), 'std_score_time': array([ 0.00075609]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.01233018]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.59831003]), 'split0_test_score': array([ 0.59612523]), 'mean_score_time': array([ 0.00822562]), 'mean_fit_time': array([ 0.71847653]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.594843571527
####################################################################################
################# Runing the itteration 168  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.77467743]), 'mean_train_score': array([ 0.76664728]), 'split3_test_score': array([ 0.59040185]), 'std_fit_time': array([ 0.0459787]), 'mean_test_score': array([ 0.61007236]), 'split1_test_score': array([ 0.62177339]), 'std_score_time': array([ 0.00266126]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.76278552]), 'std_test_score': array([ 0.01536862]), 'split2_train_score': array([ 0.76851616]), 'split3_train_score': array([ 0.76061003]), 'split2_test_score': array([ 0.62800662]), 'split0_test_score': array([ 0.60010757]), 'mean_score_time': array([ 0.0074448]), 'mean_fit_time': array([ 1.43922883]), 'std_train_score': array([ 0.00546209])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.610072359296
####################################################################################
################# Runing the itteration 169  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93127306]), 'mean_train_score': array([ 0.9245359]), 'split3_test_score': array([ 0.54215469]), 'std_fit_time': array([ 0.01315294]), 'mean_test_score': array([ 0.56439864]), 'split1_test_score': array([ 0.65487297]), 'std_score_time': array([ 0.00216413]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.91663235]), 'std_test_score': array([ 0.05266388]), 'split2_train_score': array([ 0.92352107]), 'split3_train_score': array([ 0.92671711]), 'split2_test_score': array([ 0.536835]), 'split0_test_score': array([ 0.52373188]), 'mean_score_time': array([ 0.01019245]), 'mean_fit_time': array([ 0.9952426]), 'std_train_score': array([ 0.00533017])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.564398637125
####################################################################################
################# Runing the itteration 170  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.58361887]), 'mean_train_score': array([ 0.60980722]), 'split3_test_score': array([ 0.5234188]), 'std_fit_time': array([ 0.00649456]), 'mean_test_score': array([ 0.56722414]), 'split1_test_score': array([ 0.54210202]), 'std_score_time': array([ 0.02001432]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61695226]), 'std_test_score': array([ 0.04105725]), 'split2_train_score': array([ 0.60984564]), 'split3_train_score': array([ 0.62881211]), 'split2_test_score': array([ 0.57154438]), 'split0_test_score': array([ 0.63183139]), 'mean_score_time': array([ 0.03401899]), 'mean_fit_time': array([ 0.16982776]), 'std_train_score': array([ 0.01656856])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.56722414497
####################################################################################
################# Runing the itteration 171  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.26888725]), 'mean_train_score': array([ 0.26758604]), 'split3_test_score': array([ 0.28029538]), 'std_fit_time': array([ 0.09820046]), 'mean_test_score': array([ 0.25716132]), 'split1_test_score': array([ 0.26152104]), 'std_score_time': array([ 0.00125097]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.26065158]), 'std_test_score': array([ 0.01614544]), 'split2_train_score': array([ 0.27787503]), 'split3_train_score': array([ 0.26293031]), 'split2_test_score': array([ 0.25084935]), 'split0_test_score': array([ 0.23597952]), 'mean_score_time': array([ 0.00528693]), 'mean_fit_time': array([ 0.62388831]), 'std_train_score': array([ 0.00665806])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.257161322468
####################################################################################
################# Runing the itteration 172  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.65950027]), 'mean_train_score': array([ 0.65390969]), 'split3_test_score': array([ 0.49859979]), 'std_fit_time': array([ 0.01670057]), 'mean_test_score': array([ 0.57190499]), 'split1_test_score': array([ 0.62871987]), 'std_score_time': array([ 0.01557648]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63898781]), 'std_test_score': array([ 0.04683692]), 'split2_train_score': array([ 0.65816082]), 'split3_train_score': array([ 0.65898987]), 'split2_test_score': array([ 0.58446527]), 'split0_test_score': array([ 0.57583505]), 'mean_score_time': array([ 0.02762139]), 'mean_fit_time': array([ 1.79226023]), 'std_train_score': array([ 0.00862841])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.571904994908
####################################################################################
################# Runing the itteration 173  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.6443477]), 'mean_train_score': array([ 0.63460253]), 'split3_test_score': array([ 0.64262969]), 'std_fit_time': array([ 0.03185317]), 'mean_test_score': array([ 0.59394674]), 'split1_test_score': array([ 0.59931226]), 'std_score_time': array([ 0.00315436]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.63425358]), 'std_test_score': array([ 0.03106465]), 'split2_train_score': array([ 0.64455326]), 'split3_train_score': array([ 0.61525557]), 'split2_test_score': array([ 0.56747576]), 'split0_test_score': array([ 0.56636925]), 'mean_score_time': array([ 0.00469828]), 'mean_fit_time': array([ 0.13246894]), 'std_train_score': array([ 0.0119207])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.593946742246
####################################################################################
################# Runing the itteration 174  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.6666306]), 'mean_train_score': array([ 0.65505429]), 'split3_test_score': array([ 0.61409164]), 'std_fit_time': array([ 0.05726447]), 'mean_test_score': array([ 0.57042237]), 'split1_test_score': array([ 0.61054911]), 'std_score_time': array([ 0.00106538]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64144378]), 'std_test_score': array([ 0.04193617]), 'split2_train_score': array([ 0.66633763]), 'split3_train_score': array([ 0.64580515]), 'split2_test_score': array([ 0.52671848]), 'split0_test_score': array([ 0.53033024]), 'mean_score_time': array([ 0.00479108]), 'mean_fit_time': array([ 0.20032358]), 'std_train_score': array([ 0.01153384])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.570422369963
####################################################################################
################# Runing the itteration 175  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.27937318]), 'mean_train_score': array([-0.28973227]), 'split3_test_score': array([-0.25501105]), 'std_fit_time': array([ 0.00285311]), 'mean_test_score': array([-0.29361541]), 'split1_test_score': array([-0.31365422]), 'std_score_time': array([ 0.0048387]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28245455]), 'std_test_score': array([ 0.02846178]), 'split2_train_score': array([-0.29352033]), 'split3_train_score': array([-0.30358104]), 'split2_test_score': array([-0.27864844]), 'split0_test_score': array([-0.32714793]), 'mean_score_time': array([ 0.01650906]), 'mean_fit_time': array([ 0.03780001]), 'std_train_score': array([ 0.00957097])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293615408595
####################################################################################
################# Runing the itteration 176  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.8s
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
[CV]  ................................................................
[CV] ................................................. , total=   3.2s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.64704189]), 'mean_train_score': array([ 0.6546495]), 'split3_test_score': array([ 0.62936085]), 'std_fit_time': array([ 0.17303016]), 'mean_test_score': array([ 0.47051371]), 'split1_test_score': array([ 0.53706355]), 'std_score_time': array([ 0.00648295]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.67398195]), 'std_test_score': array([ 0.21591648]), 'split2_train_score': array([ 0.65683947]), 'split3_train_score': array([ 0.64073468]), 'split2_test_score': array([ 0.10147902]), 'split0_test_score': array([ 0.61415144]), 'mean_score_time': array([ 0.01388264]), 'mean_fit_time': array([ 3.02161509]), 'std_train_score': array([ 0.01255027])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.470513714048
####################################################################################
################# Runing the itteration 177  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-236056.80334705]), 'mean_train_score': array([-74660.57205782]), 'split3_test_score': array([-4417.85663814]), 'std_fit_time': array([ 0.00244558]), 'mean_test_score': array([-10084.63356473]), 'split1_test_score': array([-0.84696818]), 'std_score_time': array([ 0.00208026]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-2.87100422]), 'std_test_score': array([ 13751.83318487]), 'split2_train_score': array([-34903.80140432]), 'split3_train_score': array([-27678.8124757]), 'split2_test_score': array([-2170.41841745]), 'split0_test_score': array([-33749.41223516]), 'mean_score_time': array([ 0.01562715]), 'mean_fit_time': array([ 0.03535879]), 'std_train_score': array([ 94088.25955878])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-10084.6335647
####################################################################################
################# Runing the itteration 178  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.61401401]), 'mean_train_score': array([ 0.62864509]), 'split3_test_score': array([ 0.56906141]), 'std_fit_time': array([ 0.01986912]), 'mean_test_score': array([ 0.58078994]), 'split1_test_score': array([ 0.51252174]), 'std_score_time': array([ 0.01396648]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.64708509]), 'std_test_score': array([ 0.04500875]), 'split2_train_score': array([ 0.62240185]), 'split3_train_score': array([ 0.63107943]), 'split2_test_score': array([ 0.61353208]), 'split0_test_score': array([ 0.62804454]), 'mean_score_time': array([ 0.01164919]), 'mean_fit_time': array([ 0.07583362]), 'std_train_score': array([ 0.0122373])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.580789941837
####################################################################################
################# Runing the itteration 179  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   4.4s
[CV]  ................................................................
[CV] ................................................. , total=   4.9s
[CV]  ................................................................
[CV] ................................................. , total=   5.0s
[CV]  ................................................................
[CV] ................................................. , total=   5.4s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([ -7.13619312e+25]), 'mean_train_score': array([ -3.19750267e+25]), 'split3_test_score': array([ -2.18330095e+25]), 'std_fit_time': array([ 0.35010717]), 'mean_test_score': array([ -3.99330869e+25]), 'split1_test_score': array([ -1.50605120e+25]), 'std_score_time': array([ 0.00209482]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -1.16004016e+25]), 'std_test_score': array([  2.65312462e+25]), 'split2_train_score': array([ -2.96600346e+25]), 'split3_train_score': array([ -1.52777395e+25]), 'split2_test_score': array([ -3.96703222e+25]), 'split0_test_score': array([ -8.31685037e+25]), 'mean_score_time': array([ 0.00521564]), 'mean_fit_time': array([ 4.93075997]), 'std_train_score': array([  2.37203087e+25])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3.99330868533e+25
####################################################################################
################# Runing the itteration 180  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.59897077]), 'mean_train_score': array([ 0.59092014]), 'split3_test_score': array([ 0.41655468]), 'std_fit_time': array([ 0.00125813]), 'mean_test_score': array([ 0.35633488]), 'split1_test_score': array([ 0.31443017]), 'std_score_time': array([ 0.08599746]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.58622907]), 'std_test_score': array([ 0.04171795]), 'split2_train_score': array([ 0.60194308]), 'split3_train_score': array([ 0.57653766]), 'split2_test_score': array([ 0.32061233]), 'split0_test_score': array([ 0.37374234]), 'mean_score_time': array([ 0.85289943]), 'mean_fit_time': array([ 0.04367197]), 'std_train_score': array([ 0.01018798])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.35633487785
####################################################################################
################# Runing the itteration 181  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_2', label_fn=<function label_gross_2>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39045218989106184}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39045218989106184}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 204 columns], y=4574            0
909     136998907
4801        ...       378650
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39045218989106184}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61642691504041947}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.58290401390347202}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60719901664987797}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.65568334360660363}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29228315367458374}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51317104012080317}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 204 columns]
        y = 4574            0
909     136998907
4801        ...       378650
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 204 columns], y=4574            0
909     136998907
4801        ...       378650
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 204 columns]
        y = 4574            0
909     136998907
4801        ...       378650
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 204 columns], y=4574            0
909     136998907
4801        ...       378650
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:38:00 2017
PID: 25512                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 204 columns], 4574            0
909     136998907
4801        ...       378650
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 204 columns], 4574            0
909     136998907
4801        ...       378650
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 204 columns], y=4574            0
909     136998907
4801        ...       378650
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns]
        y_test = 4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns], y_test=4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns]
        y_test = 4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns], 4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns], 4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns], 4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns], 4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns], y=4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns]
        y = 4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 204 columns], y=4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64, y_pred=array([             nan,   1.35645641e+08,      ...        nan,   8.79229577e+07,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 4574             0
909      136998907
4801      ...     37513213
Name: worldwide_gross, dtype: int64
        y_pred = array([             nan,   1.35645641e+08,      ...        nan,   8.79229577e+07,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([        0, 136998907,         0, ...,  16585503,  39340177,
        37513213]), y_pred=array([             nan,   1.35645641e+08,      ...        nan,   8.79229577e+07,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([             nan,   1.35645641e+08,      ...        nan,   8.79229577e+07,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([             nan,   1.35645641e+08,      ...        nan,   8.79229577e+07,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([             nan,   1.35645641e+08,      ...        nan,   8.79229577e+07,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([             nan,   1.35645641e+08,      ...        nan,   8.79229577e+07,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 182  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.2min
[CV]  ................................................................
[CV] ................................................. , total= 1.2min
[CV]  ................................................................
[CV] ................................................. , total= 1.3min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.27849027]), 'mean_train_score': array([-0.28965893]), 'split3_test_score': array([-0.30320654]), 'std_fit_time': array([ 1.40020816]), 'mean_test_score': array([-0.29251489]), 'split1_test_score': array([-0.27307449]), 'std_score_time': array([ 0.26160938]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29554519]), 'std_test_score': array([ 0.02558607]), 'split2_train_score': array([-0.29922558]), 'split3_train_score': array([-0.28537468]), 'split2_test_score': array([-0.26457768]), 'split0_test_score': array([-0.32920084]), 'mean_score_time': array([ 0.19930166]), 'mean_fit_time': array([ 74.91743362]), 'std_train_score': array([ 0.00820461])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292514888288
####################################################################################
################# Runing the itteration 183  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   4.9s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.12991855]), 'mean_train_score': array([-0.13180175]), 'split3_test_score': array([-0.14660698]), 'std_fit_time': array([ 0.02857589]), 'mean_test_score': array([-0.13321541]), 'split1_test_score': array([-0.14377448]), 'std_score_time': array([ 0.0077787]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.12562871]), 'std_test_score': array([ 0.02106802]), 'split2_train_score': array([-0.14175183]), 'split3_train_score': array([-0.12990792]), 'split2_test_score': array([-0.09676764]), 'split0_test_score': array([-0.14571254]), 'mean_score_time': array([ 1.08305132]), 'mean_fit_time': array([ 3.80484414]), 'std_train_score': array([ 0.00600507])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.133215408277
####################################################################################
################# Runing the itteration 184  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.27508311]), 'mean_train_score': array([-0.29049682]), 'split3_test_score': array([-0.30664019]), 'std_fit_time': array([ 0.00205301]), 'mean_test_score': array([-0.2978646]), 'split1_test_score': array([-0.30012108]), 'std_score_time': array([ 0.00093395]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28604271]), 'std_test_score': array([ 0.0432287]), 'split2_train_score': array([-0.31659196]), 'split3_train_score': array([-0.28426948]), 'split2_test_score': array([-0.23180137]), 'split0_test_score': array([-0.35289576]), 'mean_score_time': array([ 0.013026]), 'mean_fit_time': array([ 0.0374046]), 'std_train_score': array([ 0.01562976])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.297864599839
####################################################################################
################# Runing the itteration 185  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05212487]), 'mean_train_score': array([-0.05236495]), 'split3_test_score': array([-0.05088118]), 'std_fit_time': array([ 0.04323631]), 'mean_test_score': array([-0.05265028]), 'split1_test_score': array([-0.04589209]), 'std_score_time': array([ 0.00894946]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05264905]), 'std_test_score': array([ 0.00602047]), 'split2_train_score': array([-0.05164937]), 'split3_train_score': array([-0.05303651]), 'split2_test_score': array([-0.06238313]), 'split0_test_score': array([-0.05144472]), 'mean_score_time': array([ 0.57003146]), 'mean_fit_time': array([ 2.87200868]), 'std_train_score': array([ 0.00052474])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0526502799506
####################################################################################
################# Runing the itteration 186  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.23014834]), 'std_fit_time': array([ 0.00339003]), 'mean_test_score': array([ 0.30407796]), 'split1_test_score': array([ 0.322821]), 'std_score_time': array([ 0.00026508]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.04718016]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.3037052]), 'split0_test_score': array([ 0.35963731]), 'mean_score_time': array([ 0.00299001]), 'mean_fit_time': array([ 0.18341064]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.304077961031
####################################################################################
################# Runing the itteration 187  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.25425733]), 'std_fit_time': array([ 0.00158705]), 'mean_test_score': array([ 0.3386822]), 'split1_test_score': array([ 0.46517675]), 'std_score_time': array([ 0.00039107]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.07764749]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.32482973]), 'split0_test_score': array([ 0.31046501]), 'mean_score_time': array([ 0.0031969]), 'mean_fit_time': array([ 0.09296286]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.338682204061
####################################################################################
################# Runing the itteration 188  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'split0_train_score': array([ 0.53080606]), 'mean_train_score': array([ 0.52498462]), 'split3_test_score': array([ 0.35050272]), 'std_fit_time': array([ 0.15272535]), 'mean_test_score': array([ 0.43190948]), 'split1_test_score': array([ 0.41080152]), 'std_score_time': array([ 0.00193359]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.4427971]), 'std_test_score': array([ 0.10128291]), 'split2_train_score': array([ 0.66605373]), 'split3_train_score': array([ 0.46028159]), 'split2_test_score': array([ 0.60297016]), 'split0_test_score': array([ 0.36336352]), 'mean_score_time': array([ 0.00658506]), 'mean_fit_time': array([ 0.57193053]), 'std_train_score': array([ 0.08785735])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.431909480874
####################################################################################
################# Runing the itteration 189  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'split0_train_score': array([ 0.93956932]), 'mean_train_score': array([ 0.93719799]), 'split3_test_score': array([ 0.61925375]), 'std_fit_time': array([ 0.01471338]), 'mean_test_score': array([ 0.63405988]), 'split1_test_score': array([ 0.60316076]), 'std_score_time': array([  5.93883644e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.9402932]), 'std_test_score': array([ 0.02512537]), 'split2_train_score': array([ 0.94048255]), 'split3_train_score': array([ 0.92844689]), 'split2_test_score': array([ 0.66929548]), 'split0_test_score': array([ 0.64452952]), 'mean_score_time': array([ 0.0064801]), 'mean_fit_time': array([ 0.8317948]), 'std_train_score': array([ 0.00506393])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.63405987818
####################################################################################
################# Runing the itteration 190  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.54443162]), 'std_fit_time': array([ 0.0072702]), 'mean_test_score': array([ 0.62465364]), 'split1_test_score': array([ 0.5490936]), 'std_score_time': array([ 0.00036847]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.07791894]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.70435105]), 'split0_test_score': array([ 0.7007383]), 'mean_score_time': array([ 0.00573868]), 'mean_fit_time': array([ 0.37955916]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.624653642496
####################################################################################
################# Runing the itteration 191  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'split0_train_score': array([ 0.82190883]), 'mean_train_score': array([ 0.8164888]), 'split3_test_score': array([ 0.66999405]), 'std_fit_time': array([ 0.02513681]), 'mean_test_score': array([ 0.68019637]), 'split1_test_score': array([ 0.72664843]), 'std_score_time': array([ 0.0001792]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.80193049]), 'std_test_score': array([ 0.02713383]), 'split2_train_score': array([ 0.81823644]), 'split3_train_score': array([ 0.82387944]), 'split2_test_score': array([ 0.6656823]), 'split0_test_score': array([ 0.65846069]), 'mean_score_time': array([ 0.00350279]), 'mean_fit_time': array([ 0.76464105]), 'std_train_score': array([ 0.00864576])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.680196368824
####################################################################################
################# Runing the itteration 192  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'split0_train_score': array([ 0.93673119]), 'mean_train_score': array([ 0.93398831]), 'split3_test_score': array([ 0.6580686]), 'std_fit_time': array([ 0.01991663]), 'mean_test_score': array([ 0.65664875]), 'split1_test_score': array([ 0.69773682]), 'std_score_time': array([ 0.00052858]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.93194531]), 'std_test_score': array([ 0.04070709]), 'split2_train_score': array([ 0.93126596]), 'split3_train_score': array([ 0.93601076]), 'split2_test_score': array([ 0.68030895]), 'split0_test_score': array([ 0.59048063]), 'mean_score_time': array([ 0.00550461]), 'mean_fit_time': array([ 0.80133241]), 'std_train_score': array([ 0.00240825])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.656648751185
####################################################################################
################# Runing the itteration 193  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'split0_train_score': array([ 0.6005711]), 'mean_train_score': array([ 0.60674502]), 'split3_test_score': array([ 0.62761707]), 'std_fit_time': array([ 0.00075031]), 'mean_test_score': array([ 0.59633297]), 'split1_test_score': array([ 0.58435928]), 'std_score_time': array([ 0.01258612]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.61022308]), 'std_test_score': array([ 0.01976666]), 'split2_train_score': array([ 0.61704855]), 'split3_train_score': array([ 0.59913736]), 'split2_test_score': array([ 0.57540004]), 'split0_test_score': array([ 0.5979555]), 'mean_score_time': array([ 0.02676547]), 'mean_fit_time': array([ 0.06228888]), 'std_train_score': array([ 0.0073187])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.596332971868
####################################################################################
################# Runing the itteration 194  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'split0_train_score': array([ 0.27881468]), 'mean_train_score': array([ 0.29747842]), 'split3_test_score': array([ 0.29534324]), 'std_fit_time': array([ 0.09231686]), 'mean_test_score': array([ 0.29233705]), 'split1_test_score': array([ 0.28348557]), 'std_score_time': array([ 0.00084186]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.28457165]), 'std_test_score': array([ 0.01345957]), 'split2_train_score': array([ 0.31542404]), 'split3_train_score': array([ 0.31110329]), 'split2_test_score': array([ 0.27765045]), 'split0_test_score': array([ 0.31286893]), 'mean_score_time': array([ 0.00362498]), 'mean_fit_time': array([ 0.24045706]), 'std_train_score': array([ 0.01598908])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.292337047289
####################################################################################
################# Runing the itteration 195  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'split0_train_score': array([ 0.73181464]), 'mean_train_score': array([ 0.70432573]), 'split3_test_score': array([ 0.70279968]), 'std_fit_time': array([ 0.00686052]), 'mean_test_score': array([-1.06125528]), 'split1_test_score': array([ 0.3523275]), 'std_score_time': array([ 0.01001459]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.70622044]), 'std_test_score': array([ 2.87121831]), 'split2_train_score': array([ 0.68078677]), 'split3_train_score': array([ 0.69848106]), 'split2_test_score': array([ 0.72755679]), 'split0_test_score': array([-6.02770507]), 'mean_score_time': array([ 0.02962691]), 'mean_fit_time': array([ 0.55829269]), 'std_train_score': array([ 0.01835397])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.06125527675
####################################################################################
################# Runing the itteration 196  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'split0_train_score': array([ 0.69453329]), 'mean_train_score': array([ 0.68777397]), 'split3_test_score': array([ 0.64709938]), 'std_fit_time': array([ 0.01470052]), 'mean_test_score': array([ 0.33315253]), 'split1_test_score': array([-0.65506115]), 'std_score_time': array([ 0.0011015]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.69142349]), 'std_test_score': array([ 0.57064878]), 'split2_train_score': array([ 0.67072597]), 'split3_train_score': array([ 0.69441311]), 'split2_test_score': array([ 0.67781431]), 'split0_test_score': array([ 0.66275758]), 'mean_score_time': array([ 0.0039646]), 'mean_fit_time': array([ 0.10021704]), 'std_train_score': array([ 0.00992119])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.333152531505
####################################################################################
################# Runing the itteration 197  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'split0_train_score': array([ 0.7163394]), 'mean_train_score': array([ 0.70327777]), 'split3_test_score': array([-2.31110754]), 'std_fit_time': array([ 0.00932872]), 'mean_test_score': array([-32.82746782]), 'split1_test_score': array([ 0.69601312]), 'std_score_time': array([ 0.0032238]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.68736387]), 'std_test_score': array([ 56.31775904]), 'split2_train_score': array([ 0.70473]), 'split3_train_score': array([ 0.70467782]), 'split2_test_score': array([ 0.65504389]), 'split0_test_score': array([-130.34982076]), 'mean_score_time': array([ 0.00442141]), 'mean_fit_time': array([ 0.06533289]), 'std_train_score': array([ 0.0103432])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-32.8274678231
####################################################################################
################# Runing the itteration 198  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'split0_train_score': array([-0.28336605]), 'mean_train_score': array([-0.28954809]), 'split3_test_score': array([-0.27055184]), 'std_fit_time': array([ 0.00034516]), 'mean_test_score': array([-0.29179444]), 'split1_test_score': array([-0.29351552]), 'std_score_time': array([ 0.01560141]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.28783171]), 'std_test_score': array([ 0.01470189]), 'split2_train_score': array([-0.28876853]), 'split3_train_score': array([-0.29822606]), 'split2_test_score': array([-0.29107122]), 'split0_test_score': array([-0.31203917]), 'mean_score_time': array([ 0.02525884]), 'mean_fit_time': array([ 0.01891112]), 'std_train_score': array([ 0.00541014])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291794437984
####################################################################################
################# Runing the itteration 199  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [Ridge] estimatorrun are
{'split0_train_score': array([ 0.71328052]), 'mean_train_score': array([ 0.70333794]), 'split3_test_score': array([ 0.64221645]), 'std_fit_time': array([ 0.07152201]), 'mean_test_score': array([ 0.66798423]), 'split1_test_score': array([ 0.65446538]), 'std_score_time': array([ 0.00152094]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.70412898]), 'std_test_score': array([ 0.02963513]), 'split2_train_score': array([ 0.68353157]), 'split3_train_score': array([ 0.71241069]), 'split2_test_score': array([ 0.71840502]), 'split0_test_score': array([ 0.65685007]), 'mean_score_time': array([ 0.00610256]), 'mean_fit_time': array([ 0.86600071]), 'std_train_score': array([ 0.01198006])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.667984229522
####################################################################################
################# Runing the itteration 200  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'split0_train_score': array([-60436.14728324]), 'mean_train_score': array([-406583.3855382]), 'split3_test_score': array([-2993.1100899]), 'std_fit_time': array([ 0.00107956]), 'mean_test_score': array([-4364.42136944]), 'split1_test_score': array([-3728.92720201]), 'std_score_time': array([ 0.00331926]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-124542.1695844]), 'std_test_score': array([ 2584.36794362]), 'split2_train_score': array([-1299962.21908421]), 'split3_train_score': array([-141393.00620094]), 'split2_test_score': array([-8715.79729762]), 'split0_test_score': array([-2019.85088823]), 'mean_score_time': array([ 0.01922488]), 'mean_fit_time': array([ 0.01943809]), 'std_train_score': array([ 516676.11604595])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-4364.42136944
####################################################################################
################# Runing the itteration 201  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'split0_train_score': array([ 0.68809034]), 'mean_train_score': array([ 0.68601652]), 'split3_test_score': array([ 0.61923594]), 'std_fit_time': array([ 0.03341131]), 'mean_test_score': array([ 0.66088967]), 'split1_test_score': array([ 0.72980059]), 'std_score_time': array([ 0.01318621]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.6563111]), 'std_test_score': array([ 0.04499583]), 'split2_train_score': array([ 0.69951229]), 'split3_train_score': array([ 0.70015236]), 'split2_test_score': array([ 0.62232842]), 'split0_test_score': array([ 0.67219373]), 'mean_score_time': array([ 0.01677305]), 'mean_fit_time': array([ 0.05628657]), 'std_train_score': array([ 0.0178092])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.660889669332
####################################################################################
################# Runing the itteration 202  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'split0_train_score': array([-637.60479017]), 'mean_train_score': array([ -2.05848840e+20]), 'split3_test_score': array([ -6.11810258e+19]), 'std_fit_time': array([ 0.31221275]), 'mean_test_score': array([ -1.40421283e+20]), 'split1_test_score': array([ -5.00504107e+20]), 'std_score_time': array([ 0.00112309]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ -7.87857382e+20]), 'std_test_score': array([  2.09388952e+20]), 'split2_train_score': array([-3295.85459077]), 'split3_train_score': array([ -3.55379786e+19]), 'split2_test_score': array([-40021.7198507]), 'split0_test_score': array([ 0.3604743]), 'mean_score_time': array([ 0.00240332]), 'mean_fit_time': array([ 0.738913]), 'std_train_score': array([  3.36335853e+20])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.40421283247e+20
####################################################################################
################# Runing the itteration 203  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'split0_train_score': array([ 0.70370913]), 'mean_train_score': array([ 0.69382945]), 'split3_test_score': array([ 0.49996315]), 'std_fit_time': array([ 0.00227329]), 'mean_test_score': array([ 0.52498213]), 'split1_test_score': array([ 0.52397023]), 'std_score_time': array([ 0.03210988]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 0.69557446]), 'std_test_score': array([ 0.0260844]), 'split2_train_score': array([ 0.68802262]), 'split3_train_score': array([ 0.68801161]), 'split2_test_score': array([ 0.567627]), 'split0_test_score': array([ 0.50836813]), 'mean_score_time': array([ 0.34384674]), 'mean_fit_time': array([ 0.02387029]), 'std_train_score': array([ 0.00648497])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.524982126243
####################################################################################
################# Runing the itteration 204  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_2', label_fn=<function label_gross_2>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43190948087352266}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63405987817979237}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.59633297186808298}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.62465364249626776}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.68019636882417889}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29233704728901222}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52498212624258511}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       2
1       2
2       2
3       2
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43190948087352266}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63405987817979237}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.59633297186808298}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.62465364249626776}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.68019636882417889}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29233704728901222}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52498212624258511}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1          2         3...5  1.530507 -0.863042  

[4812 rows x 64 columns], y=3254       9615464
1706      58085235
1756      ...     20465206
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.43190948087352266}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.63405987817979237}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.39088269988344665}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.59633297186808298}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.35148917537585028}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.62465364249626776}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.68019636882417889}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.29233704728901222}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.52498212624258511}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60480322058371638}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1          2         3...5  1.530507 -0.863042  

[4812 rows x 64 columns]
        y = 3254       9615464
1706      58085235
1756      ...     20465206
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1          2         3...5  1.530507 -0.863042  

[4812 rows x 64 columns], y=3254       9615464
1706      58085235
1756      ...     20465206
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1          2         3...5  1.530507 -0.863042  

[4812 rows x 64 columns]
        y = 3254       9615464
1706      58085235
1756      ...     20465206
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1          2         3...5  1.530507 -0.863042  

[4812 rows x 64 columns], y=3254       9615464
1706      58085235
1756      ...     20465206
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 13:42:05 2017
PID: 26802                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1          2         3...5  1.530507 -0.863042  

[4812 rows x 64 columns], 3254       9615464
1706      58085235
1756      ...     20465206
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1          2         3...5  1.530507 -0.863042  

[4812 rows x 64 columns], 3254       9615464
1706      58085235
1756      ...     20465206
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1          2         3...5  1.530507 -0.863042  

[4812 rows x 64 columns], y=3254       9615464
1706      58085235
1756      ...     20465206
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns]
        y_test = 3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], y_test=3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns]
        y_test = 3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], 3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], y=3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns]
        y = 3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1          2         3...5 -0.650627  1.148997  

[1203 rows x 64 columns], y=3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64, y_pred=array([  7101761.4,         nan,  60282171.2, ...,         nan,
               nan,         nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 3254       9615464
1706      58085235
1756      ...      3727746
Name: worldwide_gross, dtype: int64
        y_pred = array([  7101761.4,         nan,  60282171.2, ...,         nan,
               nan,         nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 9615464, 58085235, 55669466, ..., 34166572,  5204007,  3727746]), y_pred=array([  7101761.4,         nan,  60282171.2, ...,         nan,
               nan,         nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  7101761.4,         nan,  60282171.2, ...,         nan,
               nan,         nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  7101761.4,         nan,  60282171.2, ...,         nan,
               nan,         nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  7101761.4,         nan,  60282171.2, ...,         nan,
               nan,         nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  7101761.4,         nan,  60282171.2, ...,         nan,
               nan,         nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 205  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  31.9s
[CV]  ................................................................
[CV] ................................................. , total=  38.8s
[CV]  ................................................................
[CV] ................................................. , total=  37.2s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'split0_train_score': array([-0.30013545]), 'mean_train_score': array([-0.28956835]), 'split3_test_score': array([-0.31850197]), 'std_fit_time': array([ 2.89315617]), 'mean_test_score': array([-0.29119859]), 'split1_test_score': array([-0.27774532]), 'std_score_time': array([ 0.26256183]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29403588]), 'std_test_score': array([ 0.02444009]), 'split2_train_score': array([-0.28256393]), 'split3_train_score': array([-0.28153812]), 'split2_test_score': array([-0.31041633]), 'split0_test_score': array([-0.25813071]), 'mean_score_time': array([ 0.1698283]), 'mean_fit_time': array([ 36.55914402]), 'std_train_score': array([ 0.00782893])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291198586141
####################################################################################
################# Runing the itteration 206  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [SVR] estimatorrun are
{'split0_train_score': array([-0.1303316]), 'mean_train_score': array([-0.13188337]), 'split3_test_score': array([-0.13862208]), 'std_fit_time': array([ 0.00998922]), 'mean_test_score': array([-0.13449216]), 'split1_test_score': array([-0.11340478]), 'std_score_time': array([ 0.00502291]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.14188166]), 'std_test_score': array([ 0.0135623]), 'split2_train_score': array([-0.12627781]), 'split3_train_score': array([-0.12904239]), 'split2_test_score': array([-0.15104037]), 'split0_test_score': array([-0.13490142]), 'mean_score_time': array([ 0.44934618]), 'mean_fit_time': array([ 1.86714077]), 'std_train_score': array([ 0.0059554])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.134492160391
####################################################################################
################# Runing the itteration 207  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'split0_train_score': array([-0.28249482]), 'mean_train_score': array([-0.2896158]), 'split3_test_score': array([-0.30827571]), 'std_fit_time': array([ 0.00177927]), 'mean_test_score': array([-0.2903653]), 'split1_test_score': array([-0.26905366]), 'std_score_time': array([ 0.01835147]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.29658463]), 'std_test_score': array([ 0.0204645]), 'split2_train_score': array([-0.29592506]), 'split3_train_score': array([-0.28345868]), 'split2_test_score': array([-0.27091846]), 'split0_test_score': array([-0.31321337]), 'mean_score_time': array([ 0.02426326]), 'mean_fit_time': array([ 0.01896548]), 'std_train_score': array([ 0.00665188])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290365297756
####################################################################################
################# Runing the itteration 208  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [NuSVR] estimatorrun are
{'split0_train_score': array([-0.05428846]), 'mean_train_score': array([-0.0525643]), 'split3_test_score': array([-0.0645933]), 'std_fit_time': array([ 0.00754967]), 'mean_test_score': array([-0.05399847]), 'split1_test_score': array([-0.0505015]), 'std_score_time': array([ 0.00149515]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([-0.05282411]), 'std_test_score': array([ 0.00658449]), 'split2_train_score': array([-0.05134561]), 'split3_train_score': array([-0.05179904]), 'split2_test_score': array([-0.05389579]), 'split0_test_score': array([-0.04700329]), 'mean_score_time': array([ 0.22596985]), 'mean_fit_time': array([ 1.47089827]), 'std_train_score': array([ 0.00113039])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0539984722351
####################################################################################
################# Runing the itteration 209  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.45084198]), 'std_fit_time': array([ 0.00429321]), 'mean_test_score': array([ 0.39942024]), 'split1_test_score': array([ 0.31262612]), 'std_score_time': array([ 0.00036152]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.06525215]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.36130164]), 'split0_test_score': array([ 0.47291124]), 'mean_score_time': array([ 0.00181293]), 'mean_fit_time': array([ 0.14411956]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.399420242357
####################################################################################
################# Runing the itteration 210  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([ 0.40970855]), 'std_fit_time': array([ 0.0011902]), 'mean_test_score': array([ 0.43154851]), 'split1_test_score': array([ 0.47459476]), 'std_score_time': array([  6.30452334e-05]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.05961533]), 'split2_train_score': array([ 1.]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([ 0.34458722]), 'split0_test_score': array([ 0.49730352]), 'mean_score_time': array([ 0.00167388]), 'mean_fit_time': array([ 0.0489437]), 'std_train_score': array([ 0.])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.431548513471
#########################################
###Finished all estimators for cl: label_gross_2
#########################################
#########################################
#######Printing results for cl: label_gross_2
#########################################
{'MLPRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}, 'score': -0.29113375665588903, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'OrthogonalMatchingPursuit': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.66088966933244819, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'BaggingRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.63405987817979237, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'GradientBoostingRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.68019636882417889, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'SVR': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121}, 'score': -0.13240032470874863, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'SGDRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': 0.59702711243412288, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'HuberRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.29233704728901222, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'RandomForestRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.65664875118477373, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'Lasso': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57}, 'score': 0.60480322058371638, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'AdaBoostRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.43190948087352266, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'LinearRegression': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}, 'score': 0.6183587606904819, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'LinearSVR': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': -0.29036529775554504, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'ElasticNet': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.59633297186808298, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'KNeighborsRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.52498212624258511, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'NuSVR': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}, 'score': -0.052442993353565337, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'LassoLars': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}, 'score': 0.64303841257666872, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'Ridge': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.66798422952203917, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'ExtraTreesRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.62465364249626776, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'PassiveAggressiveRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115}, 'score': -0.28996874914443338, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'ExtraTreeRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.4315485134705353, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'RANSACRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60}, 'score': -1.2805719551241285e+20, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}, 'DecisionTreeRegressor': {'best_cfg': {'reducer__step': 0.1, 'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63}, 'score': 0.39942024235721801, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE'}}
priting simply sorted numbers, grep them to find the best cfg or cl: label_gross_2
[-1.2805719551241285e+20, -0.29113375665588903, -0.29036529775554504, -0.28996874914443338, -0.13240032470874863, -0.052442993353565337, 0.29233704728901222, 0.39942024235721801, 0.4315485134705353, 0.43190948087352266, 0.52498212624258511, 0.59633297186808298, 0.59702711243412288, 0.60480322058371638, 0.6183587606904819, 0.62465364249626776, 0.63405987817979237, 0.64303841257666872, 0.65664875118477373, 0.66088966933244819, 0.66798422952203917, 0.68019636882417889]
