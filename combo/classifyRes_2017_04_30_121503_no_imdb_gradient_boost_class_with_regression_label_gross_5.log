#########################################
###Starting all estimators for cl: label_gross_5
#########################################

LogPol True
n_components
[193, 115, 57]
pw_lst
[{'pw': 1}]
####################################################################################
################# Runing the itteration 1  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'preprocessor__kw_args': [{'pw': 1}], 'reducer__n_features_to_select': [193, 115, 57], 'reducer__step': [0.1]}
Starting precomp pipline for {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
Finished precomp pipline for {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
Starting precomp pipline for {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
Finished precomp pipline for {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
Starting precomp pipline for {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
Finished precomp pipline for {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}

LogPol True
n_components
[203, 121, 60]
pw_lst
[{'pw': 1}, {'pw': 2}]
####################################################################################
################# Runing the itteration 2  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'preprocessor__kw_args': [{'pw': 2}], 'reducer__n_features_to_select': [203, 121, 60], 'reducer__step': [0.1]}
Starting precomp pipline for {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
Finished precomp pipline for {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
Starting precomp pipline for {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
Finished precomp pipline for {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
Starting precomp pipline for {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
Finished precomp pipline for {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}

LogPol True
n_components
[213, 127, 63]
pw_lst
[{'pw': 1}, {'pw': 2}, {'pw': 3}]
####################################################################################
################# Runing the itteration 3  of pipeline precomp      ###############
####################################################################################
| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE
{'preprocessor__kw_args': [{'pw': 3}], 'reducer__n_features_to_select': [213, 127, 63], 'reducer__step': [0.1]}
Starting precomp pipline for {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
Finished precomp pipline for {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
Starting precomp pipline for {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
Finished precomp pipline for {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
Starting precomp pipline for {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
Finished precomp pipline for {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
####################################################################################
################# Runing the itteration 4  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.18503746]), 'std_score_time': array([ 0.00177058]), 'split1_test_score': array([-0.23725461]), 'mean_train_score': array([-0.01200339]), 'std_train_score': array([ 0.18539392]), 'std_test_score': array([ 0.2524581]), 'params': ({},), 'split0_train_score': array([ 0.27337635]), 'std_fit_time': array([ 0.04455876]), 'split1_train_score': array([ 0.03129855]), 'mean_test_score': array([-0.15703605]), 'split0_test_score': array([ 0.27057922]), 'split2_test_score': array([-0.38225285]), 'mean_score_time': array([ 0.01772362]), 'split3_test_score': array([-0.27921595]), 'split2_train_score': array([-0.16765099]), 'mean_fit_time': array([ 1.28772753])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.157036047502
####################################################################################
################# Runing the itteration 5  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.93754852]), 'std_score_time': array([ 0.00194035]), 'split1_test_score': array([ 0.6865644]), 'mean_train_score': array([ 0.93613619]), 'std_train_score': array([ 0.00319705]), 'std_test_score': array([ 0.04844517]), 'params': ({},), 'split0_train_score': array([ 0.93550813]), 'std_fit_time': array([ 0.05875373]), 'split1_train_score': array([ 0.93137439]), 'mean_test_score': array([ 0.6232046]), 'split0_test_score': array([ 0.6168269]), 'split2_test_score': array([ 0.55164895]), 'mean_score_time': array([ 0.01492083]), 'split3_test_score': array([ 0.63777816]), 'split2_train_score': array([ 0.94011372]), 'mean_fit_time': array([ 1.36240703])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.62320460477
####################################################################################
################# Runing the itteration 6  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00025192]), 'split1_test_score': array([ 0.6030846]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.02340496]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.01427253]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.61745127]), 'split0_test_score': array([ 0.65146492]), 'split2_test_score': array([ 0.62544403]), 'mean_score_time': array([ 0.0072282]), 'split3_test_score': array([ 0.58981153]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.82009405])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.617451269858
####################################################################################
################# Runing the itteration 7  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.6s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.79883206]), 'std_score_time': array([ 0.00441082]), 'split1_test_score': array([ 0.63036023]), 'mean_train_score': array([ 0.80619468]), 'std_train_score': array([ 0.00658073]), 'std_test_score': array([ 0.03931865]), 'params': ({},), 'split0_train_score': array([ 0.80370533]), 'std_fit_time': array([ 0.03499659]), 'split1_train_score': array([ 0.81679025]), 'mean_test_score': array([ 0.64495568]), 'split0_test_score': array([ 0.6863606]), 'split2_test_score': array([ 0.67569308]), 'mean_score_time': array([ 0.00930148]), 'split3_test_score': array([ 0.5874088]), 'split2_train_score': array([ 0.80545108]), 'mean_fit_time': array([ 1.54919261])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.644955678205
####################################################################################
################# Runing the itteration 8  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.93170305]), 'std_score_time': array([ 0.0026003]), 'split1_test_score': array([ 0.66515862]), 'mean_train_score': array([ 0.92850745]), 'std_train_score': array([ 0.00465356]), 'std_test_score': array([ 0.04571024]), 'params': ({},), 'split0_train_score': array([ 0.92120241]), 'std_fit_time': array([ 0.02678362]), 'split1_train_score': array([ 0.92786001]), 'mean_test_score': array([ 0.61136704]), 'split0_test_score': array([ 0.63733015]), 'split2_test_score': array([ 0.54311997]), 'mean_score_time': array([ 0.01023418]), 'split3_test_score': array([ 0.59985941]), 'split2_train_score': array([ 0.93326433]), 'mean_fit_time': array([ 1.34296721])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.611367036502
####################################################################################
################# Runing the itteration 9  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.65198497]), 'std_score_time': array([ 0.01920679]), 'split1_test_score': array([ 0.65503175]), 'mean_train_score': array([ 0.63122523]), 'std_train_score': array([ 0.01397018]), 'std_test_score': array([ 0.04585922]), 'params': ({},), 'split0_train_score': array([ 0.63588827]), 'std_fit_time': array([ 0.00853971]), 'split1_train_score': array([ 0.62006217]), 'mean_test_score': array([ 0.59440621]), 'split0_test_score': array([ 0.58931652]), 'split2_test_score': array([ 0.60644276]), 'mean_score_time': array([ 0.03938639]), 'split3_test_score': array([ 0.52683379]), 'split2_train_score': array([ 0.61696552]), 'mean_fit_time': array([ 0.2480821])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.594406205463
####################################################################################
################# Runing the itteration 10  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.35632295]), 'std_score_time': array([ 0.00048759]), 'split1_test_score': array([ 0.32630335]), 'mean_train_score': array([ 0.33058798]), 'std_train_score': array([ 0.01741195]), 'std_test_score': array([ 0.01619083]), 'params': ({},), 'split0_train_score': array([ 0.30850607]), 'std_fit_time': array([ 0.11439639]), 'split1_train_score': array([ 0.32346369]), 'mean_test_score': array([ 0.318948]), 'split0_test_score': array([ 0.33194606]), 'split2_test_score': array([ 0.32635525]), 'mean_score_time': array([ 0.00405759]), 'split3_test_score': array([ 0.29118736]), 'split2_train_score': array([ 0.33405921]), 'mean_fit_time': array([ 0.34443247])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.3189480044
####################################################################################
################# Runing the itteration 11  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
GREP_ME***Results of [Lasso] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.65918096]), 'std_score_time': array([ 0.01643232]), 'split1_test_score': array([-18.4655285]), 'mean_train_score': array([ 0.66374479]), 'std_train_score': array([ 0.00482079]), 'std_test_score': array([ 8.11822866]), 'params': ({},), 'split0_train_score': array([ 0.65867488]), 'std_fit_time': array([ 0.03391551]), 'split1_train_score': array([ 0.66845424]), 'mean_test_score': array([-4.41607211]), 'split0_test_score': array([-0.27054974]), 'split2_test_score': array([ 0.59071801]), 'mean_score_time': array([ 0.03566098]), 'split3_test_score': array([ 0.48107178]), 'split2_train_score': array([ 0.6686691]), 'mean_fit_time': array([ 1.94022143])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-4.41607211158
####################################################################################
################# Runing the itteration 12  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.606118]), 'std_score_time': array([ 0.00523832]), 'split1_test_score': array([ 0.5258853]), 'mean_train_score': array([ 0.62830137]), 'std_train_score': array([ 0.01495475]), 'std_test_score': array([ 0.05419614]), 'params': ({},), 'split0_train_score': array([ 0.64312795]), 'std_fit_time': array([ 0.01835341]), 'split1_train_score': array([ 0.64079986]), 'mean_test_score': array([ 0.60510626]), 'split0_test_score': array([ 0.58608987]), 'split2_test_score': array([ 0.64226636]), 'mean_score_time': array([ 0.01007432]), 'split3_test_score': array([ 0.66618351]), 'split2_train_score': array([ 0.62315968]), 'mean_fit_time': array([ 0.10788488])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.605106260484
####################################################################################
################# Runing the itteration 13  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.66475104]), 'std_score_time': array([ 0.00611258]), 'split1_test_score': array([-3.77473068]), 'mean_train_score': array([ 0.66256899]), 'std_train_score': array([ 0.00918952]), 'std_test_score': array([ 4.77118248]), 'params': ({},), 'split0_train_score': array([ 0.6473017]), 'std_fit_time': array([ 0.05277553]), 'split1_train_score': array([ 0.66643523]), 'mean_test_score': array([-3.44040311]), 'split0_test_score': array([-11.1138833]), 'split2_test_score': array([ 0.55446128]), 'mean_score_time': array([ 0.01791358]), 'split3_test_score': array([ 0.57254024]), 'split2_train_score': array([ 0.67178798]), 'mean_fit_time': array([ 0.23492521])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3.44040311443
####################################################################################
################# Runing the itteration 14  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28267492]), 'std_score_time': array([ 0.01043157]), 'split1_test_score': array([-0.28340744]), 'mean_train_score': array([-0.28873242]), 'std_train_score': array([ 0.00996906]), 'std_test_score': array([ 0.0274716]), 'params': ({},), 'split0_train_score': array([-0.27797145]), 'std_fit_time': array([ 0.00069752]), 'split1_train_score': array([-0.2899442]), 'mean_test_score': array([-0.29190332]), 'split0_test_score': array([-0.32402109]), 'split2_test_score': array([-0.25149143]), 'mean_score_time': array([ 0.02301848]), 'split3_test_score': array([-0.30869332]), 'split2_train_score': array([-0.3043391]), 'mean_fit_time': array([ 0.03773075])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291903320439
####################################################################################
################# Runing the itteration 15  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.1s
[CV]  ................................................................
[CV] ................................................. , total=   3.2s
GREP_ME***Results of [Ridge] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.66058938]), 'std_score_time': array([ 0.00519609]), 'split1_test_score': array([-0.06341015]), 'mean_train_score': array([ 0.66490054]), 'std_train_score': array([ 0.00770505]), 'std_test_score': array([ 0.27128005]), 'params': ({},), 'split0_train_score': array([ 0.67601496]), 'std_fit_time': array([ 0.06715665]), 'split1_train_score': array([ 0.66750777]), 'mean_test_score': array([ 0.40244633]), 'split0_test_score': array([ 0.51731527]), 'split2_test_score': array([ 0.54217557]), 'mean_score_time': array([ 0.03008193]), 'split3_test_score': array([ 0.61370464]), 'split2_train_score': array([ 0.65549006]), 'mean_fit_time': array([ 3.17535394])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.40244633356
####################################################################################
################# Runing the itteration 16  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-69004.43138557]), 'std_score_time': array([ 0.00543745]), 'split1_test_score': array([-5668.11015604]), 'mean_train_score': array([-291040.43201076]), 'std_train_score': array([ 175025.07964121]), 'std_test_score': array([ 17252.50233733]), 'params': ({},), 'split0_train_score': array([-475508.22655857]), 'std_fit_time': array([ 0.0030962]), 'split1_train_score': array([-448570.84339809]), 'mean_test_score': array([-14692.67465366]), 'split0_test_score': array([-44337.69698529]), 'split2_test_score': array([-7359.32275313]), 'mean_score_time': array([ 0.01900351]), 'split3_test_score': array([-1405.56872018]), 'split2_train_score': array([-171078.2267008]), 'mean_fit_time': array([ 0.0382337])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-14692.6746537
####################################################################################
################# Runing the itteration 17  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.61201607]), 'std_score_time': array([ 0.00236072]), 'split1_test_score': array([ 0.60988415]), 'mean_train_score': array([ 0.63527664]), 'std_train_score': array([ 0.01416788]), 'std_test_score': array([ 0.04697274]), 'params': ({},), 'split0_train_score': array([ 0.6423963]), 'std_fit_time': array([ 0.00758103]), 'split1_train_score': array([ 0.63698681]), 'mean_test_score': array([ 0.60243543]), 'split0_test_score': array([ 0.5751309]), 'split2_test_score': array([ 0.54980293]), 'mean_score_time': array([ 0.00832808]), 'split3_test_score': array([ 0.67492372]), 'split2_train_score': array([ 0.6497074]), 'mean_fit_time': array([ 0.07007724])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.60243542625
####################################################################################
################# Runing the itteration 18  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   5.8s
[CV]  ................................................................
[CV] ................................................. , total=   6.4s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ -3.17931838e+25]), 'std_score_time': array([ 0.01477145]), 'split1_test_score': array([ -1.56104948e+24]), 'mean_train_score': array([ -8.67519728e+24]), 'std_train_score': array([  1.33654988e+25]), 'std_test_score': array([  1.36338720e+25]), 'params': ({},), 'split0_train_score': array([ -8.23233505e+23]), 'std_fit_time': array([ 0.41244299]), 'split1_train_score': array([ -2.02347813e+24]), 'mean_test_score': array([ -8.52475957e+24]), 'split0_test_score': array([ -3.84717917e+23]), 'split2_test_score': array([ -3.42748318e+22]), 'mean_score_time': array([ 0.01718825]), 'split3_test_score': array([ -3.21189960e+25]), 'split2_train_score': array([ -6.08936419e+22]), 'mean_fit_time': array([ 6.46125007])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-8.5247595686e+24
####################################################################################
################# Runing the itteration 19  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.59665242]), 'std_score_time': array([ 0.08003727]), 'split1_test_score': array([ 0.39483319]), 'mean_train_score': array([ 0.59773456]), 'std_train_score': array([ 0.00432774]), 'std_test_score': array([ 0.03423078]), 'params': ({},), 'split0_train_score': array([ 0.59113402]), 'std_fit_time': array([ 0.00051451]), 'split1_train_score': array([ 0.60099835]), 'mean_test_score': array([ 0.37732735]), 'split0_test_score': array([ 0.4100234]), 'split2_test_score': array([ 0.32019997]), 'mean_score_time': array([ 1.03223014]), 'split3_test_score': array([ 0.38425283]), 'split2_train_score': array([ 0.60215347]), 'mean_fit_time': array([ 0.04877323])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.377327347683
####################################################################################
################# Runing the itteration 20  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_5', label_fn=<function label_gross_5>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.15703604750226574}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.6232046047701999}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.59440620546340273}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61745126985767917}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64495567820461619}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31894800439963106}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37732734768332066}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -4.4160721115824275}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60510626048361493}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -3.4404031144318972}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.15703604750226574}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.6232046047701999}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.59440620546340273}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61745126985767917}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64495567820461619}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31894800439963106}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37732734768332066}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -4.4160721115824275}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60510626048361493}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -3.4404031144318972}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 214 columns], y=524      220241723
1193      98341932
3307      ...          527
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -0.15703604750226574}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.6232046047701999}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.59440620546340273}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61745126985767917}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64495567820461619}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31894800439963106}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.37732734768332066}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -4.4160721115824275}, 'LassoLars': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60510626048361493}, 'LinearRegression': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': -3.4404031144318972}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 524      220241723
1193      98341932
3307      ...          527
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 214 columns], y=524      220241723
1193      98341932
3307      ...          527
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 214 columns]
        y = 524      220241723
1193      98341932
3307      ...          527
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 214 columns], y=524      220241723
1193      98341932
3307      ...          527
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 15:53:31 2017
PID: 13821                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 214 columns], 524      220241723
1193      98341932
3307      ...          527
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 214 columns], 524      220241723
1193      98341932
3307      ...          527
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1          2         3... -0.043288 -0.106368  

[4812 rows x 214 columns], y=524      220241723
1193      98341932
3307      ...          527
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], y_test=524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y_test = 524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], 524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], 524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], 524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], 524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], y=524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns]
        y = 524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1          2         3... -0.043288 -0.106368  

[1203 rows x 214 columns], y=524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64, y_pred=array([       nan,        nan,        nan, ...,        nan,  10732909.,
              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 524      220241723
1193      98341932
3307      ...    115592104
Name: worldwide_gross, dtype: int64
        y_pred = array([       nan,        nan,        nan, ...,        nan,  10732909.,
              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([220241723,  98341932,   8692898, ...,  50363790,  50811858,
       115592104]), y_pred=array([       nan,        nan,        nan, ...,        nan,  10732909.,
              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([       nan,        nan,        nan, ...,        nan,  10732909.,
              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([       nan,        nan,        nan, ...,        nan,  10732909.,
              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([       nan,        nan,        nan, ...,        nan,  10732909.,
              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([       nan,        nan,        nan, ...,        nan,  10732909.,
              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 21  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.4min
[CV]  ................................................................
[CV] ................................................. , total= 1.4min
[CV]  ................................................................
[CV] ................................................. , total= 1.4min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.27737173]), 'std_score_time': array([ 0.3170208]), 'split1_test_score': array([-0.24426993]), 'mean_train_score': array([-0.29017916]), 'std_train_score': array([ 0.01456567]), 'std_test_score': array([ 0.04145193]), 'params': ({},), 'split0_train_score': array([-0.27592788]), 'std_fit_time': array([ 1.03141533]), 'split1_train_score': array([-0.31130519]), 'mean_test_score': array([-0.29675065]), 'split0_test_score': array([-0.3457664]), 'split2_test_score': array([-0.26924038]), 'mean_score_time': array([ 0.23950487]), 'split3_test_score': array([-0.32772587]), 'split2_train_score': array([-0.29611184]), 'mean_fit_time': array([ 82.06589472])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29675064537
####################################################################################
################# Runing the itteration 22  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.1332809]), 'std_score_time': array([ 0.03221379]), 'split1_test_score': array([-0.14193442]), 'mean_train_score': array([-0.1317564]), 'std_train_score': array([ 0.00302472]), 'std_test_score': array([ 0.00925241]), 'params': ({},), 'split0_train_score': array([-0.12935693]), 'std_fit_time': array([ 0.04166288]), 'split1_train_score': array([-0.12844345]), 'mean_test_score': array([-0.13301702]), 'split0_test_score': array([-0.14239907]), 'split2_test_score': array([-0.1257974]), 'mean_score_time': array([ 1.16984284]), 'split3_test_score': array([-0.1219372]), 'split2_train_score': array([-0.1359443]), 'mean_fit_time': array([ 4.08511227])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.133017024163
####################################################################################
################# Runing the itteration 23  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28095842]), 'std_score_time': array([ 0.00464074]), 'split1_test_score': array([-0.25422477]), 'mean_train_score': array([-0.29028712]), 'std_train_score': array([ 0.01153373]), 'std_test_score': array([ 0.02906546]), 'params': ({},), 'split0_train_score': array([-0.28037976]), 'std_fit_time': array([ 0.01486277]), 'split1_train_score': array([-0.30890276]), 'mean_test_score': array([-0.29644414]), 'split0_test_score': array([-0.32291403]), 'split2_test_score': array([-0.28467135]), 'mean_score_time': array([ 0.01444715]), 'split3_test_score': array([-0.3239664]), 'split2_train_score': array([-0.29090755]), 'mean_fit_time': array([ 0.05150366])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.296444137085
####################################################################################
################# Runing the itteration 24  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [NuSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.05127202]), 'std_score_time': array([ 0.0060498]), 'split1_test_score': array([-0.061827]), 'mean_train_score': array([-0.05227972]), 'std_train_score': array([ 0.00088275]), 'std_test_score': array([ 0.00791705]), 'params': ({},), 'split0_train_score': array([-0.05361103]), 'std_fit_time': array([ 0.0776582]), 'split1_train_score': array([-0.05174589]), 'mean_test_score': array([-0.05272901]), 'split0_test_score': array([-0.04380015]), 'split2_test_score': array([-0.04600342]), 'mean_score_time': array([ 0.58704698]), 'split3_test_score': array([-0.05928546]), 'split2_train_score': array([-0.05248993]), 'mean_fit_time': array([ 3.03514147])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0527290057669
####################################################################################
################# Runing the itteration 25  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([  6.61006642e-05]), 'split1_test_score': array([ 0.4460783]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.13043448]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00751855]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.31966059]), 'split0_test_score': array([ 0.2854538]), 'split2_test_score': array([ 0.42627979]), 'mean_score_time': array([ 0.00362253]), 'split3_test_score': array([ 0.12083048]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.23099905])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.319660592831
####################################################################################
################# Runing the itteration 26  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([  9.54489620e-05]), 'split1_test_score': array([ 0.31358293]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.0170778]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00089599]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.34150336]), 'split0_test_score': array([ 0.35882942]), 'split2_test_score': array([ 0.35072114]), 'mean_score_time': array([ 0.0026558]), 'split3_test_score': array([ 0.34287994]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.10553926])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.341503357003
####################################################################################
################# Runing the itteration 27  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.44871678]), 'std_score_time': array([ 0.00159296]), 'split1_test_score': array([ 0.48346287]), 'mean_train_score': array([ 0.51932033]), 'std_train_score': array([ 0.12433025]), 'std_test_score': array([ 0.14074843]), 'params': ({},), 'split0_train_score': array([ 0.35532703]), 'std_fit_time': array([ 0.11166236]), 'split1_train_score': array([ 0.60172216]), 'mean_test_score': array([ 0.4063478]), 'split0_test_score': array([ 0.32688223]), 'split2_test_score': array([ 0.59052061]), 'mean_score_time': array([ 0.00691468]), 'split3_test_score': array([ 0.22452549]), 'split2_train_score': array([ 0.67151535]), 'mean_fit_time': array([ 0.51269972])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.406347802471
####################################################################################
################# Runing the itteration 28  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.95014979]), 'std_score_time': array([  4.61920230e-05]), 'split1_test_score': array([ 0.72904532]), 'mean_train_score': array([ 0.95150484]), 'std_train_score': array([ 0.00392632]), 'std_test_score': array([ 0.03663527]), 'params': ({},), 'split0_train_score': array([ 0.95820836]), 'std_fit_time': array([ 0.01214685]), 'split1_train_score': array([ 0.94828861]), 'mean_test_score': array([ 0.70280139]), 'split0_test_score': array([ 0.65495142]), 'split2_test_score': array([ 0.68076542]), 'mean_score_time': array([ 0.00693607]), 'split3_test_score': array([ 0.7464434]), 'split2_train_score': array([ 0.94937261]), 'mean_fit_time': array([ 0.7415849])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.702801386383
####################################################################################
################# Runing the itteration 29  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.0003874]), 'split1_test_score': array([ 0.75666]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.03951238]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.0055183]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.70294813]), 'split0_test_score': array([ 0.64758727]), 'split2_test_score': array([ 0.71589213]), 'mean_score_time': array([ 0.00622952]), 'split3_test_score': array([ 0.69165315]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.35338718])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.702948134796
####################################################################################
################# Runing the itteration 30  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.86930753]), 'std_score_time': array([  8.13337648e-05]), 'split1_test_score': array([ 0.71486059]), 'mean_train_score': array([ 0.86380555]), 'std_train_score': array([ 0.01078594]), 'std_test_score': array([ 0.04592406]), 'params': ({},), 'split0_train_score': array([ 0.85613388]), 'std_fit_time': array([ 0.00311864]), 'split1_train_score': array([ 0.85121805]), 'mean_test_score': array([ 0.73296584]), 'split0_test_score': array([ 0.80214325]), 'split2_test_score': array([ 0.67566041]), 'mean_score_time': array([ 0.00413179]), 'split3_test_score': array([ 0.73919911]), 'split2_train_score': array([ 0.87856275]), 'mean_fit_time': array([ 0.68842262])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.732965840329
####################################################################################
################# Runing the itteration 31  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.94556648]), 'std_score_time': array([ 0.00019497]), 'split1_test_score': array([ 0.67874037]), 'mean_train_score': array([ 0.94896963]), 'std_train_score': array([ 0.00313098]), 'std_test_score': array([ 0.02401914]), 'params': ({},), 'split0_train_score': array([ 0.953657]), 'std_fit_time': array([ 0.00958221]), 'split1_train_score': array([ 0.94988228]), 'mean_test_score': array([ 0.70313239]), 'split0_test_score': array([ 0.69857335]), 'split2_test_score': array([ 0.69238057]), 'mean_score_time': array([ 0.00558388]), 'split3_test_score': array([ 0.74283528]), 'split2_train_score': array([ 0.94677275]), 'mean_fit_time': array([ 0.72327936])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.703132391166
####################################################################################
################# Runing the itteration 32  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.62443121]), 'std_score_time': array([ 0.00316679]), 'split1_test_score': array([ 0.65972612]), 'mean_train_score': array([ 0.62846565]), 'std_train_score': array([ 0.01856884]), 'std_test_score': array([ 0.04110525]), 'params': ({},), 'split0_train_score': array([ 0.64467996]), 'std_fit_time': array([ 0.00370401]), 'split1_train_score': array([ 0.59972784]), 'mean_test_score': array([ 0.61362106]), 'split0_test_score': array([ 0.56898898]), 'split2_test_score': array([ 0.57655427]), 'mean_score_time': array([ 0.01234567]), 'split3_test_score': array([ 0.64921486]), 'split2_train_score': array([ 0.64502357]), 'mean_fit_time': array([ 0.05591232])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.613621058587
####################################################################################
################# Runing the itteration 33  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.32010469]), 'std_score_time': array([ 0.00032458]), 'split1_test_score': array([ 0.30677362]), 'mean_train_score': array([ 0.30904836]), 'std_train_score': array([ 0.00930328]), 'std_test_score': array([ 0.00645]), 'params': ({},), 'split0_train_score': array([ 0.31383327]), 'std_fit_time': array([ 0.01626108]), 'split1_train_score': array([ 0.29497981]), 'mean_test_score': array([ 0.3052436]), 'split0_test_score': array([ 0.29457768]), 'split2_test_score': array([ 0.31188217]), 'mean_score_time': array([ 0.00336897]), 'split3_test_score': array([ 0.30774094]), 'split2_train_score': array([ 0.30727567]), 'mean_fit_time': array([ 0.09795964])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.305243604645
####################################################################################
################# Runing the itteration 34  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.69351571]), 'std_score_time': array([ 0.00525952]), 'split1_test_score': array([ 0.68499919]), 'mean_train_score': array([ 0.67760881]), 'std_train_score': array([ 0.0137964]), 'std_test_score': array([ 0.1983448]), 'params': ({},), 'split0_train_score': array([ 0.66180369]), 'std_fit_time': array([ 0.00697693]), 'split1_train_score': array([ 0.66618853]), 'mean_test_score': array([ 0.55540698]), 'split0_test_score': array([ 0.706367]), 'split2_test_score': array([ 0.21710966]), 'mean_score_time': array([ 0.03043443]), 'split3_test_score': array([ 0.61315208]), 'split2_train_score': array([ 0.68892732]), 'mean_fit_time': array([ 0.544792])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.555406981365
####################################################################################
################# Runing the itteration 35  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.66140139]), 'std_score_time': array([ 0.00147494]), 'split1_test_score': array([ 0.70522623]), 'mean_train_score': array([ 0.66174801]), 'std_train_score': array([ 0.02049439]), 'std_test_score': array([ 0.09229136]), 'params': ({},), 'split0_train_score': array([ 0.68398552]), 'std_fit_time': array([ 0.0127354]), 'split1_train_score': array([ 0.62905576]), 'mean_test_score': array([ 0.59621338]), 'split0_test_score': array([ 0.53200535]), 'split2_test_score': array([ 0.48145142]), 'mean_score_time': array([ 0.00289464]), 'split3_test_score': array([ 0.66617053]), 'split2_train_score': array([ 0.67254938]), 'mean_fit_time': array([ 0.07410431])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.596213384466
####################################################################################
################# Runing the itteration 36  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.65682494]), 'std_score_time': array([ 0.00137438]), 'split1_test_score': array([ 0.59342419]), 'mean_train_score': array([ 0.67483372]), 'std_train_score': array([ 0.01512072]), 'std_test_score': array([ 0.05383527]), 'params': ({},), 'split0_train_score': array([ 0.66346644]), 'std_fit_time': array([ 0.01102243]), 'split1_train_score': array([ 0.6933647]), 'mean_test_score': array([ 0.62248927]), 'split0_test_score': array([ 0.56179649]), 'split2_test_score': array([ 0.62840464]), 'mean_score_time': array([ 0.00262994]), 'split3_test_score': array([ 0.70633175]), 'split2_train_score': array([ 0.68567881]), 'mean_fit_time': array([ 0.13139677])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.622489270405
####################################################################################
################# Runing the itteration 37  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28168488]), 'std_score_time': array([ 0.00392497]), 'split1_test_score': array([-0.32375837]), 'mean_train_score': array([-0.28861089]), 'std_train_score': array([ 0.009388]), 'std_test_score': array([ 0.02652128]), 'params': ({},), 'split0_train_score': array([-0.30178091]), 'std_fit_time': array([ 0.00126094]), 'split1_train_score': array([-0.2780181]), 'mean_test_score': array([-0.29116545]), 'split0_test_score': array([-0.25729069]), 'split2_test_score': array([-0.27444414]), 'mean_score_time': array([ 0.01269889]), 'split3_test_score': array([-0.3091686]), 'split2_train_score': array([-0.29295968]), 'mean_fit_time': array([ 0.01908225])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29116544902
####################################################################################
################# Runing the itteration 38  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [Ridge] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.67300003]), 'std_score_time': array([ 0.00994136]), 'split1_test_score': array([ 0.60849351]), 'mean_train_score': array([ 0.67558357]), 'std_train_score': array([ 0.01130938]), 'std_test_score': array([ 0.09534226]), 'params': ({},), 'split0_train_score': array([ 0.67587204]), 'std_fit_time': array([ 0.05794964]), 'split1_train_score': array([ 0.69257751]), 'mean_test_score': array([ 0.58615715]), 'split0_test_score': array([ 0.65534016]), 'split2_test_score': array([ 0.42445031]), 'mean_score_time': array([ 0.01290917]), 'split3_test_score': array([ 0.65634464]), 'split2_train_score': array([ 0.66088472]), 'mean_fit_time': array([ 0.75527298])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.586157154956
####################################################################################
################# Runing the itteration 39  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-205.04167153]), 'std_score_time': array([ 0.00074228]), 'split1_test_score': array([-37451.56451625]), 'mean_train_score': array([-203806.64326583]), 'std_train_score': array([ 181217.73134986]), 'std_test_score': array([ 18088.77459802]), 'params': ({},), 'split0_train_score': array([-361803.14046945]), 'std_fit_time': array([ 0.00045924]), 'split1_train_score': array([-405359.0857391]), 'mean_test_score': array([-21290.38207218]), 'split0_test_score': array([-40904.25636564]), 'split2_test_score': array([-6794.00695526]), 'mean_score_time': array([ 0.01385713]), 'split3_test_score': array([-11.70045158]), 'split2_train_score': array([-47859.30518323]), 'mean_fit_time': array([ 0.01842326])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-21290.3820722
####################################################################################
################# Runing the itteration 40  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.64604435]), 'std_score_time': array([ 0.00032264]), 'split1_test_score': array([ 0.60415439]), 'mean_train_score': array([ 0.66251215]), 'std_train_score': array([ 0.01050761]), 'std_test_score': array([ 0.03219265]), 'params': ({},), 'split0_train_score': array([ 0.66599629]), 'std_fit_time': array([ 0.00529995]), 'split1_train_score': array([ 0.67508773]), 'mean_test_score': array([ 0.64896449]), 'split0_test_score': array([ 0.64555426]), 'split2_test_score': array([ 0.65112822]), 'mean_score_time': array([ 0.00208211]), 'split3_test_score': array([ 0.6950211]), 'split2_train_score': array([ 0.66292022]), 'mean_fit_time': array([ 0.03450096])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.648964493597
####################################################################################
################# Runing the itteration 41  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-378.01600405]), 'std_score_time': array([ 0.00087825]), 'split1_test_score': array([ -8.40719898e+21]), 'mean_train_score': array([ -9.08716739e+20]), 'std_train_score': array([  1.57394356e+21]), 'std_test_score': array([  3.64042395e+21]), 'params': ({},), 'split0_train_score': array([-4.47671204]), 'std_fit_time': array([ 0.24344854]), 'split1_train_score': array([ -3.63486696e+21]), 'mean_test_score': array([ -2.10179975e+21]), 'split0_test_score': array([-2.60194147]), 'split2_test_score': array([ -1.72577817e+10]), 'mean_score_time': array([ 0.00234926]), 'split3_test_score': array([-6.2892028]), 'split2_train_score': array([ -1.65506429e+10]), 'mean_fit_time': array([ 0.87087101])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.10179974598e+21
####################################################################################
################# Runing the itteration 42  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.69315857]), 'std_score_time': array([ 0.02340502]), 'split1_test_score': array([ 0.55345089]), 'mean_train_score': array([ 0.69860486]), 'std_train_score': array([ 0.00403057]), 'std_test_score': array([ 0.02868434]), 'params': ({},), 'split0_train_score': array([ 0.70373548]), 'std_fit_time': array([ 0.00050099]), 'split1_train_score': array([ 0.69664766]), 'mean_test_score': array([ 0.54529725]), 'split0_test_score': array([ 0.51473863]), 'split2_test_score': array([ 0.52456338]), 'mean_score_time': array([ 0.33509523]), 'split3_test_score': array([ 0.5884361]), 'split2_train_score': array([ 0.70087772]), 'mean_fit_time': array([ 0.02340162])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.545297254175
####################################################################################
################# Runing the itteration 43  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_5', label_fn=<function label_gross_5>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40634780247058638}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31966059283114201}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34150335700314072}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31894800439963106}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.55540698136461475}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40634780247058638}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31966059283114201}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34150335700314072}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31894800439963106}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.55540698136461475}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], y=462     245800000
1128    103891409
4350        ...    652127828
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40634780247058638}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31966059283114201}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34150335700314072}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31894800439963106}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.55540698136461475}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns]
        y = 462     245800000
1128    103891409
4350        ...    652127828
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], y=462     245800000
1128    103891409
4350        ...    652127828
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns]
        y = 462     245800000
1128    103891409
4350        ...    652127828
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], y=462     245800000
1128    103891409
4350        ...    652127828
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 16:06:13 2017
PID: 15284                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], 462     245800000
1128    103891409
4350        ...    652127828
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], 462     245800000
1128    103891409
4350        ...    652127828
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[4812 rows x 61 columns], y=462     245800000
1128    103891409
4350        ...    652127828
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns]
        y_test = 462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns], y_test=462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns]
        y_test = 462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns], 462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns], 462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns], 462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns], 462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns], y=462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns]
        y = 462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 61 columns], y=462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64, y_pred=array([  1.22780326e+08,              nan,      ...7100000e+08,              nan,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 462     245800000
1128    103891409
4350        ...            0
Name: worldwide_gross, dtype: int64
        y_pred = array([  1.22780326e+08,              nan,      ...7100000e+08,              nan,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([245800000, 103891409,     49526, ..., 349088523,  90723216,
               0]), y_pred=array([  1.22780326e+08,              nan,      ...7100000e+08,              nan,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  1.22780326e+08,              nan,      ...7100000e+08,              nan,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  1.22780326e+08,              nan,      ...7100000e+08,              nan,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  1.22780326e+08,              nan,      ...7100000e+08,              nan,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  1.22780326e+08,              nan,      ...7100000e+08,              nan,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 44  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  30.7s
[CV]  ................................................................
[CV] ................................................. , total=  33.8s
[CV]  ................................................................
[CV] ................................................. , total=  34.3s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.27721262]), 'std_score_time': array([ 0.0160544]), 'split1_test_score': array([-0.25733269]), 'mean_train_score': array([-0.28984769]), 'std_train_score': array([ 0.00926199]), 'std_test_score': array([ 0.03188067]), 'params': ({},), 'split0_train_score': array([-0.28637908]), 'std_fit_time': array([ 2.0402065]), 'split1_train_score': array([-0.30247102]), 'mean_test_score': array([-0.2947428]), 'split0_test_score': array([-0.30061101]), 'split2_test_score': array([-0.27784794]), 'mean_score_time': array([ 0.02422571]), 'split3_test_score': array([-0.34317956]), 'split2_train_score': array([-0.29332806]), 'mean_fit_time': array([ 32.02113611])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29474280039
####################################################################################
################# Runing the itteration 45  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [SVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.1314674]), 'std_score_time': array([ 0.00480972]), 'split1_test_score': array([-0.13777929]), 'mean_train_score': array([-0.13165143]), 'std_train_score': array([ 0.00098837]), 'std_test_score': array([ 0.01315635]), 'params': ({},), 'split0_train_score': array([-0.13231209]), 'std_fit_time': array([ 0.02729014]), 'split1_train_score': array([-0.13012401]), 'mean_test_score': array([-0.13285932]), 'split0_test_score': array([-0.15103438]), 'split2_test_score': array([-0.12727543]), 'mean_score_time': array([ 0.44598752]), 'split3_test_score': array([-0.11534819]), 'split2_train_score': array([-0.13270223]), 'mean_fit_time': array([ 1.9172163])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132859321957
####################################################################################
################# Runing the itteration 46  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.30322903]), 'std_score_time': array([ 0.01760431]), 'split1_test_score': array([-0.32785875]), 'mean_train_score': array([-0.29005806]), 'std_train_score': array([ 0.00919188]), 'std_test_score': array([ 0.02544138]), 'params': ({},), 'split0_train_score': array([-0.29379768]), 'std_fit_time': array([ 0.00010143]), 'split1_train_score': array([-0.27966378]), 'mean_test_score': array([-0.29502296]), 'split0_test_score': array([-0.27614357]), 'split2_test_score': array([-0.31103436]), 'mean_score_time': array([ 0.02153569]), 'split3_test_score': array([-0.26505514]), 'split2_train_score': array([-0.28354174]), 'mean_fit_time': array([ 0.0195021])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295022955235
####################################################################################
################# Runing the itteration 47  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [NuSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.0522167]), 'std_score_time': array([ 0.00170885]), 'split1_test_score': array([-0.06463117]), 'mean_train_score': array([-0.0524973]), 'std_train_score': array([ 0.0008706]), 'std_test_score': array([ 0.00786582]), 'params': ({},), 'split0_train_score': array([-0.05380577]), 'std_fit_time': array([ 0.01362406]), 'split1_train_score': array([-0.05258033]), 'mean_test_score': array([-0.05406174]), 'split0_test_score': array([-0.04661424]), 'split2_test_score': array([-0.05864217]), 'mean_score_time': array([ 0.2183128]), 'split3_test_score': array([-0.04635938]), 'split2_train_score': array([-0.05138642]), 'mean_fit_time': array([ 1.55231011])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0540617376633
####################################################################################
################# Runing the itteration 48  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00016997]), 'split1_test_score': array([ 0.50067911]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.03008334]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00105668]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.50115666]), 'split0_test_score': array([ 0.54658448]), 'split2_test_score': array([ 0.49520199]), 'mean_score_time': array([ 0.00178641]), 'split3_test_score': array([ 0.46216107]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.13180822])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.501156664103
####################################################################################
################# Runing the itteration 49  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([  3.33246472e-05]), 'split1_test_score': array([ 0.47490779]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.02737652]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00041347]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.51759215]), 'split0_test_score': array([ 0.51464769]), 'split2_test_score': array([ 0.54835254]), 'mean_score_time': array([ 0.00164407]), 'split3_test_score': array([ 0.53246057]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.04389316])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.517592146905
####################################################################################
################# Runing the itteration 50  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.48418479]), 'std_score_time': array([ 0.00121072]), 'split1_test_score': array([ 0.14406443]), 'mean_train_score': array([ 0.41095758]), 'std_train_score': array([ 0.13471493]), 'std_test_score': array([ 0.11293732]), 'params': ({},), 'split0_train_score': array([ 0.33113413]), 'std_fit_time': array([ 0.10450374]), 'split1_train_score': array([ 0.23984713]), 'mean_test_score': array([ 0.29828784]), 'split0_test_score': array([ 0.30643209]), 'split2_test_score': array([ 0.46215308]), 'mean_score_time': array([ 0.0069018]), 'split3_test_score': array([ 0.28050178]), 'split2_train_score': array([ 0.58866425]), 'mean_fit_time': array([ 0.41529614])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.298287844021
####################################################################################
################# Runing the itteration 51  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.93021661]), 'std_score_time': array([ 0.00037729]), 'split1_test_score': array([ 0.58906857]), 'mean_train_score': array([ 0.9311757]), 'std_train_score': array([ 0.00262208]), 'std_test_score': array([ 0.018323]), 'params': ({},), 'split0_train_score': array([ 0.93524292]), 'std_fit_time': array([ 0.00435268]), 'split1_train_score': array([ 0.92800783]), 'mean_test_score': array([ 0.61671851]), 'split0_test_score': array([ 0.63064627]), 'split2_test_score': array([ 0.63562696]), 'mean_score_time': array([ 0.00880837]), 'split3_test_score': array([ 0.61153224]), 'split2_train_score': array([ 0.93123543]), 'mean_fit_time': array([ 0.66968137])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.616718509689
####################################################################################
################# Runing the itteration 52  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00033578]), 'split1_test_score': array([ 0.51819766]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.04296628]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.02128649]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.56779109]), 'split0_test_score': array([ 0.59906712]), 'split2_test_score': array([ 0.53348173]), 'mean_score_time': array([ 0.00736034]), 'split3_test_score': array([ 0.62041783]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.47932178])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.567791085813
####################################################################################
################# Runing the itteration 53  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.78818106]), 'std_score_time': array([ 0.00013587]), 'split1_test_score': array([ 0.60515619]), 'mean_train_score': array([ 0.79493195]), 'std_train_score': array([ 0.01426313]), 'std_test_score': array([ 0.03626237]), 'params': ({},), 'split0_train_score': array([ 0.77477719]), 'std_fit_time': array([ 0.0195642]), 'split1_train_score': array([ 0.80835247]), 'mean_test_score': array([ 0.62797689]), 'split0_test_score': array([ 0.63273148]), 'split2_test_score': array([ 0.58929594]), 'mean_score_time': array([ 0.00394243]), 'split3_test_score': array([ 0.68472397]), 'split2_train_score': array([ 0.80841707]), 'mean_fit_time': array([ 0.84865034])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.627976891429
####################################################################################
################# Runing the itteration 54  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.92946316]), 'std_score_time': array([ 0.00029473]), 'split1_test_score': array([ 0.61402419]), 'mean_train_score': array([ 0.93199685]), 'std_train_score': array([ 0.00451034]), 'std_test_score': array([ 0.07043998]), 'params': ({},), 'split0_train_score': array([ 0.93774202]), 'std_fit_time': array([ 0.00191721]), 'split1_train_score': array([ 0.9261022]), 'mean_test_score': array([ 0.55098536]), 'split0_test_score': array([ 0.45423435]), 'split2_test_score': array([ 0.51332423]), 'mean_score_time': array([ 0.00676841]), 'split3_test_score': array([ 0.62235866]), 'split2_train_score': array([ 0.93467999]), 'mean_fit_time': array([ 0.69135422])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.55098535667
####################################################################################
################# Runing the itteration 55  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.56226551]), 'std_score_time': array([ 0.00221842]), 'split1_test_score': array([ 0.55085641]), 'mean_train_score': array([ 0.5505081]), 'std_train_score': array([ 0.00871189]), 'std_test_score': array([ 0.0350905]), 'params': ({},), 'split0_train_score': array([ 0.55397035]), 'std_fit_time': array([ 0.00106264]), 'split1_train_score': array([ 0.53856553]), 'mean_test_score': array([ 0.5239781]), 'split0_test_score': array([ 0.52295618]), 'split2_test_score': array([ 0.55502493]), 'mean_score_time': array([ 0.01193833]), 'split3_test_score': array([ 0.46707487]), 'split2_train_score': array([ 0.54723101]), 'mean_fit_time': array([ 0.08821464])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.52397809854
####################################################################################
################# Runing the itteration 56  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.2232195]), 'std_score_time': array([ 0.00049492]), 'split1_test_score': array([ 0.22665959]), 'mean_train_score': array([ 0.22159609]), 'std_train_score': array([ 0.00280854]), 'std_test_score': array([ 0.02030561]), 'params': ({},), 'split0_train_score': array([ 0.21921364]), 'std_fit_time': array([ 0.09406366]), 'split1_train_score': array([ 0.21858799]), 'mean_test_score': array([ 0.21792925]), 'split0_test_score': array([ 0.23294379]), 'split2_test_score': array([ 0.18297321]), 'mean_score_time': array([ 0.00407451]), 'split3_test_score': array([ 0.22914043]), 'split2_train_score': array([ 0.22536322]), 'mean_fit_time': array([ 0.21701801])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.217929254108
####################################################################################
################# Runing the itteration 57  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [Lasso] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.62563804]), 'std_score_time': array([ 0.00462972]), 'split1_test_score': array([ 0.5552134]), 'mean_train_score': array([ 0.6112013]), 'std_train_score': array([ 0.01034106]), 'std_test_score': array([ 0.03741695]), 'params': ({},), 'split0_train_score': array([ 0.59876567]), 'std_fit_time': array([ 0.00352267]), 'split1_train_score': array([ 0.61579909]), 'mean_test_score': array([ 0.56988546]), 'split0_test_score': array([ 0.61101138]), 'split2_test_score': array([ 0.59754616]), 'mean_score_time': array([ 0.01679134]), 'split3_test_score': array([ 0.51577089]), 'split2_train_score': array([ 0.60460238]), 'mean_fit_time': array([ 1.01448089])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.569885459789
####################################################################################
################# Runing the itteration 58  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.6007732]), 'std_score_time': array([ 0.00470844]), 'split1_test_score': array([ 0.5560265]), 'mean_train_score': array([ 0.60169078]), 'std_train_score': array([ 0.00956655]), 'std_test_score': array([ 0.02288332]), 'params': ({},), 'split0_train_score': array([ 0.58801358]), 'std_fit_time': array([ 0.05954083]), 'split1_train_score': array([ 0.61497416]), 'mean_test_score': array([ 0.57391881]), 'split0_test_score': array([ 0.61248009]), 'split2_test_score': array([ 0.56966199]), 'mean_score_time': array([ 0.00900853]), 'split3_test_score': array([ 0.55750668]), 'split2_train_score': array([ 0.60300217]), 'mean_fit_time': array([ 0.13549185])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.573918811721
####################################################################################
################# Runing the itteration 59  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.60125453]), 'std_score_time': array([ 0.00320818]), 'split1_test_score': array([ 0.55875845]), 'mean_train_score': array([ 0.61350916]), 'std_train_score': array([ 0.00812082]), 'std_test_score': array([ 0.02523]), 'params': ({},), 'split0_train_score': array([ 0.61180063]), 'std_fit_time': array([ 0.02887388]), 'split1_train_score': array([ 0.6179206]), 'mean_test_score': array([ 0.57357648]), 'split0_test_score': array([ 0.57851472]), 'split2_test_score': array([ 0.54494967]), 'mean_score_time': array([ 0.01069993]), 'split3_test_score': array([ 0.61208306]), 'split2_train_score': array([ 0.62306088]), 'mean_fit_time': array([ 0.15289766])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.573576477541
####################################################################################
################# Runing the itteration 60  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.27600456]), 'std_score_time': array([ 0.00812513]), 'split1_test_score': array([-0.27706708]), 'mean_train_score': array([-0.28852812]), 'std_train_score': array([ 0.00756123]), 'std_test_score': array([ 0.02210665]), 'params': ({},), 'split0_train_score': array([-0.2960304]), 'std_fit_time': array([ 0.00226186]), 'split1_train_score': array([-0.29225491]), 'mean_test_score': array([-0.28988945]), 'split0_test_score': array([-0.26987051]), 'split2_test_score': array([-0.28569014]), 'mean_score_time': array([ 0.01491034]), 'split3_test_score': array([-0.3269301]), 'split2_train_score': array([-0.28982262]), 'mean_fit_time': array([ 0.02831787])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.289889454955
####################################################################################
################# Runing the itteration 61  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
[CV]  ................................................................
[CV] ................................................. , total=   1.5s
GREP_ME***Results of [Ridge] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.60493859]), 'std_score_time': array([ 0.00218797]), 'split1_test_score': array([ 0.58263077]), 'mean_train_score': array([ 0.61285216]), 'std_train_score': array([ 0.00555947]), 'std_test_score': array([ 0.01869499]), 'params': ({},), 'split0_train_score': array([ 0.61442433]), 'std_fit_time': array([ 0.0806252]), 'split1_train_score': array([ 0.61163949]), 'mean_test_score': array([ 0.57554864]), 'split0_test_score': array([ 0.56910713]), 'split2_test_score': array([ 0.54967293]), 'mean_score_time': array([ 0.00946665]), 'split3_test_score': array([ 0.60078371]), 'split2_train_score': array([ 0.62040623]), 'mean_fit_time': array([ 1.48618376])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.575548636146
####################################################################################
################# Runing the itteration 62  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.59259155]), 'std_score_time': array([ 0.00907354]), 'split1_test_score': array([ 0.57439032]), 'mean_train_score': array([ 0.58847516]), 'std_train_score': array([ 0.0075115]), 'std_test_score': array([ 0.01316618]), 'params': ({},), 'split0_train_score': array([ 0.57666105]), 'std_fit_time': array([ 0.00268636]), 'split1_train_score': array([ 0.58787739]), 'mean_test_score': array([ 0.55341176]), 'split0_test_score': array([ 0.54919264]), 'split2_test_score': array([ 0.53813809]), 'mean_score_time': array([ 0.01864523]), 'split3_test_score': array([ 0.55192598]), 'split2_train_score': array([ 0.59677066]), 'mean_fit_time': array([ 0.03055477])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.553411756699
####################################################################################
################# Runing the itteration 63  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.59157324]), 'std_score_time': array([ 0.00414902]), 'split1_test_score': array([ 0.54104032]), 'mean_train_score': array([ 0.59370459]), 'std_train_score': array([ 0.00686808]), 'std_test_score': array([ 0.02424803]), 'params': ({},), 'split0_train_score': array([ 0.59896395]), 'std_fit_time': array([ 0.01391008]), 'split1_train_score': array([ 0.6008465]), 'mean_test_score': array([ 0.56534235]), 'split0_test_score': array([ 0.55783991]), 'split2_test_score': array([ 0.60573162]), 'mean_score_time': array([ 0.00601673]), 'split3_test_score': array([ 0.55675754]), 'split2_train_score': array([ 0.58343466]), 'mean_fit_time': array([ 0.05949455])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.56534234979
####################################################################################
################# Runing the itteration 64  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   2.1s
[CV]  ................................................................
[CV] ................................................. , total=   2.1s
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ -3.75569646e+24]), 'std_score_time': array([ 0.00103105]), 'split1_test_score': array([ -2.14493535e+24]), 'mean_train_score': array([ -1.83279700e+24]), 'std_train_score': array([  1.53135567e+24]), 'std_test_score': array([  1.96597414e+24]), 'params': ({},), 'split0_train_score': array([ -1.23954133e+18]), 'std_fit_time': array([ 0.1459479]), 'split1_train_score': array([ -2.86465247e+24]), 'mean_test_score': array([ -2.13877317e+24]), 'split0_test_score': array([ -1.34014897e+18]), 'split2_test_score': array([ -1.13000904e+24]), 'mean_score_time': array([ 0.00364906]), 'split3_test_score': array([ -5.28014697e+24]), 'split2_train_score': array([ -7.10837843e+23]), 'mean_fit_time': array([ 2.07853055])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.13877317378e+24
####################################################################################
################# Runing the itteration 65  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63859687]), 'std_score_time': array([ 0.05247422]), 'split1_test_score': array([ 0.38082552]), 'mean_train_score': array([ 0.62641119]), 'std_train_score': array([ 0.01264406]), 'std_test_score': array([ 0.03844582]), 'params': ({},), 'split0_train_score': array([ 0.60556382]), 'std_fit_time': array([ 0.00552391]), 'split1_train_score': array([ 0.62767016]), 'mean_test_score': array([ 0.42266192]), 'split0_test_score': array([ 0.48531656]), 'split2_test_score': array([ 0.41539431]), 'mean_score_time': array([ 0.54967546]), 'split3_test_score': array([ 0.40911129]), 'split2_train_score': array([ 0.6338139]), 'mean_fit_time': array([ 0.04202014])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.422661917453
####################################################################################
################# Runing the itteration 66  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_5', label_fn=<function label_gross_5>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40634780247058638}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31894800439963106}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56988545978877381}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.86304212,
        -0.06123763, -0.10636806]])}
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40634780247058638}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31894800439963106}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56988545978877381}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0          0         1         2         3... -0.061238 -0.106368  

[4812 rows x 116 columns], y=2142      37537675
1131     103735965
1269      ...       282687
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40634780247058638}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 213, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.31894800439963106}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56988545978877381}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0          0         1         2         3... -0.061238 -0.106368  

[4812 rows x 116 columns]
        y = 2142      37537675
1131     103735965
1269      ...       282687
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0          0         1         2         3... -0.061238 -0.106368  

[4812 rows x 116 columns], y=2142      37537675
1131     103735965
1269      ...       282687
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0          0         1         2         3... -0.061238 -0.106368  

[4812 rows x 116 columns]
        y = 2142      37537675
1131     103735965
1269      ...       282687
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0          0         1         2         3... -0.061238 -0.106368  

[4812 rows x 116 columns], y=2142      37537675
1131     103735965
1269      ...       282687
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 16:15:37 2017
PID: 16598                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0          0         1         2         3... -0.061238 -0.106368  

[4812 rows x 116 columns], 2142      37537675
1131     103735965
1269      ...       282687
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0          0         1         2         3... -0.061238 -0.106368  

[4812 rows x 116 columns], 2142      37537675
1131     103735965
1269      ...       282687
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1         2         3... -0.061238 -0.106368  

[4812 rows x 116 columns], y=2142      37537675
1131     103735965
1269      ...       282687
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns]
        y_test = 2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns], y_test=2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns]
        y_test = 2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns], 2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns], 2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns], 2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns], 2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns], y=2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns]
        y = 2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0          0         1         2         3... -0.061238 -0.106368  

[1203 rows x 116 columns], y=2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64, y_pred=array([         nan,          nan,  22559737.75,...         nan,
        41457834.  ,  51884578.  ]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 2142      37537675
1131     103735965
1269      ...     32092761
Name: worldwide_gross, dtype: int64
        y_pred = array([         nan,          nan,  22559737.75,...         nan,
        41457834.  ,  51884578.  ])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 37537675, 103735965,  91036760, ...,   2000093,  52880016,
        32092761]), y_pred=array([         nan,          nan,  22559737.75,...         nan,
        41457834.  ,  51884578.  ]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([         nan,          nan,  22559737.75,...         nan,
        41457834.  ,  51884578.  ])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([         nan,          nan,  22559737.75,...         nan,
        41457834.  ,  51884578.  ]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([         nan,          nan,  22559737.75,...         nan,
        41457834.  ,  51884578.  ])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([         nan,          nan,  22559737.75,...         nan,
        41457834.  ,  51884578.  ]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 67  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  39.3s
[CV]  ................................................................
[CV] ................................................. , total=  43.1s
[CV]  ................................................................
[CV] ................................................. , total=  46.1s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.3009402]), 'std_score_time': array([ 0.26605833]), 'split1_test_score': array([-0.26844022]), 'mean_train_score': array([-0.28990048]), 'std_train_score': array([ 0.0109272]), 'std_test_score': array([ 0.03725612]), 'params': ({},), 'split0_train_score': array([-0.28618682]), 'std_fit_time': array([ 3.15234924]), 'split1_train_score': array([-0.29878958]), 'mean_test_score': array([-0.2948328]), 'split0_test_score': array([-0.29954529]), 'split2_test_score': array([-0.35362222]), 'mean_score_time': array([ 0.17354655]), 'split3_test_score': array([-0.25772348]), 'split2_train_score': array([-0.2736853]), 'mean_fit_time': array([ 43.59145659])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.294832801373
####################################################################################
################# Runing the itteration 68  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.3s
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
GREP_ME***Results of [SVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.1330542]), 'std_score_time': array([ 0.01038446]), 'split1_test_score': array([-0.15392766]), 'mean_train_score': array([-0.13209844]), 'std_train_score': array([ 0.0032237]), 'std_test_score': array([ 0.01268481]), 'params': ({},), 'split0_train_score': array([-0.12865904]), 'std_fit_time': array([ 0.03956207]), 'split1_train_score': array([-0.12975265]), 'mean_test_score': array([-0.13292975]), 'split0_test_score': array([-0.11995753]), 'split2_test_score': array([-0.12786315]), 'mean_score_time': array([ 0.68629044]), 'split3_test_score': array([-0.12997066]), 'split2_train_score': array([-0.13692787]), 'mean_fit_time': array([ 2.64559066])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132929749716
####################################################################################
################# Runing the itteration 69  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.29621742]), 'std_score_time': array([ 0.01835061]), 'split1_test_score': array([-0.26677012]), 'mean_train_score': array([-0.28955628]), 'std_train_score': array([ 0.00843683]), 'std_test_score': array([ 0.02708465]), 'params': ({},), 'split0_train_score': array([-0.27666627]), 'std_fit_time': array([ 0.00113698]), 'split1_train_score': array([-0.2979051]), 'mean_test_score': array([-0.29131921]), 'split0_test_score': array([-0.33407341]), 'split2_test_score': array([-0.29521706]), 'mean_score_time': array([ 0.02029032]), 'split3_test_score': array([-0.26921625]), 'split2_train_score': array([-0.28743632]), 'mean_fit_time': array([ 0.03017342])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291319209179
####################################################################################
################# Runing the itteration 70  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
GREP_ME***Results of [NuSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.05331887]), 'std_score_time': array([ 0.00510977]), 'split1_test_score': array([-0.04775125]), 'mean_train_score': array([-0.05233937]), 'std_train_score': array([ 0.00173807]), 'std_test_score': array([ 0.00349201]), 'params': ({},), 'split0_train_score': array([-0.05092965]), 'std_fit_time': array([ 0.03527567]), 'split1_train_score': array([-0.05468101]), 'mean_test_score': array([-0.0524817]), 'split0_test_score': array([-0.05050805]), 'split2_test_score': array([-0.05570797]), 'mean_score_time': array([ 0.35000277]), 'split3_test_score': array([-0.05595952]), 'split2_train_score': array([-0.05042795]), 'mean_fit_time': array([ 2.03460115])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0524816975747
####################################################################################
################# Runing the itteration 71  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00011863]), 'split1_test_score': array([ 0.27941597]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.04998334]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00280278]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.31172247]), 'split0_test_score': array([ 0.38652042]), 'split2_test_score': array([ 0.25546151]), 'mean_score_time': array([ 0.00206751]), 'split3_test_score': array([ 0.32549196]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.1211741])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.311722465951
####################################################################################
################# Runing the itteration 72  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.0004458]), 'split1_test_score': array([ 0.27557971]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.07716044]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00451323]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.37037136]), 'split0_test_score': array([ 0.3983993]), 'split2_test_score': array([ 0.32689225]), 'mean_score_time': array([ 0.00224411]), 'split3_test_score': array([ 0.48061416]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.06440961])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.370371357273
####################################################################################
################# Runing the itteration 73  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.04331022]), 'std_score_time': array([ 0.0024835]), 'split1_test_score': array([ 0.17536393]), 'mean_train_score': array([ 0.22389567]), 'std_train_score': array([ 0.23189156]), 'std_test_score': array([ 0.3367728]), 'params': ({},), 'split0_train_score': array([ 0.13021511]), 'std_fit_time': array([ 0.19946921]), 'split1_train_score': array([ 0.21752319]), 'mean_test_score': array([ 0.05980043]), 'split0_test_score': array([-0.02145322]), 'split2_test_score': array([ 0.50800451]), 'mean_score_time': array([ 0.01209706]), 'split3_test_score': array([-0.4227135]), 'split2_train_score': array([ 0.59115462]), 'mean_fit_time': array([ 0.81489187])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.0598004301644
####################################################################################
################# Runing the itteration 74  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.92157518]), 'std_score_time': array([ 0.00135681]), 'split1_test_score': array([ 0.60784729]), 'mean_train_score': array([ 0.92877722]), 'std_train_score': array([ 0.0052946]), 'std_test_score': array([ 0.02101703]), 'params': ({},), 'split0_train_score': array([ 0.93220451]), 'std_fit_time': array([ 0.02800905]), 'split1_train_score': array([ 0.93521383]), 'mean_test_score': array([ 0.63000231]), 'split0_test_score': array([ 0.66343627]), 'split2_test_score': array([ 0.61748604]), 'mean_score_time': array([ 0.01206172]), 'split3_test_score': array([ 0.63123963]), 'split2_train_score': array([ 0.92611535]), 'mean_fit_time': array([ 1.11195409])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.630002308227
####################################################################################
################# Runing the itteration 75  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00034416]), 'split1_test_score': array([ 0.61510848]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.01791687]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.01689964]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.60520961]), 'split0_test_score': array([ 0.57598556]), 'split2_test_score': array([ 0.60634895]), 'mean_score_time': array([ 0.00750631]), 'split3_test_score': array([ 0.62339547]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.60921615])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.605209614913
####################################################################################
################# Runing the itteration 76  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.8040757]), 'std_score_time': array([ 0.0014161]), 'split1_test_score': array([ 0.71655127]), 'mean_train_score': array([ 0.80668456]), 'std_train_score': array([ 0.0054242]), 'std_test_score': array([ 0.0380109]), 'params': ({},), 'split0_train_score': array([ 0.81441703]), 'std_fit_time': array([ 0.01252891]), 'split1_train_score': array([ 0.79976586]), 'mean_test_score': array([ 0.67051353]), 'split0_test_score': array([ 0.62963817]), 'split2_test_score': array([ 0.69936259]), 'mean_score_time': array([ 0.00761867]), 'split3_test_score': array([ 0.63650209]), 'split2_train_score': array([ 0.80847962]), 'mean_fit_time': array([ 1.0872066])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.670513529718
####################################################################################
################# Runing the itteration 77  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.9381987]), 'std_score_time': array([ 0.00287794]), 'split1_test_score': array([ 0.66119434]), 'mean_train_score': array([ 0.93981263]), 'std_train_score': array([ 0.00365907]), 'std_test_score': array([ 0.02127951]), 'params': ({},), 'split0_train_score': array([ 0.94338181]), 'std_fit_time': array([ 0.02706591]), 'split1_train_score': array([ 0.94309527]), 'mean_test_score': array([ 0.66169482]), 'split0_test_score': array([ 0.68965641]), 'split2_test_score': array([ 0.66602131]), 'mean_score_time': array([ 0.00994283]), 'split3_test_score': array([ 0.62990723]), 'split2_train_score': array([ 0.93457472]), 'mean_fit_time': array([ 1.07005727])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.661694823294
####################################################################################
################# Runing the itteration 78  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.64016175]), 'std_score_time': array([ 0.00601859]), 'split1_test_score': array([ 0.57664848]), 'mean_train_score': array([ 0.62213466]), 'std_train_score': array([ 0.01455752]), 'std_test_score': array([ 0.04313323]), 'params': ({},), 'split0_train_score': array([ 0.62130556]), 'std_fit_time': array([ 0.01157872]), 'split1_train_score': array([ 0.62721295]), 'mean_test_score': array([ 0.59889723]), 'split0_test_score': array([ 0.60328105]), 'split2_test_score': array([ 0.66600228]), 'mean_score_time': array([ 0.0242309]), 'split3_test_score': array([ 0.5496571]), 'split2_train_score': array([ 0.59985837]), 'mean_fit_time': array([ 0.14546132])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.598897228544
####################################################################################
################# Runing the itteration 79  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.33053833]), 'std_score_time': array([ 0.00070718]), 'split1_test_score': array([ 0.32627079]), 'mean_train_score': array([ 0.33042669]), 'std_train_score': array([ 0.00597198]), 'std_test_score': array([ 0.00833315]), 'params': ({},), 'split0_train_score': array([ 0.33343682]), 'std_fit_time': array([ 0.06966095]), 'split1_train_score': array([ 0.33688801]), 'mean_test_score': array([ 0.32159279]), 'split0_test_score': array([ 0.3265062]), 'split2_test_score': array([ 0.32643405]), 'mean_score_time': array([ 0.00479978]), 'split3_test_score': array([ 0.3071601]), 'split2_train_score': array([ 0.32084358]), 'mean_fit_time': array([ 0.45161247])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.32159278578
####################################################################################
################# Runing the itteration 80  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [Lasso] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.65836555]), 'std_score_time': array([ 0.0073248]), 'split1_test_score': array([-109.46637361]), 'mean_train_score': array([ 0.65284013]), 'std_train_score': array([ 0.01193006]), 'std_test_score': array([ 47.64248494]), 'params': ({},), 'split0_train_score': array([ 0.66859156]), 'std_fit_time': array([ 0.04327432]), 'split1_train_score': array([ 0.63653093]), 'mean_test_score': array([-26.94719705]), 'split0_test_score': array([ 0.49886275]), 'split2_test_score': array([ 0.6079396]), 'mean_score_time': array([ 0.01971054]), 'split3_test_score': array([ 0.57078307]), 'split2_train_score': array([ 0.64787249]), 'mean_fit_time': array([ 1.16829139])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-26.947197049
####################################################################################
################# Runing the itteration 81  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63306242]), 'std_score_time': array([ 0.01048174]), 'split1_test_score': array([ 0.60204703]), 'mean_train_score': array([ 0.6393178]), 'std_train_score': array([ 0.01733391]), 'std_test_score': array([ 1.24412639]), 'params': ({},), 'split0_train_score': array([ 0.66654341]), 'std_fit_time': array([ 0.03140683]), 'split1_train_score': array([ 0.63887306]), 'mean_test_score': array([-0.07602606]), 'split0_test_score': array([-2.23034814]), 'split2_test_score': array([ 0.68282961]), 'mean_score_time': array([ 0.01279134]), 'split3_test_score': array([ 0.64136727]), 'split2_train_score': array([ 0.61879231]), 'mean_fit_time': array([ 0.12331742])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0760260596475
####################################################################################
################# Runing the itteration 82  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.66375505]), 'std_score_time': array([ 0.00874884]), 'split1_test_score': array([-12.41493918]), 'mean_train_score': array([ 0.65156674]), 'std_train_score': array([ 0.00727738]), 'std_test_score': array([ 5.33798044]), 'params': ({},), 'split0_train_score': array([ 0.64614076]), 'std_fit_time': array([ 0.01703323]), 'split1_train_score': array([ 0.64584245]), 'mean_test_score': array([-3.33695061]), 'split0_test_score': array([ 0.53867578]), 'split2_test_score': array([-1.96326658]), 'mean_score_time': array([ 0.01152247]), 'split3_test_score': array([ 0.49172754]), 'split2_train_score': array([ 0.65052871]), 'mean_fit_time': array([ 0.14659399])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3.33695061115
####################################################################################
################# Runing the itteration 83  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.30563559]), 'std_score_time': array([ 0.0132437]), 'split1_test_score': array([-0.28964042]), 'mean_train_score': array([-0.28866741]), 'std_train_score': array([ 0.01052777]), 'std_test_score': array([ 0.02852804]), 'params': ({},), 'split0_train_score': array([-0.284078]), 'std_fit_time': array([ 0.00091005]), 'split1_train_score': array([-0.28785094]), 'mean_test_score': array([-0.2913238]), 'split0_test_score': array([-0.30382329]), 'split2_test_score': array([-0.32488902]), 'mean_score_time': array([ 0.02015054]), 'split3_test_score': array([-0.24694247]), 'split2_train_score': array([-0.27710509]), 'mean_fit_time': array([ 0.0299753])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.291323800755
####################################################################################
################# Runing the itteration 84  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   2.0s
GREP_ME***Results of [Ridge] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63408438]), 'std_score_time': array([ 0.00215634]), 'split1_test_score': array([ 0.09301952]), 'mean_train_score': array([ 0.6541859]), 'std_train_score': array([ 0.01356211]), 'std_test_score': array([ 0.20353542]), 'params': ({},), 'split0_train_score': array([ 0.65080803]), 'std_fit_time': array([ 0.10939747]), 'split1_train_score': array([ 0.67064794]), 'mean_test_score': array([ 0.42464668]), 'split0_test_score': array([ 0.62089015]), 'split2_test_score': array([ 0.55579807]), 'mean_score_time': array([ 0.00536907]), 'split3_test_score': array([ 0.42887898]), 'split2_train_score': array([ 0.66120324]), 'mean_fit_time': array([ 1.87968212])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.424646681067
####################################################################################
################# Runing the itteration 85  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-795034.95937165]), 'std_score_time': array([ 0.00243193]), 'split1_test_score': array([-11746.97616822]), 'mean_train_score': array([-1214109.09025044]), 'std_train_score': array([ 1153972.44744861]), 'std_test_score': array([ 27701.05408408]), 'params': ({},), 'split0_train_score': array([-864677.26671008]), 'std_fit_time': array([ 0.00486691]), 'split1_train_score': array([-59924.02671566]), 'mean_test_score': array([-59556.06952669]), 'split0_test_score': array([-76262.70325643]), 'split2_test_score': array([-78339.25491479]), 'mean_score_time': array([ 0.01451558]), 'split3_test_score': array([-71875.34376731]), 'split2_train_score': array([-3136800.10820439]), 'mean_fit_time': array([ 0.03258723])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-59556.0695267
####################################################################################
################# Runing the itteration 86  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63863982]), 'std_score_time': array([ 0.00678123]), 'split1_test_score': array([ 0.61520227]), 'mean_train_score': array([ 0.62897374]), 'std_train_score': array([ 0.01454215]), 'std_test_score': array([ 0.0400124]), 'params': ({},), 'split0_train_score': array([ 0.60580384]), 'std_fit_time': array([ 0.01727518]), 'split1_train_score': array([ 0.62783758]), 'mean_test_score': array([ 0.60537844]), 'split0_test_score': array([ 0.66665686]), 'split2_test_score': array([ 0.56631661]), 'mean_score_time': array([ 0.01198143]), 'split3_test_score': array([ 0.57333803]), 'split2_train_score': array([ 0.6436137]), 'mean_fit_time': array([ 0.07423878])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.605378441932
####################################################################################
################# Runing the itteration 87  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.5s
[CV]  ................................................................
[CV] ................................................. , total=   2.9s
[CV]  ................................................................
[CV] ................................................. , total=   2.9s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ -3.19608788e+21]), 'std_score_time': array([ 0.00434075]), 'split1_test_score': array([ -2.28678411e+22]), 'mean_train_score': array([ -1.15745920e+23]), 'std_train_score': array([  1.84399884e+23]), 'std_test_score': array([  2.39141974e+23]), 'params': ({},), 'split0_train_score': array([ -2.03974018e+20]), 'std_fit_time': array([ 0.24065032]), 'split1_train_score': array([ -2.48736155e+22]), 'mean_test_score': array([ -1.47610348e+23]), 'split0_test_score': array([ -1.63969583e+20]), 'split2_test_score': array([ -5.61563580e+23]), 'mean_score_time': array([ 0.00687408]), 'split3_test_score': array([ -5.84600198e+21]), 'split2_train_score': array([ -4.34710004e+23]), 'mean_fit_time': array([ 2.87467647])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.47610348128e+23
####################################################################################
################# Runing the itteration 88  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63386722]), 'std_score_time': array([ 0.04427006]), 'split1_test_score': array([ 0.41971087]), 'mean_train_score': array([ 0.64148571]), 'std_train_score': array([ 0.00506165]), 'std_test_score': array([ 0.05733493]), 'params': ({},), 'split0_train_score': array([ 0.64505726]), 'std_fit_time': array([ 0.00621747]), 'split1_train_score': array([ 0.64693665]), 'mean_test_score': array([ 0.43353087]), 'split0_test_score': array([ 0.48542915]), 'split2_test_score': array([ 0.34542736]), 'mean_score_time': array([ 0.72305584]), 'split3_test_score': array([ 0.48355609]), 'split2_train_score': array([ 0.64008171]), 'mean_fit_time': array([ 0.0556376])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.433530868767
####################################################################################
################# Runing the itteration 89  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_5', label_fn=<function label_gross_5>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40634780247058638}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56988545978877381}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.86304212,
        -0.06123763, -0.10636806]])}
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40634780247058638}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56988545978877381}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], y=1092    108119662
2598     23299151
886     1408...        32544
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.40634780247058638}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56988545978877381}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns]
        y = 1092    108119662
2598     23299151
886     1408...        32544
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], y=1092    108119662
2598     23299151
886     1408...        32544
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns]
        y = 1092    108119662
2598     23299151
886     1408...        32544
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], y=1092    108119662
2598     23299151
886     1408...        32544
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 16:24:59 2017
PID: 17900                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], 1092    108119662
2598     23299151
886     1408...        32544
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], 1092    108119662
2598     23299151
886     1408...        32544
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 128 columns], y=1092    108119662
2598     23299151
886     1408...        32544
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns]
        y_test = 1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], y_test=1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns]
        y_test = 1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], 1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], 1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], 1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], 1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], y=1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns]
        y = 1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 128 columns], y=1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64, y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 1092    108119662
2598     23299151
886     1408...      9345061
Name: worldwide_gross, dtype: int64
        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([108119662,  23299151, 140894685, ...,  94944017, 329809326,
         9345061]), y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 90  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  32.6s
[CV]  ................................................................
[CV] ................................................. , total=  33.5s
[CV]  ................................................................
[CV] ................................................. , total=  35.2s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.2854225]), 'std_score_time': array([ 0.00605067]), 'split1_test_score': array([-0.28214437]), 'mean_train_score': array([-0.28979614]), 'std_train_score': array([ 0.00342972]), 'std_test_score': array([ 0.01438046]), 'params': ({},), 'split0_train_score': array([-0.29430128]), 'std_fit_time': array([ 1.25368152]), 'split1_train_score': array([-0.29168209]), 'mean_test_score': array([-0.29453099]), 'split0_test_score': array([-0.2838597]), 'split2_test_score': array([-0.29393451]), 'mean_score_time': array([ 0.01248699]), 'split3_test_score': array([-0.31818537]), 'split2_train_score': array([-0.28777869]), 'mean_fit_time': array([ 34.26222318])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.294530988217
####################################################################################
################# Runing the itteration 91  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
[CV]  ................................................................
[CV] ................................................. , total=   3.6s
GREP_ME***Results of [SVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.13249481]), 'std_score_time': array([ 0.01126629]), 'split1_test_score': array([-0.12797027]), 'mean_train_score': array([-0.13190619]), 'std_train_score': array([ 0.0051441]), 'std_test_score': array([ 0.02296128]), 'params': ({},), 'split0_train_score': array([-0.13871756]), 'std_fit_time': array([ 0.06984559]), 'split1_train_score': array([-0.13218906]), 'mean_test_score': array([-0.13413209]), 'split0_test_score': array([-0.12308805]), 'split2_test_score': array([-0.1727427]), 'mean_score_time': array([ 0.74707919]), 'split3_test_score': array([-0.11272735]), 'split2_train_score': array([-0.12422335]), 'mean_fit_time': array([ 2.81611174])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.13413209242
####################################################################################
################# Runing the itteration 92  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28462873]), 'std_score_time': array([ 0.01359236]), 'split1_test_score': array([-0.29557179]), 'mean_train_score': array([-0.289409]), 'std_train_score': array([ 0.00354261]), 'std_test_score': array([ 0.01032229]), 'params': ({},), 'split0_train_score': array([-0.29234086]), 'std_fit_time': array([ 0.00079048]), 'split1_train_score': array([-0.28741385]), 'mean_test_score': array([-0.28991731]), 'split0_test_score': array([-0.28233796]), 'split2_test_score': array([-0.27793898]), 'mean_score_time': array([ 0.02646571]), 'split3_test_score': array([-0.3038205]), 'split2_train_score': array([-0.29325257]), 'mean_fit_time': array([ 0.02979726])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.289917306936
####################################################################################
################# Runing the itteration 93  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.5s
GREP_ME***Results of [NuSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.05136978]), 'std_score_time': array([ 0.00450191]), 'split1_test_score': array([-0.06915547]), 'mean_train_score': array([-0.05243379]), 'std_train_score': array([ 0.00290925]), 'std_test_score': array([ 0.00974342]), 'params': ({},), 'split0_train_score': array([-0.05660628]), 'std_fit_time': array([ 0.0547186]), 'split1_train_score': array([-0.04859026]), 'mean_test_score': array([-0.05309584]), 'split0_test_score': array([-0.04415313]), 'split2_test_score': array([-0.05241211]), 'mean_score_time': array([ 0.37074524]), 'split3_test_score': array([-0.04666264]), 'split2_train_score': array([-0.05316885]), 'mean_fit_time': array([ 2.20487046])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0530958379257
####################################################################################
################# Runing the itteration 94  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00023139]), 'split1_test_score': array([ 0.44361432]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.08716874]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00573464]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.42847537]), 'split0_test_score': array([ 0.28600896]), 'split2_test_score': array([ 0.4624612]), 'mean_score_time': array([ 0.00287575]), 'split3_test_score': array([ 0.52181698]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.19262075])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.428475367982
####################################################################################
################# Runing the itteration 95  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00010372]), 'split1_test_score': array([ 0.32179994]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.07535865]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.01060661]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.44089811]), 'split0_test_score': array([ 0.52987824]), 'split2_test_score': array([ 0.4649103]), 'mean_score_time': array([ 0.00268936]), 'split3_test_score': array([ 0.44700398]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.08793455])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.440898114102
####################################################################################
################# Runing the itteration 96  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.49641841]), 'std_score_time': array([ 0.00100022]), 'split1_test_score': array([ 0.38250195]), 'mean_train_score': array([ 0.51226149]), 'std_train_score': array([ 0.06126307]), 'std_test_score': array([ 0.03106596]), 'params': ({},), 'split0_train_score': array([ 0.5538352]), 'std_fit_time': array([ 0.06663705]), 'split1_train_score': array([ 0.41970224]), 'mean_test_score': array([ 0.41715085]), 'split0_test_score': array([ 0.40309584]), 'split2_test_score': array([ 0.46676396]), 'mean_score_time': array([ 0.00680286]), 'split3_test_score': array([ 0.41624163]), 'split2_train_score': array([ 0.57909012]), 'mean_fit_time': array([ 0.48052406])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.417150845252
####################################################################################
################# Runing the itteration 97  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.92238298]), 'std_score_time': array([ 0.00253553]), 'split1_test_score': array([ 0.56713796]), 'mean_train_score': array([ 0.92504796]), 'std_train_score': array([ 0.00446802]), 'std_test_score': array([ 0.01556494]), 'params': ({},), 'split0_train_score': array([ 0.93272597]), 'std_fit_time': array([ 0.0420054]), 'split1_train_score': array([ 0.92332689]), 'mean_test_score': array([ 0.59216628]), 'split0_test_score': array([ 0.60534088]), 'split2_test_score': array([ 0.60512263]), 'mean_score_time': array([ 0.01315475]), 'split3_test_score': array([ 0.59106363]), 'split2_train_score': array([ 0.92175602]), 'mean_fit_time': array([ 0.83122683])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.592166275337
####################################################################################
################# Runing the itteration 98  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00041746]), 'split1_test_score': array([ 0.58582666]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.03698219]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.0229402]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.5578559]), 'split0_test_score': array([ 0.49420551]), 'split2_test_score': array([ 0.57520813]), 'mean_score_time': array([ 0.007581]), 'split3_test_score': array([ 0.57618332]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.68557233])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.55785590418
####################################################################################
################# Runing the itteration 99  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.74694216]), 'std_score_time': array([ 0.00406001]), 'split1_test_score': array([ 0.59286367]), 'mean_train_score': array([ 0.76786858]), 'std_train_score': array([ 0.01234667]), 'std_test_score': array([ 0.03705128]), 'params': ({},), 'split0_train_score': array([ 0.77271037]), 'std_fit_time': array([ 0.03831785]), 'split1_train_score': array([ 0.77899683]), 'mean_test_score': array([ 0.58946235]), 'split0_test_score': array([ 0.59774983]), 'split2_test_score': array([ 0.53193321]), 'mean_score_time': array([ 0.01014048]), 'split3_test_score': array([ 0.63530268]), 'split2_train_score': array([ 0.77282496]), 'mean_fit_time': array([ 1.31959844])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.589462347398
####################################################################################
################# Runing the itteration 100  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.92417767]), 'std_score_time': array([ 0.00020693]), 'split1_test_score': array([ 0.50692214]), 'mean_train_score': array([ 0.92625355]), 'std_train_score': array([ 0.00237683]), 'std_test_score': array([ 0.0354418]), 'params': ({},), 'split0_train_score': array([ 0.92630949]), 'std_fit_time': array([ 0.01942414]), 'split1_train_score': array([ 0.93011349]), 'mean_test_score': array([ 0.56728791]), 'split0_test_score': array([ 0.59744332]), 'split2_test_score': array([ 0.57967493]), 'mean_score_time': array([ 0.0069955]), 'split3_test_score': array([ 0.58511124]), 'split2_train_score': array([ 0.92441355]), 'mean_fit_time': array([ 0.79942024])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.567287907147
####################################################################################
################# Runing the itteration 101  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.53222004]), 'std_score_time': array([ 0.02375258]), 'split1_test_score': array([ 0.49665622]), 'mean_train_score': array([ 0.5526301]), 'std_train_score': array([ 0.01302827]), 'std_test_score': array([ 0.0288944]), 'params': ({},), 'split0_train_score': array([ 0.55037287]), 'std_fit_time': array([ 0.00629041]), 'split1_train_score': array([ 0.56439659]), 'mean_test_score': array([ 0.51105305]), 'split0_test_score': array([ 0.500989]), 'split2_test_score': array([ 0.48632523]), 'mean_score_time': array([ 0.04068315]), 'split3_test_score': array([ 0.56024174]), 'split2_train_score': array([ 0.56353091]), 'mean_fit_time': array([ 0.16082692])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.511053045552
####################################################################################
################# Runing the itteration 102  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.21930246]), 'std_score_time': array([ 0.00161358]), 'split1_test_score': array([ 0.21418193]), 'mean_train_score': array([ 0.21650831]), 'std_train_score': array([ 0.00180607]), 'std_test_score': array([ 0.00779958]), 'params': ({},), 'split0_train_score': array([ 0.21651493]), 'std_fit_time': array([ 0.19686008]), 'split1_train_score': array([ 0.21591974]), 'mean_test_score': array([ 0.20900879]), 'split0_test_score': array([ 0.2189491]), 'split2_test_score': array([ 0.20011893]), 'mean_score_time': array([ 0.00675249]), 'split3_test_score': array([ 0.20278519]), 'split2_train_score': array([ 0.21429613]), 'mean_fit_time': array([ 0.53437155])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.20900878736
####################################################################################
################# Runing the itteration 103  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [Lasso] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63189188]), 'std_score_time': array([ 0.00286566]), 'split1_test_score': array([ 0.58341713]), 'mean_train_score': array([ 0.62239329]), 'std_train_score': array([ 0.00632734]), 'std_test_score': array([ 0.02137947]), 'params': ({},), 'split0_train_score': array([ 0.62187878]), 'std_fit_time': array([ 0.02060291]), 'split1_train_score': array([ 0.61407399]), 'mean_test_score': array([ 0.56059008]), 'split0_test_score': array([ 0.56067926]), 'split2_test_score': array([ 0.5719866]), 'mean_score_time': array([ 0.0138976]), 'split3_test_score': array([ 0.52627734]), 'split2_train_score': array([ 0.62172852]), 'mean_fit_time': array([ 1.7379247])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.560590084267
####################################################################################
################# Runing the itteration 104  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [LassoLars] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.62904896]), 'std_score_time': array([ 0.00497276]), 'split1_test_score': array([ 0.56924958]), 'mean_train_score': array([ 0.60743754]), 'std_train_score': array([ 0.0156721]), 'std_test_score': array([ 0.02052166]), 'params': ({},), 'split0_train_score': array([ 0.60799329]), 'std_fit_time': array([ 0.10240053]), 'split1_train_score': array([ 0.60796012]), 'mean_test_score': array([ 0.56176518]), 'split0_test_score': array([ 0.58326827]), 'split2_test_score': array([ 0.56658487]), 'mean_score_time': array([ 0.00907379]), 'split3_test_score': array([ 0.527958]), 'split2_train_score': array([ 0.58474781]), 'mean_fit_time': array([ 0.36327928])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.56176518056
####################################################################################
################# Runing the itteration 105  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.60071491]), 'std_score_time': array([ 0.00176792]), 'split1_test_score': array([ 0.47092048]), 'mean_train_score': array([ 0.6215648]), 'std_train_score': array([ 0.01425896]), 'std_test_score': array([ 0.06100345]), 'params': ({},), 'split0_train_score': array([ 0.63180656]), 'std_fit_time': array([ 0.0332961]), 'split1_train_score': array([ 0.63729465]), 'mean_test_score': array([ 0.5544943]), 'split0_test_score': array([ 0.52934426]), 'split2_test_score': array([ 0.58279728]), 'mean_score_time': array([ 0.00713152]), 'split3_test_score': array([ 0.63491517]), 'split2_train_score': array([ 0.61644308]), 'mean_fit_time': array([ 0.21460867])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.554494295889
####################################################################################
################# Runing the itteration 106  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28453056]), 'std_score_time': array([ 0.00334316]), 'split1_test_score': array([-0.2468585]), 'mean_train_score': array([-0.28897736]), 'std_train_score': array([ 0.01093756]), 'std_test_score': array([ 0.03097558]), 'params': ({},), 'split0_train_score': array([-0.27635181]), 'std_fit_time': array([ 0.01268488]), 'split1_train_score': array([-0.30627736]), 'mean_test_score': array([-0.29354262]), 'split0_test_score': array([-0.33186532]), 'split2_test_score': array([-0.28892123]), 'mean_score_time': array([ 0.01815856]), 'split3_test_score': array([-0.30652544]), 'split2_train_score': array([-0.28874971]), 'mean_fit_time': array([ 0.04470336])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293542623041
####################################################################################
################# Runing the itteration 107  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.7s
[CV]  ................................................................
[CV] ................................................. , total=   2.7s
[CV]  ................................................................
[CV] ................................................. , total=   2.8s
GREP_ME***Results of [Ridge] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.61349556]), 'std_score_time': array([ 0.00303197]), 'split1_test_score': array([ 0.48436039]), 'mean_train_score': array([ 0.62205939]), 'std_train_score': array([ 0.01549332]), 'std_test_score': array([ 0.05656921]), 'params': ({},), 'split0_train_score': array([ 0.6011864]), 'std_fit_time': array([ 0.09656839]), 'split1_train_score': array([ 0.63378717]), 'mean_test_score': array([ 0.55165083]), 'split0_test_score': array([ 0.62137155]), 'split2_test_score': array([ 0.50915392]), 'mean_score_time': array([ 0.00880212]), 'split3_test_score': array([ 0.59171745]), 'split2_train_score': array([ 0.63976843]), 'mean_fit_time': array([ 2.79240292])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.551650828262
####################################################################################
################# Runing the itteration 108  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.58073564]), 'std_score_time': array([ 0.00954112]), 'split1_test_score': array([ 0.48799589]), 'mean_train_score': array([ 0.58499533]), 'std_train_score': array([ 0.00495414]), 'std_test_score': array([ 0.02238919]), 'params': ({},), 'split0_train_score': array([ 0.58724687]), 'std_fit_time': array([ 0.00073158]), 'split1_train_score': array([ 0.59203858]), 'mean_test_score': array([ 0.51384222]), 'split0_test_score': array([ 0.52812024]), 'split2_test_score': array([ 0.54271638]), 'mean_score_time': array([ 0.02380019]), 'split3_test_score': array([ 0.49653639]), 'split2_train_score': array([ 0.57996022]), 'mean_fit_time': array([ 0.03734303])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.513842224974
####################################################################################
################# Runing the itteration 109  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.60086006]), 'std_score_time': array([ 0.00474154]), 'split1_test_score': array([ 0.61798575]), 'mean_train_score': array([ 0.59683576]), 'std_train_score': array([ 0.0110415]), 'std_test_score': array([ 0.03339387]), 'params': ({},), 'split0_train_score': array([ 0.60952664]), 'std_fit_time': array([ 0.0157479]), 'split1_train_score': array([ 0.57923949]), 'mean_test_score': array([ 0.56474265]), 'split0_test_score': array([ 0.545047]), 'split2_test_score': array([ 0.56634197]), 'mean_score_time': array([ 0.02686638]), 'split3_test_score': array([ 0.52959587]), 'split2_train_score': array([ 0.59771685]), 'mean_fit_time': array([ 0.08466417])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.564742648464
####################################################################################
################# Runing the itteration 110  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   5.5s
[CV]  ................................................................
[CV] ................................................. , total=   5.6s
[CV]  ................................................................
[CV] ................................................. , total=   5.8s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ -8.86542647e+25]), 'std_score_time': array([ 0.01076134]), 'split1_test_score': array([ -1.29548433e+26]), 'mean_train_score': array([ -7.86756085e+25]), 'std_train_score': array([  1.81988719e+25]), 'std_test_score': array([  4.24866541e+25]), 'params': ({},), 'split0_train_score': array([ -9.49477926e+25]), 'std_fit_time': array([ 0.13151416]), 'split1_train_score': array([ -8.30984774e+25]), 'mean_test_score': array([ -8.61845083e+25]), 'split0_test_score': array([ -4.28917119e+25]), 'split2_test_score': array([ -4.45210425e+25]), 'mean_score_time': array([ 0.01723343]), 'split3_test_score': array([ -1.27776846e+26]), 'split2_train_score': array([ -4.80018994e+25]), 'mean_fit_time': array([ 5.6563012])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-8.61845082832e+25
####################################################################################
################# Runing the itteration 111  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.6074577]), 'std_score_time': array([ 0.15784775]), 'split1_test_score': array([ 0.38488443]), 'mean_train_score': array([ 0.59308484]), 'std_train_score': array([ 0.01310861]), 'std_test_score': array([ 0.02237049]), 'params': ({},), 'split0_train_score': array([ 0.60479647]), 'std_fit_time': array([ 0.0053462]), 'split1_train_score': array([ 0.57873863]), 'mean_test_score': array([ 0.35879859]), 'split0_test_score': array([ 0.33053728]), 'split2_test_score': array([ 0.37601421]), 'mean_score_time': array([ 0.89811945]), 'split3_test_score': array([ 0.34375845]), 'split2_train_score': array([ 0.58134655]), 'mean_fit_time': array([ 0.04953659])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.358798592906
####################################################################################
################# Runing the itteration 112  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_5', label_fn=<function label_gross_5>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56988545978877381}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56988545978877381}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=2282      32968648
687      176885658
3659      ...    121706019
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56988545978877381}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns]
        y = 2282      32968648
687      176885658
3659      ...    121706019
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=2282      32968648
687      176885658
3659      ...    121706019
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns]
        y = 2282      32968648
687      176885658
3659      ...    121706019
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=2282      32968648
687      176885658
3659      ...    121706019
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 16:33:17 2017
PID: 19197                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], 2282      32968648
687      176885658
3659      ...    121706019
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], 2282      32968648
687      176885658
3659      ...    121706019
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[4812 rows x 194 columns], y=2282      32968648
687      176885658
3659      ...    121706019
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y_test = 2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y_test=2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y_test = 2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], 2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y=2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns]
        y = 2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.043288 -0.106368  

[1203 rows x 194 columns], y=2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64, y_pred=array([  2.86495560e+07,              nan,      ...0251024e+07,   1.09111734e+08,   3.22688177e+07]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 2282      32968648
687      176885658
3659      ...      5516708
Name: worldwide_gross, dtype: int64
        y_pred = array([  2.86495560e+07,              nan,      ...0251024e+07,   1.09111734e+08,   3.22688177e+07])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 32968648, 176885658,   3721988, ...,  12592907, 121706019,
         5516708]), y_pred=array([  2.86495560e+07,              nan,      ...0251024e+07,   1.09111734e+08,   3.22688177e+07]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([  2.86495560e+07,              nan,      ...0251024e+07,   1.09111734e+08,   3.22688177e+07])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([  2.86495560e+07,              nan,      ...0251024e+07,   1.09111734e+08,   3.22688177e+07]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([  2.86495560e+07,              nan,      ...0251024e+07,   1.09111734e+08,   3.22688177e+07])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([  2.86495560e+07,              nan,      ...0251024e+07,   1.09111734e+08,   3.22688177e+07]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 113  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  56.7s
[CV]  ................................................................
[CV] ................................................. , total= 1.2min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28651876]), 'std_score_time': array([ 0.01409266]), 'split1_test_score': array([-0.3280448]), 'mean_train_score': array([-0.29055519]), 'std_train_score': array([ 0.01775716]), 'std_test_score': array([ 0.04199347]), 'params': ({},), 'split0_train_score': array([-0.27683475]), 'std_fit_time': array([ 6.10035037]), 'split1_train_score': array([-0.27823138]), 'mean_test_score': array([-0.29784506]), 'split0_test_score': array([-0.33446863]), 'split2_test_score': array([-0.22860172]), 'mean_score_time': array([ 0.02783012]), 'split3_test_score': array([-0.30026508]), 'split2_train_score': array([-0.32063587]), 'mean_fit_time': array([ 67.22164088])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.297845057852
####################################################################################
################# Runing the itteration 114  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   4.6s
GREP_ME***Results of [SVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.13510581]), 'std_score_time': array([ 0.01516854]), 'split1_test_score': array([-0.11031432]), 'mean_train_score': array([-0.13155808]), 'std_train_score': array([ 0.00315066]), 'std_test_score': array([ 0.01615984]), 'params': ({},), 'split0_train_score': array([-0.13128464]), 'std_fit_time': array([ 0.05895385]), 'split1_train_score': array([-0.13321371]), 'mean_test_score': array([-0.13271611]), 'split0_test_score': array([-0.14606922]), 'split2_test_score': array([-0.14995809]), 'mean_score_time': array([ 1.04983872]), 'split3_test_score': array([-0.12452283]), 'split2_train_score': array([-0.12662814]), 'mean_fit_time': array([ 3.69882333])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132716114595
####################################################################################
################# Runing the itteration 115  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28160131]), 'std_score_time': array([ 0.00295062]), 'split1_test_score': array([-0.23202033]), 'mean_train_score': array([-0.2902448]), 'std_train_score': array([ 0.01526764]), 'std_test_score': array([ 0.03698458]), 'params': ({},), 'split0_train_score': array([-0.28116469]), 'std_fit_time': array([ 0.00974227]), 'split1_train_score': array([-0.31668758]), 'mean_test_score': array([-0.29597082]), 'split0_test_score': array([-0.31921069]), 'split2_test_score': array([-0.31377645]), 'mean_score_time': array([ 0.01780432]), 'split3_test_score': array([-0.3188758]), 'split2_train_score': array([-0.2815256]), 'mean_fit_time': array([ 0.04379916])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295970817143
####################################################################################
################# Runing the itteration 116  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.2s
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
GREP_ME***Results of [NuSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.05196322]), 'std_score_time': array([ 0.00432104]), 'split1_test_score': array([-0.04977776]), 'mean_train_score': array([-0.05216614]), 'std_train_score': array([ 0.00180993]), 'std_test_score': array([ 0.01434594]), 'params': ({},), 'split0_train_score': array([-0.05516542]), 'std_fit_time': array([ 0.07221798]), 'split1_train_score': array([-0.05104796]), 'mean_test_score': array([-0.05298411]), 'split0_test_score': array([-0.04478386]), 'split2_test_score': array([-0.07713522]), 'mean_score_time': array([ 0.52420479]), 'split3_test_score': array([-0.04023958]), 'split2_train_score': array([-0.05048798]), 'mean_fit_time': array([ 2.84267503])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.052984107514
####################################################################################
################# Runing the itteration 117  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00022318]), 'split1_test_score': array([ 0.07265412]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.12543206]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00317622]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.28312385]), 'split0_test_score': array([ 0.31070915]), 'split2_test_score': array([ 0.39855557]), 'mean_score_time': array([ 0.00283349]), 'split3_test_score': array([ 0.35057657]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.14402473])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.283123852421
####################################################################################
################# Runing the itteration 118  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00018351]), 'split1_test_score': array([ 0.34606691]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.10957979]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.0013342]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.25280049]), 'split0_test_score': array([ 0.27191722]), 'split2_test_score': array([ 0.32438188]), 'mean_score_time': array([ 0.00277925]), 'split3_test_score': array([ 0.06883596]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.08390319])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.252800491576
####################################################################################
################# Runing the itteration 119  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.16803694]), 'std_score_time': array([ 0.00253438]), 'split1_test_score': array([ 0.56994706]), 'mean_train_score': array([ 0.39299412]), 'std_train_score': array([ 0.23544856]), 'std_test_score': array([ 0.18127811]), 'params': ({},), 'split0_train_score': array([ 0.55815331]), 'std_fit_time': array([ 0.14062262]), 'split1_train_score': array([ 0.68941975]), 'mean_test_score': array([ 0.3194136]), 'split0_test_score': array([ 0.38995599]), 'split2_test_score': array([ 0.08090479]), 'mean_score_time': array([ 0.00797266]), 'split3_test_score': array([ 0.23684654]), 'split2_train_score': array([ 0.15636647]), 'mean_fit_time': array([ 0.44725573])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.31941359716
####################################################################################
################# Runing the itteration 120  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.94347177]), 'std_score_time': array([ 0.00046977]), 'split1_test_score': array([ 0.68027565]), 'mean_train_score': array([ 0.93928503]), 'std_train_score': array([ 0.0048694]), 'std_test_score': array([ 0.01400247]), 'params': ({},), 'split0_train_score': array([ 0.94436436]), 'std_fit_time': array([ 0.0156576]), 'split1_train_score': array([ 0.93672397]), 'mean_test_score': array([ 0.67207514]), 'split0_test_score': array([ 0.6785239]), 'split2_test_score': array([ 0.6816049]), 'mean_score_time': array([ 0.0069738]), 'split3_test_score': array([ 0.64789611]), 'split2_train_score': array([ 0.93258004]), 'mean_fit_time': array([ 0.53649104])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.672075141681
####################################################################################
################# Runing the itteration 121  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00029221]), 'split1_test_score': array([ 0.57409693]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.046207]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.01430605]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.63830863]), 'split0_test_score': array([ 0.62963531]), 'split2_test_score': array([ 0.70378445]), 'mean_score_time': array([ 0.00681251]), 'split3_test_score': array([ 0.64571783]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.30112821])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.638308627787
####################################################################################
################# Runing the itteration 122  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.83946955]), 'std_score_time': array([  4.88299571e-05]), 'split1_test_score': array([ 0.66276491]), 'mean_train_score': array([ 0.83043459]), 'std_train_score': array([ 0.00842284]), 'std_test_score': array([ 0.03085394]), 'params': ({},), 'split0_train_score': array([ 0.83187583]), 'std_fit_time': array([ 0.01368255]), 'split1_train_score': array([ 0.8166761]), 'mean_test_score': array([ 0.71379557]), 'split0_test_score': array([ 0.73940949]), 'split2_test_score': array([ 0.73710245]), 'mean_score_time': array([ 0.00345725]), 'split3_test_score': array([ 0.71590543]), 'split2_train_score': array([ 0.83371689]), 'mean_fit_time': array([ 0.57225347])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.713795570253
####################################################################################
################# Runing the itteration 123  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.94087953]), 'std_score_time': array([ 0.00028009]), 'split1_test_score': array([ 0.59374994]), 'mean_train_score': array([ 0.94064093]), 'std_train_score': array([ 0.00574635]), 'std_test_score': array([ 0.08203502]), 'params': ({},), 'split0_train_score': array([ 0.93475182]), 'std_fit_time': array([ 0.00384616]), 'split1_train_score': array([ 0.94984503]), 'mean_test_score': array([ 0.64867503]), 'split0_test_score': array([ 0.73020562]), 'split2_test_score': array([ 0.72729902]), 'mean_score_time': array([ 0.00604165]), 'split3_test_score': array([ 0.54344554]), 'split2_train_score': array([ 0.93708733]), 'mean_fit_time': array([ 0.54457885])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.648675030684
####################################################################################
################# Runing the itteration 124  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.54470629]), 'std_score_time': array([ 0.01150545]), 'split1_test_score': array([ 0.50984216]), 'mean_train_score': array([ 0.5519569]), 'std_train_score': array([ 0.00641079]), 'std_test_score': array([ 0.01889754]), 'params': ({},), 'split0_train_score': array([ 0.55165855]), 'std_fit_time': array([ 0.00127511]), 'split1_train_score': array([ 0.5621827]), 'mean_test_score': array([ 0.5411721]), 'split0_test_score': array([ 0.55627424]), 'split2_test_score': array([ 0.54268457]), 'mean_score_time': array([ 0.02306372]), 'split3_test_score': array([ 0.55588742]), 'split2_train_score': array([ 0.54928005]), 'mean_fit_time': array([ 0.04506594])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.54117209525
####################################################################################
################# Runing the itteration 125  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.2367592]), 'std_score_time': array([  8.12336744e-05]), 'split1_test_score': array([ 0.28692264]), 'mean_train_score': array([ 0.23283798]), 'std_train_score': array([ 0.00582095]), 'std_test_score': array([ 0.03487168]), 'params': ({},), 'split0_train_score': array([ 0.23025936]), 'std_fit_time': array([ 0.05024571]), 'split1_train_score': array([ 0.22466311]), 'mean_test_score': array([ 0.23443219]), 'split0_test_score': array([ 0.24011828]), 'split2_test_score': array([ 0.21920578]), 'mean_score_time': array([ 0.00302088]), 'split3_test_score': array([ 0.19148207]), 'split2_train_score': array([ 0.23967026]), 'mean_fit_time': array([ 0.16376925])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.2344321934
####################################################################################
################# Runing the itteration 126  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.60653149]), 'std_score_time': array([ 0.00391711]), 'split1_test_score': array([ 0.55912334]), 'mean_train_score': array([ 0.62354352]), 'std_train_score': array([ 0.01088823]), 'std_test_score': array([ 0.03861525]), 'params': ({},), 'split0_train_score': array([ 0.6285031]), 'std_fit_time': array([ 0.01554054]), 'split1_train_score': array([ 0.63618703]), 'mean_test_score': array([ 0.60578651]), 'split0_test_score': array([ 0.59115193]), 'split2_test_score': array([ 0.60733025]), 'mean_score_time': array([ 0.02439976]), 'split3_test_score': array([ 0.66554054]), 'split2_train_score': array([ 0.62295246]), 'mean_fit_time': array([ 0.52341449])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.605786513884
####################################################################################
################# Runing the itteration 127  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.60257118]), 'std_score_time': array([ 0.00326848]), 'split1_test_score': array([ 0.60143294]), 'mean_train_score': array([ 0.61367575]), 'std_train_score': array([ 0.0079586]), 'std_test_score': array([ 0.0225766]), 'params': ({},), 'split0_train_score': array([ 0.62474578]), 'std_fit_time': array([ 0.02266101]), 'split1_train_score': array([ 0.61175656]), 'mean_test_score': array([ 0.60534991]), 'split0_test_score': array([ 0.57872687]), 'split2_test_score': array([ 0.60002454]), 'mean_score_time': array([ 0.00529808]), 'split3_test_score': array([ 0.64121526]), 'split2_train_score': array([ 0.61562947]), 'mean_fit_time': array([ 0.08353502])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.605349905389
####################################################################################
################# Runing the itteration 128  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.62667601]), 'std_score_time': array([ 0.00277087]), 'split1_test_score': array([ 0.62255053]), 'mean_train_score': array([ 0.62027446]), 'std_train_score': array([ 0.01147228]), 'std_test_score': array([ 0.03736731]), 'params': ({},), 'split0_train_score': array([ 0.63507181]), 'std_fit_time': array([ 0.01762679]), 'split1_train_score': array([ 0.61424743]), 'mean_test_score': array([ 0.6048905]), 'split0_test_score': array([ 0.55236503]), 'split2_test_score': array([ 0.65319928]), 'mean_score_time': array([ 0.00451648]), 'split3_test_score': array([ 0.59144716]), 'split2_train_score': array([ 0.60510259]), 'mean_fit_time': array([ 0.06958777])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.604890502618
####################################################################################
################# Runing the itteration 129  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28349055]), 'std_score_time': array([ 0.00692418]), 'split1_test_score': array([-0.23626268]), 'mean_train_score': array([-0.28885134]), 'std_train_score': array([ 0.01190587]), 'std_test_score': array([ 0.03498471]), 'params': ({},), 'split0_train_score': array([-0.28707679]), 'std_fit_time': array([ 0.00103088]), 'split1_train_score': array([-0.30838234]), 'mean_test_score': array([-0.29349687]), 'split0_test_score': array([-0.29678217]), 'split2_test_score': array([-0.32924441]), 'mean_score_time': array([ 0.01823807]), 'split3_test_score': array([-0.31169822]), 'split2_train_score': array([-0.27645571]), 'mean_fit_time': array([ 0.01818657])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293496870133
####################################################################################
################# Runing the itteration 130  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
GREP_ME***Results of [Ridge] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.60980165]), 'std_score_time': array([ 0.0050974]), 'split1_test_score': array([ 0.56959633]), 'mean_train_score': array([ 0.61724236]), 'std_train_score': array([ 0.01064357]), 'std_test_score': array([ 0.0317205]), 'params': ({},), 'split0_train_score': array([ 0.62973569]), 'std_fit_time': array([ 0.05287509]), 'split1_train_score': array([ 0.6254149]), 'mean_test_score': array([ 0.5950166]), 'split0_test_score': array([ 0.55785094]), 'split2_test_score': array([ 0.63071329]), 'mean_score_time': array([ 0.01242727]), 'split3_test_score': array([ 0.62190582]), 'split2_train_score': array([ 0.6040172]), 'mean_fit_time': array([ 0.65230829])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.595016595892
####################################################################################
################# Runing the itteration 131  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.58922422]), 'std_score_time': array([ 0.01218656]), 'split1_test_score': array([ 0.59166132]), 'mean_train_score': array([ 0.60567939]), 'std_train_score': array([ 0.01261058]), 'std_test_score': array([ 0.03102464]), 'params': ({},), 'split0_train_score': array([ 0.60975639]), 'std_fit_time': array([ 0.00056082]), 'split1_train_score': array([ 0.60020436]), 'mean_test_score': array([ 0.59075537]), 'split0_test_score': array([ 0.56788252]), 'split2_test_score': array([ 0.56246509]), 'mean_score_time': array([ 0.02254677]), 'split3_test_score': array([ 0.64101256]), 'split2_train_score': array([ 0.62353258]), 'mean_fit_time': array([ 0.01805764])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.590755371063
####################################################################################
################# Runing the itteration 132  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.61628651]), 'std_score_time': array([ 0.00046399]), 'split1_test_score': array([ 0.59610858]), 'mean_train_score': array([ 0.60697227]), 'std_train_score': array([ 0.01191475]), 'std_test_score': array([ 0.03451177]), 'params': ({},), 'split0_train_score': array([ 0.61526449]), 'std_fit_time': array([ 0.01543778]), 'split1_train_score': array([ 0.60951221]), 'mean_test_score': array([ 0.59998264]), 'split0_test_score': array([ 0.56666454]), 'split2_test_score': array([ 0.65696829]), 'mean_score_time': array([ 0.00243974]), 'split3_test_score': array([ 0.58018915]), 'split2_train_score': array([ 0.58682587]), 'mean_fit_time': array([ 0.04310864])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.599982641561
####################################################################################
################# Runing the itteration 133  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ -4.05399407e+18]), 'std_score_time': array([ 0.00030616]), 'split1_test_score': array([ -2.90899486e+18]), 'mean_train_score': array([ -4.17450287e+21]), 'std_train_score': array([  7.22647207e+21]), 'std_test_score': array([  6.75475369e+21]), 'params': ({},), 'split0_train_score': array([-59597.43697342]), 'std_fit_time': array([ 0.17908065]), 'split1_train_score': array([ -2.83809673e+18]), 'mean_test_score': array([ -3.90247199e+21]), 'split0_test_score': array([-60635.70430161]), 'split2_test_score': array([ -1.56020482e+22]), 'mean_score_time': array([ 0.00213706]), 'split3_test_score': array([ -4.93078188e+18]), 'split2_train_score': array([ -1.66911194e+22]), 'mean_fit_time': array([ 0.73796427])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3.90247199072e+21
####################################################################################
################# Runing the itteration 134  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.68808466]), 'std_score_time': array([ 0.06103688]), 'split1_test_score': array([ 0.52262531]), 'mean_train_score': array([ 0.68145462]), 'std_train_score': array([ 0.01059759]), 'std_test_score': array([ 0.03365479]), 'params': ({},), 'split0_train_score': array([ 0.68454977]), 'std_fit_time': array([ 0.00531116]), 'split1_train_score': array([ 0.68979069]), 'mean_test_score': array([ 0.49911899]), 'split0_test_score': array([ 0.49691785]), 'split2_test_score': array([ 0.53174591]), 'mean_score_time': array([ 0.35612619]), 'split3_test_score': array([ 0.44518688]), 'split2_train_score': array([ 0.66339338]), 'mean_fit_time': array([ 0.02537549])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.499118987307
####################################################################################
################# Runing the itteration 135  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_5', label_fn=<function label_gross_5>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.65062747,
        -0.86304212, -0.10636806]])}
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...7  1.148997 -0.106368  

[4812 rows x 58 columns], y=807     155931301
3606      4420000
3696      32...     64240813
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...7  1.148997 -0.106368  

[4812 rows x 58 columns]
        y = 807     155931301
3606      4420000
3696      32...     64240813
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...7  1.148997 -0.106368  

[4812 rows x 58 columns], y=807     155931301
3606      4420000
3696      32...     64240813
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...7  1.148997 -0.106368  

[4812 rows x 58 columns]
        y = 807     155931301
3606      4420000
3696      32...     64240813
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...7  1.148997 -0.106368  

[4812 rows x 58 columns], y=807     155931301
3606      4420000
3696      32...     64240813
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 16:43:43 2017
PID: 20654                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...7  1.148997 -0.106368  

[4812 rows x 58 columns], 807     155931301
3606      4420000
3696      32...     64240813
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...7  1.148997 -0.106368  

[4812 rows x 58 columns], 807     155931301
3606      4420000
3696      32...     64240813
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...7  1.148997 -0.106368  

[4812 rows x 58 columns], y=807     155931301
3606      4420000
3696      32...     64240813
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns]
        y_test = 807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns], y_test=807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns]
        y_test = 807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns], 807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns], 807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns], 807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns], 807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns], y=807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns]
        y = 807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...7 -0.863042 -0.106368  

[1203 rows x 58 columns], y=807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64, y_pred=array([               nan,                nan,  ...    nan,  77746101.45454545,                nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 807     155931301
3606      4420000
3696      32...     57604723
Name: worldwide_gross, dtype: int64
        y_pred = array([               nan,                nan,  ...    nan,  77746101.45454545,                nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([155931301,   4420000,   3293258, ...,  83282296,  24474463,
        57604723]), y_pred=array([               nan,                nan,  ...    nan,  77746101.45454545,                nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([               nan,                nan,  ...    nan,  77746101.45454545,                nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([               nan,                nan,  ...    nan,  77746101.45454545,                nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([               nan,                nan,  ...    nan,  77746101.45454545,                nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([               nan,                nan,  ...    nan,  77746101.45454545,                nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 136  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  30.7s
[CV]  ................................................................
[CV] ................................................. , total=  29.8s
[CV]  ................................................................
[CV] ................................................. , total=  28.8s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.29161629]), 'std_score_time': array([ 0.01093807]), 'split1_test_score': array([-0.28118589]), 'mean_train_score': array([-0.28948688]), 'std_train_score': array([ 0.00344454]), 'std_test_score': array([ 0.01025708]), 'params': ({},), 'split0_train_score': array([-0.29020687]), 'std_fit_time': array([ 0.79085091]), 'split1_train_score': array([-0.29244096]), 'mean_test_score': array([-0.29038242]), 'split0_test_score': array([-0.28822718]), 'split2_test_score': array([-0.30761638]), 'mean_score_time': array([ 0.02931732]), 'split3_test_score': array([-0.28450025]), 'split2_train_score': array([-0.28368342]), 'mean_fit_time': array([ 30.00556713])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290382424505
####################################################################################
################# Runing the itteration 137  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.2s
GREP_ME***Results of [SVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.13102999]), 'std_score_time': array([ 0.0212441]), 'split1_test_score': array([-0.11695172]), 'mean_train_score': array([-0.13184858]), 'std_train_score': array([ 0.00245008]), 'std_test_score': array([ 0.00940528]), 'params': ({},), 'split0_train_score': array([-0.12920371]), 'std_fit_time': array([ 0.02919944]), 'split1_train_score': array([-0.13585499]), 'mean_test_score': array([-0.1329873]), 'split0_test_score': array([-0.13784063]), 'split2_test_score': array([-0.14088288]), 'mean_score_time': array([ 0.43780267]), 'split3_test_score': array([-0.13627396]), 'split2_train_score': array([-0.13130561]), 'mean_fit_time': array([ 1.82407385])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132987296983
####################################################################################
################# Runing the itteration 138  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.30014044]), 'std_score_time': array([ 0.00106367]), 'split1_test_score': array([-0.2833741]), 'mean_train_score': array([-0.28970181]), 'std_train_score': array([ 0.00702956]), 'std_test_score': array([ 0.02214263]), 'params': ({},), 'split0_train_score': array([-0.28153425]), 'std_fit_time': array([ 0.00356147]), 'split1_train_score': array([-0.29168123]), 'mean_test_score': array([-0.29287303]), 'split0_test_score': array([-0.32323689]), 'split2_test_score': array([-0.30156276]), 'mean_score_time': array([ 0.01219833]), 'split3_test_score': array([-0.26331836]), 'split2_train_score': array([-0.28545132]), 'mean_fit_time': array([ 0.02598357])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292873026063
####################################################################################
################# Runing the itteration 139  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
GREP_ME***Results of [NuSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.052342]), 'std_score_time': array([ 0.00552161]), 'split1_test_score': array([-0.04390313]), 'mean_train_score': array([-0.05256718]), 'std_train_score': array([ 0.00189852]), 'std_test_score': array([ 0.00766819]), 'params': ({},), 'split0_train_score': array([-0.04955232]), 'std_fit_time': array([ 0.01834119]), 'split1_train_score': array([-0.05430667]), 'mean_test_score': array([-0.05274144]), 'split0_test_score': array([-0.05907845]), 'split2_test_score': array([-0.06153539]), 'mean_score_time': array([ 0.21617472]), 'split3_test_score': array([-0.04644881]), 'split2_train_score': array([-0.05406772]), 'mean_fit_time': array([ 1.46827543])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0527414427448
####################################################################################
################# Runing the itteration 140  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.0002834]), 'split1_test_score': array([ 0.3263757]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.0768859]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00281099]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.43464654]), 'split0_test_score': array([ 0.5395557]), 'split2_test_score': array([ 0.45767696]), 'mean_score_time': array([ 0.00209773]), 'split3_test_score': array([ 0.41497779]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.09643376])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.43464653868
####################################################################################
################# Runing the itteration 141  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00020722]), 'split1_test_score': array([ 0.53751652]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.08128697]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.0021184]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.41937796]), 'split0_test_score': array([ 0.40108788]), 'split2_test_score': array([ 0.42926251]), 'mean_score_time': array([ 0.00200146]), 'split3_test_score': array([ 0.30964494]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.04182899])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.419377963933
####################################################################################
################# Runing the itteration 142  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.26204235]), 'std_score_time': array([ 0.00208028]), 'split1_test_score': array([ 0.09530981]), 'mean_train_score': array([ 0.37683141]), 'std_train_score': array([ 0.13571073]), 'std_test_score': array([ 0.14852114]), 'params': ({},), 'split0_train_score': array([ 0.49929187]), 'std_fit_time': array([ 0.13183963]), 'split1_train_score': array([ 0.22221923]), 'mean_test_score': array([ 0.27750076]), 'split0_test_score': array([ 0.37005081]), 'split2_test_score': array([ 0.46802178]), 'mean_score_time': array([ 0.00920492]), 'split3_test_score': array([ 0.17662064]), 'split2_train_score': array([ 0.5237722]), 'mean_fit_time': array([ 0.63282466])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.277500759144
####################################################################################
################# Runing the itteration 143  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.93403653]), 'std_score_time': array([ 0.00140572]), 'split1_test_score': array([ 0.69179581]), 'mean_train_score': array([ 0.92976584]), 'std_train_score': array([ 0.00408742]), 'std_test_score': array([ 0.04088928]), 'params': ({},), 'split0_train_score': array([ 0.92800847]), 'std_fit_time': array([ 0.01865992]), 'split1_train_score': array([ 0.92390796]), 'mean_test_score': array([ 0.6351144]), 'split0_test_score': array([ 0.58491307]), 'split2_test_score': array([ 0.65348202]), 'mean_score_time': array([ 0.00992382]), 'split3_test_score': array([ 0.61026668]), 'split2_train_score': array([ 0.93311042]), 'mean_fit_time': array([ 0.88422328])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.635114396481
####################################################################################
################# Runing the itteration 144  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00040222]), 'split1_test_score': array([ 0.61455799]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.00901346]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.01200672]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.59993994]), 'split0_test_score': array([ 0.59145169]), 'split2_test_score': array([ 0.60007232]), 'mean_score_time': array([ 0.00744027]), 'split3_test_score': array([ 0.59367777]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.53023839])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.599939939201
####################################################################################
################# Runing the itteration 145  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.79981568]), 'std_score_time': array([ 0.00037253]), 'split1_test_score': array([ 0.66728093]), 'mean_train_score': array([ 0.80058676]), 'std_train_score': array([ 0.01250821]), 'std_test_score': array([ 0.01835645]), 'params': ({},), 'split0_train_score': array([ 0.81512483]), 'std_fit_time': array([ 0.02852114]), 'split1_train_score': array([ 0.80633469]), 'mean_test_score': array([ 0.65720506]), 'split0_test_score': array([ 0.62938718]), 'split2_test_score': array([ 0.67862775]), 'mean_score_time': array([ 0.00492746]), 'split3_test_score': array([ 0.65352438]), 'split2_train_score': array([ 0.78107184]), 'mean_fit_time': array([ 0.99736118])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.657205060004
####################################################################################
################# Runing the itteration 146  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.93628735]), 'std_score_time': array([ 0.00052274]), 'split1_test_score': array([ 0.63689886]), 'mean_train_score': array([ 0.93817]), 'std_train_score': array([ 0.00130061]), 'std_test_score': array([ 0.01870667]), 'params': ({},), 'split0_train_score': array([ 0.9396847]), 'std_fit_time': array([ 0.00972774]), 'split1_train_score': array([ 0.93769824]), 'mean_test_score': array([ 0.61924909]), 'split0_test_score': array([ 0.61522955]), 'split2_test_score': array([ 0.59030712]), 'mean_score_time': array([ 0.00712067]), 'split3_test_score': array([ 0.63456082]), 'split2_train_score': array([ 0.93900972]), 'mean_fit_time': array([ 0.90438485])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.619249090085
####################################################################################
################# Runing the itteration 147  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.62158869]), 'std_score_time': array([ 0.00545262]), 'split1_test_score': array([ 0.56273892]), 'mean_train_score': array([ 0.61287788]), 'std_train_score': array([ 0.01247674]), 'std_test_score': array([ 0.02334095]), 'params': ({},), 'split0_train_score': array([ 0.59147132]), 'std_fit_time': array([ 0.00302787]), 'split1_train_score': array([ 0.62122151]), 'mean_test_score': array([ 0.58323685]), 'split0_test_score': array([ 0.61336279]), 'split2_test_score': array([ 0.59848666]), 'mean_score_time': array([ 0.02067822]), 'split3_test_score': array([ 0.55835901]), 'split2_train_score': array([ 0.61723001]), 'mean_fit_time': array([ 0.10268593])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.583236846382
####################################################################################
################# Runing the itteration 148  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.28832858]), 'std_score_time': array([ 0.00032053]), 'split1_test_score': array([ 0.29137656]), 'mean_train_score': array([ 0.28972734]), 'std_train_score': array([ 0.00749755]), 'std_test_score': array([ 0.01743224]), 'params': ({},), 'split0_train_score': array([ 0.27904986]), 'std_fit_time': array([ 0.0658244]), 'split1_train_score': array([ 0.29152456]), 'mean_test_score': array([ 0.28427156]), 'split0_test_score': array([ 0.28130943]), 'split2_test_score': array([ 0.25824501]), 'mean_score_time': array([ 0.00356054]), 'split3_test_score': array([ 0.30615525]), 'split2_train_score': array([ 0.30000635]), 'mean_fit_time': array([ 0.25357771])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.284271564614
####################################################################################
################# Runing the itteration 149  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [Lasso] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.6497931]), 'std_score_time': array([ 0.00545323]), 'split1_test_score': array([ 0.34294891]), 'mean_train_score': array([ 0.64173457]), 'std_train_score': array([ 0.01119706]), 'std_test_score': array([ 0.10218333]), 'params': ({},), 'split0_train_score': array([ 0.65036455]), 'std_fit_time': array([ 0.01735454]), 'split1_train_score': array([ 0.62283505]), 'mean_test_score': array([ 0.51926438]), 'split0_test_score': array([ 0.56983569]), 'split2_test_score': array([ 0.59251262]), 'mean_score_time': array([ 0.03747094]), 'split3_test_score': array([ 0.57176031]), 'split2_train_score': array([ 0.64394559]), 'mean_fit_time': array([ 1.09935349])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.519264383385
####################################################################################
################# Runing the itteration 150  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LassoLars] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63088041]), 'std_score_time': array([ 0.00090113]), 'split1_test_score': array([ 0.64543736]), 'mean_train_score': array([ 0.6168358]), 'std_train_score': array([ 0.01054857]), 'std_test_score': array([ 0.03763226]), 'params': ({},), 'split0_train_score': array([ 0.61587531]), 'std_fit_time': array([ 0.01786751]), 'split1_train_score': array([ 0.6192748]), 'mean_test_score': array([ 0.58249347]), 'split0_test_score': array([ 0.5729963]), 'split2_test_score': array([ 0.56537068]), 'mean_score_time': array([ 0.00492871]), 'split3_test_score': array([ 0.54616955]), 'split2_train_score': array([ 0.60131268]), 'mean_fit_time': array([ 0.0997206])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.582493470402
####################################################################################
################# Runing the itteration 151  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63585693]), 'std_score_time': array([ 0.0026386]), 'split1_test_score': array([ 0.5521465]), 'mean_train_score': array([ 0.64360903]), 'std_train_score': array([ 0.0176249]), 'std_test_score': array([ 0.10583382]), 'params': ({},), 'split0_train_score': array([ 0.66328196]), 'std_fit_time': array([ 0.04749274]), 'split1_train_score': array([ 0.65667985]), 'mean_test_score': array([ 0.53381852]), 'split0_test_score': array([ 0.53675778]), 'split2_test_score': array([ 0.6719002]), 'mean_score_time': array([ 0.00602651]), 'split3_test_score': array([ 0.37446957]), 'split2_train_score': array([ 0.61861738]), 'mean_fit_time': array([ 0.13049453])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.53381851545
####################################################################################
################# Runing the itteration 152  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.27286775]), 'std_score_time': array([ 0.00108787]), 'split1_test_score': array([-0.29069157]), 'mean_train_score': array([-0.28893627]), 'std_train_score': array([ 0.01008358]), 'std_test_score': array([ 0.03359164]), 'params': ({},), 'split0_train_score': array([-0.29460518]), 'std_fit_time': array([ 0.00010114]), 'split1_train_score': array([-0.28855464]), 'mean_test_score': array([-0.29391611]), 'split0_test_score': array([-0.28061377]), 'split2_test_score': array([-0.25641017]), 'mean_score_time': array([ 0.0122211]), 'split3_test_score': array([-0.34794894]), 'split2_train_score': array([-0.2997175]), 'mean_fit_time': array([ 0.02692634])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293916112697
####################################################################################
################# Runing the itteration 153  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
GREP_ME***Results of [Ridge] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.6442577]), 'std_score_time': array([ 0.00238792]), 'split1_test_score': array([ 0.14299586]), 'mean_train_score': array([ 0.645224]), 'std_train_score': array([ 0.01850323]), 'std_test_score': array([ 0.20528536]), 'params': ({},), 'split0_train_score': array([ 0.61610336]), 'std_fit_time': array([ 0.02797479]), 'split1_train_score': array([ 0.65443992]), 'mean_test_score': array([ 0.48998831]), 'split0_test_score': array([ 0.67091799]), 'split2_test_score': array([ 0.54437894]), 'mean_score_time': array([ 0.01090252]), 'split3_test_score': array([ 0.60166044]), 'split2_train_score': array([ 0.66609502]), 'mean_fit_time': array([ 1.75667191])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.489988305998
####################################################################################
################# Runing the itteration 154  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-461749.0606979]), 'std_score_time': array([ 0.00145221]), 'split1_test_score': array([-997.34073014]), 'mean_train_score': array([-124916.79591859]), 'std_train_score': array([ 194758.27950944]), 'std_test_score': array([ 15278.92858951]), 'params': ({},), 'split0_train_score': array([-29279.32583538]), 'std_fit_time': array([ 0.00287049]), 'split1_train_score': array([-8392.78631259]), 'mean_test_score': array([-9798.99640028]), 'split0_test_score': array([-1953.94374562]), 'split2_test_score': array([-8.65142834]), 'mean_score_time': array([ 0.01569688]), 'split3_test_score': array([-36236.04969701]), 'split2_train_score': array([-246.01082851]), 'mean_fit_time': array([ 0.02749884])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-9798.99640028
####################################################################################
################# Runing the itteration 155  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.61235048]), 'std_score_time': array([ 0.01378585]), 'split1_test_score': array([ 0.57989644]), 'mean_train_score': array([ 0.62810058]), 'std_train_score': array([ 0.01134253]), 'std_test_score': array([ 0.03875168]), 'params': ({},), 'split0_train_score': array([ 0.64119103]), 'std_fit_time': array([ 0.01338269]), 'split1_train_score': array([ 0.63619981]), 'mean_test_score': array([ 0.60532056]), 'split0_test_score': array([ 0.56011997]), 'split2_test_score': array([ 0.62034293]), 'mean_score_time': array([ 0.01353014]), 'split3_test_score': array([ 0.6609229]), 'split2_train_score': array([ 0.62266098]), 'mean_fit_time': array([ 0.07113534])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.60532056034
####################################################################################
################# Runing the itteration 156  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.9s
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ -2.49146891e+23]), 'std_score_time': array([ 0.00110432]), 'split1_test_score': array([ -3.64215593e+10]), 'mean_train_score': array([ -2.57899344e+23]), 'std_train_score': array([  3.19348689e+23]), 'std_test_score': array([  3.91846653e+23]), 'params': ({},), 'split0_train_score': array([ -7.82245749e+23]), 'std_fit_time': array([ 0.27588385]), 'split1_train_score': array([ -6.15714730e+10]), 'mean_test_score': array([ -3.90213467e+23]), 'split0_test_score': array([ -7.27874164e+23]), 'split2_test_score': array([ -2.48932385e+20]), 'mean_score_time': array([ 0.00408638]), 'split3_test_score': array([ -8.32730770e+23]), 'split2_train_score': array([ -2.04736224e+20]), 'mean_fit_time': array([ 2.82215577])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-3.90213466641e+23
####################################################################################
################# Runing the itteration 157  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63573261]), 'std_score_time': array([ 0.05491295]), 'split1_test_score': array([ 0.42327531]), 'mean_train_score': array([ 0.63574329]), 'std_train_score': array([ 0.01254061]), 'std_test_score': array([ 0.054779]), 'params': ({},), 'split0_train_score': array([ 0.61939475]), 'std_fit_time': array([ 0.00323282]), 'split1_train_score': array([ 0.63324626]), 'mean_test_score': array([ 0.4275487]), 'split0_test_score': array([ 0.5181788]), 'split2_test_score': array([ 0.38896032]), 'mean_score_time': array([ 0.59684479]), 'split3_test_score': array([ 0.37978036]), 'split2_train_score': array([ 0.65459953]), 'mean_fit_time': array([ 0.04517591])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.427548695424
####################################################################################
################# Runing the itteration 158  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_5', label_fn=<function label_gross_5>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.86304212,
        -0.06123763, -0.10636806]])}
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], y=169     467381584
3782      2419669
4122       4...     67182787
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns]
        y = 169     467381584
3782      2419669
4122       4...     67182787
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], y=169     467381584
3782      2419669
4122       4...     67182787
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns]
        y = 169     467381584
3782      2419669
4122       4...     67182787
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], y=169     467381584
3782      2419669
4122       4...     67182787
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 16:52:49 2017
PID: 21954                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], 169     467381584
3782      2419669
4122       4...     67182787
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], 169     467381584
3782      2419669
4122       4...     67182787
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[4812 rows x 122 columns], y=169     467381584
3782      2419669
4122       4...     67182787
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns]
        y_test = 169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], y_test=169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns]
        y_test = 169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], 169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], 169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], 169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], 169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], y=169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns]
        y = 169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ... -0.061238 -0.106368  

[1203 rows x 122 columns], y=169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64, y_pred=array([               nan,   2419669.        ,  ...5714286,                nan,                nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 169     467381584
3782      2419669
4122       4...      2041928
Name: worldwide_gross, dtype: int64
        y_pred = array([               nan,   2419669.        ,  ...5714286,                nan,                nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([467381584,   2419669,    414617, ...,  29227561,  28400715,
         2041928]), y_pred=array([               nan,   2419669.        ,  ...5714286,                nan,                nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([               nan,   2419669.        ,  ...5714286,                nan,                nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([               nan,   2419669.        ,  ...5714286,                nan,                nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([               nan,   2419669.        ,  ...5714286,                nan,                nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([               nan,   2419669.        ,  ...5714286,                nan,                nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 159  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  48.1s
[CV]  ................................................................
[CV] ................................................. , total=  48.5s
[CV]  ................................................................
[CV] ................................................. , total=  50.7s
[CV]  ................................................................
[CV] ................................................. , total=  51.1s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.29202658]), 'std_score_time': array([ 0.11030861]), 'split1_test_score': array([-0.281228]), 'mean_train_score': array([-0.28965078]), 'std_train_score': array([ 0.00700107]), 'std_test_score': array([ 0.02497891]), 'params': ({},), 'split0_train_score': array([-0.27773538]), 'std_fit_time': array([ 1.26005211]), 'split1_train_score': array([-0.29320887]), 'mean_test_score': array([-0.29263124]), 'split0_test_score': array([-0.33543345]), 'split2_test_score': array([-0.27241664]), 'mean_score_time': array([ 0.07269019]), 'split3_test_score': array([-0.28144688]), 'split2_train_score': array([-0.29563229]), 'mean_fit_time': array([ 49.55177307])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.292631243459
####################################################################################
################# Runing the itteration 160  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.5s
GREP_ME***Results of [SVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.13243281]), 'std_score_time': array([ 0.00910708]), 'split1_test_score': array([-0.13118792]), 'mean_train_score': array([-0.13159397]), 'std_train_score': array([ 0.00136909]), 'std_test_score': array([ 0.01417656]), 'params': ({},), 'split0_train_score': array([-0.13077985]), 'std_fit_time': array([ 0.06869168]), 'split1_train_score': array([-0.12983077]), 'mean_test_score': array([-0.13271754]), 'split0_test_score': array([-0.14043024]), 'split2_test_score': array([-0.11061339]), 'mean_score_time': array([ 0.73976403]), 'split3_test_score': array([-0.14863862]), 'split2_train_score': array([-0.13333245]), 'mean_fit_time': array([ 2.72245103])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132717543667
####################################################################################
################# Runing the itteration 161  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.2817667]), 'std_score_time': array([ 0.00763472]), 'split1_test_score': array([-0.25493272]), 'mean_train_score': array([-0.29000053]), 'std_train_score': array([ 0.00992914]), 'std_test_score': array([ 0.02327159]), 'params': ({},), 'split0_train_score': array([-0.28469889]), 'std_fit_time': array([ 0.00558256]), 'split1_train_score': array([-0.30693792]), 'mean_test_score': array([-0.29412299]), 'split0_test_score': array([-0.30420394]), 'split2_test_score': array([-0.30142891]), 'mean_score_time': array([ 0.02659839]), 'split3_test_score': array([-0.3159264]), 'split2_train_score': array([-0.28659862]), 'mean_fit_time': array([ 0.03252578])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.294122992967
####################################################################################
################# Runing the itteration 162  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.5s
GREP_ME***Results of [NuSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.05281396]), 'std_score_time': array([ 0.00378575]), 'split1_test_score': array([-0.04711711]), 'mean_train_score': array([-0.05253626]), 'std_train_score': array([ 0.00100112]), 'std_test_score': array([ 0.01294708]), 'params': ({},), 'split0_train_score': array([-0.05401145]), 'std_fit_time': array([ 0.02181867]), 'split1_train_score': array([-0.05132862]), 'mean_test_score': array([-0.05414195]), 'split0_test_score': array([-0.0750991]), 'split2_test_score': array([-0.05369125]), 'mean_score_time': array([ 0.35727692]), 'split3_test_score': array([-0.04066033]), 'split2_train_score': array([-0.05199099]), 'mean_fit_time': array([ 2.11289924])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0541419476731
####################################################################################
################# Runing the itteration 163  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00028144]), 'split1_test_score': array([ 0.408353]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.12879569]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00172102]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.31574807]), 'split0_test_score': array([ 0.34334779]), 'split2_test_score': array([ 0.09786215]), 'mean_score_time': array([ 0.00270575]), 'split3_test_score': array([ 0.41342933]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.15631962])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.315748065251
####################################################################################
################# Runing the itteration 164  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00031736]), 'split1_test_score': array([ 0.10605374]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.14638504]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.01180343]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.24529506]), 'split0_test_score': array([ 0.39429069]), 'split2_test_score': array([ 0.38887481]), 'mean_score_time': array([ 0.00274497]), 'split3_test_score': array([ 0.09196099]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.08131647])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 121, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.245295057412
####################################################################################
################# Runing the itteration 165  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.5213255]), 'std_score_time': array([ 0.00484215]), 'split1_test_score': array([-0.32165664]), 'mean_train_score': array([ 0.37794936]), 'std_train_score': array([ 0.28013064]), 'std_test_score': array([ 0.33777624]), 'params': ({},), 'split0_train_score': array([ 0.46964998]), 'std_fit_time': array([ 0.3210909]), 'split1_train_score': array([-0.09826468]), 'mean_test_score': array([ 0.25407528]), 'split0_test_score': array([ 0.34798453]), 'split2_test_score': array([ 0.49293557]), 'mean_score_time': array([ 0.00991189]), 'split3_test_score': array([ 0.49703766]), 'split2_train_score': array([ 0.61908663]), 'mean_fit_time': array([ 0.73434693])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.254075280152
####################################################################################
################# Runing the itteration 166  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.92405423]), 'std_score_time': array([ 0.00445719]), 'split1_test_score': array([ 0.5933121]), 'mean_train_score': array([ 0.92918925]), 'std_train_score': array([ 0.004155]), 'std_test_score': array([ 0.01687417]), 'params': ({},), 'split0_train_score': array([ 0.92686548]), 'std_fit_time': array([ 0.05464745]), 'split1_train_score': array([ 0.93074253]), 'mean_test_score': array([ 0.61711195]), 'split0_test_score': array([ 0.63226527]), 'split2_test_score': array([ 0.60907575]), 'mean_score_time': array([ 0.01717401]), 'split3_test_score': array([ 0.6337947]), 'split2_train_score': array([ 0.93509475]), 'mean_fit_time': array([ 1.12277865])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.617111952026
####################################################################################
################# Runing the itteration 167  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00012776]), 'split1_test_score': array([ 0.61707318]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.05546597]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.02124031]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.60202949]), 'split0_test_score': array([ 0.62784788]), 'split2_test_score': array([ 0.50887247]), 'mean_score_time': array([ 0.00810558]), 'split3_test_score': array([ 0.65432444]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.77344549])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.60202949225
####################################################################################
################# Runing the itteration 168  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
[CV]  ................................................................
[CV] ................................................. , total=   1.4s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.80776707]), 'std_score_time': array([ 0.00098112]), 'split1_test_score': array([ 0.6461025]), 'mean_train_score': array([ 0.79755185]), 'std_train_score': array([ 0.01055693]), 'std_test_score': array([ 0.01145509]), 'params': ({},), 'split0_train_score': array([ 0.79386109]), 'std_fit_time': array([ 0.02435829]), 'split1_train_score': array([ 0.8066698]), 'mean_test_score': array([ 0.65865828]), 'split0_test_score': array([ 0.66985104]), 'split2_test_score': array([ 0.64836206]), 'mean_score_time': array([ 0.00855494]), 'split3_test_score': array([ 0.67031754]), 'split2_train_score': array([ 0.78190942]), 'mean_fit_time': array([ 1.39902157])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.658658283547
####################################################################################
################# Runing the itteration 169  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
[CV]  ................................................................
[CV] ................................................. , total=   1.1s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.93351952]), 'std_score_time': array([ 0.0073615]), 'split1_test_score': array([ 0.65162988]), 'mean_train_score': array([ 0.9364347]), 'std_train_score': array([ 0.00315236]), 'std_test_score': array([ 0.02216545]), 'params': ({},), 'split0_train_score': array([ 0.937849]), 'std_fit_time': array([ 0.01045728]), 'split1_train_score': array([ 0.93343516]), 'mean_test_score': array([ 0.61839273]), 'split0_test_score': array([ 0.61688447]), 'split2_test_score': array([ 0.58920756]), 'mean_score_time': array([ 0.01577568]), 'split3_test_score': array([ 0.615849]), 'split2_train_score': array([ 0.94093512]), 'mean_fit_time': array([ 1.08500421])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.618392728273
####################################################################################
################# Runing the itteration 170  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.6189966]), 'std_score_time': array([ 0.00606292]), 'split1_test_score': array([ 0.56659266]), 'mean_train_score': array([ 0.61765779]), 'std_train_score': array([ 0.00621728]), 'std_test_score': array([ 0.01672437]), 'params': ({},), 'split0_train_score': array([ 0.62003307]), 'std_fit_time': array([ 0.00991887]), 'split1_train_score': array([ 0.62417592]), 'mean_test_score': array([ 0.58048745]), 'split0_test_score': array([ 0.58375073]), 'split2_test_score': array([ 0.60652263]), 'mean_score_time': array([ 0.01769882]), 'split3_test_score': array([ 0.56508377]), 'split2_train_score': array([ 0.60742558]), 'mean_fit_time': array([ 0.19115978])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.580487447985
####################################################################################
################# Runing the itteration 171  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.28346669]), 'std_score_time': array([ 0.00181866]), 'split1_test_score': array([ 0.26140281]), 'mean_train_score': array([ 0.29411255]), 'std_train_score': array([ 0.00754748]), 'std_test_score': array([ 0.02225095]), 'params': ({},), 'split0_train_score': array([ 0.30060457]), 'std_fit_time': array([ 0.0705306]), 'split1_train_score': array([ 0.29054368]), 'mean_test_score': array([ 0.28557644]), 'split0_test_score': array([ 0.2806898]), 'split2_test_score': array([ 0.27831293]), 'mean_score_time': array([ 0.00613314]), 'split3_test_score': array([ 0.32190022]), 'split2_train_score': array([ 0.30183527]), 'mean_fit_time': array([ 0.37471122])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.285576437073
####################################################################################
################# Runing the itteration 172  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   1.8s
[CV]  ................................................................
[CV] ................................................. , total=   1.9s
GREP_ME***Results of [Lasso] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.67433285]), 'std_score_time': array([ 0.0152954]), 'split1_test_score': array([ 0.66397621]), 'mean_train_score': array([ 0.65380235]), 'std_train_score': array([ 0.01842351]), 'std_test_score': array([ 0.06243349]), 'params': ({},), 'split0_train_score': array([ 0.64090225]), 'std_fit_time': array([ 0.04082487]), 'split1_train_score': array([ 0.63074298]), 'mean_test_score': array([ 0.58246946]), 'split0_test_score': array([ 0.62226015]), 'split2_test_score': array([ 0.51974982]), 'mean_score_time': array([ 0.0267719]), 'split3_test_score': array([ 0.52389165]), 'split2_train_score': array([ 0.66923133]), 'mean_fit_time': array([ 1.8361972])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.582469455238
####################################################################################
################# Runing the itteration 173  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [LassoLars] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.6465138]), 'std_score_time': array([ 0.0008844]), 'split1_test_score': array([ 0.61667811]), 'mean_train_score': array([ 0.64330732]), 'std_train_score': array([ 0.01316061]), 'std_test_score': array([ 0.02616578]), 'params': ({},), 'split0_train_score': array([ 0.62150306]), 'std_fit_time': array([ 0.05257966]), 'split1_train_score': array([ 0.64847336]), 'mean_test_score': array([ 0.61270498]), 'split0_test_score': array([ 0.65301707]), 'split2_test_score': array([ 0.58290895]), 'mean_score_time': array([ 0.00470138]), 'split3_test_score': array([ 0.59821577]), 'split2_train_score': array([ 0.65673906]), 'mean_fit_time': array([ 0.16653126])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.612704977199
####################################################################################
################# Runing the itteration 174  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.3s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.65429671]), 'std_score_time': array([ 0.00123908]), 'split1_test_score': array([ 0.58751121]), 'mean_train_score': array([ 0.65109428]), 'std_train_score': array([ 0.00948479]), 'std_test_score': array([ 0.0399362]), 'params': ({},), 'split0_train_score': array([ 0.66147275]), 'std_fit_time': array([ 0.0497026]), 'split1_train_score': array([ 0.65295416]), 'mean_test_score': array([ 0.53352326]), 'split0_test_score': array([ 0.50847383]), 'split2_test_score': array([ 0.48427823]), 'mean_score_time': array([ 0.00807267]), 'split3_test_score': array([ 0.55382977]), 'split2_train_score': array([ 0.6356535]), 'mean_fit_time': array([ 0.24716717])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.533523262141
####################################################################################
################# Runing the itteration 175  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.295112]), 'std_score_time': array([ 0.00235892]), 'split1_test_score': array([-0.26676322]), 'mean_train_score': array([-0.28878009]), 'std_train_score': array([ 0.00802332]), 'std_test_score': array([ 0.02872301]), 'params': ({},), 'split0_train_score': array([-0.2764365]), 'std_fit_time': array([ 0.00713539]), 'split1_train_score': array([-0.29663193]), 'mean_test_score': array([-0.29320957]), 'split0_test_score': array([-0.34010467]), 'split2_test_score': array([-0.29279359]), 'mean_score_time': array([ 0.0141415]), 'split3_test_score': array([-0.27317679]), 'split2_train_score': array([-0.28693993]), 'mean_fit_time': array([ 0.04094088])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.293209568713
####################################################################################
################# Runing the itteration 176  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.8s
[CV]  ................................................................
[CV] ................................................. , total=   2.9s
[CV]  ................................................................
[CV] ................................................. , total=   3.0s
[CV]  ................................................................
[CV] ................................................. , total=   3.1s
GREP_ME***Results of [Ridge] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.66979827]), 'std_score_time': array([ 0.00309962]), 'split1_test_score': array([ 0.6731948]), 'mean_train_score': array([ 0.65668639]), 'std_train_score': array([ 0.02532906]), 'std_test_score': array([ 0.08547759]), 'params': ({},), 'split0_train_score': array([ 0.64287269]), 'std_fit_time': array([ 0.12538181]), 'split1_train_score': array([ 0.62384649]), 'mean_test_score': array([ 0.57999585]), 'split0_test_score': array([ 0.63108149]), 'split2_test_score': array([ 0.4465312]), 'mean_score_time': array([ 0.0109852]), 'split3_test_score': array([ 0.5691759]), 'split2_train_score': array([ 0.69022811]), 'mean_fit_time': array([ 2.94385439])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.579995848016
####################################################################################
################# Runing the itteration 177  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-222655.95249578]), 'std_score_time': array([ 0.00165883]), 'split1_test_score': array([-1674.09608687]), 'mean_train_score': array([-110950.33830265]), 'std_train_score': array([ 93390.99761935]), 'std_test_score': array([ 4720.21109584]), 'params': ({},), 'split0_train_score': array([-181747.3891133]), 'std_fit_time': array([ 0.00039779]), 'split1_train_score': array([-38980.28860122]), 'mean_test_score': array([-5527.51193367]), 'split0_test_score': array([-10164.97972188]), 'split2_test_score': array([-13.99783653]), 'mean_score_time': array([ 0.01247215]), 'split3_test_score': array([-10256.97408941]), 'split2_train_score': array([-417.72300032]), 'mean_fit_time': array([ 0.0352881])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-5527.51193367
####################################################################################
################# Runing the itteration 178  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63720427]), 'std_score_time': array([ 0.01362578]), 'split1_test_score': array([ 0.48473819]), 'mean_train_score': array([ 0.63152093]), 'std_train_score': array([ 0.02530053]), 'std_test_score': array([ 0.06723279]), 'params': ({},), 'split0_train_score': array([ 0.63435877]), 'std_fit_time': array([ 0.02889439]), 'split1_train_score': array([ 0.66250099]), 'mean_test_score': array([ 0.58940007]), 'split0_test_score': array([ 0.60408179]), 'split2_test_score': array([ 0.6722261]), 'mean_score_time': array([ 0.01291847]), 'split3_test_score': array([ 0.5965542]), 'split2_train_score': array([ 0.59201967]), 'mean_fit_time': array([ 0.09372717])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.58940006717
####################################################################################
################# Runing the itteration 179  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   5.9s
[CV]  ................................................................
[CV] ................................................. , total=   6.1s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ -2.22491019e+24]), 'std_score_time': array([ 0.00107024]), 'split1_test_score': array([ -6.69620572e+20]), 'mean_train_score': array([ -1.08501538e+25]), 'std_train_score': array([  1.75308866e+25]), 'std_test_score': array([  2.08216658e+25]), 'params': ({},), 'split0_train_score': array([ -1.18961227e+21]), 'std_fit_time': array([ 0.41801928]), 'split1_train_score': array([ -7.24312396e+20]), 'mean_test_score': array([ -1.30711532e+25]), 'split0_test_score': array([ -1.63948635e+21]), 'split2_test_score': array([ -4.90634948e+25]), 'mean_score_time': array([ 0.00631618]), 'split3_test_score': array([ -3.21880903e+24]), 'split2_train_score': array([ -4.11737909e+25]), 'mean_fit_time': array([ 5.84881973])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-1.30711532227e+25
####################################################################################
################# Runing the itteration 180  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.60323989]), 'std_score_time': array([ 0.14387945]), 'split1_test_score': array([ 0.3255167]), 'mean_train_score': array([ 0.59587336]), 'std_train_score': array([ 0.01309438]), 'std_test_score': array([ 0.03797241]), 'params': ({},), 'split0_train_score': array([ 0.59542969]), 'std_fit_time': array([ 0.00859696]), 'split1_train_score': array([ 0.60983928]), 'mean_test_score': array([ 0.37347029]), 'split0_test_score': array([ 0.40766351]), 'split2_test_score': array([ 0.4135485]), 'mean_score_time': array([ 0.96910834]), 'split3_test_score': array([ 0.34715245]), 'split2_train_score': array([ 0.57498457]), 'mean_fit_time': array([ 0.0572437])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.373470290344
####################################################################################
################# Runing the itteration 181  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_5', label_fn=<function label_gross_5>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.05200382,
        -0.04328774, -0.10636806]])}
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], y=417     268268174
756     162839667
3916      13...    174810815
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 193, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.41715084525242052}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70280138638319878}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.61362105858655114}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.70294813479553953}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73296584032856904}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.32159278577968786}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.54529725417531971}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns]
        y = 417     268268174
756     162839667
3916      13...    174810815
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], y=417     268268174
756     162839667
3916      13...    174810815
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns]
        y = 417     268268174
756     162839667
3916      13...    174810815
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], y=417     268268174
756     162839667
3916      13...    174810815
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 17:02:33 2017
PID: 23257                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], 417     268268174
756     162839667
3916      13...    174810815
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], 417     268268174
756     162839667
3916      13...    174810815
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[4812 rows x 204 columns], y=417     268268174
756     162839667
3916      13...    174810815
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns]
        y_test = 417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], y_test=417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns]
        y_test = 417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], 417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], 417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], 417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], 417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], y=417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns]
        y = 417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...-0.043288  -0.106368  

[1203 rows x 204 columns], y=417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64, y_pred=array([               nan,                nan,  ...5714286,                nan,                nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 417     268268174
756     162839667
3916      13...     23344056
Name: worldwide_gross, dtype: int64
        y_pred = array([               nan,                nan,  ...5714286,                nan,                nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([268268174, 162839667,   1373407, ..., 118537627,    440821,
        23344056]), y_pred=array([               nan,                nan,  ...5714286,                nan,                nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([               nan,                nan,  ...5714286,                nan,                nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([               nan,                nan,  ...5714286,                nan,                nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([               nan,                nan,  ...5714286,                nan,                nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([               nan,                nan,  ...5714286,                nan,                nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 182  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total= 1.1min
[CV]  ................................................................
[CV] ................................................. , total= 1.2min
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28672206]), 'std_score_time': array([ 0.09622897]), 'split1_test_score': array([-0.27703448]), 'mean_train_score': array([-0.28987372]), 'std_train_score': array([ 0.00839054]), 'std_test_score': array([ 0.02981226]), 'params': ({},), 'split0_train_score': array([-0.27804956]), 'std_fit_time': array([ 3.05992376]), 'split1_train_score': array([-0.29422129]), 'mean_test_score': array([-0.29522834]), 'split0_test_score': array([-0.34246368]), 'split2_test_score': array([-0.26380812]), 'mean_score_time': array([ 0.09078526]), 'split3_test_score': array([-0.29760707]), 'split2_train_score': array([-0.30050197]), 'mean_fit_time': array([ 72.2897656])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.295228336799
####################################################################################
################# Runing the itteration 183  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [SVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.13033602]), 'std_score_time': array([ 0.02162675]), 'split1_test_score': array([-0.14328169]), 'mean_train_score': array([-0.1315835]), 'std_train_score': array([ 0.00289925]), 'std_test_score': array([ 0.01821543]), 'params': ({},), 'split0_train_score': array([-0.13658301]), 'std_fit_time': array([ 0.07032756]), 'split1_train_score': array([-0.12983463]), 'mean_test_score': array([-0.13225693]), 'split0_test_score': array([-0.10233625]), 'split2_test_score': array([-0.13358433]), 'mean_score_time': array([ 1.10230577]), 'split3_test_score': array([-0.14982545]), 'split2_train_score': array([-0.12958034]), 'mean_fit_time': array([ 3.89923787])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132256931752
####################################################################################
################# Runing the itteration 184  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.29447587]), 'std_score_time': array([ 0.00572828]), 'split1_test_score': array([-0.32963456]), 'mean_train_score': array([-0.29028813]), 'std_train_score': array([ 0.01280384]), 'std_test_score': array([ 0.03286674]), 'params': ({},), 'split0_train_score': array([-0.30938665]), 'std_fit_time': array([ 0.00719409]), 'split1_train_score': array([-0.27756383]), 'mean_test_score': array([-0.29612057]), 'split0_test_score': array([-0.25345559]), 'split2_test_score': array([-0.32653722]), 'mean_score_time': array([ 0.02011937]), 'split3_test_score': array([-0.27485491]), 'split2_train_score': array([-0.27972616]), 'mean_fit_time': array([ 0.04051691])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.296120569131
####################################################################################
################# Runing the itteration 185  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   3.4s
GREP_ME***Results of [NuSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.05039031]), 'std_score_time': array([ 0.0046851]), 'split1_test_score': array([-0.06419134]), 'mean_train_score': array([-0.05216895]), 'std_train_score': array([ 0.00131882]), 'std_test_score': array([ 0.00964826]), 'params': ({},), 'split0_train_score': array([-0.05143622]), 'std_fit_time': array([ 0.06513365]), 'split1_train_score': array([-0.0531975]), 'mean_test_score': array([-0.05226945]), 'split0_test_score': array([-0.03977939]), 'split2_test_score': array([-0.04646827]), 'mean_score_time': array([ 0.54372269]), 'split3_test_score': array([-0.05863882]), 'split2_train_score': array([-0.05365178]), 'mean_fit_time': array([ 2.93287736])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0522694534534
####################################################################################
################# Runing the itteration 186  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00030966]), 'split1_test_score': array([ 0.3792336]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.06207514]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00193063]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.40936125]), 'split0_test_score': array([ 0.47659478]), 'split2_test_score': array([ 0.45898765]), 'mean_score_time': array([ 0.00282097]), 'split3_test_score': array([ 0.32262897]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.18496859])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.409361253433
####################################################################################
################# Runing the itteration 187  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00011868]), 'split1_test_score': array([ 0.28535399]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.07351926]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.01493132]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.40922036]), 'split0_test_score': array([ 0.47322069]), 'split2_test_score': array([ 0.42519923]), 'mean_score_time': array([ 0.00255257]), 'split3_test_score': array([ 0.45310753]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.11206001])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.409220359859
####################################################################################
################# Runing the itteration 188  of the GridSearchCV ####################
####################################################################################
***Starting [AdaBoostRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [AdaBoostRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.60473817]), 'std_score_time': array([ 0.0002975]), 'split1_test_score': array([ 0.39568098]), 'mean_train_score': array([ 0.58351066]), 'std_train_score': array([ 0.06141094]), 'std_test_score': array([ 0.06958707]), 'params': ({},), 'split0_train_score': array([ 0.65758633]), 'std_fit_time': array([ 0.02375636]), 'split1_train_score': array([ 0.48786921]), 'mean_test_score': array([ 0.46682722]), 'split0_test_score': array([ 0.5481963]), 'split2_test_score': array([ 0.39993201]), 'mean_score_time': array([ 0.00886941]), 'split3_test_score': array([ 0.52349959]), 'split2_train_score': array([ 0.58384892]), 'mean_fit_time': array([ 0.76561856])}
GREP_ME***Best params of [AdaBoostRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [AdaBoostRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.46682722155
####################################################################################
################# Runing the itteration 189  of the GridSearchCV ####################
####################################################################################
***Starting [BaggingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [BaggingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.95235988]), 'std_score_time': array([ 0.00052403]), 'split1_test_score': array([ 0.72484662]), 'mean_train_score': array([ 0.95036132]), 'std_train_score': array([ 0.00235346]), 'std_test_score': array([ 0.01040557]), 'params': ({},), 'split0_train_score': array([ 0.94666539]), 'std_fit_time': array([ 0.01223761]), 'split1_train_score': array([ 0.94997299]), 'mean_test_score': array([ 0.73110955]), 'split0_test_score': array([ 0.72504248]), 'split2_test_score': array([ 0.74912898]), 'mean_score_time': array([ 0.00700378]), 'split3_test_score': array([ 0.72542011]), 'split2_train_score': array([ 0.95244703]), 'mean_fit_time': array([ 0.90585643])}
GREP_ME***Best params of [BaggingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [BaggingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.731109545196
####################################################################################
################# Runing the itteration 190  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreesRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.5s
GREP_ME***Results of [ExtraTreesRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00035288]), 'split1_test_score': array([ 0.76225997]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.05219427]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.02279051]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.73867481]), 'split0_test_score': array([ 0.72086168]), 'split2_test_score': array([ 0.66505428]), 'mean_score_time': array([ 0.0063265]), 'split3_test_score': array([ 0.80652332]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.43258238])}
GREP_ME***Best params of [ExtraTreesRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreesRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.738674813042
####################################################################################
################# Runing the itteration 191  of the GridSearchCV ####################
####################################################################################
***Starting [GradientBoostingRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
GREP_ME***Results of [GradientBoostingRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.87127776]), 'std_score_time': array([  9.40429649e-05]), 'split1_test_score': array([ 0.79874539]), 'mean_train_score': array([ 0.88043769]), 'std_train_score': array([ 0.00630363]), 'std_test_score': array([ 0.02923652]), 'params': ({},), 'split0_train_score': array([ 0.88073768]), 'std_fit_time': array([ 0.02267018]), 'split1_train_score': array([ 0.88064277]), 'mean_test_score': array([ 0.75604885]), 'split0_test_score': array([ 0.74908748]), 'split2_test_score': array([ 0.71686061]), 'mean_score_time': array([ 0.00370759]), 'split3_test_score': array([ 0.75950191]), 'split2_train_score': array([ 0.88909255]), 'mean_fit_time': array([ 0.77478778])}
GREP_ME***Best params of [GradientBoostingRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [GradientBoostingRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.756048849077
####################################################################################
################# Runing the itteration 192  of the GridSearchCV ####################
####################################################################################
***Starting [RandomForestRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [RandomForestRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.94268238]), 'std_score_time': array([ 0.00017754]), 'split1_test_score': array([ 0.68993414]), 'mean_train_score': array([ 0.95036991]), 'std_train_score': array([ 0.00693798]), 'std_test_score': array([ 0.03342403]), 'params': ({},), 'split0_train_score': array([ 0.95791232]), 'std_fit_time': array([ 0.01288537]), 'split1_train_score': array([ 0.95662899]), 'mean_test_score': array([ 0.73398619]), 'split0_test_score': array([ 0.73432396]), 'split2_test_score': array([ 0.72780319]), 'mean_score_time': array([ 0.00536358]), 'split3_test_score': array([ 0.78388346]), 'split2_train_score': array([ 0.94425597]), 'mean_fit_time': array([ 0.89349288])}
GREP_ME***Best params of [RandomForestRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [RandomForestRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.73398618592
####################################################################################
################# Runing the itteration 193  of the GridSearchCV ####################
####################################################################################
***Starting [ElasticNet] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [ElasticNet] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.63030327]), 'std_score_time': array([ 0.01800447]), 'split1_test_score': array([ 0.6154477]), 'mean_train_score': array([ 0.65300838]), 'std_train_score': array([ 0.01576303]), 'std_test_score': array([ 0.04470654]), 'params': ({},), 'split0_train_score': array([ 0.67103976]), 'std_fit_time': array([ 0.0034481]), 'split1_train_score': array([ 0.66378084]), 'mean_test_score': array([ 0.64102088]), 'split0_test_score': array([ 0.58278427]), 'split2_test_score': array([ 0.66814122]), 'mean_score_time': array([ 0.02712113]), 'split3_test_score': array([ 0.69771033]), 'split2_train_score': array([ 0.64690963]), 'mean_fit_time': array([ 0.07027161])}
GREP_ME***Best params of [ElasticNet] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [ElasticNet] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.641020879257
####################################################################################
################# Runing the itteration 194  of the GridSearchCV ####################
####################################################################################
***Starting [HuberRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [HuberRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.35317228]), 'std_score_time': array([ 0.00025549]), 'split1_test_score': array([ 0.31011606]), 'mean_train_score': array([ 0.35119522]), 'std_train_score': array([ 0.00744027]), 'std_test_score': array([ 0.02645262]), 'params': ({},), 'split0_train_score': array([ 0.34166797]), 'std_fit_time': array([ 0.01018427]), 'split1_train_score': array([ 0.34796135]), 'mean_test_score': array([ 0.34845226]), 'split0_test_score': array([ 0.37436457]), 'split2_test_score': array([ 0.33762488]), 'mean_score_time': array([ 0.00330698]), 'split3_test_score': array([ 0.37170353]), 'split2_train_score': array([ 0.36197926]), 'mean_fit_time': array([ 0.12781429])}
GREP_ME***Best params of [HuberRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [HuberRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.348452259351
####################################################################################
################# Runing the itteration 195  of the GridSearchCV ####################
####################################################################################
***Starting [Lasso] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
GREP_ME***Results of [Lasso] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.6977157]), 'std_score_time': array([ 0.00909102]), 'split1_test_score': array([ 0.62429673]), 'mean_train_score': array([ 0.68775291]), 'std_train_score': array([ 0.00941173]), 'std_test_score': array([ 8.91709205]), 'params': ({},), 'split0_train_score': array([ 0.68405841]), 'std_fit_time': array([ 0.01687658]), 'split1_train_score': array([ 0.69514897]), 'mean_test_score': array([-4.50725962]), 'split0_test_score': array([ 0.66963013]), 'split2_test_score': array([-19.95208601]), 'mean_score_time': array([ 0.02709574]), 'split3_test_score': array([ 0.62912066]), 'split2_train_score': array([ 0.67408857]), 'mean_fit_time': array([ 0.56797272])}
GREP_ME***Best params of [Lasso] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [Lasso] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-4.50725962231
####################################################################################
################# Runing the itteration 196  of the GridSearchCV ####################
####################################################################################
***Starting [LassoLars] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ...........................GREP_ME***Results of [LassoLars] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.67932196]), 'std_score_time': array([ 0.00044321]), 'split1_test_score': array([ 0.64294171]), 'mean_train_score': array([ 0.67606428]), 'std_train_score': array([ 0.01018882]), 'std_test_score': array([ 0.7221743]), 'params': ({},), 'split0_train_score': array([ 0.67546886]), 'std_fit_time': array([ 0.05000965]), 'split1_train_score': array([ 0.68888831]), 'mean_test_score': array([ 0.23770381]), 'split0_test_score': array([ 0.65447256]), 'split2_test_score': array([-1.01305587]), 'mean_score_time': array([ 0.00212216]), 'split3_test_score': array([ 0.66645686]), 'split2_train_score': array([ 0.66057797]), 'mean_fit_time': array([ 0.09315121])}
GREP_ME***Best params of [LassoLars] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [LassoLars] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.237703813225
####################################################################################
################# Runing the itteration 197  of the GridSearchCV ####################
####################################################################################
***Starting [LinearRegression] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [LinearRegression] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.70415615]), 'std_score_time': array([ 0.00336816]), 'split1_test_score': array([-11.48785922]), 'mean_train_score': array([ 0.68845243]), 'std_train_score': array([ 0.0094709]), 'std_test_score': array([ 5.15719634]), 'params': ({},), 'split0_train_score': array([ 0.68280817]), 'std_fit_time': array([ 0.02027133]), 'split1_train_score': array([ 0.6872783]), 'mean_test_score': array([-2.56121646]), 'split0_test_score': array([ 0.11566486]), 'split2_test_score': array([ 0.50757107]), 'mean_score_time': array([ 0.00425482]), 'split3_test_score': array([ 0.61975745]), 'split2_train_score': array([ 0.67956712]), 'mean_fit_time': array([ 0.08006412])}
GREP_ME***Best params of [LinearRegression] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearRegression] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-2.56121646138
####################################################################################
################# Runing the itteration 198  of the GridSearchCV ####################
####################################################################################
***Starting [PassiveAggressiveRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [PassiveAggressiveRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.30677707]), 'std_score_time': array([ 0.00299967]), 'split1_test_score': array([-0.31212184]), 'mean_train_score': array([-0.28862763]), 'std_train_score': array([ 0.01173307]), 'std_test_score': array([ 0.03323266]), 'params': ({},), 'split0_train_score': array([-0.27639513]), 'std_fit_time': array([ 0.00061608]), 'split1_train_score': array([-0.28046728]), 'mean_test_score': array([-0.29168409]), 'split0_test_score': array([-0.33067354]), 'split2_test_score': array([-0.28086442]), 'mean_score_time': array([ 0.01201534]), 'split3_test_score': array([-0.24307654]), 'split2_train_score': array([-0.29087102]), 'mean_fit_time': array([ 0.01768756])}
GREP_ME***Best params of [PassiveAggressiveRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [PassiveAggressiveRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.29168408615
####################################################################################
################# Runing the itteration 199  of the GridSearchCV ####################
####################################################################################
***Starting [Ridge] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.6s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.8s
[CV]  ................................................................
[CV] ................................................. , total=   0.9s
GREP_ME***Results of [Ridge] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.68552171]), 'std_score_time': array([ 0.0024312]), 'split1_test_score': array([ 0.66803363]), 'mean_train_score': array([ 0.69358706]), 'std_train_score': array([ 0.00549369]), 'std_test_score': array([ 0.30199068]), 'params': ({},), 'split0_train_score': array([ 0.69221866]), 'std_fit_time': array([ 0.08411563]), 'split1_train_score': array([ 0.69614729]), 'mean_test_score': array([ 0.44668231]), 'split0_test_score': array([ 0.54023245]), 'split2_test_score': array([ 0.64802397]), 'mean_score_time': array([ 0.00576383]), 'split3_test_score': array([-0.06956083]), 'split2_train_score': array([ 0.70046059]), 'mean_fit_time': array([ 0.76820868])}
GREP_ME***Best params of [Ridge] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [Ridge] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.446682305389
####################################################################################
################# Runing the itteration 200  of the GridSearchCV ####################
####################################################################################
***Starting [SGDRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [SGDRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-1027960.47905546]), 'std_score_time': array([ 0.02146525]), 'split1_test_score': array([-1186.79338475]), 'mean_train_score': array([-655386.43648607]), 'std_train_score': array([ 436329.23586449]), 'std_test_score': array([ 90933.53293156]), 'params': ({},), 'split0_train_score': array([-423558.71112865]), 'std_fit_time': array([ 0.00041011]), 'split1_train_score': array([-56301.3837756]), 'mean_test_score': array([-153152.48092425]), 'split0_test_score': array([-207388.41728158]), 'split2_test_score': array([-168364.93809789]), 'mean_score_time': array([ 0.02747208]), 'split3_test_score': array([-235669.77493277]), 'split2_train_score': array([-1113725.17198456]), 'mean_fit_time': array([ 0.02046031])}
GREP_ME***Best params of [SGDRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [SGDRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-153152.480924
####################################################################################
################# Runing the itteration 201  of the GridSearchCV ####################
####################################################################################
***Starting [OrthogonalMatchingPursuit] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
GREP_ME***Results of [OrthogonalMatchingPursuit] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.64582793]), 'std_score_time': array([ 0.00539674]), 'split1_test_score': array([ 0.63147045]), 'mean_train_score': array([ 0.66972854]), 'std_train_score': array([ 0.01652706]), 'std_test_score': array([ 0.04336176]), 'params': ({},), 'split0_train_score': array([ 0.6641306]), 'std_fit_time': array([ 0.00881283]), 'split1_train_score': array([ 0.67923771]), 'mean_test_score': array([ 0.66467057]), 'split0_test_score': array([ 0.68738535]), 'split2_test_score': array([ 0.6158402]), 'mean_score_time': array([ 0.00525522]), 'split3_test_score': array([ 0.7239863]), 'split2_train_score': array([ 0.68971791]), 'mean_fit_time': array([ 0.04532588])}
GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.664670573925
####################################################################################
################# Runing the itteration 202  of the GridSearchCV ####################
####################################################################################
***Starting [RANSACRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.7s
[CV]  ................................................................
[CV] ................................................. , total=   1.0s
[CV]  ................................................................
[CV] ................................................. , total=   1.2s
[CV]  ................................................................
[CV] ................................................. , total=   1.3s
GREP_ME***Results of [RANSACRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ -1.30033082e+23]), 'std_score_time': array([ 0.00137498]), 'split1_test_score': array([-2548122.98099]), 'mean_train_score': array([ -3.37247294e+22]), 'std_train_score': array([  5.56391258e+22]), 'std_test_score': array([  7.68206378e+22]), 'params': ({},), 'split0_train_score': array([ -4.86583558e+21]), 'std_fit_time': array([ 0.22030223]), 'split1_train_score': array([-11923.87459355]), 'mean_test_score': array([ -4.56574513e+22]), 'split0_test_score': array([ -3.94434089e+21]), 'split2_test_score': array([-450.28401485]), 'mean_score_time': array([ 0.00394541]), 'split3_test_score': array([ -1.78685464e+23]), 'split2_train_score': array([-3483.02906257]), 'mean_fit_time': array([ 1.06913698])}
GREP_ME***Best params of [RANSACRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [RANSACRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-4.56574513352e+22
####################################################################################
################# Runing the itteration 203  of the GridSearchCV ####################
####################################################################################
***Starting [KNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
[CV]  ................................................................
[CV] ................................................. , total=   0.4s
GREP_ME***Results of [KNeighborsRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 0.70328441]), 'std_score_time': array([ 0.00681499]), 'split1_test_score': array([ 0.56739586]), 'mean_train_score': array([ 0.70127543]), 'std_train_score': array([ 0.00798303]), 'std_test_score': array([ 0.02488437]), 'params': ({},), 'split0_train_score': array([ 0.6901505]), 'std_fit_time': array([ 0.00014311]), 'split1_train_score': array([ 0.69929258]), 'mean_test_score': array([ 0.5649249]), 'split0_test_score': array([ 0.6032615]), 'split2_test_score': array([ 0.55369983]), 'mean_score_time': array([ 0.39404643]), 'split3_test_score': array([ 0.5353424]), 'split2_train_score': array([ 0.71237423]), 'mean_fit_time': array([ 0.0245353])}
GREP_ME***Best params of [KNeighborsRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [KNeighborsRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.564924899246
####################################################################################
################# Runing the itteration 204  of the GridSearchCV ####################
####################################################################################
***Starting [RadiusNeighborsRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
[CV]  ................................................................
GREP_ME***Error caught for  [RadiusNeighborsRegressor] , pipeline: [| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE] 
JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/user/data_mining/combo/combo.py in <module>()
    716         new_file = open(trg,"w")
    717         sys.stdout = new_file
    718         #set the itterator run to start from
    719         global itter_start
    720         itter_start = 0        
--> 721         run_for_many(cb.__name__,cb)
    722         #return stdout for some reason
    723 sys.stdout = orig_stdout
    724 
    725 

...........................................................................
/home/user/data_mining/combo/combo.py in run_for_many(cl_n='label_gross_5', label_fn=<function label_gross_5>)
    682     X = dta_clean.drop('worldwide_gross', axis=1)
    683     y = dta_clean.worldwide_gross.apply (lambda gross: label_fn (gross))
    684     print ("#########################################")
    685     print ("###Starting all estimators for cl: "+ str(cl_n))
    686     print ("#########################################")
--> 687     run_solver(X,y, preprocessors, transfomers, reducers, models_class, models_reg, results, errors, errors_ind, precomp_pipe)
        X =       actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns]
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        errors = []
        errors_ind = []
        precomp_pipe = []
    688     print ("#########################################")
    689     print ("###Finished all estimators for cl: "+ str(cl_n))
    690     print ("#########################################")
    691 

...........................................................................
/home/user/data_mining/combo/combo.py in run_solver(x=      actor_1_facebook_likes  actor_2_facebook_l...0.0              0.0  

[4812 rows x 183 columns], y=0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64, preprocessors=[FunctionTransformer(accept_sparse=False,
       ...=None, kw_args=None, pass_y=False, validate=True)], transfomers=[StandardScaler(copy=True, with_mean=True, with_std=True)], reducers=[RFE(estimator=ExtraTreesRegressor(bootstrap=Fals...,
  n_features_to_select=None, step=1, verbose=0)], models_class=[GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)], models_reg=[AdaBoostRegressor(base_estimator=None, learning_...ar',
         n_estimators=50, random_state=None), BaggingRegressor(base_estimator=None, bootstrap=...state=None,
         verbose=0, warm_start=False), ExtraTreesRegressor(bootstrap=False, criterion='...tate=None,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,
             warm_start=False), RandomForestRegressor(bootstrap=True, criterion=...ate=None,
           verbose=0, warm_start=False), ElasticNet(alpha=1.0, copy_X=True, fit_intercept...selection='cyclic', tol=0.0001, warm_start=False), HuberRegressor(alpha=0.0001, epsilon=1.35, fit_i...ax_iter=100,
        tol=1e-05, warm_start=False), Lasso(alpha=1.0, copy_X=True, fit_intercept=True...selection='cyclic', tol=0.0001, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.22044604...positive=False, precompute='auto', verbose=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False), PassiveAggressiveRegressor(C=1.0, epsilon=0.1, f...       shuffle=True, verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True...lse, random_state=None, solver='auto', tol=0.001), SGDRegressor(alpha=0.0001, average=False, epsilo...=None, shuffle=True, verbose=0, warm_start=False), OrthogonalMatchingPursuit(fit_intercept=True, n_...     normalize=True, precompute='auto', tol=None), RANSACRegressor(base_estimator=None, is_data_val...liers=inf, stop_probability=0.99, stop_score=inf), KNeighborsRegressor(algorithm='auto', leaf_size=... n_neighbors=5, p=2,
          weights='uniform'), RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), MLPRegressor(activation='relu', alpha=0.0001, ba...tion=0.1,
       verbose=False, warm_start=False), SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, ...ter=-1, shrinking=True, tol=0.001, verbose=False), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_int...0,
     random_state=None, tol=0.0001, verbose=0), ...], results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.46682722154980649}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73110954519610083}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64102087925711426}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.7386748130415729}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.75604884907713243}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34845225935077473}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56492489924559031}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}, errors=[], errors_ind=[], precomp_pipe=[])
    646     #for each physically saved pickle run grid search for each model
    647     for filename in os.listdir("./tmp"):
    648         pipe_dict = pickle.loads(open("./tmp/" + filename, 'rb').read())
    649         for model_class in models_class: 
    650             for model_reg in models_reg: 
--> 651                 run_grid_search( pipe_dict['precomp_transform'],y, model_class, model_reg,  pipe_dict['cfg_dict'],  pipe_dict['pipeline_cfg'], results, errors, errors_ind)
        pipe_dict = {'cfg_dict': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipeline_cfg': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'precomp_transform': array([[-0.37063813, -0.18958359,  0.11999121, .... -0.40589462,
        -0.65062747, -0.86304212]])}
        y = 0       5
1       5
2       5
3       5
4       ...  1
4811    1
Name: worldwide_gross, dtype: int64
        model_class = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)
        model_reg = RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform')
        results = {'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.46682722154980649}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73110954519610083}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64102087925711426}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.7386748130415729}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.75604884907713243}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34845225935077473}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56492489924559031}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}
        errors = []
        errors_ind = []
    652 
    653 ##run calssifiers for two 4 cases - 2 classes, 3 clasees, 4 classes, 5 clasess
    654 
    655 def label_gross_2 (gross):

...........................................................................
/home/user/data_mining/combo/combo.py in run_grid_search(x=      0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], y=1539     69131860
793     158162788
1180     992...     51204567
Name: worldwide_gross, dtype: int64, model_class=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), model_reg=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), cfg_dict={'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, pipeline_cfg='| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', results={'AdaBoostRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.46682722154980649}, 'BaggingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.73110954519610083}, 'DecisionTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.5011566641026165}, 'ElasticNet': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.64102087925711426}, 'ExtraTreeRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.51759214690461552}, 'ExtraTreesRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.7386748130415729}, 'GradientBoostingRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.75604884907713243}, 'HuberRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.34845225935077473}, 'KNeighborsRegressor': {'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.56492489924559031}, 'Lasso': {'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'score': 0.60578651388418248}, ...}, errors=[], errors_ind=[])
    576     print("##param_grid##")
    577     print(param_grid)
    578     estimator = GridSearchCV(pipe,param_grid,verbose=2, cv=cv, n_jobs=-1)
    579     #run the esmimator, except eceptions, sape errors
    580     try:
--> 581             estimator.fit(x, y)
        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...rain_score=True,
       scoring=None, verbose=2)>
        x =       0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns]
        y = 1539     69131860
793     158162788
1180     992...     51204567
Name: worldwide_gross, dtype: int64
    582             print ("GREP_ME***Results of ["  + name + "] estimatorrun are")
    583             print (estimator.cv_results_)            
    584             print ("GREP_ME***Best params of ["  + name + "] estimator,pipeline:"+ pipeline_cfg+"  run are")
    585             best_param = dict(estimator.best_params_, **cfg_dict)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], y=1539     69131860
793     158162788
1180     992...     51204567
Name: worldwide_gross, dtype: int64, groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,
       scoring=None, verbose=2)>
        X =       0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns]
        y = 1539     69131860
793     158162788
1180     992...     51204567
Name: worldwide_gross, dtype: int64
        groups = None
        self.param_grid = {}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=4, error_score='raise',
       e...train_score=True,
       scoring=None, verbose=2), X=      0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], y=1539     69131860
793     158162788
1180     992...     51204567
Name: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Sun Apr 30 17:17:07 2017
PID: 24733                                   Python 3.4.3: /usr/bin/python3
...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], 1539     69131860
793     158162788
1180     992...     51204567
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]),       0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], 1539     69131860
793     158162788
1180     992...     51204567
Name: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([1203, 1204, 1205, ..., 4809, 4810, 4811]), array([   0,    1,    2, ..., 1200, 1201, 1202]), 2, {})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...5 -0.650627 -0.863042  

[4812 rows x 64 columns], y=1539     69131860
793     158162788
1180     992...     51204567
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1203, 1204, 1205, ..., 4809, 4810, 4811]), test=array([   0,    1,    2, ..., 1200, 1201, 1202]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    255                              " numeric value. (Hint: if using 'raise', please"
    256                              " make sure that it has been spelled correctly.)")
    257 
    258     else:
    259         fit_time = time.time() - start_time
--> 260         test_score = _score(estimator, X_test, y_test, scorer)
        test_score = undefined
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns]
        y_test = 1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64
        scorer = <function _passthrough_scorer>
    261         score_time = time.time() - start_time - fit_time
    262         if return_train_score:
    263             train_score = _score(estimator, X_train, y_train, scorer)
    264 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _score(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X_test=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns], y_test=1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>)
    283 def _score(estimator, X_test, y_test, scorer):
    284     """Compute the score of an estimator on a given test set."""
    285     if y_test is None:
    286         score = scorer(estimator, X_test)
    287     else:
--> 288         score = scorer(estimator, X_test, y_test)
        score = undefined
        scorer = <function _passthrough_scorer>
        estimator = Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))])
        X_test =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns]
        y_test = 1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64
    289     if hasattr(score, 'item'):
    290         try:
    291             # e.g. unwrap memmapped scalars
    292             score = score.item()

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/scorer.py in _passthrough_scorer(estimator=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), *args=(      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns], 1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64), **kwargs={})
    214     return scorer
    215 
    216 
    217 def _passthrough_scorer(estimator, *args, **kwargs):
    218     """Function that wraps estimator.score"""
--> 219     return estimator.score(*args, **kwargs)
        estimator.score = <function Pipeline.score>
        args = (      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns], 1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64)
        kwargs = {}
    220 
    221 
    222 def check_scoring(estimator, scoring=None, allow_none=False):
    223     """Determine scorer from user options.

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/metaestimators.py in <lambda>(*args=(      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns], 1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64), **kwargs={})
     49                     break
     50             else:
     51                 attrgetter(self.delegate_names[-1])(obj)
     52 
     53         # lambda, but not partial, allows help() to work with update_wrapper
---> 54         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)
        args = (      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns], 1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64)
        kwargs = {}
     55         # update the docstring of the returned function
     56         update_wrapper(out, self.fn)
     57         return out
     58 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in score(self=Pipeline(steps=[('model', RadiusNeighborsRegress...rams=None, p=2, radius=1.0, weights='uniform'))]), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns], y=1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64)
    500         """
    501         Xt = X
    502         for name, transform in self.steps[:-1]:
    503             if transform is not None:
    504                 Xt = transform.transform(Xt)
--> 505         return self.steps[-1][-1].score(Xt, y)
        self.steps.score = undefined
        Xt =       0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns]
        y = 1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64
    506 
    507     @property
    508     def classes_(self):
    509         return self.steps[-1][-1].classes_

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/base.py in score(self=RadiusNeighborsRegressor(algorithm='auto', leaf_..._params=None, p=2, radius=1.0, weights='uniform'), X=      0         0         1         2         3 ...9 -0.650627 -0.863042  

[1203 rows x 64 columns], y=1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64, sample_weight=None)
    382             R^2 of self.predict(X) wrt. y.
    383         """
    384 
    385         from .metrics import r2_score
    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,
--> 387                         multioutput='variance_weighted')
    388 
    389 
    390 ###############################################################################
    391 class ClusterMixin(object):

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in r2_score(y_true=1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64, y_pred=array([             nan,   1.89738192e+08,      ...        nan,              nan,              nan]), sample_weight=None, multioutput='variance_weighted')
    450     >>> y_pred = [3,2,1]
    451     >>> r2_score(y_true, y_pred)
    452     -3.0
    453     """
    454     y_type, y_true, y_pred, multioutput = _check_reg_targets(
--> 455         y_true, y_pred, multioutput)
        y_true = 1539     69131860
793     158162788
1180     992...    381687380
Name: worldwide_gross, dtype: int64
        y_pred = array([             nan,   1.89738192e+08,      ...        nan,              nan,              nan])
        multioutput = 'variance_weighted'
    456 
    457     if sample_weight is not None:
    458         sample_weight = column_or_1d(sample_weight)
    459         weight = sample_weight[:, np.newaxis]

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([ 69131860, 158162788,  99296462, ...,    887000,   6276869,
       381687380]), y_pred=array([             nan,   1.89738192e+08,      ...        nan,              nan,              nan]), multioutput='variance_weighted')
     71         correct keyword.
     72 
     73     """
     74     check_consistent_length(y_true, y_pred)
     75     y_true = check_array(y_true, ensure_2d=False)
---> 76     y_pred = check_array(y_pred, ensure_2d=False)
        y_pred = array([             nan,   1.89738192e+08,      ...        nan,              nan,              nan])
     77 
     78     if y_true.ndim == 1:
     79         y_true = y_true.reshape((-1, 1))
     80 

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in check_array(array=array([             nan,   1.89738192e+08,      ...        nan,              nan,              nan]), accept_sparse=None, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)
    402             array = array.astype(np.float64)
    403         if not allow_nd and array.ndim >= 3:
    404             raise ValueError("Found array with dim %d. %s expected <= 2."
    405                              % (array.ndim, estimator_name))
    406         if force_all_finite:
--> 407             _assert_all_finite(array)
        array = array([             nan,   1.89738192e+08,      ...        nan,              nan,              nan])
    408 
    409     shape_repr = _shape_repr(array.shape)
    410     if ensure_min_samples > 0:
    411         n_samples = _num_samples(array)

...........................................................................
/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([             nan,   1.89738192e+08,      ...        nan,              nan,              nan]))
     53     # everything is finite; fall back to O(n) space np.isfinite to prevent
     54     # false positives from overflow in sum method.
     55     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())
     56             and not np.isfinite(X).all()):
     57         raise ValueError("Input contains NaN, infinity"
---> 58                          " or a value too large for %r." % X.dtype)
        X.dtype = dtype('float64')
     59 
     60 
     61 def assert_all_finite(X):
     62     """Throw a ValueError if X contains NaN or infinity.

ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
___________________________________________________________________________
####################################################################################
################# Runing the itteration 205  of the GridSearchCV ####################
####################################################################################
***Starting [MLPRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=  25.9s
[CV]  ................................................................
[CV] ................................................. , total=  27.6s
[CV]  ................................................................
[CV] ................................................. , total=  27.6s
GREP_ME***Results of [MLPRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.3021075]), 'std_score_time': array([ 0.16377885]), 'split1_test_score': array([-0.29038529]), 'mean_train_score': array([-0.28980524]), 'std_train_score': array([ 0.00960807]), 'std_test_score': array([ 0.03447727]), 'params': ({},), 'split0_train_score': array([-0.29271351]), 'std_fit_time': array([ 1.32137106]), 'split1_train_score': array([-0.28904745]), 'mean_test_score': array([-0.29413401]), 'split0_test_score': array([-0.28398436]), 'split2_test_score': array([-0.34873336]), 'mean_score_time': array([ 0.18105286]), 'split3_test_score': array([-0.25343302]), 'split2_train_score': array([-0.27535248]), 'mean_fit_time': array([ 26.25151372])}
GREP_ME***Best params of [MLPRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [MLPRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.294134007189
####################################################################################
################# Runing the itteration 206  of the GridSearchCV ####################
####################################################################################
***Starting [SVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.4s
[CV]  ................................................................
[CV] ................................................. , total=   2.3s
[CV]  ................................................................
[CV] ................................................. , total=   2.5s
GREP_ME***Results of [SVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.13246013]), 'std_score_time': array([ 0.00940605]), 'split1_test_score': array([-0.12335546]), 'mean_train_score': array([-0.13178428]), 'std_train_score': array([ 0.00351671]), 'std_test_score': array([ 0.01128575]), 'params': ({},), 'split0_train_score': array([-0.12760549]), 'std_fit_time': array([ 0.0572387]), 'split1_train_score': array([-0.13710047]), 'mean_test_score': array([-0.13253701]), 'split0_test_score': array([-0.12694041]), 'split2_test_score': array([-0.15185615]), 'mean_score_time': array([ 0.45793784]), 'split3_test_score': array([-0.12799601]), 'split2_train_score': array([-0.12997102]), 'mean_fit_time': array([ 1.93182516])}
GREP_ME***Best params of [SVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [SVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.132537008634
####################################################################################
################# Runing the itteration 207  of the GridSearchCV ####################
####################################################################################
***Starting [LinearSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [LinearSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.28610714]), 'std_score_time': array([ 0.00509525]), 'split1_test_score': array([-0.25780698]), 'mean_train_score': array([-0.28948582]), 'std_train_score': array([ 0.00625548]), 'std_test_score': array([ 0.01918802]), 'params': ({},), 'split0_train_score': array([-0.28482621]), 'std_fit_time': array([ 0.00151223]), 'split1_train_score': array([-0.30025366]), 'mean_test_score': array([-0.29073787]), 'split0_test_score': array([-0.30593476]), 'split2_test_score': array([-0.29980983]), 'mean_score_time': array([ 0.01478916]), 'split3_test_score': array([-0.29939992]), 'split2_train_score': array([-0.28675625]), 'mean_fit_time': array([ 0.01983327])}
GREP_ME***Best params of [LinearSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [LinearSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.290737871726
####################################################################################
################# Runing the itteration 208  of the GridSearchCV ####################
####################################################################################
***Starting [NuSVR] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
GREP_ME***Results of [NuSVR] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([-0.05372086]), 'std_score_time': array([ 0.00196878]), 'split1_test_score': array([-0.05424704]), 'mean_train_score': array([-0.05228023]), 'std_train_score': array([ 0.00147258]), 'std_test_score': array([ 0.00510407]), 'params': ({},), 'split0_train_score': array([-0.05041266]), 'std_fit_time': array([ 0.01486142]), 'split1_train_score': array([-0.05372244]), 'mean_test_score': array([-0.05254098]), 'split0_test_score': array([-0.04379696]), 'split2_test_score': array([-0.05624829]), 'mean_score_time': array([ 0.2266838]), 'split3_test_score': array([-0.05587164]), 'split2_train_score': array([-0.05126498]), 'mean_fit_time': array([ 1.55883485])}
GREP_ME***Best params of [NuSVR] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [NuSVR] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
-0.0525409804009
####################################################################################
################# Runing the itteration 209  of the GridSearchCV ####################
####################################################################################
***Starting [DecisionTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
[CV]  ................................................................
[CV] ................................................. , total=   0.2s
GREP_ME***Results of [DecisionTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00023265]), 'split1_test_score': array([ 0.52523693]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.02533395]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.0018078]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.530175]), 'split0_test_score': array([ 0.54528244]), 'split2_test_score': array([ 0.55872741]), 'mean_score_time': array([ 0.00195664]), 'split3_test_score': array([ 0.49145321]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.15822887])}
GREP_ME***Best params of [DecisionTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [DecisionTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.530174997361
####################################################################################
################# Runing the itteration 210  of the GridSearchCV ####################
####################################################################################
***Starting [ExtraTreeRegressor] estimator run, pipeline: | preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE 
##param_grid##
{}
Fitting 4 folds for each of 1 candidates, totalling 4 fits
[CV]  ................................................................
[CV] ................................................. , total=   0.1s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
[CV]  ................................................................
[CV] ................................................. , total=   0.0s
GREP_ME***Results of [ExtraTreeRegressor] estimatorrun are
{'rank_test_score': array([1], dtype=int32), 'split3_train_score': array([ 1.]), 'std_score_time': array([ 0.00018422]), 'split1_test_score': array([ 0.62033416]), 'mean_train_score': array([ 1.]), 'std_train_score': array([ 0.]), 'std_test_score': array([ 0.03452746]), 'params': ({},), 'split0_train_score': array([ 1.]), 'std_fit_time': array([ 0.00190958]), 'split1_train_score': array([ 1.]), 'mean_test_score': array([ 0.57245156]), 'split0_test_score': array([ 0.52438272]), 'split2_test_score': array([ 0.56345603]), 'mean_score_time': array([ 0.00171864]), 'split3_test_score': array([ 0.58163332]), 'split2_train_score': array([ 1.]), 'mean_fit_time': array([ 0.04729921])}
GREP_ME***Best params of [ExtraTreeRegressor] estimator,pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE  run are
{'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}
GREP_ME***Best score of [ExtraTreeRegressor] estimator, pipeline:| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE run are
0.57245155506
#########################################
###Finished all estimators for cl: label_gross_5
#########################################
#########################################
#######Printing results for cl: label_gross_5
#########################################
{'KNeighborsRegressor': {'score': 0.56492489924559031, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'SVR': {'score': -0.13225693175196362, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}}, 'Lasso': {'score': 0.60578651388418248, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}}, 'ExtraTreeRegressor': {'score': 0.57245155506009526, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'BaggingRegressor': {'score': 0.73110954519610083, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'ExtraTreesRegressor': {'score': 0.7386748130415729, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'RANSACRegressor': {'score': -2.101799745980484e+21, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}}, 'LinearSVR': {'score': -0.28991730693635248, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 127, 'reducer__step': 0.1}}, 'AdaBoostRegressor': {'score': 0.46682722154980649, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'LassoLars': {'score': 0.61270497719899153, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}}, 'MLPRegressor': {'score': -0.29038242450538565, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}}, 'SGDRegressor': {'score': 0.59075537106294351, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}}, 'ElasticNet': {'score': 0.64102087925711426, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'LinearRegression': {'score': 0.62248927040547852, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 60, 'reducer__step': 0.1}}, 'RandomForestRegressor': {'score': 0.73398618591977338, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'OrthogonalMatchingPursuit': {'score': 0.66467057392496764, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'Ridge': {'score': 0.59501659589226419, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 57, 'reducer__step': 0.1}}, 'GradientBoostingRegressor': {'score': 0.75604884907713243, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'PassiveAggressiveRegressor': {'score': -0.2898894549546705, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 1}, 'reducer__n_features_to_select': 115, 'reducer__step': 0.1}}, 'DecisionTreeRegressor': {'score': 0.53017499736127605, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}, 'NuSVR': {'score': -0.052269453453405501, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 2}, 'reducer__n_features_to_select': 203, 'reducer__step': 0.1}}, 'HuberRegressor': {'score': 0.34845225935077473, 'pipe': '| preprocessor:log_poly | transfomer: StandardScaler | reducer: RFE', 'best_cfg': {'preprocessor__kw_args': {'pw': 3}, 'reducer__n_features_to_select': 63, 'reducer__step': 0.1}}}
priting simply sorted numbers, grep them to find the best cfg or cl: label_gross_5
[-2.101799745980484e+21, -0.29038242450538565, -0.28991730693635248, -0.2898894549546705, -0.13225693175196362, -0.052269453453405501, 0.34845225935077473, 0.46682722154980649, 0.53017499736127605, 0.56492489924559031, 0.57245155506009526, 0.59075537106294351, 0.59501659589226419, 0.60578651388418248, 0.61270497719899153, 0.62248927040547852, 0.64102087925711426, 0.66467057392496764, 0.73110954519610083, 0.73398618591977338, 0.7386748130415729, 0.75604884907713243]
