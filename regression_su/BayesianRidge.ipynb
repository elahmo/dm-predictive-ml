{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syz/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "from subprocess import check_output\n",
    "input_folder = \"../../moviedata\"\n",
    "# print(check_output([\"ls\", input_folder]).decode(\"utf8\"))\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "from sklearn import tree\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import BayesianRidge as br\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f = pd.read_csv(input_folder+\"/movie_metadata.csv\")\n",
    "f = pd.read_csv(input_folder+\"/movie_metadata_cleaned_categ_num_only.csv\")\n",
    "\n",
    "#data=DataFrame(f)\n",
    "# data.head(10)\n",
    "\n",
    "# np.sum(data.isnull())\n",
    "data_2 = f.dropna()\n",
    "# print( np.sum(data_2.isnull()) )\n",
    "# print( data_2.shape )\n",
    "# print( type(data_2) )\n",
    "\n",
    "# Select all numerical features\n",
    "# index_filter_num_all=data_2.dtypes[data.dtypes!='object'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictors_name = ['num_critic_for_reviews', 'duration', 'director_facebook_likes',\n",
    "#        'actor_3_facebook_likes', 'actor_1_facebook_likes', \n",
    "#        'num_voted_users', 'cast_total_facebook_likes', 'facenumber_in_poster',\n",
    "#        'num_user_for_reviews', 'budget', 'title_year',\n",
    "#        'actor_2_facebook_likes', 'imdb_score', 'aspect_ratio',\n",
    "#        'movie_facebook_likes']\n",
    "# targets_names = ['gross', 'gross_millions', 'gross_log']\n",
    "\n",
    "# all_num_names = predictors_name + targets_names\n",
    "# print(\"All:\")\n",
    "# print(all_num_names)\n",
    "y = data_2['worldwide_gross']\n",
    "X = data_2.drop('worldwide_gross', axis=1)\n",
    "\n",
    "# Split data into training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(xIn, yIn, test_size=0.2, random_state=0)\n",
    "# msk = np.random.rand(len(data_2)) < 0.8\n",
    "# train = data_2[msk]\n",
    "# test = data_2[~msk]\n",
    "# print len(data_2)\n",
    "# print len(train)\n",
    "# print len(test)\n",
    "\n",
    "# Training\n",
    "# X=train[predictors_name]\n",
    "# y=np.log(train['budget'])\n",
    "# X0=data_2[predictors_name]\n",
    "# y0=np.log(data_2['budget'])\n",
    "\n",
    "# Testing\n",
    "# X1=test[predictors_name]\n",
    "# y1=np.log(test['budget'])\n",
    "# print clf.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  1  iterations\n",
      "Convergence after  1  iterations\n",
      "Convergence after  71  iterations\n",
      "Convergence after  71  iterations\n",
      "Convergence after  61  iterations\n",
      "Convergence after  61  iterations\n",
      "Convergence after  61  iterations\n",
      "Convergence after  61  iterations\n",
      "Convergence after  1  iterations\n",
      "Convergence after  1  iterations\n",
      "Convergence after  71  iterations\n",
      "Convergence after  71  iterations\n",
      "Convergence after  61  iterations\n",
      "Convergence after  61  iterations\n",
      "Convergence after  61  iterations\n",
      "Convergence after  61  iterations\n",
      "0.676833431174\n",
      "<bound method BayesianRidge.get_params of BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=True, copy_X=True,\n",
      "       fit_intercept=False, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=True, tol=0.001, verbose=True)>\n"
     ]
    }
   ],
   "source": [
    "# Apply BayesianRidge Regression\n",
    "max_score = 0\n",
    "para = None\n",
    "for compute_score in [True, False]:\n",
    "    for fit_intercept in [True, False]:\n",
    "        for normalize in [True, False]:\n",
    "            for copy_X in [True, False]:\n",
    "                for verbose in [True, False]:\n",
    "                    \n",
    "                    clf = br(compute_score=compute_score, fit_intercept = fit_intercept, normalize = normalize, copy_X = copy_X, verbose = verbose)\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    score = clf.score(X_test, y_test)\n",
    "                    if score > max_score:\n",
    "                        max_score = score\n",
    "                        para =  clf.get_params\n",
    "#                     y_pred = clf.predict(X_test)\n",
    "#                     print clf.get_params\n",
    "# print clf.scores_\n",
    "print max_score\n",
    "print para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67677757  0.71018648  0.63724302  0.67792935  0.65465286]\n",
      "0.671357855063\n",
      "[ -7.59552097e-01  -1.39476163e+01  -5.16184022e+01  -7.57170732e+01\n",
      "  -3.04164468e+04]\n",
      "-6111.69788962\n"
     ]
    }
   ],
   "source": [
    "X_r, X_d, y_r, y_d = train_test_split(X, y, test_size=0, random_state=0)\n",
    "# scaler = preprocessing.StandardScaler().fit(X_r)\n",
    "# X_train_transformed = scaler.transform(X_r)\n",
    "clf1 = br()\n",
    "clf2 = br()\n",
    "score = cross_val_score(clf1, X_r, y_r, cv=5)\n",
    "print score\n",
    "print score.mean()\n",
    "\n",
    "score2 = cross_val_score(clf2, X, y, cv=5)\n",
    "print score2\n",
    "print score2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.25318003e+08,   5.29767190e+07,   9.97487099e+06, ...,\n",
       "         1.32710665e+08,  -8.70481386e+06,   3.88872593e+07])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
