{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 1\n",
      "676\n",
      "class 2\n",
      "111\n",
      "class 3\n",
      "789\n",
      "class 4\n",
      "1325\n",
      "class 5\n",
      "16\n",
      "class 6\n",
      "179\n",
      "class 7\n",
      "506\n",
      "class 8\n",
      "96\n",
      "class 9\n",
      "14\n",
      "class 10\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, RFE\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "import seaborn as sns # More snazzy plotting library\n",
    "import itertools\n",
    "from itertools import  product\n",
    "import pprint\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from multiprocessing import Process, Value, Array\n",
    "#from asyncio import Queue\n",
    "from threading import Thread\n",
    "import pickle\n",
    "import shutil\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "path_full = \"../dataset/no_imdb_names-count_cat-tf_184f.csv\"\n",
    "path_train = \"../dataset/no_imdb_names-count_cat-tf_184f_train.csv\"\n",
    "path_test = \"../dataset/no_imdb_names-count_cat-tf_184f_test.csv\"\n",
    "\n",
    "dta_full = pd.read_csv(path_full)\n",
    "dta_full = dta_full.fillna(value=0, axis=1)\n",
    "dta_full = dta_full.dropna()\n",
    "dta_full = dta_full.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "dta_train = pd.read_csv(path_train)\n",
    "dta_train = dta_train.fillna(value=0, axis=1)\n",
    "dta_train = dta_train.dropna()\n",
    "dta_train = dta_train.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "dta_test = pd.read_csv(path_test)\n",
    "dta_test = dta_test.fillna(value=0, axis=1)\n",
    "dta_test = dta_test.dropna()\n",
    "dta_test = dta_test.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "def label_gross_2 (gross):\n",
    "    if (gross < 200000000) : return 1\n",
    "    elif (gross >= 200000000) : return 2\n",
    "\n",
    "def label_gross_3 (gross):\n",
    "    if (gross < 10000000) : return 1\n",
    "    elif ((gross >= 10000000) & (gross < 300000000)) : return 2\n",
    "    elif (gross >= 300000000) : return 3\n",
    "\n",
    "def label_gross_4 (gross):\n",
    "    if (gross < 5000000) : return 1\n",
    "    elif ((gross >= 5000000) & (gross < 50000000)) : return 2\n",
    "    elif ((gross >= 50000000) & (gross < 350000000)) : return 3\n",
    "    elif (gross >= 350000000) : return 4\n",
    "\n",
    "def label_gross_5 (gross):\n",
    "    if (gross < 1000000) : return 1\n",
    "    elif ((gross >= 1000000) & (gross < 25000000)) : return 2\n",
    "    elif ((gross >= 25000000) & (gross < 100000000)) : return 3\n",
    "    elif ((gross >= 100000000) & (gross < 400000000)) : return 4\n",
    "    elif (gross >= 400000000) : return 5\n",
    "    \n",
    "def label_gross_6 (gross):\n",
    "    if (gross < 1000000) : return 1\n",
    "    elif ((gross >= 1000000) & (gross < 25000000)) : return 2\n",
    "    elif ((gross >= 25000000) & (gross < 50000000)) : return 3\n",
    "    elif ((gross >= 50000000) & (gross < 150000000)) : return 4\n",
    "    elif ((gross >= 150000000) & (gross < 450000000)) : return 5\n",
    "    elif (gross >= 450000000) : return 6\n",
    "\n",
    "def label_gross_7 (gross):\n",
    "    if (gross < 500000) : return 1\n",
    "    elif ((gross >= 500000) & (gross < 5000000)) : return 2\n",
    "    elif ((gross >= 5000000) & (gross < 50000000)) : return 3\n",
    "    elif ((gross >= 50000000) & (gross < 150000000)) : return 4\n",
    "    elif ((gross >= 150000000) & (gross < 200000000)) : return 5\n",
    "    elif ((gross >= 200000000) & (gross < 500000000)) : return 6\n",
    "    elif (gross >= 500000000) : return 7\n",
    "    \n",
    "def label_gross_8 (gross):\n",
    "    if (gross < 500000) : return 1\n",
    "    elif ((gross >= 500000) & (gross < 5000000)) : return 2\n",
    "    elif ((gross >= 5000000) & (gross < 20000000)) : return 3\n",
    "    elif ((gross >= 20000000) & (gross < 50000000)) : return 4\n",
    "    elif ((gross >= 50000000) & (gross < 100000000)) : return 5\n",
    "    elif ((gross >= 100000000) & (gross < 250000000)) : return 6\n",
    "    elif ((gross >= 250000000) & (gross < 550000000)) : return 7\n",
    "    elif (gross >= 550000000) : return 8\n",
    "\n",
    "def label_gross_9 (gross):\n",
    "    if (gross < 500000) : return 1\n",
    "    elif ((gross >= 500000) & (gross < 5000000)) : return 2\n",
    "    elif ((gross >= 5000000) & (gross < 20000000)) : return 3\n",
    "    elif ((gross >= 20000000) & (gross < 50000000)) : return 4\n",
    "    elif ((gross >= 50000000) & (gross < 70000000)) : return 5\n",
    "    elif ((gross >= 70000000) & (gross < 125000000)) : return 6\n",
    "    elif ((gross >= 125000000) & (gross < 250000000)) : return 7\n",
    "    elif ((gross >= 250000000) & (gross < 550000000)) : return 8\n",
    "    elif (gross >= 550000000) : return 9\n",
    "    \n",
    "def label_gross_10 (gross):\n",
    "    if    (gross  < 500000) : return 1\n",
    "    elif ((gross >= 500000)    & (gross < 5000000)) : return 2\n",
    "    elif ((gross >= 5000000)   & (gross < 20000000)) : return 3\n",
    "    elif ((gross >= 20000000)  & (gross < 50000000)) : return 4\n",
    "    elif ((gross >= 50000000)  & (gross < 70000000)) : return 5\n",
    "    elif ((gross >= 70000000)  & (gross < 125000000)) : return 6\n",
    "    elif ((gross >= 125000000) & (gross < 250000000)) : return 7\n",
    "    elif ((gross >= 250000000) & (gross < 400000000)) : return 8\n",
    "    elif ((gross >= 400000000) & (gross < 600000000)) : return 9\n",
    "    elif  (gross >= 600000000) : return 10\n",
    "\n",
    "pw = 1\n",
    "def log_poly(X):\n",
    "    #hardcoe for this test\n",
    "    global pw\n",
    "    #do log\n",
    "    df_t = pd.DataFrame(X[:,:10])\n",
    "    X_t = df_t.replace(0, 1/math.e)\n",
    "    log_res = np.log(X_t)\n",
    "    \n",
    "    #do poly\n",
    "    vector = X[:,10:]\n",
    "    res    = X[:,:10]\n",
    "    X      = X[:,:10]\n",
    "    for power in range(2,pw + 1):\n",
    "        res = np.concatenate((res, np.power(X, power)), axis=1)\n",
    "    res_poly_log = np.concatenate((res, log_res), axis=1)\n",
    "    \n",
    "    #return conat results\n",
    "    return np.concatenate((res_poly_log, vector), axis=1)\n",
    "\n",
    "LogPolynomialTransformer = FunctionTransformer(log_poly)\n",
    "\n",
    "preprocessor = LogPolynomialTransformer\n",
    "\n",
    "transfomer = StandardScaler()\n",
    "\n",
    "reducer = RFE(ExtraTreesRegressor(), step=0.1, n_features_to_select =round((dta_train.shape[1] + (pw -1) *10)*0.33) )\n",
    "\n",
    "model_class = GradientBoostingClassifier()\n",
    "model_reg = GradientBoostingRegressor()\n",
    "\n",
    "pipe_cl = Pipeline(steps=[('preprocessor', preprocessor), ('transfomer', transfomer), ('reducer', reducer)])\n",
    "pipe_reg = Pipeline(steps=[('preprocessor', preprocessor), ('transfomer', transfomer), ('reducer', reducer)])\n",
    "\n",
    "x_train = dta_train.drop('worldwide_gross', axis=1)\n",
    "y_train_cl = dta_train.worldwide_gross.apply (lambda gross: label_gross_10 (gross))\n",
    "y_train_reg = dta_train['worldwide_gross']\n",
    "\n",
    "x_test = dta_test.drop('worldwide_gross', axis=1)\n",
    "y_test_cl = dta_test.worldwide_gross.apply (lambda gross: label_gross_10 (gross))\n",
    "y_test_reg = dta_test['worldwide_gross']\n",
    "\n",
    "\n",
    "x_train_cl_tr = pipe_cl.fit_transform(x_train,y_train_cl)\n",
    "x_train_reg_tr = pipe_cl.fit_transform(x_train,y_train_reg)\n",
    "\n",
    "x_test_cl_tr = pipe_cl.transform(x_test)\n",
    "x_test_reg_tr = pipe_cl.transform(x_test)\n",
    "\n",
    "mode = GradientBoostingClassifier(\n",
    "    max_depth = 10, \n",
    "    max_features = 0.01,\n",
    "    max_leaf_nodes = None,\n",
    "    learning_rate = 0.01, \n",
    "    n_estimators =  200, \n",
    "    min_samples_leaf = 5\n",
    ")\n",
    "\n",
    "#cross_val_score(mode, x_train_cl_tr, y_train_cl, cv=10).mean()\n",
    "mode.fit(x_train_cl_tr, y_train_cl)\n",
    "res = mode.predict(x_train_cl_tr)\n",
    "uniq = set(res)\n",
    "for un in uniq:\n",
    "    print(\"class \" + str(un))\n",
    "    print(len(filter(lambda x: x == un, res)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 1\n",
      "3665\n",
      "class 2\n",
      "119\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_test_grtb_reg =  GradientBoostingClassifier().fit(x_train, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.458509513742\n",
      "0.75096597253\n"
     ]
    }
   ],
   "source": [
    "model_test_cl =  pipe_cl.fit(x_train, y_train_cl)\n",
    "model_test_reg =  pipe_reg.fit(x_train, y_train_reg)\n",
    "print(model_test_cl.score(x_train,y_train_cl))\n",
    "print(model_test_reg.score(x_train,y_train_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.421330517423\n",
      "0.640583692201\n"
     ]
    }
   ],
   "source": [
    "print(model_test_cl.score(x_test,y_test_cl))\n",
    "print(model_test_reg.score(x_test,y_test_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82822410148\n",
      "0.794086589229\n"
     ]
    }
   ],
   "source": [
    "model_test_grtb_cl =  GradientBoostingClassifier().fit(x_train, y_train_cl)\n",
    "print(model_test_grtb_cl.score(x_train,y_train_cl))\n",
    "print(model_test_grtb_cl.score(x_test,y_test_cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746206504992\n",
      "0.648444194927\n"
     ]
    }
   ],
   "source": [
    "model_test_grtb_reg =  GradientBoostingRegressor().fit(x_train, y_train_reg)\n",
    "print(model_test_grtb_reg.score(x_train,y_train_reg))\n",
    "print(model_test_grtb_reg.score(x_test,y_test_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.451800357303\n",
      "0.32032433973\n",
      "############################\n",
      "0.486610018717\n",
      "0.376987111481\n",
      "############################\n",
      "0.807096287635\n",
      "0.421949603602\n",
      "############################\n"
     ]
    }
   ],
   "source": [
    "df_1_train = dta_train[dta_train[\"worldwide_gross\"] < 10000000]\n",
    "X_1_train = df_1_train.drop('worldwide_gross', axis=1)\n",
    "y_1_train = df_1_train['worldwide_gross']\n",
    "\n",
    "df_1_test = dta_test[dta_test[\"worldwide_gross\"] < 10000000]\n",
    "X_1_test = df_1_test.drop('worldwide_gross', axis=1)\n",
    "y_1_test = df_1_test['worldwide_gross']\n",
    "\n",
    "\n",
    "df_2_train = dta_train[dta_train[\"worldwide_gross\"] >= 10000000]\n",
    "df_2_train = df_2_train[df_2_train[\"worldwide_gross\"] < 300000000]\n",
    "X_2_train = df_2_train.drop('worldwide_gross', axis=1)\n",
    "y_2_train = df_2_train['worldwide_gross']\n",
    "\n",
    "df_2_test = dta_test[dta_train[\"worldwide_gross\"] >= 10000000]\n",
    "df_2_test = df_2_test[df_2_test[\"worldwide_gross\"] < 300000000]\n",
    "X_2_test = df_2_test.drop('worldwide_gross', axis=1)\n",
    "y_2_test = df_2_test['worldwide_gross']\n",
    "\n",
    "df_3_train = dta_train[dta_train[\"worldwide_gross\"] >= 300000000]\n",
    "X_3_train = df_3_train.drop('worldwide_gross', axis=1)\n",
    "y_3_train = df_3_train['worldwide_gross']\n",
    "\n",
    "df_3_test = dta_test[dta_test[\"worldwide_gross\"] >= 300000000]\n",
    "X_3_test = df_3_test.drop('worldwide_gross', axis=1)\n",
    "y_3_test = df_3_test['worldwide_gross']\n",
    "\n",
    "\n",
    "model_1 =  GradientBoostingRegressor().fit(X_1_train, y_1_train)\n",
    "print(model_1.score(X_1_train,y_1_train))\n",
    "print(model_1.score(X_1_test,y_1_test))\n",
    "print('############################')\n",
    "model_2 =  GradientBoostingRegressor().fit(X_2_train, y_2_train)\n",
    "print(model_2.score(X_2_train,y_2_train))\n",
    "print(model_2.score(X_2_test,y_2_test))\n",
    "print('############################')\n",
    "model_3 =  GradientBoostingRegressor().fit(X_3_train, y_3_train)\n",
    "print(model_3.score(X_3_train,y_3_train))\n",
    "print(model_3.score(X_3_test,y_3_test))\n",
    "print('############################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_test_cl = pd.concat([pd.DataFrame(model_test_grtb_cl.predict(x_test)), pd.DataFrame(x_test)], axis=1)\n",
    "x_train_cl = pd.concat([pd.DataFrame(model_test_grtb_cl.predict(x_train)), pd.DataFrame(x_train)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58182443054843747"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lst = []\n",
    "row_ggl = None\n",
    "for ind, row in x_test_cl.iterrows():\n",
    "    row_for_pred = row.drop(row.index[0]).reshape(1, -1)\n",
    "    if row[0] == 1:\n",
    "        y_pred = model_1.predict(row_for_pred)\n",
    "    elif row[0] == 2:\n",
    "        y_pred = model_2.predict(row_for_pred)\n",
    "    elif row[0] == 3:\n",
    "        y_pred = model_3.predict(row_for_pred)\n",
    "    else:\n",
    "        print(\"No class ffound\", end=\" \")\n",
    "        print(ind)\n",
    "    y_pred_lst.append(y_pred)\n",
    "r2_score(y_test_reg,y_pred_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772238798525\n",
      "0.618416611594\n"
     ]
    }
   ],
   "source": [
    "model_regressor_with_cl =  GradientBoostingRegressor().fit(x_train_cl, y_train_reg)\n",
    "print(model_regressor_with_cl.score(x_train_cl,y_train_reg))\n",
    "print(model_regressor_with_cl.score(x_test_cl,y_test_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876623340409\n",
      "0.599733139766\n"
     ]
    }
   ],
   "source": [
    "x_with_given_cl = pd.concat([y_train_cl, x_train], axis=1)\n",
    "model_regressor_with_cl_with_cl_bef =  GradientBoostingRegressor().fit(x_with_given_cl, y_train_reg)\n",
    "print(model_regressor_with_cl_with_cl_bef.score(x_with_given_cl,y_train_reg))\n",
    "print(model_regressor_with_cl_with_cl_bef.score(x_test_cl,y_test_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prove_results(data_train, data_test, pipe, class_fn):\n",
    "    print(\"\")\n",
    "    print(\"Proving results for: \" + class_fn.__name__)\n",
    "    #define data\n",
    "    x_train = data_train.drop('worldwide_gross', axis=1)\n",
    "    y_train_cl = data_train.worldwide_gross.apply (lambda gross: class_fn (gross))\n",
    "    y_train_reg = data_train['worldwide_gross']\n",
    "\n",
    "    x_test = data_test.drop('worldwide_gross', axis=1)\n",
    "    y_test_cl = data_test.worldwide_gross.apply (lambda gross: class_fn (gross))\n",
    "    y_test_reg = data_test['worldwide_gross']\n",
    "    \n",
    "    #transform X's\n",
    "    #x_train_pipe_cl = x_train    \n",
    "    #x_test_pipe_cl = x_test\n",
    "    x_train_pipe_cl = pipe.fit_transform(x_train, y_train_cl)    \n",
    "    x_test_pipe_cl = pipe.transform(x_test)\n",
    "    \n",
    "    #train calssify model\n",
    "    gardient_class = GradientBoostingClassifier(n_estimators = 1000,\n",
    "                      learning_rate = 0.01,\n",
    "                      max_depth =  10,\n",
    "                      min_samples_leaf = 5,\n",
    "                      max_features = 0.01,\n",
    "                      max_leaf_nodes =  None)\n",
    "    gardient_class.fit(x_train_pipe_cl, y_train_cl)\n",
    "    print(\"Classify train score is :\" + str(gardient_class.score(x_train_pipe_cl,y_train_cl)))\n",
    "    print(\"Classify test score is :\" + str(gardient_class.score(x_test_pipe_cl,y_test_cl)))\n",
    "    \n",
    "    #populate x_train and x_test with class data\n",
    "    x_train_cl = pd.concat([pd.DataFrame(gardient_class.predict(x_train_pipe_cl)), pd.DataFrame(x_train)], axis=1)\n",
    "    x_test_cl = pd.concat([pd.DataFrame(gardient_class.predict(x_test_pipe_cl)), pd.DataFrame(x_test)], axis=1)\n",
    "    \n",
    "    #train the regressor\n",
    "    gardient_reg = GradientBoostingRegressor(learning_rate = 0.1, \n",
    "                                            max_depth = 3,\n",
    "                                            n_estimators = 200)\n",
    "    gardient_reg.fit(x_train_cl, y_train_reg)\n",
    "    print(\"Regressor train score is :\" + str(gardient_reg.score(x_train_cl,y_train_reg)))\n",
    "    print(\"Regressor test  score is :\" + str(gardient_reg.score(x_test_cl,y_test_reg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proving results for: label_gross_10\n",
      "Classify train score is :1.0\n",
      "Classify test score is :0.361140443506\n",
      "Regressor train score is :0.98425498846\n",
      "Regressor test  score is :0.58790177432\n",
      "\n",
      "Proving results for: label_gross_9\n",
      "Classify train score is :1.0\n",
      "Classify test score is :0.353748680042\n",
      "Regressor train score is :0.975234751132\n",
      "Regressor test  score is :0.574568756473\n",
      "\n",
      "Proving results for: label_gross_8\n",
      "Classify train score is :0.999735729387\n",
      "Classify test score is :0.375923970433\n",
      "Regressor train score is :0.973287807267\n",
      "Regressor test  score is :0.598197139875\n",
      "\n",
      "Proving results for: label_gross_7\n",
      "Classify train score is :0.99656448203\n",
      "Classify test score is :0.49419218585\n",
      "Regressor train score is :0.964559804363\n",
      "Regressor test  score is :0.572573207886\n",
      "\n",
      "Proving results for: label_gross_6\n",
      "Classify train score is :0.99656448203\n",
      "Classify test score is :0.493136219641\n",
      "Regressor train score is :0.958177165961\n",
      "Regressor test  score is :0.599758206562\n",
      "\n",
      "Proving results for: label_gross_5\n",
      "Classify train score is :0.992600422833\n",
      "Classify test score is :0.539598732841\n",
      "Regressor train score is :0.942369218412\n",
      "Regressor test  score is :0.579088197998\n",
      "\n",
      "Proving results for: label_gross_4\n",
      "Classify train score is :0.993393234672\n",
      "Classify test score is :0.621964097149\n",
      "Regressor train score is :0.915992029347\n",
      "Regressor test  score is :0.598389782345\n",
      "\n",
      "Proving results for: label_gross_3\n",
      "Classify train score is :0.990486257928\n",
      "Classify test score is :0.798310454065\n",
      "Regressor train score is :0.892617513264\n",
      "Regressor test  score is :0.605982358963\n",
      "\n",
      "Proving results for: label_gross_2\n",
      "Classify train score is :0.993128964059\n",
      "Classify test score is :0.904963041183\n",
      "Regressor train score is :0.87819300977\n",
      "Regressor test  score is :0.603328781347\n"
     ]
    }
   ],
   "source": [
    "pipe_prove = Pipeline(steps=[('preprocessor', preprocessor), ('transfomer', transfomer), ('reducer', reducer)])\n",
    "\n",
    "labels = [label_gross_10, label_gross_9, label_gross_8, label_gross_7, label_gross_6, label_gross_5, label_gross_4, label_gross_3, label_gross_2]\n",
    "\n",
    "for label in labels: prove_results(dta_train, dta_test, pipe_prove, label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
