{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import all helpers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns # More snazzy plotting library\n",
    "import itertools\n",
    "\n",
    "#import regressors\n",
    "#-----Ensemble---------------------\n",
    "from sklearn.ensemble import       AdaBoostRegressor\n",
    "from sklearn.ensemble import       BaggingRegressor\n",
    "from sklearn.ensemble import       ExtraTreesRegressor\n",
    "from sklearn.ensemble import       GradientBoostingRegressor\n",
    "from sklearn.ensemble import       RandomForestRegressor\n",
    "\n",
    "#----Generalized Linear models-----\n",
    "from sklearn.linear_model import   ARDRegression\n",
    "from sklearn.linear_model import   BayesianRidge\n",
    "from sklearn.linear_model import   ElasticNet\n",
    "from sklearn.linear_model import   HuberRegressor\n",
    "from sklearn.linear_model import   Lars\n",
    "from sklearn.linear_model import   Lasso\n",
    "from sklearn.linear_model import   LassoLars\n",
    "from sklearn.linear_model import   LinearRegression\n",
    "from sklearn.linear_model import   PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import   Ridge\n",
    "from sklearn.linear_model import   SGDRegressor\n",
    "\n",
    "#---Nearest Neighbors----\n",
    "from sklearn.neighbors import      KNeighborsRegressor\n",
    "from sklearn.neighbors import      RadiusNeighborsRegressor\n",
    "\n",
    "\n",
    "#----Neural Networks--------------- \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#-----Support Vector Machines------\n",
    "from sklearn.svm import            SVR\n",
    "from sklearn.svm import            LinearSVR\n",
    "from sklearn.svm import            NuSVR\n",
    "\n",
    "#-----Decission Trees--------------\n",
    "from sklearn.tree import           DecisionTreeRegressor\n",
    "from sklearn.tree import           ExtraTreeRegressor\n",
    "\n",
    "#----extras\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.isotonic import         IsotonicRegression\n",
    "from sklearn.kernel_ridge import     KernelRidge\n",
    "from sklearn.linear_model import     OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import     RANSACRegressor\n",
    "from sklearn.linear_model import     TheilSenRegressor\n",
    "\n",
    "extra_mods = [GaussianProcessRegressor,IsotonicRegression,KernelRidge,OrthogonalMatchingPursuit,RANSACRegressor,TheilSenRegressor]\n",
    "#file_path =  \"../dataset/movie_metadata_cleaned_tfidf_num_only_min.csv\"\n",
    "file_path =  \"../dataset/movie_metadata_cleaned_categ_num_only.csv\"\n",
    "#file_path = \"../dataset/movie_metadata_cleaned_no_vector_num_only.csv\"\n",
    "\n",
    "dta = pd.read_csv(file_path)\n",
    "dta_clean = dta\n",
    "#remove the null values, that is fill NaN with there - FIXME: Rihards, naive implementation\n",
    "dta_clean = dta_clean.fillna(value=0, axis=1)\n",
    "dta_clean = dta_clean.dropna()\n",
    "dta_clean = dta_clean.drop('Unnamed: 0', axis=1)\n",
    "dta_clean.describe()\n",
    "    \n",
    "y = dta_clean['worldwide_gross']\n",
    "X = dta_clean.drop('worldwide_gross', axis=1)\n",
    "X, _X_dummy, y, _y_dummy = train_test_split(X, y, test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "models = [AdaBoostRegressor,BaggingRegressor,ExtraTreesRegressor,GradientBoostingRegressor,RandomForestRegressor,BayesianRidge,ElasticNet,HuberRegressor,Lars,Lasso,LassoLars,LinearRegression,PassiveAggressiveRegressor,Ridge,SGDRegressor,KNeighborsRegressor,RadiusNeighborsRegressor,MLPRegressor,SVR,LinearSVR,NuSVR,DecisionTreeRegressor,ExtraTreeRegressor]#classifiers = [RadiusNeighborsClassifier]\n",
    "#models= [LinearRegression]\n",
    "results = {}\n",
    "errors = {}\n",
    "\n",
    "def run_grid_search(x,y,Model, res_dict, error):\n",
    "    #create pipline and use GridSearch to find the betst params\n",
    "    name = Model.__name__\n",
    "    #if name == \"MLPClassifier\" or name == \"MLPRegressor\": \n",
    "    #    cv = 50\n",
    "    #else: \n",
    "    cv = 5\n",
    "    model = Model()\n",
    "    pipe = Pipeline(steps=[('model', model)])\n",
    "    #create estimator\n",
    "    print()\n",
    "    print (\"***Starting [\"  + name + \"] estimator run \")\n",
    "    estimator = GridSearchCV(pipe,dict(),verbose=2, cv=cv, n_jobs=4)\n",
    "    #run the esmimator, except eceptions, sape errors\n",
    "    try:\n",
    "            estimator.fit(x, y)\n",
    "            print (\"GREP_ME***Results of [\"  + name + \"] estimator run are\")\n",
    "            print (estimator.cv_results_)\n",
    "            print (\"GREP_ME***Best params of [\"  + name + \"] estimator run are\")\n",
    "            print (estimator.best_params_)\n",
    "            print (\"GREP_ME***Best score of [\"  + name + \"] estimator run are\")\n",
    "            print (estimator.best_score_)\n",
    "            results[name] = estimator.best_score_\n",
    "    except ValueError as err:\n",
    "            print (\"GREP_ME***Error caught for  [\"  + name + \"]\")\n",
    "            errors[name] = err\n",
    "            pass\n",
    "            \n",
    "def run_solver(X,y,models_arr, res_dict, errors):\n",
    "    for model in models_arr:\n",
    "        run_grid_search(X,y, model, res_dict, errors)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Starting [GaussianProcessRegressor] estimator run \n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.6s\n",
      "[CV] ................................................. , total=   5.8s\n",
      "[CV] ................................................. , total=   5.8s\n",
      "[CV] ................................................. , total=   6.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP_ME***Results of [GaussianProcessRegressor] estimator run are\n",
      "{'split4_train_score': array([ 1.]), 'mean_score_time': array([ 0.50541658]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split0_train_score': array([ 1.]), 'mean_train_score': array([ 1.]), 'split3_test_score': array([-0.27459981]), 'mean_fit_time': array([ 4.81412849]), 'mean_test_score': array([-0.29211234]), 'split2_train_score': array([ 1.]), 'split0_test_score': array([-0.30393826]), 'split3_train_score': array([ 1.]), 'split2_test_score': array([-0.31287388]), 'split4_test_score': array([-0.28172426]), 'std_score_time': array([ 0.06053125]), 'split1_test_score': array([-0.28741809]), 'std_fit_time': array([ 0.92762512]), 'split1_train_score': array([ 1.]), 'std_test_score': array([ 0.01419352]), 'std_train_score': array([ 0.])}\n",
      "GREP_ME***Best params of [GaussianProcessRegressor] estimator run are\n",
      "{}\n",
      "GREP_ME***Best score of [GaussianProcessRegressor] estimator run are\n",
      "-0.292112342841\n",
      "\n",
      "***Starting [IsotonicRegression] estimator run \n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "GREP_ME***Error caught for  [IsotonicRegression]\n",
      "\n",
      "***Starting [KernelRidge] estimator run \n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.2s\n",
      "[CV] ................................................. , total=   5.5s\n",
      "[CV] ................................................. , total=   5.7s\n",
      "[CV] ................................................. , total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP_ME***Results of [KernelRidge] estimator run are\n",
      "{'split4_train_score': array([-2557126.82232622]), 'mean_score_time': array([ 0.06729708]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split0_train_score': array([ -2.36843953e+14]), 'mean_train_score': array([ -4.74283351e+13]), 'split3_test_score': array([ -2.91798829e+11]), 'mean_fit_time': array([ 4.63265262]), 'mean_test_score': array([ -4.06341004e+13]), 'split2_train_score': array([ -1.60346637e+10]), 'split0_test_score': array([ -2.02735226e+14]), 'split3_train_score': array([ -2.81287959e+11]), 'split2_test_score': array([ -1.67736006e+10]), 'split4_test_score': array([-2312733.14772845]), 'std_score_time': array([ 0.03102257]), 'split1_test_score': array([ -4.35286848e+08]), 'std_fit_time': array([ 1.42049165]), 'split1_train_score': array([ -3.97692645e+08]), 'std_test_score': array([  8.10822191e+13]), 'std_train_score': array([  9.47078692e+13])}\n",
      "GREP_ME***Best params of [KernelRidge] estimator run are\n",
      "{}\n",
      "GREP_ME***Best score of [KernelRidge] estimator run are\n",
      "-4.0634100388e+13\n",
      "\n",
      "***Starting [OrthogonalMatchingPursuit] estimator run \n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV] ................................................. , total=   0.1s\n",
      "GREP_ME***Results of [OrthogonalMatchingPursuit] estimator run are\n",
      "{'split4_train_score': array([ 0.66970399]), 'mean_score_time': array([ 0.00588489]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split0_train_score': array([ 0.66298679]), 'mean_train_score': array([ 0.66644064]), 'split3_test_score': array([ 0.65065237]), 'mean_fit_time': array([ 0.05795116]), 'mean_test_score': array([ 0.65561144]), 'split2_train_score': array([ 0.67245003]), 'split0_test_score': array([ 0.67351746]), 'split3_train_score': array([ 0.66669425]), 'split2_test_score': array([ 0.61891843]), 'split4_test_score': array([ 0.64744618]), 'std_score_time': array([ 0.00478389]), 'split1_test_score': array([ 0.68747102]), 'std_fit_time': array([ 0.02023053]), 'split1_train_score': array([ 0.66036816]), 'std_test_score': array([ 0.02355222]), 'std_train_score': array([ 0.00437334])}\n",
      "GREP_ME***Best params of [OrthogonalMatchingPursuit] estimator run are\n",
      "{}\n",
      "GREP_ME***Best score of [OrthogonalMatchingPursuit] estimator run are\n",
      "0.655611438215\n",
      "\n",
      "***Starting [RANSACRegressor] estimator run \n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   1.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   2.2s\n",
      "[CV] ................................................. , total=   2.3s\n",
      "[CV] ................................................. , total=   2.4s\n",
      "[CV] ................................................. , total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP_ME***Results of [RANSACRegressor] estimator run are\n",
      "{'split4_train_score': array([ 0.55103313]), 'mean_score_time': array([ 0.00247955]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split0_train_score': array([ 0.50467272]), 'mean_train_score': array([ 0.54071398]), 'split3_test_score': array([ 0.55227181]), 'mean_fit_time': array([ 1.92293315]), 'mean_test_score': array([ 0.5332811]), 'split2_train_score': array([ 0.55205452]), 'split0_test_score': array([ 0.541972]), 'split3_train_score': array([ 0.57702799]), 'split2_test_score': array([ 0.43223151]), 'split4_test_score': array([ 0.56735692]), 'std_score_time': array([ 0.00083565]), 'split1_test_score': array([ 0.57252343]), 'std_fit_time': array([ 0.57840225]), 'split1_train_score': array([ 0.51878153]), 'std_test_score': array([ 0.0516613]), 'std_train_score': array([ 0.02582171])}\n",
      "GREP_ME***Best params of [RANSACRegressor] estimator run are\n",
      "{}\n",
      "GREP_ME***Best score of [RANSACRegressor] estimator run are\n",
      "0.533281099352\n",
      "\n",
      "***Starting [TheilSenRegressor] estimator run \n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 4.8min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 5.1min\n",
      "[CV] ................................................. , total= 5.2min\n",
      "[CV] ................................................. , total= 5.3min\n",
      "[CV] ................................................. , total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP_ME***Results of [TheilSenRegressor] estimator run are\n",
      "{'split4_train_score': array([ 0.6636878]), 'mean_score_time': array([ 0.01300163]), 'rank_test_score': array([1], dtype=int32), 'params': ({},), 'split0_train_score': array([ 0.65510519]), 'mean_train_score': array([ 0.66181897]), 'split3_test_score': array([ 0.65194785]), 'mean_fit_time': array([ 263.10558391]), 'mean_test_score': array([ 0.6524548]), 'split2_train_score': array([ 0.67004249]), 'split0_test_score': array([ 0.67359218]), 'split3_train_score': array([ 0.66509738]), 'split2_test_score': array([ 0.59767929]), 'split4_test_score': array([ 0.65504665]), 'std_score_time': array([ 0.00977112]), 'split1_test_score': array([ 0.68395331]), 'std_fit_time': array([ 86.89690375]), 'split1_train_score': array([ 0.65516201]), 'std_test_score': array([ 0.0298192]), 'std_train_score': array([ 0.00585246])}\n",
      "GREP_ME***Best params of [TheilSenRegressor] estimator run are\n",
      "{}\n",
      "GREP_ME***Best score of [TheilSenRegressor] estimator run are\n",
      "0.652454799043\n"
     ]
    }
   ],
   "source": [
    "run_solver(X,y, extra_mods, results, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KernelRidge', -40634100388046.898),\n",
       " ('GaussianProcessRegressor', -0.29211234284061061),\n",
       " ('RANSACRegressor', 0.53328109935233614),\n",
       " ('TheilSenRegressor', 0.65245479904349846),\n",
       " ('OrthogonalMatchingPursuit', 0.65561143821505341)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results.items(), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IsotonicRegression': sklearn.externals.joblib.my_exceptions.JoblibValueError('Multiprocessing exception:\\n...........................................................................\\n/usr/lib/python3.4/runpy.py in _run_module_as_main(mod_name=\\'ipykernel.__main__\\', alter_argv=1)\\n    165         sys.exit(msg)\\n    166     main_globals = sys.modules[\"__main__\"].__dict__\\n    167     if alter_argv:\\n    168         sys.argv[0] = mod_spec.origin\\n    169     return _run_code(code, main_globals, None,\\n--> 170                      \"__main__\", mod_spec)\\n        mod_spec = ModuleSpec(name=\\'ipykernel.__main__\\', loader=<_f...b/python3.4/dist-packages/ipykernel/__main__.py\\')\\n    171 \\n    172 def run_module(mod_name, init_globals=None,\\n    173                run_name=None, alter_sys=False):\\n    174     \"\"\"Execute a module\\'s code without importing it\\n\\n...........................................................................\\n/usr/lib/python3.4/runpy.py in _run_code(code=<code object <module> at 0x7f9bf28ba300, file \"/...3.4/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={\\'__builtins__\\': <module \\'builtins\\' (built-in)>, \\'__cached__\\': \\'/usr/local/lib/python3.4/dist-packages/ipykernel/__pycache__/__main__.cpython-34.pyc\\', \\'__doc__\\': None, \\'__file__\\': \\'/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py\\', \\'__loader__\\': <_frozen_importlib.SourceFileLoader object>, \\'__name__\\': \\'__main__\\', \\'__package__\\': \\'ipykernel\\', \\'__spec__\\': ModuleSpec(name=\\'ipykernel.__main__\\', loader=<_f...b/python3.4/dist-packages/ipykernel/__main__.py\\'), \\'app\\': <module \\'ipykernel.kernelapp\\' from \\'/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py\\'>}, init_globals=None, mod_name=\\'__main__\\', mod_spec=ModuleSpec(name=\\'ipykernel.__main__\\', loader=<_f...b/python3.4/dist-packages/ipykernel/__main__.py\\'), pkg_name=\\'ipykernel\\', script_name=None)\\n     80                        __cached__ = cached,\\n     81                        __doc__ = None,\\n     82                        __loader__ = loader,\\n     83                        __package__ = pkg_name,\\n     84                        __spec__ = mod_spec)\\n---> 85     exec(code, run_globals)\\n        code = <code object <module> at 0x7f9bf28ba300, file \"/...3.4/dist-packages/ipykernel/__main__.py\", line 1>\\n        run_globals = {\\'__builtins__\\': <module \\'builtins\\' (built-in)>, \\'__cached__\\': \\'/usr/local/lib/python3.4/dist-packages/ipykernel/__pycache__/__main__.cpython-34.pyc\\', \\'__doc__\\': None, \\'__file__\\': \\'/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py\\', \\'__loader__\\': <_frozen_importlib.SourceFileLoader object>, \\'__name__\\': \\'__main__\\', \\'__package__\\': \\'ipykernel\\', \\'__spec__\\': ModuleSpec(name=\\'ipykernel.__main__\\', loader=<_f...b/python3.4/dist-packages/ipykernel/__main__.py\\'), \\'app\\': <module \\'ipykernel.kernelapp\\' from \\'/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py\\'>}\\n     86     return run_globals\\n     87 \\n     88 def _run_module_code(code, init_globals=None,\\n     89                     mod_name=None, mod_spec=None,\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py in <module>()\\n      1 \\n      2 \\n----> 3 \\n      4 if __name__ == \\'__main__\\':\\n      5     from ipykernel import kernelapp as app\\n      6     app.launch_new_instance()\\n      7 \\n      8 \\n      9 \\n     10 \\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py in launch_instance(cls=<class \\'ipykernel.kernelapp.IPKernelApp\\'>, argv=None, **kwargs={})\\n    653 \\n    654         If a global instance already exists, this reinitializes and starts it\\n    655         \"\"\"\\n    656         app = cls.instance(**kwargs)\\n    657         app.initialize(argv)\\n--> 658         app.start()\\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\\n    659 \\n    660 #-----------------------------------------------------------------------------\\n    661 # utility functions, for convenience\\n    662 #-----------------------------------------------------------------------------\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\\n    469             return self.subapp.start()\\n    470         if self.poller is not None:\\n    471             self.poller.start()\\n    472         self.kernel.start()\\n    473         try:\\n--> 474             ioloop.IOLoop.instance().start()\\n    475         except KeyboardInterrupt:\\n    476             pass\\n    477 \\n    478 launch_new_instance = IPKernelApp.launch_instance\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\\n    172             )\\n    173         return loop\\n    174     \\n    175     def start(self):\\n    176         try:\\n--> 177             super(ZMQIOLoop, self).start()\\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\\n    178         except ZMQError as e:\\n    179             if e.errno == ETERM:\\n    180                 # quietly return on ETERM\\n    181                 pass\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\\n    882                 self._events.update(event_pairs)\\n    883                 while self._events:\\n    884                     fd, events = self._events.popitem()\\n    885                     try:\\n    886                         fd_obj, handler_func = self._handlers[fd]\\n--> 887                         handler_func(fd_obj, events)\\n        handler_func = <function wrap.<locals>.null_wrapper>\\n        fd_obj = <zmq.sugar.socket.Socket object>\\n        events = 1\\n    888                     except (OSError, IOError) as e:\\n    889                         if errno_from_exception(e) == errno.EPIPE:\\n    890                             # Happens when the client closes the connection\\n    891                             pass\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\\n    270         # Fast path when there are no active contexts.\\n    271         def null_wrapper(*args, **kwargs):\\n    272             try:\\n    273                 current_state = _state.contexts\\n    274                 _state.contexts = cap_contexts[0]\\n--> 275                 return fn(*args, **kwargs)\\n        args = (<zmq.sugar.socket.Socket object>, 1)\\n        kwargs = {}\\n    276             finally:\\n    277                 _state.contexts = current_state\\n    278         null_wrapper._wrapped = True\\n    279         return null_wrapper\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\\n    435             # dispatch events:\\n    436             if events & IOLoop.ERROR:\\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn\\'t make sense\")\\n    438                 return\\n    439             if events & IOLoop.READ:\\n--> 440                 self._handle_recv()\\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\\n    441                 if not self.socket:\\n    442                     return\\n    443             if events & IOLoop.WRITE:\\n    444                 self._handle_send()\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\\n    468         else:\\n    469             if self._recv_callback:\\n    470                 callback = self._recv_callback\\n    471                 # self._recv_callback = None\\n--> 472                 self._run_callback(callback, msg)\\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\\n        callback = <function wrap.<locals>.null_wrapper>\\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\\n    473                 \\n    474         # self.update_state()\\n    475         \\n    476 \\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\\n    409         close our socket.\"\"\"\\n    410         try:\\n    411             # Use a NullContext to ensure that all StackContexts are run\\n    412             # inside our blanket exception handler rather than outside.\\n    413             with stack_context.NullContext():\\n--> 414                 callback(*args, **kwargs)\\n        callback = <function wrap.<locals>.null_wrapper>\\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\\n        kwargs = {}\\n    415         except:\\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\\n    417                           exc_info=True)\\n    418             # Close the socket on an uncaught exception from a user callback\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\\n    270         # Fast path when there are no active contexts.\\n    271         def null_wrapper(*args, **kwargs):\\n    272             try:\\n    273                 current_state = _state.contexts\\n    274                 _state.contexts = cap_contexts[0]\\n--> 275                 return fn(*args, **kwargs)\\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\\n        kwargs = {}\\n    276             finally:\\n    277                 _state.contexts = current_state\\n    278         null_wrapper._wrapped = True\\n    279         return null_wrapper\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\\n    271         if self.control_stream:\\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\\n    273 \\n    274         def make_dispatcher(stream):\\n    275             def dispatcher(msg):\\n--> 276                 return self.dispatch_shell(stream, msg)\\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\\n    277             return dispatcher\\n    278 \\n    279         for s in self.shell_streams:\\n    280             s.on_recv(make_dispatcher(s), copy=False)\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={\\'buffers\\': [], \\'content\\': {\\'allow_stdin\\': True, \\'code\\': \\'run_solver(X,y, extra_mods, results, errors)\\', \\'silent\\': False, \\'stop_on_error\\': True, \\'store_history\\': True, \\'user_expressions\\': {}}, \\'header\\': {\\'date\\': datetime.datetime(2017, 4, 3, 15, 36, 44, 88117, tzinfo=datetime.timezone.utc), \\'msg_id\\': \\'4044032FA1B74F6A8E667CF453B6430F\\', \\'msg_type\\': \\'execute_request\\', \\'session\\': \\'500016386DA3442A899E91D5152C59E4\\', \\'username\\': \\'username\\', \\'version\\': \\'5.0\\'}, \\'metadata\\': {}, \\'msg_id\\': \\'4044032FA1B74F6A8E667CF453B6430F\\', \\'msg_type\\': \\'execute_request\\', \\'parent_header\\': {}})\\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\\n    224         else:\\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\\n    226             self.pre_handler_hook()\\n    227             try:\\n--> 228                 handler(stream, idents, msg)\\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\\n        idents = [b\\'500016386DA3442A899E91D5152C59E4\\']\\n        msg = {\\'buffers\\': [], \\'content\\': {\\'allow_stdin\\': True, \\'code\\': \\'run_solver(X,y, extra_mods, results, errors)\\', \\'silent\\': False, \\'stop_on_error\\': True, \\'store_history\\': True, \\'user_expressions\\': {}}, \\'header\\': {\\'date\\': datetime.datetime(2017, 4, 3, 15, 36, 44, 88117, tzinfo=datetime.timezone.utc), \\'msg_id\\': \\'4044032FA1B74F6A8E667CF453B6430F\\', \\'msg_type\\': \\'execute_request\\', \\'session\\': \\'500016386DA3442A899E91D5152C59E4\\', \\'username\\': \\'username\\', \\'version\\': \\'5.0\\'}, \\'metadata\\': {}, \\'msg_id\\': \\'4044032FA1B74F6A8E667CF453B6430F\\', \\'msg_type\\': \\'execute_request\\', \\'parent_header\\': {}}\\n    229             except Exception:\\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\\n    231             finally:\\n    232                 self.post_handler_hook()\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b\\'500016386DA3442A899E91D5152C59E4\\'], parent={\\'buffers\\': [], \\'content\\': {\\'allow_stdin\\': True, \\'code\\': \\'run_solver(X,y, extra_mods, results, errors)\\', \\'silent\\': False, \\'stop_on_error\\': True, \\'store_history\\': True, \\'user_expressions\\': {}}, \\'header\\': {\\'date\\': datetime.datetime(2017, 4, 3, 15, 36, 44, 88117, tzinfo=datetime.timezone.utc), \\'msg_id\\': \\'4044032FA1B74F6A8E667CF453B6430F\\', \\'msg_type\\': \\'execute_request\\', \\'session\\': \\'500016386DA3442A899E91D5152C59E4\\', \\'username\\': \\'username\\', \\'version\\': \\'5.0\\'}, \\'metadata\\': {}, \\'msg_id\\': \\'4044032FA1B74F6A8E667CF453B6430F\\', \\'msg_type\\': \\'execute_request\\', \\'parent_header\\': {}})\\n    385         if not silent:\\n    386             self.execution_count += 1\\n    387             self._publish_execute_input(code, parent, self.execution_count)\\n    388 \\n    389         reply_content = self.do_execute(code, silent, store_history,\\n--> 390                                         user_expressions, allow_stdin)\\n        user_expressions = {}\\n        allow_stdin = True\\n    391 \\n    392         # Flush output before sending the reply.\\n    393         sys.stdout.flush()\\n    394         sys.stderr.flush()\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\\'run_solver(X,y, extra_mods, results, errors)\\', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\\n    191 \\n    192         self._forward_input(allow_stdin)\\n    193 \\n    194         reply_content = {}\\n    195         try:\\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\\n        res = undefined\\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\\n        code = \\'run_solver(X,y, extra_mods, results, errors)\\'\\n        store_history = True\\n        silent = False\\n    197         finally:\\n    198             self._restore_input()\\n    199 \\n    200         if res.error_before_exec is not None:\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\\'run_solver(X,y, extra_mods, results, errors)\\',), **kwargs={\\'silent\\': False, \\'store_history\\': True})\\n    496             )\\n    497         self.payload_manager.write_payload(payload)\\n    498 \\n    499     def run_cell(self, *args, **kwargs):\\n    500         self._last_traceback = None\\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\\n        args = (\\'run_solver(X,y, extra_mods, results, errors)\\',)\\n        kwargs = {\\'silent\\': False, \\'store_history\\': True}\\n    502 \\n    503     def _showtraceback(self, etype, evalue, stb):\\n    504         # try to preserve ordering of tracebacks and print statements\\n    505         sys.stdout.flush()\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\\'run_solver(X,y, extra_mods, results, errors)\\', store_history=True, silent=False, shell_futures=True)\\n   2712                 self.displayhook.exec_result = result\\n   2713 \\n   2714                 # Execute the user code\\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\\n        interactivity = \\'last_expr\\'\\n        compiler = <IPython.core.compilerop.CachingCompiler object>\\n   2718                 \\n   2719                 self.last_execution_succeeded = not has_raised\\n   2720 \\n   2721                 # Reset this so later displayed values do not modify the\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name=\\'<ipython-input-28-274cf85325bb>\\', interactivity=\\'last\\', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f9bb0b38780, executi..._before_exec=None error_in_exec=None result=None>)\\n   2822                     return True\\n   2823 \\n   2824             for i, node in enumerate(to_run_interactive):\\n   2825                 mod = ast.Interactive([node])\\n   2826                 code = compiler(mod, cell_name, \"single\")\\n-> 2827                 if self.run_code(code, result):\\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\\n        code = <code object <module> at 0x7f9be9e8c8a0, file \"<ipython-input-28-274cf85325bb>\", line 1>\\n        result = <ExecutionResult object at 7f9bb0b38780, executi..._before_exec=None error_in_exec=None result=None>\\n   2828                     return True\\n   2829 \\n   2830             # Flush softspace\\n   2831             if softspace(sys.stdout, 0):\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f9be9e8c8a0, file \"<ipython-input-28-274cf85325bb>\", line 1>, result=<ExecutionResult object at 7f9bb0b38780, executi..._before_exec=None error_in_exec=None result=None>)\\n   2876         outflag = 1  # happens in more places, so it\\'s easier as default\\n   2877         try:\\n   2878             try:\\n   2879                 self.hooks.pre_run_code_hook()\\n   2880                 #rprint(\\'Running code\\', repr(code_obj)) # dbg\\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\\n        code_obj = <code object <module> at 0x7f9be9e8c8a0, file \"<ipython-input-28-274cf85325bb>\", line 1>\\n        self.user_global_ns = {\\'ARDRegression\\': <class \\'sklearn.linear_model.bayes.ARDRegression\\'>, \\'AdaBoostRegressor\\': <class \\'sklearn.ensemble.weight_boosting.AdaBoostRegressor\\'>, \\'BaggingRegressor\\': <class \\'sklearn.ensemble.bagging.BaggingRegressor\\'>, \\'BayesianRidge\\': <class \\'sklearn.linear_model.bayes.BayesianRidge\\'>, \\'DecisionTreeRegressor\\': <class \\'sklearn.tree.tree.DecisionTreeRegressor\\'>, \\'ElasticNet\\': <class \\'sklearn.linear_model.coordinate_descent.ElasticNet\\'>, \\'ExtraTreeRegressor\\': <class \\'sklearn.tree.tree.ExtraTreeRegressor\\'>, \\'ExtraTreesRegressor\\': <class \\'sklearn.ensemble.forest.ExtraTreesRegressor\\'>, \\'GaussianProcessRegressor\\': <class \\'sklearn.gaussian_process.gpr.GaussianProcessRegressor\\'>, \\'GradientBoostingRegressor\\': <class \\'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor\\'>, ...}\\n        self.user_ns = {\\'ARDRegression\\': <class \\'sklearn.linear_model.bayes.ARDRegression\\'>, \\'AdaBoostRegressor\\': <class \\'sklearn.ensemble.weight_boosting.AdaBoostRegressor\\'>, \\'BaggingRegressor\\': <class \\'sklearn.ensemble.bagging.BaggingRegressor\\'>, \\'BayesianRidge\\': <class \\'sklearn.linear_model.bayes.BayesianRidge\\'>, \\'DecisionTreeRegressor\\': <class \\'sklearn.tree.tree.DecisionTreeRegressor\\'>, \\'ElasticNet\\': <class \\'sklearn.linear_model.coordinate_descent.ElasticNet\\'>, \\'ExtraTreeRegressor\\': <class \\'sklearn.tree.tree.ExtraTreeRegressor\\'>, \\'ExtraTreesRegressor\\': <class \\'sklearn.ensemble.forest.ExtraTreesRegressor\\'>, \\'GaussianProcessRegressor\\': <class \\'sklearn.gaussian_process.gpr.GaussianProcessRegressor\\'>, \\'GradientBoostingRegressor\\': <class \\'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor\\'>, ...}\\n   2882             finally:\\n   2883                 # Reset our crash handler in place\\n   2884                 sys.excepthook = old_excepthook\\n   2885         except SystemExit as e:\\n\\n...........................................................................\\n/home/user/data_mining/logistic_regression/<ipython-input-28-274cf85325bb> in <module>()\\n----> 1 \\n      2 \\n      3 \\n      4 \\n      5 \\n      6 run_solver(X,y, extra_mods, results, errors)\\n      7 \\n      8 \\n      9 \\n     10 \\n\\n...........................................................................\\n/home/user/data_mining/logistic_regression/<ipython-input-27-637055b8307f> in run_solver(X=      actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[4812 rows x 138 columns], y=634     190191646\\n3155     11014043\\n626     1929...     68582095\\nName: worldwide_gross, dtype: int64, models_arr=[<class \\'sklearn.gaussian_process.gpr.GaussianProcessRegressor\\'>, <class \\'sklearn.isotonic.IsotonicRegression\\'>, <class \\'sklearn.kernel_ridge.KernelRidge\\'>, <class \\'sklearn.linear_model.omp.OrthogonalMatchingPursuit\\'>, <class \\'sklearn.linear_model.ransac.RANSACRegressor\\'>, <class \\'sklearn.linear_model.theil_sen.TheilSenRegressor\\'>], res_dict={\\'GaussianProcessRegressor\\': -0.29211234284061061}, errors={})\\n     31             errors[name] = err\\n     32             pass\\n     33             \\n     34 def run_solver(X,y,models_arr, res_dict, errors):\\n     35     for model in models_arr:\\n---> 36         run_grid_search(X,y, model, res_dict, errors)    \\n     37 \\n     38 \\n     39 \\n     40 \\n\\n...........................................................................\\n/home/user/data_mining/logistic_regression/<ipython-input-27-637055b8307f> in run_grid_search(x=      actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[4812 rows x 138 columns], y=634     190191646\\n3155     11014043\\n626     1929...     68582095\\nName: worldwide_gross, dtype: int64, Model=<class \\'sklearn.isotonic.IsotonicRegression\\'>, res_dict={\\'GaussianProcessRegressor\\': -0.29211234284061061}, error={})\\n     16     print()\\n     17     print (\"***Starting [\"  + name + \"] estimator run \")\\n     18     estimator = GridSearchCV(pipe,dict(),verbose=2, cv=cv, n_jobs=4)\\n     19     #run the esmimator, except eceptions, sape errors\\n     20     try:\\n---> 21             estimator.fit(x, y)\\n     22             print (\"GREP_ME***Results of [\"  + name + \"] estimator run are\")\\n     23             print (estimator.cv_results_)\\n     24             print (\"GREP_ME***Best params of [\"  + name + \"] estimator run are\")\\n     25             print (estimator.best_params_)\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score=\\'raise\\',\\n       e...train_score=True,\\n       scoring=None, verbose=2), X=      actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[4812 rows x 138 columns], y=634     190191646\\n3155     11014043\\n626     1929...     68582095\\nName: worldwide_gross, dtype: int64, groups=None)\\n    940 \\n    941         groups : array-like, with shape (n_samples,), optional\\n    942             Group labels for the samples used while splitting the dataset into\\n    943             train/test set.\\n    944         \"\"\"\\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...rain_score=True,\\n       scoring=None, verbose=2)>\\n        X =       actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[4812 rows x 138 columns]\\n        y = 634     190191646\\n3155     11014043\\n626     1929...     68582095\\nName: worldwide_gross, dtype: int64\\n        groups = None\\n        self.param_grid = {}\\n    946 \\n    947 \\n    948 class RandomizedSearchCV(BaseSearchCV):\\n    949     \"\"\"Randomized search on hyper parameters.\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score=\\'raise\\',\\n       e...train_score=True,\\n       scoring=None, verbose=2), X=      actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[4812 rows x 138 columns], y=634     190191646\\n3155     11014043\\n626     1929...     68582095\\nName: worldwide_gross, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\\n    559                                   fit_params=self.fit_params,\\n    560                                   return_train_score=self.return_train_score,\\n    561                                   return_n_test_samples=True,\\n    562                                   return_times=True, return_parameters=True,\\n    563                                   error_score=self.error_score)\\n--> 564           for parameters in parameter_iterable\\n        parameters = undefined\\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\\n    565           for train, test in cv_iter)\\n    566 \\n    567         # if one choose to see train score, \"out\" will contain train score info\\n    568         if self.return_train_score:\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object <genexpr>>)\\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\\n    764                 # The iterable was consumed all at once by the above for loop.\\n    765                 # No need to wait for async callbacks to trigger to\\n    766                 # consumption.\\n    767                 self._iterating = False\\n--> 768             self.retrieve()\\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\\n    769             # Make sure that we get a last message telling us we are done\\n    770             elapsed_time = time.time() - self._start_time\\n    771             self._print(\\'Done %3i out of %3i | elapsed: %s finished\\',\\n    772                         (len(self._output), len(self._output),\\n\\n---------------------------------------------------------------------------\\nSub-process traceback:\\n---------------------------------------------------------------------------\\nValueError                                         Mon Apr  3 16:37:02 2017\\nPID: 25693                                   Python 3.4.3: /usr/bin/python3\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\\n    126     def __init__(self, iterator_slice):\\n    127         self.items = list(iterator_slice)\\n    128         self._size = len(self.items)\\n    129 \\n    130     def __call__(self):\\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[(\\'model\\', IsotonicRegression(inc...ounds=\\'nan\\', y_max=None,\\n          y_min=None))]),       actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[4812 rows x 138 columns], 634     190191646\\n3155     11014043\\n626     1929...     68582095\\nName: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([ 963,  964,  965, ..., 4809, 4810, 4811]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...53, 954, 955, 956, 957, 958, 959, 960, 961, 962]), 2, {}), {\\'error_score\\': \\'raise\\', \\'fit_params\\': {}, \\'return_n_test_samples\\': True, \\'return_parameters\\': True, \\'return_times\\': True, \\'return_train_score\\': True})]\\n    132 \\n    133     def __len__(self):\\n    134         return self._size\\n    135 \\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\\n    126     def __init__(self, iterator_slice):\\n    127         self.items = list(iterator_slice)\\n    128         self._size = len(self.items)\\n    129 \\n    130     def __call__(self):\\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\\n        func = <function _fit_and_score>\\n        args = (Pipeline(steps=[(\\'model\\', IsotonicRegression(inc...ounds=\\'nan\\', y_max=None,\\n          y_min=None))]),       actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[4812 rows x 138 columns], 634     190191646\\n3155     11014043\\n626     1929...     68582095\\nName: worldwide_gross, dtype: int64, <function _passthrough_scorer>, array([ 963,  964,  965, ..., 4809, 4810, 4811]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...53, 954, 955, 956, 957, 958, 959, 960, 961, 962]), 2, {})\\n        kwargs = {\\'error_score\\': \\'raise\\', \\'fit_params\\': {}, \\'return_n_test_samples\\': True, \\'return_parameters\\': True, \\'return_times\\': True, \\'return_train_score\\': True}\\n    132 \\n    133     def __len__(self):\\n    134         return self._size\\n    135 \\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[(\\'model\\', IsotonicRegression(inc...ounds=\\'nan\\', y_max=None,\\n          y_min=None))]), X=      actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[4812 rows x 138 columns], y=634     190191646\\n3155     11014043\\n626     1929...     68582095\\nName: worldwide_gross, dtype: int64, scorer=<function _passthrough_scorer>, train=array([ 963,  964,  965, ..., 4809, 4810, 4811]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...53, 954, 955, 956, 957, 958, 959, 960, 961, 962]), verbose=2, parameters={}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score=\\'raise\\')\\n    233 \\n    234     try:\\n    235         if y_train is None:\\n    236             estimator.fit(X_train, **fit_params)\\n    237         else:\\n--> 238             estimator.fit(X_train, y_train, **fit_params)\\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[(\\'...unds=\\'nan\\', y_max=None,\\n          y_min=None))])>\\n        X_train =       actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[3849 rows x 138 columns]\\n        y_train = 1385     80491516\\n2887     16193713\\n448     2522...     68582095\\nName: worldwide_gross, dtype: int64\\n        fit_params = {}\\n    239 \\n    240     except Exception as e:\\n    241         # Note fit time as time until error\\n    242         fit_time = time.time() - start_time\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[(\\'model\\', IsotonicRegression(inc...ounds=\\'nan\\', y_max=None,\\n          y_min=None))]), X=      actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[3849 rows x 138 columns], y=1385     80491516\\n2887     16193713\\n448     2522...     68582095\\nName: worldwide_gross, dtype: int64, **fit_params={})\\n    265         self : Pipeline\\n    266             This estimator\\n    267         \"\"\"\\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\\n    269         if self._final_estimator is not None:\\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\\n        self._final_estimator.fit = <bound method IsotonicRegression.fit of Isotonic..._bounds=\\'nan\\', y_max=None,\\n          y_min=None)>\\n        Xt =       actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[3849 rows x 138 columns]\\n        y = 1385     80491516\\n2887     16193713\\n448     2522...     68582095\\nName: worldwide_gross, dtype: int64\\n        fit_params = {}\\n    271         return self\\n    272 \\n    273     def fit_transform(self, X, y=None, **fit_params):\\n    274         \"\"\"Fit the model and transform with the final estimator\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/isotonic.py in fit(self=IsotonicRegression(increasing=True, out_of_bounds=\\'nan\\', y_max=None,\\n          y_min=None), X=      actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[3849 rows x 138 columns], y=1385     80491516\\n2887     16193713\\n448     2522...     68582095\\nName: worldwide_gross, dtype: int64, sample_weight=None)\\n    348         X is stored for future use, as `transform` needs X to interpolate\\n    349         new input data.\\n    350         \"\"\"\\n    351         # Transform y by running the isotonic regression algorithm and\\n    352         # transform X accordingly.\\n--> 353         X, y = self._build_y(X, y, sample_weight)\\n        X =       actor_1_facebook_likes  actor_2_facebook_l...        0          0  \\n\\n[3849 rows x 138 columns]\\n        y = 1385     80491516\\n2887     16193713\\n448     2522...     68582095\\nName: worldwide_gross, dtype: int64\\n        self._build_y = <bound method IsotonicRegression._build_y of Iso..._bounds=\\'nan\\', y_max=None,\\n          y_min=None)>\\n        sample_weight = None\\n    354 \\n    355         # It is necessary to store the non-redundant part of the training set\\n    356         # on the model to make it possible to support model persistence via\\n    357         # the pickle module as the object built by scipy.interp1d is not\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/isotonic.py in _build_y(self=IsotonicRegression(increasing=True, out_of_bounds=\\'nan\\', y_max=None,\\n          y_min=None), X=array([[  2000.,   1000.,    828., ...,      0.,...3000.,    588., ...,      0.,      0.,      0.]]), y=array([  8.04915160e+07,   1.61937130e+07,   2.5...6938910e+07,   4.61227130e+07,   6.85820950e+07]), sample_weight=None, trim_duplicates=True)\\n    271         \"\"\"Build the y_ IsotonicRegression.\"\"\"\\n    272         check_consistent_length(X, y, sample_weight)\\n    273         X, y = [check_array(x, ensure_2d=False) for x in [X, y]]\\n    274 \\n    275         y = as_float_array(y)\\n--> 276         self._check_fit_data(X, y, sample_weight)\\n        self._check_fit_data = <bound method IsotonicRegression._check_fit_data..._bounds=\\'nan\\', y_max=None,\\n          y_min=None)>\\n        X = array([[  2000.,   1000.,    828., ...,      0.,...3000.,    588., ...,      0.,      0.,      0.]])\\n        y = array([  8.04915160e+07,   1.61937130e+07,   2.5...6938910e+07,   4.61227130e+07,   6.85820950e+07])\\n        sample_weight = None\\n    277 \\n    278         # Determine increasing if auto-determination requested\\n    279         if self.increasing == \\'auto\\':\\n    280             self.increasing_ = check_increasing(X, y)\\n\\n...........................................................................\\n/usr/local/lib/python3.4/dist-packages/sklearn/isotonic.py in _check_fit_data(self=IsotonicRegression(increasing=True, out_of_bounds=\\'nan\\', y_max=None,\\n          y_min=None), X=array([[  2000.,   1000.,    828., ...,      0.,...3000.,    588., ...,      0.,      0.,      0.]]), y=array([  8.04915160e+07,   1.61937130e+07,   2.5...6938910e+07,   4.61227130e+07,   6.85820950e+07]), sample_weight=None)\\n    246     def y_(self):\\n    247         del self._y_\\n    248 \\n    249     def _check_fit_data(self, X, y, sample_weight=None):\\n    250         if len(X.shape) != 1:\\n--> 251             raise ValueError(\"X should be a 1d array\")\\n    252 \\n    253     def _build_f(self, X, y):\\n    254         \"\"\"Build the f_ interp1d function.\"\"\"\\n    255 \\n\\nValueError: X should be a 1d array')}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
